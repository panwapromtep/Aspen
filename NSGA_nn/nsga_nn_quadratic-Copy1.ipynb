{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\programdata\\anaconda3\\lib\\site-packages (2.6.0)\n",
      "Requirement already satisfied: filelock in c:\\programdata\\anaconda3\\lib\\site-packages (from torch) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from torch) (4.13.1)\n",
      "Requirement already satisfied: networkx in c:\\programdata\\anaconda3\\lib\\site-packages (from torch) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\programdata\\anaconda3\\lib\\site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: fsspec in c:\\programdata\\anaconda3\\lib\\site-packages (from torch) (2023.4.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from jinja2->torch) (2.1.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: pymoo in c:\\programdata\\anaconda3\\lib\\site-packages (0.6.1.3)\n",
      "Requirement already satisfied: numpy>=1.15 in c:\\programdata\\anaconda3\\lib\\site-packages (from pymoo) (1.24.3)\n",
      "Requirement already satisfied: scipy>=1.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from pymoo) (1.11.1)\n",
      "Requirement already satisfied: matplotlib>=3 in c:\\programdata\\anaconda3\\lib\\site-packages (from pymoo) (3.7.2)\n",
      "Requirement already satisfied: autograd>=1.4 in c:\\programdata\\anaconda3\\lib\\site-packages (from pymoo) (1.7.0)\n",
      "Requirement already satisfied: cma==3.2.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from pymoo) (3.2.2)\n",
      "Requirement already satisfied: alive-progress in c:\\programdata\\anaconda3\\lib\\site-packages (from pymoo) (3.2.0)\n",
      "Requirement already satisfied: dill in c:\\programdata\\anaconda3\\lib\\site-packages (from pymoo) (0.3.6)\n",
      "Requirement already satisfied: Deprecated in c:\\programdata\\anaconda3\\lib\\site-packages (from pymoo) (1.2.18)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib>=3->pymoo) (1.0.5)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib>=3->pymoo) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib>=3->pymoo) (4.25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib>=3->pymoo) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib>=3->pymoo) (23.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib>=3->pymoo) (9.4.0)\n",
      "Requirement already satisfied: pyparsing<3.1,>=2.3.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib>=3->pymoo) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib>=3->pymoo) (2.8.2)\n",
      "Requirement already satisfied: about-time==4.2.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from alive-progress->pymoo) (4.2.1)\n",
      "Requirement already satisfied: grapheme==0.6.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from alive-progress->pymoo) (0.6.0)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in c:\\programdata\\anaconda3\\lib\\site-packages (from Deprecated->pymoo) (1.14.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7->matplotlib>=3->pymoo) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: pywin32 in c:\\programdata\\anaconda3\\lib\\site-packages (305.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install torch\n",
    "%pip install pymoo\n",
    "%pip install pywin32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added to sys.path: C:\\Users\\flin33\\OneDrive - Johns Hopkins\\ASPEN\\Aspen\n",
      "C:\\Users\\flin33\\OneDrive - Johns Hopkins\\ASPEN\\Aspen\n",
      "['C:\\\\Users\\\\flin33\\\\OneDrive - Johns Hopkins\\\\ASPEN\\\\Aspen\\\\NSGA_nn', 'C:\\\\ProgramData\\\\anaconda3\\\\python311.zip', 'C:\\\\ProgramData\\\\anaconda3\\\\DLLs', 'C:\\\\ProgramData\\\\anaconda3\\\\Lib', 'C:\\\\ProgramData\\\\anaconda3', '', 'C:\\\\ProgramData\\\\anaconda3\\\\Lib\\\\site-packages', 'C:\\\\ProgramData\\\\anaconda3\\\\Lib\\\\site-packages\\\\win32', 'C:\\\\ProgramData\\\\anaconda3\\\\Lib\\\\site-packages\\\\win32\\\\lib', 'C:\\\\ProgramData\\\\anaconda3\\\\Lib\\\\site-packages\\\\Pythonwin', 'C:\\\\Users\\\\flin33\\\\OneDrive - Johns Hopkins\\\\ASPEN\\\\Aspen', 'C:\\\\Users\\\\flin33\\\\OneDrive - Johns Hopkins\\\\ASPEN\\\\Aspen', 'C:\\\\Users\\\\flin33\\\\OneDrive - Johns Hopkins\\\\ASPEN\\\\Aspen']\n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "\n",
    "# Get the absolute path of the notebook's directory\n",
    "notebook_dir = os.getcwd()\n",
    "\n",
    "# Navigate to the parent directory\n",
    "parent_dir = os.path.abspath(os.path.join(notebook_dir, \"..\"))\n",
    "\n",
    "# Add the parent directory to sys.path so we can import modules\n",
    "sys.path.append(parent_dir)\n",
    "\n",
    "# Verify the path\n",
    "print(f\"Added to sys.path: {parent_dir}\")\n",
    "\n",
    "# Add it to sys.path\n",
    "sys.path.append(parent_dir)\n",
    "\n",
    "print(parent_dir)\n",
    "from localityaware.module import *\n",
    "from NSGA_nn.nsga import optimize_surr_nsga_1, optimize_surr_nsga_2\n",
    "from FlashOperation.Refrig2DrumHeatExConstr1 import Refrig2DrumConstraintHeatExConstr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating new data...\n",
      "The current Directory is :  \n",
      "C:\\Users\\flin33\\OneDrive - Johns Hopkins\\ASPEN\\Aspen\\NSGA_nn\n",
      "The new Directory where you should also have your Aspen file is : \n",
      "C:\\Users\\flin33\\OneDrive - Johns Hopkins\\ASPEN\\Aspen\\FlashOperation\n",
      "Aspen is active now. If you dont want to see aspen open again take VISIBITLY as False \n",
      "\n",
      "TEMPOUT: -65.0630049\n",
      "The cost is 0.00\n",
      "TEMPOUT: -65.3737009\n",
      "The cost is 0.00\n",
      "TEMPOUT: -63.4166894\n",
      "The cost is 0.00\n",
      "TEMPOUT: None\n",
      "The cost is 0.00\n",
      "TEMPOUT: None\n",
      "The cost is 0.00\n",
      "TEMPOUT: None\n",
      "The cost is 0.00\n",
      "TEMPOUT: None\n",
      "The cost is 0.00\n",
      "TEMPOUT: None\n",
      "The cost is 0.00\n",
      "TEMPOUT: None\n",
      "The cost is 0.00\n",
      "TEMPOUT: None\n",
      "The cost is 0.00\n",
      "TEMPOUT: -67.9285032\n",
      "The cost is 0.00\n",
      "TEMPOUT: None\n",
      "The cost is 0.00\n",
      "TEMPOUT: None\n",
      "The cost is 0.00\n",
      "TEMPOUT: -41.5834814\n",
      "The cost is 0.00\n",
      "TEMPOUT: -41.3230188\n",
      "The cost is 0.00\n",
      "TEMPOUT: -40.1724406\n",
      "The cost is 0.00\n",
      "TEMPOUT: -38.9136662\n",
      "The cost is 0.00\n",
      "TEMPOUT: -38.9107242\n",
      "The cost is 0.00\n",
      "TEMPOUT: -38.9782192\n",
      "The cost is 0.00\n",
      "TEMPOUT: -39.0446441\n",
      "The cost is 0.00\n",
      "TEMPOUT: -66.4023539\n",
      "The cost is 0.00\n",
      "TEMPOUT: -38.7941965\n",
      "The cost is 0.00\n",
      "TEMPOUT: -22.2938836\n",
      "The cost is 0.00\n",
      "TEMPOUT: -22.3331247\n",
      "The cost is 0.00\n",
      "TEMPOUT: -22.3737901\n",
      "The cost is 0.00\n",
      "TEMPOUT: -22.415005\n",
      "The cost is 0.00\n",
      "TEMPOUT: -22.4571661\n",
      "The cost is 0.00\n",
      "TEMPOUT: -22.5000798\n",
      "The cost is 0.00\n",
      "TEMPOUT: -22.5438114\n",
      "The cost is 0.00\n",
      "TEMPOUT: -22.5882775\n",
      "The cost is 0.00\n",
      "TEMPOUT: -66.1971742\n",
      "The cost is 0.00\n",
      "TEMPOUT: -38.5489557\n",
      "The cost is 0.00\n",
      "TEMPOUT: -22.2956412\n",
      "The cost is 0.00\n",
      "TEMPOUT: -10.4092616\n",
      "The cost is 0.00\n",
      "TEMPOUT: -10.4257563\n",
      "The cost is 0.00\n",
      "TEMPOUT: -10.4433426\n",
      "The cost is 0.00\n",
      "TEMPOUT: -10.4621208\n",
      "The cost is 0.00\n",
      "TEMPOUT: -10.4821631\n",
      "The cost is 0.00\n",
      "TEMPOUT: -10.5032081\n",
      "The cost is 0.00\n",
      "TEMPOUT: -10.5254703\n",
      "The cost is 0.00\n",
      "TEMPOUT: -66.4754827\n",
      "The cost is 0.00\n",
      "TEMPOUT: -38.7256162\n",
      "The cost is 0.00\n",
      "TEMPOUT: -22.2968264\n",
      "The cost is 0.00\n",
      "TEMPOUT: -10.4082155\n",
      "The cost is 0.00\n",
      "TEMPOUT: -0.814553801\n",
      "The cost is 0.00\n",
      "TEMPOUT: -0.807735676\n",
      "The cost is 0.00\n",
      "TEMPOUT: -0.80264624\n",
      "The cost is 0.00\n",
      "TEMPOUT: -0.799155768\n",
      "The cost is 0.00\n",
      "TEMPOUT: -0.797213337\n",
      "The cost is 0.00\n",
      "TEMPOUT: -0.796786328\n",
      "The cost is 0.00\n",
      "TEMPOUT: -66.8700687\n",
      "The cost is 0.00\n",
      "TEMPOUT: -38.5641046\n",
      "The cost is 0.00\n",
      "TEMPOUT: -22.2987386\n",
      "The cost is 0.00\n",
      "TEMPOUT: -10.4085093\n",
      "The cost is 0.00\n",
      "TEMPOUT: -0.813525753\n",
      "The cost is 0.00\n",
      "TEMPOUT: 7.33348791\n",
      "The cost is 0.00\n",
      "TEMPOUT: 7.36420233\n",
      "The cost is 0.00\n",
      "TEMPOUT: 7.39280917\n",
      "The cost is 0.00\n",
      "TEMPOUT: 7.41937203\n",
      "The cost is 0.00\n",
      "TEMPOUT: 7.44393792\n",
      "The cost is 0.00\n",
      "TEMPOUT: -66.76124\n",
      "The cost is 0.00\n",
      "TEMPOUT: -38.535802\n",
      "The cost is 0.00\n",
      "TEMPOUT: -22.2957282\n",
      "The cost is 0.00\n",
      "TEMPOUT: -10.4082512\n",
      "The cost is 0.00\n",
      "TEMPOUT: -0.813481748\n",
      "The cost is 0.00\n",
      "TEMPOUT: 7.33284983\n",
      "The cost is 0.00\n",
      "TEMPOUT: 14.4737903\n",
      "The cost is 0.00\n",
      "TEMPOUT: 14.5301432\n",
      "The cost is 0.00\n",
      "TEMPOUT: 14.5837083\n",
      "The cost is 0.00\n",
      "TEMPOUT: 14.6346007\n",
      "The cost is 0.00\n",
      "TEMPOUT: -66.7824625\n",
      "The cost is 0.00\n",
      "TEMPOUT: -38.5321759\n",
      "The cost is 0.00\n",
      "TEMPOUT: -22.2981851\n",
      "The cost is 0.00\n",
      "TEMPOUT: -10.4085357\n",
      "The cost is 0.00\n",
      "TEMPOUT: -0.815785919\n",
      "The cost is 0.00\n",
      "TEMPOUT: 7.333611\n",
      "The cost is 0.00\n",
      "TEMPOUT: 14.4738403\n",
      "The cost is 0.00\n",
      "TEMPOUT: 20.8684533\n",
      "The cost is 0.00\n",
      "TEMPOUT: 20.9518277\n",
      "The cost is 0.00\n",
      "TEMPOUT: 21.0318214\n",
      "The cost is 0.00\n",
      "TEMPOUT: -66.9985599\n",
      "The cost is 0.00\n",
      "TEMPOUT: -38.5939745\n",
      "The cost is 0.00\n",
      "TEMPOUT: -22.2932722\n",
      "The cost is 0.00\n",
      "TEMPOUT: -10.4086211\n",
      "The cost is 0.00\n",
      "TEMPOUT: -0.813150703\n",
      "The cost is 0.00\n",
      "TEMPOUT: 7.33287761\n",
      "The cost is 0.00\n",
      "TEMPOUT: 14.4731724\n",
      "The cost is 0.00\n",
      "TEMPOUT: 20.8675835\n",
      "The cost is 0.00\n",
      "TEMPOUT: 26.6853692\n",
      "The cost is 0.00\n",
      "TEMPOUT: 26.7976007\n",
      "The cost is 0.00\n",
      "TEMPOUT: -66.7835035\n",
      "The cost is 0.00\n",
      "TEMPOUT: -38.4998499\n",
      "The cost is 0.00\n",
      "TEMPOUT: -22.2929009\n",
      "The cost is 0.00\n",
      "TEMPOUT: -10.4082727\n",
      "The cost is 0.00\n",
      "TEMPOUT: -0.816418503\n",
      "The cost is 0.00\n",
      "TEMPOUT: 7.33363633\n",
      "The cost is 0.00\n",
      "TEMPOUT: 14.4725527\n",
      "The cost is 0.00\n",
      "TEMPOUT: 20.8671614\n",
      "The cost is 0.00\n",
      "TEMPOUT: 26.6857784\n",
      "The cost is 0.00\n",
      "TEMPOUT: 32.0380181\n",
      "The cost is 0.00\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "# Define the file path for saving/loading the data\n",
    "data_file = \"flash_simulation_data_sim_new.pkl\"\n",
    "\n",
    "# Define parameter ranges\n",
    "flash_1_range_sim = np.linspace(1, 20, 10)\n",
    "flash_2_range_sim = np.linspace(1, 20, 10)\n",
    "\n",
    "print(\"Generating new data...\")\n",
    "assSim = Refrig2DrumConstraintHeatExConstr(AspenFile=\"../FlashOperation/FlashOperation_HeatExchanger.bkp\",\n",
    "                                        wdpath=\"../FlashOperation\",\n",
    "                                        visibility=False,\n",
    "                                        Penalty=1e3)\n",
    "data_sim = []\n",
    "for flash_1 in flash_1_range_sim:\n",
    "    for flash_2 in flash_2_range_sim:\n",
    "        x_unflat = assSim.unflatten_params([float(flash_1), float(flash_2)])\n",
    "        data_sim.append([flash_1, flash_2, assSim.run_obj(x_unflat)])\n",
    "\n",
    "data_sim = np.array(data_sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.interpolate import griddata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_contour_surface(data, x_label, y_label, z_label, x_point=None, gradient=None):\n",
    "    \"\"\"\n",
    "    Generate a high-resolution heatmap with contour lines based on the given 3D data.\n",
    "    Optionally overlays a single point (x_point) and its gradient vector on the plot.\n",
    "    \"\"\"\n",
    "    # Convert data to numpy array for easier manipulation\n",
    "    data = np.array(data)\n",
    "    x, y, z = data[:, 0], data[:, 1], data[:, 2]\n",
    "\n",
    "    # Generate a finer grid for interpolation\n",
    "    grid_x, grid_y = np.meshgrid(\n",
    "        np.linspace(x.min(), x.max(), 200),\n",
    "        np.linspace(y.min(), y.max(), 200)\n",
    "    )\n",
    "    \n",
    "    # Interpolate z values using cubic interpolation\n",
    "    grid_z = griddata((x, y), z, (grid_x, grid_y), method='cubic')\n",
    "\n",
    "    # Create the heatmap and add contour lines\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.imshow(grid_z, extent=[x.min(), x.max(), y.min(), y.max()], origin='lower', cmap='viridis', aspect='auto')\n",
    "    plt.colorbar(label=z_label)\n",
    "\n",
    "    contour_levels = np.linspace(np.nanmin(grid_z), np.nanmax(grid_z), 15)\n",
    "    plt.contour(grid_x, grid_y, grid_z, levels=contour_levels, colors='black', linewidths=0.8)\n",
    "    \n",
    "    # Plot the true optimal point\n",
    "    true_optimal = np.array([-1.11, -0.5])\n",
    "    plt.scatter(true_optimal[0], true_optimal[1], color='blue', zorder=5)\n",
    "    plt.text(true_optimal[0], true_optimal[1], 'True Optimal', color='white', fontsize=10, ha='right')\n",
    "    \n",
    "    # Plot the local minimum points\n",
    "    local_minima = [np.array([0.84, -0.5]), np.array([0.27, -0.5])]\n",
    "    for lm in local_minima:\n",
    "        plt.scatter(lm[0], lm[1], color='orange', zorder=5)\n",
    "        plt.text(lm[0], lm[1], 'Local Min', color='orange', fontsize=10, ha='right')\n",
    "    \n",
    "    # Overlay the x point and gradient arrow if provided\n",
    "    if x_point is not None and gradient is not None:\n",
    "        # Convert the x and grad lists to NumPy arrays with float type\n",
    "        gradient = np.asarray(gradient, dtype=float) # grad is grad_pred.tolist() passed in\n",
    "        plt.quiver(\n",
    "            x_point[0], x_point[1],\n",
    "            gradient[0], gradient[1],\n",
    "            color='red', angles='xy', scale_units='xy', scale=0.1, zorder=10\n",
    "        )\n",
    "        plt.scatter(x_point[0], x_point[1], color='red', zorder=10)  # Mark the point\n",
    "        plt.text(x_point[0], x_point[1], 'x_point', color='red', fontsize=10, ha='left')\n",
    "    \n",
    "    plt.xlabel(x_label)\n",
    "    plt.ylabel(y_label)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract columns\n",
    "x, y, z = data_sim[:, 0], data_sim[:, 1], data_sim[:, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a finer grid for interpolation\n",
    "grid_x, grid_y = np.meshgrid(\n",
    "    np.linspace(x.min(), x.max(), 200),  # Increased resolution\n",
    "    np.linspace(y.min(), y.max(), 200)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interpolate z values using cubic interpolation\n",
    "grid_z = griddata((x, y), z, (grid_x, grid_y), method='cubic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create a high-resolution heatmap with contour lines\n",
    "# plt.figure(figsize=(8, 6))\n",
    "# plt.imshow(grid_z, extent=[x.min(), x.max(), y.min(), y.max()], origin='lower', cmap='viridis', aspect='auto')\n",
    "# plt.colorbar(label='Objective Value')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add contour lines\n",
    "# contour_levels = np.linspace(grid_z.min(), grid_z.max(), 15)  # Define contour levels\n",
    "# plt.contour(grid_x, grid_y, grid_z, levels=contour_levels, colors='black', linewidths=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Add labels and title\n",
    "# plt.xlabel('Flash 1')\n",
    "# plt.ylabel('Flash 2')\n",
    "# plt.title('Fine-Grained Heatmap with Contour Lines')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Show the plot\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "[[ 1.          1.          0.        ]\n",
      " [ 1.          3.11111111  0.        ]\n",
      " [ 1.          5.22222222  0.        ]\n",
      " [ 1.          7.33333333  0.        ]\n",
      " [ 1.          9.44444444  0.        ]\n",
      " [ 1.         11.55555556  0.        ]\n",
      " [ 1.         13.66666667  0.        ]\n",
      " [ 1.         15.77777778  0.        ]\n",
      " [ 1.         17.88888889  0.        ]\n",
      " [ 1.         20.          0.        ]\n",
      " [ 3.11111111  1.          0.        ]\n",
      " [ 3.11111111  3.11111111  0.        ]\n",
      " [ 3.11111111  5.22222222  0.        ]\n",
      " [ 3.11111111  7.33333333  0.        ]\n",
      " [ 3.11111111  9.44444444  0.        ]\n",
      " [ 3.11111111 11.55555556  0.        ]\n",
      " [ 3.11111111 13.66666667  0.        ]\n",
      " [ 3.11111111 15.77777778  0.        ]\n",
      " [ 3.11111111 17.88888889  0.        ]\n",
      " [ 3.11111111 20.          0.        ]\n",
      " [ 5.22222222  1.          0.        ]\n",
      " [ 5.22222222  3.11111111  0.        ]\n",
      " [ 5.22222222  5.22222222  0.        ]\n",
      " [ 5.22222222  7.33333333  0.        ]\n",
      " [ 5.22222222  9.44444444  0.        ]\n",
      " [ 5.22222222 11.55555556  0.        ]\n",
      " [ 5.22222222 13.66666667  0.        ]\n",
      " [ 5.22222222 15.77777778  0.        ]\n",
      " [ 5.22222222 17.88888889  0.        ]\n",
      " [ 5.22222222 20.          0.        ]\n",
      " [ 7.33333333  1.          0.        ]\n",
      " [ 7.33333333  3.11111111  0.        ]\n",
      " [ 7.33333333  5.22222222  0.        ]\n",
      " [ 7.33333333  7.33333333  0.        ]\n",
      " [ 7.33333333  9.44444444  0.        ]\n",
      " [ 7.33333333 11.55555556  0.        ]\n",
      " [ 7.33333333 13.66666667  0.        ]\n",
      " [ 7.33333333 15.77777778  0.        ]\n",
      " [ 7.33333333 17.88888889  0.        ]\n",
      " [ 7.33333333 20.          0.        ]\n",
      " [ 9.44444444  1.          0.        ]\n",
      " [ 9.44444444  3.11111111  0.        ]\n",
      " [ 9.44444444  5.22222222  0.        ]\n",
      " [ 9.44444444  7.33333333  0.        ]\n",
      " [ 9.44444444  9.44444444  0.        ]\n",
      " [ 9.44444444 11.55555556  0.        ]\n",
      " [ 9.44444444 13.66666667  0.        ]\n",
      " [ 9.44444444 15.77777778  0.        ]\n",
      " [ 9.44444444 17.88888889  0.        ]\n",
      " [ 9.44444444 20.          0.        ]\n",
      " [11.55555556  1.          0.        ]\n",
      " [11.55555556  3.11111111  0.        ]\n",
      " [11.55555556  5.22222222  0.        ]\n",
      " [11.55555556  7.33333333  0.        ]\n",
      " [11.55555556  9.44444444  0.        ]\n",
      " [11.55555556 11.55555556  0.        ]\n",
      " [11.55555556 13.66666667  0.        ]\n",
      " [11.55555556 15.77777778  0.        ]\n",
      " [11.55555556 17.88888889  0.        ]\n",
      " [11.55555556 20.          0.        ]\n",
      " [13.66666667  1.          0.        ]\n",
      " [13.66666667  3.11111111  0.        ]\n",
      " [13.66666667  5.22222222  0.        ]\n",
      " [13.66666667  7.33333333  0.        ]\n",
      " [13.66666667  9.44444444  0.        ]\n",
      " [13.66666667 11.55555556  0.        ]\n",
      " [13.66666667 13.66666667  0.        ]\n",
      " [13.66666667 15.77777778  0.        ]\n",
      " [13.66666667 17.88888889  0.        ]\n",
      " [13.66666667 20.          0.        ]\n",
      " [15.77777778  1.          0.        ]\n",
      " [15.77777778  3.11111111  0.        ]\n",
      " [15.77777778  5.22222222  0.        ]\n",
      " [15.77777778  7.33333333  0.        ]\n",
      " [15.77777778  9.44444444  0.        ]\n",
      " [15.77777778 11.55555556  0.        ]\n",
      " [15.77777778 13.66666667  0.        ]\n",
      " [15.77777778 15.77777778  0.        ]\n",
      " [15.77777778 17.88888889  0.        ]\n",
      " [15.77777778 20.          0.        ]\n",
      " [17.88888889  1.          0.        ]\n",
      " [17.88888889  3.11111111  0.        ]\n",
      " [17.88888889  5.22222222  0.        ]\n",
      " [17.88888889  7.33333333  0.        ]\n",
      " [17.88888889  9.44444444  0.        ]\n",
      " [17.88888889 11.55555556  0.        ]\n",
      " [17.88888889 13.66666667  0.        ]\n",
      " [17.88888889 15.77777778  0.        ]\n",
      " [17.88888889 17.88888889  0.        ]\n",
      " [17.88888889 20.          0.        ]\n",
      " [20.          1.          0.        ]\n",
      " [20.          3.11111111  0.        ]\n",
      " [20.          5.22222222  0.        ]\n",
      " [20.          7.33333333  0.        ]\n",
      " [20.          9.44444444  0.        ]\n",
      " [20.         11.55555556  0.        ]\n",
      " [20.         13.66666667  0.        ]\n",
      " [20.         15.77777778  0.        ]\n",
      " [20.         17.88888889  0.        ]\n",
      " [20.         20.          0.        ]]\n",
      "[[-1.         -1.         -1.        ]\n",
      " [-1.         -0.7777778  -1.        ]\n",
      " [-1.         -0.5555556  -1.        ]\n",
      " [-1.         -0.3333333  -1.        ]\n",
      " [-1.         -0.1111111  -1.        ]\n",
      " [-1.          0.11111104 -1.        ]\n",
      " [-1.          0.33333337 -1.        ]\n",
      " [-1.          0.5555556  -1.        ]\n",
      " [-1.          0.7777778  -1.        ]\n",
      " [-1.          1.         -1.        ]\n",
      " [-0.7777778  -1.         -1.        ]\n",
      " [-0.7777778  -0.7777778  -1.        ]\n",
      " [-0.7777778  -0.5555556  -1.        ]\n",
      " [-0.7777778  -0.3333333  -1.        ]\n",
      " [-0.7777778  -0.1111111  -1.        ]\n",
      " [-0.7777778   0.11111104 -1.        ]\n",
      " [-0.7777778   0.33333337 -1.        ]\n",
      " [-0.7777778   0.5555556  -1.        ]\n",
      " [-0.7777778   0.7777778  -1.        ]\n",
      " [-0.7777778   1.         -1.        ]\n",
      " [-0.5555556  -1.         -1.        ]\n",
      " [-0.5555556  -0.7777778  -1.        ]\n",
      " [-0.5555556  -0.5555556  -1.        ]\n",
      " [-0.5555556  -0.3333333  -1.        ]\n",
      " [-0.5555556  -0.1111111  -1.        ]\n",
      " [-0.5555556   0.11111104 -1.        ]\n",
      " [-0.5555556   0.33333337 -1.        ]\n",
      " [-0.5555556   0.5555556  -1.        ]\n",
      " [-0.5555556   0.7777778  -1.        ]\n",
      " [-0.5555556   1.         -1.        ]\n",
      " [-0.3333333  -1.         -1.        ]\n",
      " [-0.3333333  -0.7777778  -1.        ]\n",
      " [-0.3333333  -0.5555556  -1.        ]\n",
      " [-0.3333333  -0.3333333  -1.        ]\n",
      " [-0.3333333  -0.1111111  -1.        ]\n",
      " [-0.3333333   0.11111104 -1.        ]\n",
      " [-0.3333333   0.33333337 -1.        ]\n",
      " [-0.3333333   0.5555556  -1.        ]\n",
      " [-0.3333333   0.7777778  -1.        ]\n",
      " [-0.3333333   1.         -1.        ]\n",
      " [-0.1111111  -1.         -1.        ]\n",
      " [-0.1111111  -0.7777778  -1.        ]\n",
      " [-0.1111111  -0.5555556  -1.        ]\n",
      " [-0.1111111  -0.3333333  -1.        ]\n",
      " [-0.1111111  -0.1111111  -1.        ]\n",
      " [-0.1111111   0.11111104 -1.        ]\n",
      " [-0.1111111   0.33333337 -1.        ]\n",
      " [-0.1111111   0.5555556  -1.        ]\n",
      " [-0.1111111   0.7777778  -1.        ]\n",
      " [-0.1111111   1.         -1.        ]\n",
      " [ 0.11111104 -1.         -1.        ]\n",
      " [ 0.11111104 -0.7777778  -1.        ]\n",
      " [ 0.11111104 -0.5555556  -1.        ]\n",
      " [ 0.11111104 -0.3333333  -1.        ]\n",
      " [ 0.11111104 -0.1111111  -1.        ]\n",
      " [ 0.11111104  0.11111104 -1.        ]\n",
      " [ 0.11111104  0.33333337 -1.        ]\n",
      " [ 0.11111104  0.5555556  -1.        ]\n",
      " [ 0.11111104  0.7777778  -1.        ]\n",
      " [ 0.11111104  1.         -1.        ]\n",
      " [ 0.33333337 -1.         -1.        ]\n",
      " [ 0.33333337 -0.7777778  -1.        ]\n",
      " [ 0.33333337 -0.5555556  -1.        ]\n",
      " [ 0.33333337 -0.3333333  -1.        ]\n",
      " [ 0.33333337 -0.1111111  -1.        ]\n",
      " [ 0.33333337  0.11111104 -1.        ]\n",
      " [ 0.33333337  0.33333337 -1.        ]\n",
      " [ 0.33333337  0.5555556  -1.        ]\n",
      " [ 0.33333337  0.7777778  -1.        ]\n",
      " [ 0.33333337  1.         -1.        ]\n",
      " [ 0.5555556  -1.         -1.        ]\n",
      " [ 0.5555556  -0.7777778  -1.        ]\n",
      " [ 0.5555556  -0.5555556  -1.        ]\n",
      " [ 0.5555556  -0.3333333  -1.        ]\n",
      " [ 0.5555556  -0.1111111  -1.        ]\n",
      " [ 0.5555556   0.11111104 -1.        ]\n",
      " [ 0.5555556   0.33333337 -1.        ]\n",
      " [ 0.5555556   0.5555556  -1.        ]\n",
      " [ 0.5555556   0.7777778  -1.        ]\n",
      " [ 0.5555556   1.         -1.        ]\n",
      " [ 0.7777778  -1.         -1.        ]\n",
      " [ 0.7777778  -0.7777778  -1.        ]\n",
      " [ 0.7777778  -0.5555556  -1.        ]\n",
      " [ 0.7777778  -0.3333333  -1.        ]\n",
      " [ 0.7777778  -0.1111111  -1.        ]\n",
      " [ 0.7777778   0.11111104 -1.        ]\n",
      " [ 0.7777778   0.33333337 -1.        ]\n",
      " [ 0.7777778   0.5555556  -1.        ]\n",
      " [ 0.7777778   0.7777778  -1.        ]\n",
      " [ 0.7777778   1.         -1.        ]\n",
      " [ 1.         -1.         -1.        ]\n",
      " [ 1.         -0.7777778  -1.        ]\n",
      " [ 1.         -0.5555556  -1.        ]\n",
      " [ 1.         -0.3333333  -1.        ]\n",
      " [ 1.         -0.1111111  -1.        ]\n",
      " [ 1.          0.11111104 -1.        ]\n",
      " [ 1.          0.33333337 -1.        ]\n",
      " [ 1.          0.5555556  -1.        ]\n",
      " [ 1.          0.7777778  -1.        ]\n",
      " [ 1.          1.         -1.        ]]\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class Dataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = self.data[idx, :-1]  # all but last column = input\n",
    "        y = self.data[idx, -1]   # last column = output\n",
    "        return x, y\n",
    "\n",
    "    def merge(self, new_data):\n",
    "        self.data = np.vstack([self.data, new_data])\n",
    "\n",
    "    def clear(self):\n",
    "        self.data = np.empty((0, self.data.shape[1]))\n",
    "        \n",
    "print(len(data_sim))\n",
    "print((data_sim))\n",
    "data_sim = np.array(data_sim)\n",
    "x_data = data_sim[:, :2]\n",
    "y_data = data_sim[:, 2]\n",
    "\n",
    "x_min = x_data.min(axis=0)\n",
    "x_max = x_data.max(axis=0)\n",
    "\n",
    "\n",
    "scaler = TorchMinMaxScaler((-1, 1), \n",
    "                           max_vals=x_max,\n",
    "                           min_vals=x_min,\n",
    "                           min_y=0,\n",
    "                           max_y=1e6 ,\n",
    "                           scale_y=True)\n",
    "#scale data_sim \n",
    "data_sim_xscaled, data_sim_yscaled = scaler.transform(data_sim[:, :2], data_sim[:, 2])\n",
    "\n",
    "#recombine the data\n",
    "data_sim_scaled = np.column_stack([data_sim_xscaled, data_sim_yscaled])\n",
    "print(data_sim_scaled)\n",
    "\n",
    "# **Initialize Model & Datasets**\n",
    "dataset = Dataset(data_sim_scaled)\n",
    "model = MLP(2, [20,20,20,20,20], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0: Training surrogate model...\n",
      "device cpu\n",
      "Epoch 0: Total Loss=0.9974\n",
      "Epoch 10: Total Loss=0.9895\n",
      "Epoch 20: Total Loss=0.9818\n",
      "Epoch 30: Total Loss=0.9740\n",
      "Epoch 40: Total Loss=0.9663\n",
      "Epoch 50: Total Loss=0.9584\n",
      "Epoch 60: Total Loss=0.9503\n",
      "Epoch 70: Total Loss=0.9420\n",
      "Epoch 80: Total Loss=0.9333\n",
      "Epoch 90: Total Loss=0.9243\n",
      "Epoch 100: Total Loss=0.9148\n",
      "Epoch 110: Total Loss=0.9049\n",
      "Epoch 120: Total Loss=0.8944\n",
      "Epoch 130: Total Loss=0.8834\n",
      "Epoch 140: Total Loss=0.8717\n",
      "Epoch 150: Total Loss=0.8594\n",
      "Epoch 160: Total Loss=0.8463\n",
      "Epoch 170: Total Loss=0.8325\n",
      "Epoch 180: Total Loss=0.8177\n",
      "Epoch 190: Total Loss=0.8021\n",
      "Epoch 200: Total Loss=0.7856\n",
      "Epoch 210: Total Loss=0.7679\n",
      "Epoch 220: Total Loss=0.7493\n",
      "Epoch 230: Total Loss=0.7295\n",
      "Epoch 240: Total Loss=0.7084\n",
      "Epoch 250: Total Loss=0.6862\n",
      "Epoch 260: Total Loss=0.6627\n",
      "Epoch 270: Total Loss=0.6378\n",
      "Epoch 280: Total Loss=0.6116\n",
      "Epoch 290: Total Loss=0.5840\n",
      "Epoch 300: Total Loss=0.5551\n",
      "Epoch 310: Total Loss=0.5249\n",
      "Epoch 320: Total Loss=0.4935\n",
      "Epoch 330: Total Loss=0.4611\n",
      "Epoch 340: Total Loss=0.4278\n",
      "Epoch 350: Total Loss=0.3938\n",
      "Epoch 360: Total Loss=0.3596\n",
      "Epoch 370: Total Loss=0.3254\n",
      "Epoch 380: Total Loss=0.2916\n",
      "Epoch 390: Total Loss=0.2588\n",
      "Epoch 400: Total Loss=0.2274\n",
      "Epoch 410: Total Loss=0.1981\n",
      "Epoch 420: Total Loss=0.1713\n",
      "Epoch 430: Total Loss=0.1475\n",
      "Epoch 440: Total Loss=0.1271\n",
      "Epoch 450: Total Loss=0.1102\n",
      "Epoch 460: Total Loss=0.0967\n",
      "Epoch 470: Total Loss=0.0862\n",
      "Epoch 480: Total Loss=0.0783\n",
      "Epoch 490: Total Loss=0.0724\n",
      "Epoch 500: Total Loss=0.0677\n",
      "Epoch 510: Total Loss=0.0640\n",
      "Epoch 520: Total Loss=0.0609\n",
      "Epoch 530: Total Loss=0.0581\n",
      "Epoch 540: Total Loss=0.0555\n",
      "Epoch 550: Total Loss=0.0531\n",
      "Epoch 560: Total Loss=0.0508\n",
      "Epoch 570: Total Loss=0.0486\n",
      "Epoch 580: Total Loss=0.0465\n",
      "Epoch 590: Total Loss=0.0445\n",
      "Epoch 600: Total Loss=0.0426\n",
      "Epoch 610: Total Loss=0.0408\n",
      "Epoch 620: Total Loss=0.0391\n",
      "Epoch 630: Total Loss=0.0374\n",
      "Epoch 640: Total Loss=0.0358\n",
      "Epoch 650: Total Loss=0.0342\n",
      "Epoch 660: Total Loss=0.0328\n",
      "Epoch 670: Total Loss=0.0313\n",
      "Epoch 680: Total Loss=0.0300\n",
      "Epoch 690: Total Loss=0.0287\n",
      "Epoch 700: Total Loss=0.0274\n",
      "Epoch 710: Total Loss=0.0262\n",
      "Epoch 720: Total Loss=0.0250\n",
      "Epoch 730: Total Loss=0.0239\n",
      "Epoch 740: Total Loss=0.0229\n",
      "Epoch 750: Total Loss=0.0218\n",
      "Epoch 760: Total Loss=0.0208\n",
      "Epoch 770: Total Loss=0.0199\n",
      "Epoch 780: Total Loss=0.0190\n",
      "Epoch 790: Total Loss=0.0181\n",
      "Epoch 800: Total Loss=0.0173\n",
      "Epoch 810: Total Loss=0.0165\n",
      "Epoch 820: Total Loss=0.0157\n",
      "Epoch 830: Total Loss=0.0150\n",
      "Epoch 840: Total Loss=0.0143\n",
      "Epoch 850: Total Loss=0.0136\n",
      "Epoch 860: Total Loss=0.0130\n",
      "Epoch 870: Total Loss=0.0124\n",
      "Epoch 880: Total Loss=0.0118\n",
      "Epoch 890: Total Loss=0.0112\n",
      "Epoch 900: Total Loss=0.0107\n",
      "Epoch 910: Total Loss=0.0102\n",
      "Epoch 920: Total Loss=0.0097\n",
      "Epoch 930: Total Loss=0.0092\n",
      "Epoch 940: Total Loss=0.0088\n",
      "Epoch 950: Total Loss=0.0084\n",
      "Epoch 960: Total Loss=0.0080\n",
      "Epoch 970: Total Loss=0.0076\n",
      "Epoch 980: Total Loss=0.0072\n",
      "Epoch 990: Total Loss=0.0069\n",
      "=================================================\n",
      "n_gen  |  n_eval  |     f_avg     |     f_min    \n",
      "=================================================\n",
      "     1 |      100 | -9.626458E-01 | -1.087158E+00\n",
      "     2 |      200 | -1.039215E+00 | -1.093112E+00\n",
      "     3 |      300 | -1.061790E+00 | -1.096780E+00\n",
      "TEMPOUT: -56.6087756\n",
      "The cost is 0.00\n",
      "TEMPOUT: -56.6087756\n",
      "The cost is 0.00\n",
      "TEMPOUT: -59.6273384\n",
      "The cost is 0.00\n",
      "TEMPOUT: -59.2457423\n",
      "The cost is 0.00\n",
      "TEMPOUT: -59.3295951\n",
      "The cost is 0.00\n",
      "TEMPOUT: -59.3911893\n",
      "The cost is 0.00\n",
      "TEMPOUT: -62.7125645\n",
      "The cost is 0.00\n",
      "TEMPOUT: -54.1324865\n",
      "The cost is 0.00\n",
      "TEMPOUT: -51.8908448\n",
      "The cost is 0.00\n",
      "TEMPOUT: 30.5492136\n",
      "The cost is 0.00\n",
      "TEMPOUT: -66.3970809\n",
      "The cost is 0.00\n",
      "TEMPOUT: -66.7209622\n",
      "The cost is 0.00\n",
      "TEMPOUT: -63.9643558\n",
      "The cost is 0.00\n",
      "TEMPOUT: -51.3294151\n",
      "The cost is 0.00\n",
      "TEMPOUT: 30.1141092\n",
      "The cost is 0.00\n",
      "TEMPOUT: -40.950716\n",
      "The cost is 0.00\n",
      "TEMPOUT: -39.3307692\n",
      "The cost is 0.00\n",
      "TEMPOUT: 28.8515337\n",
      "The cost is 0.00\n",
      "TEMPOUT: -42.0537859\n",
      "The cost is 0.00\n",
      "TEMPOUT: -53.6656423\n",
      "The cost is 0.00\n",
      "TEMPOUT: -37.6704241\n",
      "The cost is 0.00\n",
      "Iteration 0: Optimal input [ 1.5717764 19.858097 ], output 0, dataset size (121, 3)\n",
      "Iteration 1: Training surrogate model...\n",
      "device cpu\n",
      "Epoch 0: Total Loss=0.0066\n",
      "Epoch 10: Total Loss=0.0051\n",
      "Epoch 20: Total Loss=0.0040\n",
      "Epoch 30: Total Loss=0.0032\n",
      "Epoch 40: Total Loss=0.0025\n",
      "Epoch 50: Total Loss=0.0020\n",
      "Epoch 60: Total Loss=0.0016\n",
      "Epoch 70: Total Loss=0.0014\n",
      "Epoch 80: Total Loss=0.0012\n",
      "Epoch 90: Total Loss=0.0010\n",
      "Epoch 100: Total Loss=0.0009\n",
      "Epoch 110: Total Loss=0.0008\n",
      "Epoch 120: Total Loss=0.0008\n",
      "Epoch 130: Total Loss=0.0007\n",
      "Epoch 140: Total Loss=0.0007\n",
      "Epoch 150: Total Loss=0.0006\n",
      "Epoch 160: Total Loss=0.0006\n",
      "Epoch 170: Total Loss=0.0006\n",
      "Epoch 180: Total Loss=0.0005\n",
      "Epoch 190: Total Loss=0.0005\n",
      "Epoch 200: Total Loss=0.0005\n",
      "Epoch 210: Total Loss=0.0004\n",
      "Epoch 220: Total Loss=0.0004\n",
      "Epoch 230: Total Loss=0.0004\n",
      "Epoch 240: Total Loss=0.0004\n",
      "Epoch 250: Total Loss=0.0003\n",
      "Epoch 260: Total Loss=0.0003\n",
      "Epoch 270: Total Loss=0.0003\n",
      "Epoch 280: Total Loss=0.0003\n",
      "Epoch 290: Total Loss=0.0003\n",
      "Epoch 300: Total Loss=0.0003\n",
      "Epoch 310: Total Loss=0.0002\n",
      "Epoch 320: Total Loss=0.0002\n",
      "Epoch 330: Total Loss=0.0002\n",
      "Epoch 340: Total Loss=0.0002\n",
      "Epoch 350: Total Loss=0.0002\n",
      "Epoch 360: Total Loss=0.0002\n",
      "Epoch 370: Total Loss=0.0002\n",
      "Epoch 380: Total Loss=0.0002\n",
      "Epoch 390: Total Loss=0.0002\n",
      "Epoch 400: Total Loss=0.0001\n",
      "Epoch 410: Total Loss=0.0001\n",
      "Epoch 420: Total Loss=0.0001\n",
      "Epoch 430: Total Loss=0.0001\n",
      "Epoch 440: Total Loss=0.0001\n",
      "Epoch 450: Total Loss=0.0001\n",
      "Epoch 460: Total Loss=0.0001\n",
      "Epoch 470: Total Loss=0.0001\n",
      "Epoch 480: Total Loss=0.0001\n",
      "Epoch 490: Total Loss=0.0001\n",
      "Epoch 500: Total Loss=0.0001\n",
      "Epoch 510: Total Loss=0.0001\n",
      "Epoch 520: Total Loss=0.0001\n",
      "Epoch 530: Total Loss=0.0001\n",
      "Epoch 540: Total Loss=0.0001\n",
      "Epoch 550: Total Loss=0.0001\n",
      "Epoch 560: Total Loss=0.0001\n",
      "Epoch 570: Total Loss=0.0001\n",
      "Epoch 580: Total Loss=0.0001\n",
      "Epoch 590: Total Loss=0.0001\n",
      "Epoch 600: Total Loss=0.0001\n",
      "Epoch 610: Total Loss=0.0001\n",
      "Epoch 620: Total Loss=0.0001\n",
      "Epoch 630: Total Loss=0.0001\n",
      "Epoch 640: Total Loss=0.0001\n",
      "Epoch 650: Total Loss=0.0001\n",
      "Epoch 660: Total Loss=0.0001\n",
      "Epoch 670: Total Loss=0.0001\n",
      "Epoch 680: Total Loss=0.0001\n",
      "Epoch 690: Total Loss=0.0001\n",
      "Epoch 700: Total Loss=0.0001\n",
      "Epoch 710: Total Loss=0.0001\n",
      "Epoch 720: Total Loss=0.0000\n",
      "Epoch 730: Total Loss=0.0000\n",
      "Epoch 740: Total Loss=0.0000\n",
      "Epoch 750: Total Loss=0.0000\n",
      "Epoch 760: Total Loss=0.0000\n",
      "Epoch 770: Total Loss=0.0000\n",
      "Epoch 780: Total Loss=0.0000\n",
      "Epoch 790: Total Loss=0.0000\n",
      "Epoch 800: Total Loss=0.0000\n",
      "Epoch 810: Total Loss=0.0000\n",
      "Epoch 820: Total Loss=0.0000\n",
      "Epoch 830: Total Loss=0.0000\n",
      "Epoch 840: Total Loss=0.0000\n",
      "Epoch 850: Total Loss=0.0000\n",
      "Epoch 860: Total Loss=0.0000\n",
      "Epoch 870: Total Loss=0.0000\n",
      "Epoch 880: Total Loss=0.0000\n",
      "Epoch 890: Total Loss=0.0000\n",
      "Epoch 900: Total Loss=0.0000\n",
      "Epoch 910: Total Loss=0.0000\n",
      "Epoch 920: Total Loss=0.0000\n",
      "Epoch 930: Total Loss=0.0000\n",
      "Epoch 940: Total Loss=0.0000\n",
      "Epoch 950: Total Loss=0.0000\n",
      "Epoch 960: Total Loss=0.0000\n",
      "Epoch 970: Total Loss=0.0000\n",
      "Epoch 980: Total Loss=0.0000\n",
      "Epoch 990: Total Loss=0.0000\n",
      "Using previous population of size 100\n",
      "=================================================\n",
      "n_gen  |  n_eval  |     f_avg     |     f_min    \n",
      "=================================================\n",
      "     1 |      100 | -9.958106E-01 | -1.006413E+00\n",
      "     2 |      200 | -9.999167E-01 | -1.008225E+00\n",
      "     3 |      300 | -1.002547E+00 | -1.008225E+00\n",
      "TEMPOUT: -64.3746147\n",
      "The cost is 0.00\n",
      "TEMPOUT: -64.3746147\n",
      "The cost is 0.00\n",
      "TEMPOUT: -64.2220995\n",
      "The cost is 0.00\n",
      "TEMPOUT: -59.3738628\n",
      "The cost is 0.00\n",
      "TEMPOUT: -59.1183335\n",
      "The cost is 0.00\n",
      "TEMPOUT: -62.1750587\n",
      "The cost is 0.00\n",
      "TEMPOUT: None\n",
      "The cost is 0.00\n",
      "TEMPOUT: None\n",
      "The cost is 0.00\n",
      "TEMPOUT: None\n",
      "The cost is 0.00\n",
      "TEMPOUT: None\n",
      "The cost is 0.00\n",
      "TEMPOUT: None\n",
      "The cost is 0.00\n",
      "TEMPOUT: -47.4979019\n",
      "The cost is 0.00\n",
      "TEMPOUT: -45.9991331\n",
      "The cost is 0.00\n",
      "TEMPOUT: -46.0544626\n",
      "The cost is 0.00\n",
      "TEMPOUT: -67.1869857\n",
      "The cost is 0.00\n",
      "TEMPOUT: -67.1142429\n",
      "The cost is 0.00\n",
      "TEMPOUT: -67.0956046\n",
      "The cost is 0.00\n",
      "TEMPOUT: -57.8924481\n",
      "The cost is 0.00\n",
      "TEMPOUT: -67.3360316\n",
      "The cost is 0.00\n",
      "TEMPOUT: -26.537958\n",
      "The cost is 0.00\n",
      "TEMPOUT: -65.7723324\n",
      "The cost is 0.00\n",
      "Iteration 1: Optimal input [1.5198976 1.0368308], output 0, dataset size (142, 3)\n",
      "Iteration 2: Training surrogate model...\n",
      "device cpu\n",
      "Epoch 0: Total Loss=0.0000\n",
      "Epoch 10: Total Loss=0.0000\n",
      "Epoch 20: Total Loss=0.0000\n",
      "Epoch 30: Total Loss=0.0000\n",
      "Epoch 40: Total Loss=0.0000\n",
      "Epoch 50: Total Loss=0.0000\n",
      "Epoch 60: Total Loss=0.0000\n",
      "Epoch 70: Total Loss=0.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80: Total Loss=0.0000\n",
      "Epoch 90: Total Loss=0.0000\n",
      "Epoch 100: Total Loss=0.0000\n",
      "Epoch 110: Total Loss=0.0000\n",
      "Epoch 120: Total Loss=0.0000\n",
      "Epoch 130: Total Loss=0.0000\n",
      "Epoch 140: Total Loss=0.0000\n",
      "Epoch 150: Total Loss=0.0000\n",
      "Epoch 160: Total Loss=0.0000\n",
      "Epoch 170: Total Loss=0.0000\n",
      "Epoch 180: Total Loss=0.0000\n",
      "Epoch 190: Total Loss=0.0000\n",
      "Epoch 200: Total Loss=0.0000\n",
      "Epoch 210: Total Loss=0.0000\n",
      "Epoch 220: Total Loss=0.0000\n",
      "Epoch 230: Total Loss=0.0000\n",
      "Epoch 240: Total Loss=0.0000\n",
      "Epoch 250: Total Loss=0.0000\n",
      "Epoch 260: Total Loss=0.0000\n",
      "Epoch 270: Total Loss=0.0000\n",
      "Epoch 280: Total Loss=0.0000\n",
      "Epoch 290: Total Loss=0.0000\n",
      "Epoch 300: Total Loss=0.0000\n",
      "Epoch 310: Total Loss=0.0000\n",
      "Epoch 320: Total Loss=0.0000\n",
      "Epoch 330: Total Loss=0.0000\n",
      "Epoch 340: Total Loss=0.0000\n",
      "Epoch 350: Total Loss=0.0000\n",
      "Epoch 360: Total Loss=0.0000\n",
      "Epoch 370: Total Loss=0.0000\n",
      "Epoch 380: Total Loss=0.0000\n",
      "Epoch 390: Total Loss=0.0000\n",
      "Epoch 400: Total Loss=0.0000\n",
      "Epoch 410: Total Loss=0.0000\n",
      "Epoch 420: Total Loss=0.0000\n",
      "Epoch 430: Total Loss=0.0000\n",
      "Epoch 440: Total Loss=0.0000\n",
      "Epoch 450: Total Loss=0.0000\n",
      "Epoch 460: Total Loss=0.0000\n",
      "Epoch 470: Total Loss=0.0000\n",
      "Epoch 480: Total Loss=0.0000\n",
      "Epoch 490: Total Loss=0.0000\n",
      "Epoch 500: Total Loss=0.0000\n",
      "Epoch 510: Total Loss=0.0000\n",
      "Epoch 520: Total Loss=0.0000\n",
      "Epoch 530: Total Loss=0.0000\n",
      "Epoch 540: Total Loss=0.0000\n",
      "Epoch 550: Total Loss=0.0000\n",
      "Epoch 560: Total Loss=0.0000\n",
      "Epoch 570: Total Loss=0.0000\n",
      "Epoch 580: Total Loss=0.0000\n",
      "Epoch 590: Total Loss=0.0000\n",
      "Epoch 600: Total Loss=0.0000\n",
      "Epoch 610: Total Loss=0.0000\n",
      "Epoch 620: Total Loss=0.0000\n",
      "Epoch 630: Total Loss=0.0000\n",
      "Epoch 640: Total Loss=0.0000\n",
      "Epoch 650: Total Loss=0.0000\n",
      "Epoch 660: Total Loss=0.0000\n",
      "Epoch 670: Total Loss=0.0000\n",
      "Epoch 680: Total Loss=0.0000\n",
      "Epoch 690: Total Loss=0.0000\n",
      "Epoch 700: Total Loss=0.0000\n",
      "Epoch 710: Total Loss=0.0000\n",
      "Epoch 720: Total Loss=0.0000\n",
      "Epoch 730: Total Loss=0.0000\n",
      "Epoch 740: Total Loss=0.0000\n",
      "Epoch 750: Total Loss=0.0000\n",
      "Epoch 760: Total Loss=0.0000\n",
      "Epoch 770: Total Loss=0.0000\n",
      "Epoch 780: Total Loss=0.0000\n",
      "Epoch 790: Total Loss=0.0000\n",
      "Epoch 800: Total Loss=0.0000\n",
      "Epoch 810: Total Loss=0.0000\n",
      "Epoch 820: Total Loss=0.0000\n",
      "Epoch 830: Total Loss=0.0000\n",
      "Epoch 840: Total Loss=0.0000\n",
      "Epoch 850: Total Loss=0.0000\n",
      "Epoch 860: Total Loss=0.0000\n",
      "Epoch 870: Total Loss=0.0000\n",
      "Epoch 880: Total Loss=0.0000\n",
      "Epoch 890: Total Loss=0.0000\n",
      "Epoch 900: Total Loss=0.0000\n",
      "Epoch 910: Total Loss=0.0000\n",
      "Epoch 920: Total Loss=0.0000\n",
      "Epoch 930: Total Loss=0.0000\n",
      "Epoch 940: Total Loss=0.0000\n",
      "Epoch 950: Total Loss=0.0000\n",
      "Epoch 960: Total Loss=0.0000\n",
      "Epoch 970: Total Loss=0.0000\n",
      "Epoch 980: Total Loss=0.0000\n",
      "Epoch 990: Total Loss=0.0000\n",
      "Using previous population of size 100\n",
      "=================================================\n",
      "n_gen  |  n_eval  |     f_avg     |     f_min    \n",
      "=================================================\n",
      "     1 |      100 | -1.000075E+00 | -1.000581E+00\n",
      "     2 |      200 | -1.000275E+00 | -1.000987E+00\n",
      "     3 |      300 | -1.000420E+00 | -1.001203E+00\n",
      "TEMPOUT: 31.9718085\n",
      "The cost is 0.00\n",
      "TEMPOUT: 31.9718085\n",
      "The cost is 0.00\n",
      "TEMPOUT: 31.8676278\n",
      "The cost is 0.00\n",
      "TEMPOUT: 31.836541\n",
      "The cost is 0.00\n",
      "TEMPOUT: 31.6666878\n",
      "The cost is 0.00\n",
      "TEMPOUT: 31.5667757\n",
      "The cost is 0.00\n",
      "TEMPOUT: 31.4924735\n",
      "The cost is 0.00\n",
      "TEMPOUT: 31.5251577\n",
      "The cost is 0.00\n",
      "TEMPOUT: 31.5003141\n",
      "The cost is 0.00\n",
      "TEMPOUT: 31.5877564\n",
      "The cost is 0.00\n",
      "TEMPOUT: 31.4412808\n",
      "The cost is 0.00\n",
      "TEMPOUT: 31.4712073\n",
      "The cost is 0.00\n",
      "TEMPOUT: -65.1789718\n",
      "The cost is 0.00\n",
      "TEMPOUT: 31.2107776\n",
      "The cost is 0.00\n",
      "TEMPOUT: -64.2954153\n",
      "The cost is 0.00\n",
      "TEMPOUT: -64.7711903\n",
      "The cost is 0.00\n",
      "TEMPOUT: -63.8427186\n",
      "The cost is 0.00\n",
      "TEMPOUT: None\n",
      "The cost is 0.00\n",
      "TEMPOUT: 30.9641873\n",
      "The cost is 0.00\n",
      "TEMPOUT: 31.0154449\n",
      "The cost is 0.00\n",
      "TEMPOUT: 31.2096099\n",
      "The cost is 0.00\n",
      "Iteration 2: Optimal input [19.97227 19.98139], output 0, dataset size (163, 3)\n",
      "Iteration 3: Training surrogate model...\n",
      "device cpu\n",
      "Epoch 0: Total Loss=0.0000\n",
      "Epoch 10: Total Loss=0.0000\n",
      "Epoch 20: Total Loss=0.0000\n",
      "Epoch 30: Total Loss=0.0000\n",
      "Epoch 40: Total Loss=0.0000\n",
      "Epoch 50: Total Loss=0.0000\n",
      "Epoch 60: Total Loss=0.0000\n",
      "Epoch 70: Total Loss=0.0000\n",
      "Epoch 80: Total Loss=0.0000\n",
      "Epoch 90: Total Loss=0.0000\n",
      "Epoch 100: Total Loss=0.0000\n",
      "Epoch 110: Total Loss=0.0000\n",
      "Epoch 120: Total Loss=0.0000\n",
      "Epoch 130: Total Loss=0.0000\n",
      "Epoch 140: Total Loss=0.0000\n",
      "Epoch 150: Total Loss=0.0000\n",
      "Epoch 160: Total Loss=0.0000\n",
      "Epoch 170: Total Loss=0.0000\n",
      "Epoch 180: Total Loss=0.0000\n",
      "Epoch 190: Total Loss=0.0000\n",
      "Epoch 200: Total Loss=0.0000\n",
      "Epoch 210: Total Loss=0.0000\n",
      "Epoch 220: Total Loss=0.0000\n",
      "Epoch 230: Total Loss=0.0000\n",
      "Epoch 240: Total Loss=0.0000\n",
      "Epoch 250: Total Loss=0.0000\n",
      "Epoch 260: Total Loss=0.0000\n",
      "Epoch 270: Total Loss=0.0000\n",
      "Epoch 280: Total Loss=0.0000\n",
      "Epoch 290: Total Loss=0.0000\n",
      "Epoch 300: Total Loss=0.0000\n",
      "Epoch 310: Total Loss=0.0000\n",
      "Epoch 320: Total Loss=0.0000\n",
      "Epoch 330: Total Loss=0.0000\n",
      "Epoch 340: Total Loss=0.0000\n",
      "Epoch 350: Total Loss=0.0000\n",
      "Epoch 360: Total Loss=0.0000\n",
      "Epoch 370: Total Loss=0.0000\n",
      "Epoch 380: Total Loss=0.0000\n",
      "Epoch 390: Total Loss=0.0000\n",
      "Epoch 400: Total Loss=0.0000\n",
      "Epoch 410: Total Loss=0.0000\n",
      "Epoch 420: Total Loss=0.0000\n",
      "Epoch 430: Total Loss=0.0000\n",
      "Epoch 440: Total Loss=0.0000\n",
      "Epoch 450: Total Loss=0.0000\n",
      "Epoch 460: Total Loss=0.0000\n",
      "Epoch 470: Total Loss=0.0000\n",
      "Epoch 480: Total Loss=0.0000\n",
      "Epoch 490: Total Loss=0.0000\n",
      "Epoch 500: Total Loss=0.0000\n",
      "Epoch 510: Total Loss=0.0000\n",
      "Epoch 520: Total Loss=0.0000\n",
      "Epoch 530: Total Loss=0.0000\n",
      "Epoch 540: Total Loss=0.0000\n",
      "Epoch 550: Total Loss=0.0000\n",
      "Epoch 560: Total Loss=0.0000\n",
      "Epoch 570: Total Loss=0.0000\n",
      "Epoch 580: Total Loss=0.0000\n",
      "Epoch 590: Total Loss=0.0000\n",
      "Epoch 600: Total Loss=0.0000\n",
      "Epoch 610: Total Loss=0.0000\n",
      "Epoch 620: Total Loss=0.0000\n",
      "Epoch 630: Total Loss=0.0000\n",
      "Epoch 640: Total Loss=0.0000\n",
      "Epoch 650: Total Loss=0.0000\n",
      "Epoch 660: Total Loss=0.0000\n",
      "Epoch 670: Total Loss=0.0000\n",
      "Epoch 680: Total Loss=0.0000\n",
      "Epoch 690: Total Loss=0.0000\n",
      "Epoch 700: Total Loss=0.0000\n",
      "Epoch 710: Total Loss=0.0000\n",
      "Epoch 720: Total Loss=0.0000\n",
      "Epoch 730: Total Loss=0.0000\n",
      "Epoch 740: Total Loss=0.0000\n",
      "Epoch 750: Total Loss=0.0000\n",
      "Epoch 760: Total Loss=0.0000\n",
      "Epoch 770: Total Loss=0.0000\n",
      "Epoch 780: Total Loss=0.0000\n",
      "Epoch 790: Total Loss=0.0000\n",
      "Epoch 800: Total Loss=0.0000\n",
      "Epoch 810: Total Loss=0.0000\n",
      "Epoch 820: Total Loss=0.0000\n",
      "Epoch 830: Total Loss=0.0000\n",
      "Epoch 840: Total Loss=0.0000\n",
      "Epoch 850: Total Loss=0.0000\n",
      "Epoch 860: Total Loss=0.0000\n",
      "Epoch 870: Total Loss=0.0000\n",
      "Epoch 880: Total Loss=0.0000\n",
      "Epoch 890: Total Loss=0.0000\n",
      "Epoch 900: Total Loss=0.0000\n",
      "Epoch 910: Total Loss=0.0000\n",
      "Epoch 920: Total Loss=0.0000\n",
      "Epoch 930: Total Loss=0.0000\n",
      "Epoch 940: Total Loss=0.0000\n",
      "Epoch 950: Total Loss=0.0000\n",
      "Epoch 960: Total Loss=0.0000\n",
      "Epoch 970: Total Loss=0.0000\n",
      "Epoch 980: Total Loss=0.0000\n",
      "Epoch 990: Total Loss=0.0000\n",
      "Using previous population of size 100\n",
      "=================================================\n",
      "n_gen  |  n_eval  |     f_avg     |     f_min    \n",
      "=================================================\n",
      "     1 |      100 | -1.000022E+00 | -1.000470E+00\n",
      "     2 |      200 | -1.000087E+00 | -1.000470E+00\n",
      "     3 |      300 | -1.000145E+00 | -1.000470E+00\n",
      "TEMPOUT: -65.9923515\n",
      "The cost is 0.00\n",
      "TEMPOUT: -65.9923515\n",
      "The cost is 0.00\n",
      "TEMPOUT: -66.2915098\n",
      "The cost is 0.00\n",
      "TEMPOUT: -66.0517636\n",
      "The cost is 0.00\n",
      "TEMPOUT: -66.9514823\n",
      "The cost is 0.00\n",
      "TEMPOUT: -67.3292544\n",
      "The cost is 0.00\n",
      "TEMPOUT: -64.1571646\n",
      "The cost is 0.00\n",
      "TEMPOUT: -67.2690982\n",
      "The cost is 0.00\n",
      "TEMPOUT: -66.6801857\n",
      "The cost is 0.00\n",
      "TEMPOUT: -67.2205746\n",
      "The cost is 0.00\n",
      "TEMPOUT: -66.7193171\n",
      "The cost is 0.00\n",
      "TEMPOUT: 22.5849979\n",
      "The cost is 0.00\n",
      "TEMPOUT: -64.2599773\n",
      "The cost is 0.00\n",
      "TEMPOUT: -46.7080345\n",
      "The cost is 0.00\n",
      "TEMPOUT: -45.949197\n",
      "The cost is 0.00\n",
      "TEMPOUT: 23.7354081\n",
      "The cost is 0.00\n",
      "TEMPOUT: -48.0590673\n",
      "The cost is 0.00\n",
      "TEMPOUT: -50.0742318\n",
      "The cost is 0.00\n",
      "TEMPOUT: 32.0059248\n",
      "The cost is 0.00\n",
      "TEMPOUT: -45.9086501\n",
      "The cost is 0.00\n",
      "TEMPOUT: 31.9724447\n",
      "The cost is 0.00\n",
      "Iteration 3: Optimal input [18.092676   1.0383444], output 0, dataset size (184, 3)\n",
      "Iteration 4: Training surrogate model...\n",
      "device cpu\n",
      "Epoch 0: Total Loss=0.0000\n",
      "Epoch 10: Total Loss=0.0000\n",
      "Epoch 20: Total Loss=0.0000\n",
      "Epoch 30: Total Loss=0.0000\n",
      "Epoch 40: Total Loss=0.0000\n",
      "Epoch 50: Total Loss=0.0000\n",
      "Epoch 60: Total Loss=0.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 70: Total Loss=0.0000\n",
      "Epoch 80: Total Loss=0.0000\n",
      "Epoch 90: Total Loss=0.0000\n",
      "Epoch 100: Total Loss=0.0000\n",
      "Epoch 110: Total Loss=0.0000\n",
      "Epoch 120: Total Loss=0.0000\n",
      "Epoch 130: Total Loss=0.0000\n",
      "Epoch 140: Total Loss=0.0000\n",
      "Epoch 150: Total Loss=0.0000\n",
      "Epoch 160: Total Loss=0.0000\n",
      "Epoch 170: Total Loss=0.0000\n",
      "Epoch 180: Total Loss=0.0000\n",
      "Epoch 190: Total Loss=0.0000\n",
      "Epoch 200: Total Loss=0.0000\n",
      "Epoch 210: Total Loss=0.0000\n",
      "Epoch 220: Total Loss=0.0000\n",
      "Epoch 230: Total Loss=0.0000\n",
      "Epoch 240: Total Loss=0.0000\n",
      "Epoch 250: Total Loss=0.0000\n",
      "Epoch 260: Total Loss=0.0000\n",
      "Epoch 270: Total Loss=0.0000\n",
      "Epoch 280: Total Loss=0.0000\n",
      "Epoch 290: Total Loss=0.0000\n",
      "Epoch 300: Total Loss=0.0000\n",
      "Epoch 310: Total Loss=0.0000\n",
      "Epoch 320: Total Loss=0.0000\n",
      "Epoch 330: Total Loss=0.0000\n",
      "Epoch 340: Total Loss=0.0000\n",
      "Epoch 350: Total Loss=0.0000\n",
      "Epoch 360: Total Loss=0.0000\n",
      "Epoch 370: Total Loss=0.0000\n",
      "Epoch 380: Total Loss=0.0000\n",
      "Epoch 390: Total Loss=0.0000\n",
      "Epoch 400: Total Loss=0.0000\n",
      "Epoch 410: Total Loss=0.0000\n",
      "Epoch 420: Total Loss=0.0000\n",
      "Epoch 430: Total Loss=0.0000\n",
      "Epoch 440: Total Loss=0.0000\n",
      "Epoch 450: Total Loss=0.0000\n",
      "Epoch 460: Total Loss=0.0000\n",
      "Epoch 470: Total Loss=0.0000\n",
      "Epoch 480: Total Loss=0.0000\n",
      "Epoch 490: Total Loss=0.0000\n",
      "Epoch 500: Total Loss=0.0000\n",
      "Epoch 510: Total Loss=0.0000\n",
      "Epoch 520: Total Loss=0.0000\n",
      "Epoch 530: Total Loss=0.0000\n",
      "Epoch 540: Total Loss=0.0000\n",
      "Epoch 550: Total Loss=0.0000\n",
      "Epoch 560: Total Loss=0.0000\n",
      "Epoch 570: Total Loss=0.0000\n",
      "Epoch 580: Total Loss=0.0000\n",
      "Epoch 590: Total Loss=0.0000\n",
      "Epoch 600: Total Loss=0.0000\n",
      "Epoch 610: Total Loss=0.0000\n",
      "Epoch 620: Total Loss=0.0000\n",
      "Epoch 630: Total Loss=0.0000\n",
      "Epoch 640: Total Loss=0.0000\n",
      "Epoch 650: Total Loss=0.0000\n",
      "Epoch 660: Total Loss=0.0000\n",
      "Epoch 670: Total Loss=0.0000\n",
      "Epoch 680: Total Loss=0.0000\n",
      "Epoch 690: Total Loss=0.0000\n",
      "Epoch 700: Total Loss=0.0000\n",
      "Epoch 710: Total Loss=0.0000\n",
      "Epoch 720: Total Loss=0.0000\n",
      "Epoch 730: Total Loss=0.0000\n",
      "Epoch 740: Total Loss=0.0000\n",
      "Epoch 750: Total Loss=0.0000\n",
      "Epoch 760: Total Loss=0.0000\n",
      "Epoch 770: Total Loss=0.0000\n",
      "Epoch 780: Total Loss=0.0000\n",
      "Epoch 790: Total Loss=0.0000\n",
      "Epoch 800: Total Loss=0.0000\n",
      "Epoch 810: Total Loss=0.0000\n",
      "Epoch 820: Total Loss=0.0000\n",
      "Epoch 830: Total Loss=0.0000\n",
      "Epoch 840: Total Loss=0.0000\n",
      "Epoch 850: Total Loss=0.0000\n",
      "Epoch 860: Total Loss=0.0000\n",
      "Epoch 870: Total Loss=0.0000\n",
      "Epoch 880: Total Loss=0.0000\n",
      "Epoch 890: Total Loss=0.0000\n",
      "Epoch 900: Total Loss=0.0000\n",
      "Epoch 910: Total Loss=0.0000\n",
      "Epoch 920: Total Loss=0.0000\n",
      "Epoch 930: Total Loss=0.0000\n",
      "Epoch 940: Total Loss=0.0000\n",
      "Epoch 950: Total Loss=0.0000\n",
      "Epoch 960: Total Loss=0.0000\n",
      "Epoch 970: Total Loss=0.0000\n",
      "Epoch 980: Total Loss=0.0000\n",
      "Epoch 990: Total Loss=0.0000\n",
      "Using previous population of size 100\n",
      "=================================================\n",
      "n_gen  |  n_eval  |     f_avg     |     f_min    \n",
      "=================================================\n",
      "     1 |      100 | -1.000086E+00 | -1.000306E+00\n",
      "     2 |      200 | -1.000132E+00 | -1.000306E+00\n",
      "     3 |      300 | -1.000180E+00 | -1.000339E+00\n",
      "TEMPOUT: 21.6365587\n",
      "The cost is 0.00\n",
      "TEMPOUT: 21.6365587\n",
      "The cost is 0.00\n",
      "TEMPOUT: 20.9634503\n",
      "The cost is 0.00\n",
      "TEMPOUT: 22.5848307\n",
      "The cost is 0.00\n",
      "TEMPOUT: 22.2088361\n",
      "The cost is 0.00\n",
      "TEMPOUT: 22.5849091\n",
      "The cost is 0.00\n",
      "TEMPOUT: 21.4909267\n",
      "The cost is 0.00\n",
      "TEMPOUT: 23.1157833\n",
      "The cost is 0.00\n",
      "TEMPOUT: -45.6601387\n",
      "The cost is 0.00\n",
      "TEMPOUT: -45.4308068\n",
      "The cost is 0.00\n",
      "TEMPOUT: -48.9315795\n",
      "The cost is 0.00\n",
      "TEMPOUT: -40.2102094\n",
      "The cost is 0.00\n",
      "TEMPOUT: -46.2027818\n",
      "The cost is 0.00\n",
      "TEMPOUT: -49.4895464\n",
      "The cost is 0.00\n",
      "TEMPOUT: -46.1788609\n",
      "The cost is 0.00\n",
      "TEMPOUT: -38.9893324\n",
      "The cost is 0.00\n",
      "TEMPOUT: 23.7349728\n",
      "The cost is 0.00\n",
      "TEMPOUT: -49.6439189\n",
      "The cost is 0.00\n",
      "TEMPOUT: -41.1043047\n",
      "The cost is 0.00\n",
      "TEMPOUT: -37.7437005\n",
      "The cost is 0.00\n",
      "TEMPOUT: -44.0138159\n",
      "The cost is 0.00\n",
      "Iteration 4: Optimal input [19.973928 16.045628], output 0, dataset size (205, 3)\n",
      "Iteration 5: Training surrogate model...\n",
      "device cpu\n",
      "Epoch 0: Total Loss=0.0000\n",
      "Epoch 10: Total Loss=0.0000\n",
      "Epoch 20: Total Loss=0.0000\n",
      "Epoch 30: Total Loss=0.0000\n",
      "Epoch 40: Total Loss=0.0000\n",
      "Epoch 50: Total Loss=0.0000\n",
      "Epoch 60: Total Loss=0.0000\n",
      "Epoch 70: Total Loss=0.0000\n",
      "Epoch 80: Total Loss=0.0000\n",
      "Epoch 90: Total Loss=0.0000\n",
      "Epoch 100: Total Loss=0.0000\n",
      "Epoch 110: Total Loss=0.0000\n",
      "Epoch 120: Total Loss=0.0000\n",
      "Epoch 130: Total Loss=0.0000\n",
      "Epoch 140: Total Loss=0.0000\n",
      "Epoch 150: Total Loss=0.0000\n",
      "Epoch 160: Total Loss=0.0000\n",
      "Epoch 170: Total Loss=0.0000\n",
      "Epoch 180: Total Loss=0.0000\n",
      "Epoch 190: Total Loss=0.0000\n",
      "Epoch 200: Total Loss=0.0000\n",
      "Epoch 210: Total Loss=0.0000\n",
      "Epoch 220: Total Loss=0.0000\n",
      "Epoch 230: Total Loss=0.0000\n",
      "Epoch 240: Total Loss=0.0000\n",
      "Epoch 250: Total Loss=0.0000\n",
      "Epoch 260: Total Loss=0.0000\n",
      "Epoch 270: Total Loss=0.0000\n",
      "Epoch 280: Total Loss=0.0000\n",
      "Epoch 290: Total Loss=0.0000\n",
      "Epoch 300: Total Loss=0.0000\n",
      "Epoch 310: Total Loss=0.0000\n",
      "Epoch 320: Total Loss=0.0000\n",
      "Epoch 330: Total Loss=0.0000\n",
      "Epoch 340: Total Loss=0.0000\n",
      "Epoch 350: Total Loss=0.0000\n",
      "Epoch 360: Total Loss=0.0000\n",
      "Epoch 370: Total Loss=0.0000\n",
      "Epoch 380: Total Loss=0.0000\n",
      "Epoch 390: Total Loss=0.0000\n",
      "Epoch 400: Total Loss=0.0000\n",
      "Epoch 410: Total Loss=0.0000\n",
      "Epoch 420: Total Loss=0.0000\n",
      "Epoch 430: Total Loss=0.0000\n",
      "Epoch 440: Total Loss=0.0000\n",
      "Epoch 450: Total Loss=0.0000\n",
      "Epoch 460: Total Loss=0.0000\n",
      "Epoch 470: Total Loss=0.0000\n",
      "Epoch 480: Total Loss=0.0000\n",
      "Epoch 490: Total Loss=0.0000\n",
      "Epoch 500: Total Loss=0.0000\n",
      "Epoch 510: Total Loss=0.0000\n",
      "Epoch 520: Total Loss=0.0000\n",
      "Epoch 530: Total Loss=0.0000\n",
      "Epoch 540: Total Loss=0.0000\n",
      "Epoch 550: Total Loss=0.0000\n",
      "Epoch 560: Total Loss=0.0000\n",
      "Epoch 570: Total Loss=0.0000\n",
      "Epoch 580: Total Loss=0.0000\n",
      "Epoch 590: Total Loss=0.0000\n",
      "Epoch 600: Total Loss=0.0000\n",
      "Epoch 610: Total Loss=0.0000\n",
      "Epoch 620: Total Loss=0.0000\n",
      "Epoch 630: Total Loss=0.0000\n",
      "Epoch 640: Total Loss=0.0000\n",
      "Epoch 650: Total Loss=0.0000\n",
      "Epoch 660: Total Loss=0.0000\n",
      "Epoch 670: Total Loss=0.0000\n",
      "Epoch 680: Total Loss=0.0000\n",
      "Epoch 690: Total Loss=0.0000\n",
      "Epoch 700: Total Loss=0.0000\n",
      "Epoch 710: Total Loss=0.0000\n",
      "Epoch 720: Total Loss=0.0000\n",
      "Epoch 730: Total Loss=0.0000\n",
      "Epoch 740: Total Loss=0.0000\n",
      "Epoch 750: Total Loss=0.0000\n",
      "Epoch 760: Total Loss=0.0000\n",
      "Epoch 770: Total Loss=0.0000\n",
      "Epoch 780: Total Loss=0.0000\n",
      "Epoch 790: Total Loss=0.0000\n",
      "Epoch 800: Total Loss=0.0000\n",
      "Epoch 810: Total Loss=0.0000\n",
      "Epoch 820: Total Loss=0.0000\n",
      "Epoch 830: Total Loss=0.0000\n",
      "Epoch 840: Total Loss=0.0000\n",
      "Epoch 850: Total Loss=0.0000\n",
      "Epoch 860: Total Loss=0.0000\n",
      "Epoch 870: Total Loss=0.0000\n",
      "Epoch 880: Total Loss=0.0000\n",
      "Epoch 890: Total Loss=0.0000\n",
      "Epoch 900: Total Loss=0.0000\n",
      "Epoch 910: Total Loss=0.0000\n",
      "Epoch 920: Total Loss=0.0000\n",
      "Epoch 930: Total Loss=0.0000\n",
      "Epoch 940: Total Loss=0.0000\n",
      "Epoch 950: Total Loss=0.0000\n",
      "Epoch 960: Total Loss=0.0000\n",
      "Epoch 970: Total Loss=0.0000\n",
      "Epoch 980: Total Loss=0.0000\n",
      "Epoch 990: Total Loss=0.0000\n",
      "Using previous population of size 100\n",
      "=================================================\n",
      "n_gen  |  n_eval  |     f_avg     |     f_min    \n",
      "=================================================\n",
      "     1 |      100 | -1.000103E+00 | -1.000197E+00\n",
      "     2 |      200 | -1.000142E+00 | -1.000266E+00\n",
      "     3 |      300 | -1.000166E+00 | -1.000266E+00\n",
      "TEMPOUT: 19.6190401\n",
      "The cost is 0.00\n",
      "TEMPOUT: 19.6190401\n",
      "The cost is 0.00\n",
      "TEMPOUT: 19.6258604\n",
      "The cost is 0.00\n",
      "TEMPOUT: 16.3928659\n",
      "The cost is 0.00\n",
      "TEMPOUT: -66.5896891\n",
      "The cost is 0.00\n",
      "TEMPOUT: -67.0237696\n",
      "The cost is 0.00\n",
      "TEMPOUT: -67.2041513\n",
      "The cost is 0.00\n",
      "TEMPOUT: -67.3108259\n",
      "The cost is 0.00\n",
      "TEMPOUT: -67.2024892\n",
      "The cost is 0.00\n",
      "TEMPOUT: -67.0230339\n",
      "The cost is 0.00\n",
      "TEMPOUT: -67.1587298\n",
      "The cost is 0.00\n",
      "TEMPOUT: -67.0738949\n",
      "The cost is 0.00\n",
      "TEMPOUT: -67.1188724\n",
      "The cost is 0.00\n",
      "TEMPOUT: -66.9516355\n",
      "The cost is 0.00\n",
      "TEMPOUT: -67.5289902\n",
      "The cost is 0.00\n",
      "TEMPOUT: -66.7576243\n",
      "The cost is 0.00\n",
      "TEMPOUT: -67.4387095\n",
      "The cost is 0.00\n",
      "TEMPOUT: -66.7520353\n",
      "The cost is 0.00\n",
      "TEMPOUT: -66.9222857\n",
      "The cost is 0.00\n",
      "TEMPOUT: -67.3948444\n",
      "The cost is 0.00\n",
      "TEMPOUT: -67.3807311\n",
      "The cost is 0.00\n",
      "Iteration 5: Optimal input [15.3276205 16.943634 ], output 0, dataset size (226, 3)\n",
      "Iteration 6: Training surrogate model...\n",
      "device cpu\n",
      "Epoch 0: Total Loss=0.0000\n",
      "Epoch 10: Total Loss=0.0000\n",
      "Epoch 20: Total Loss=0.0000\n",
      "Epoch 30: Total Loss=0.0000\n",
      "Epoch 40: Total Loss=0.0000\n",
      "Epoch 50: Total Loss=0.0000\n",
      "Epoch 60: Total Loss=0.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 70: Total Loss=0.0000\n",
      "Epoch 80: Total Loss=0.0000\n",
      "Epoch 90: Total Loss=0.0000\n",
      "Epoch 100: Total Loss=0.0000\n",
      "Epoch 110: Total Loss=0.0000\n",
      "Epoch 120: Total Loss=0.0000\n",
      "Epoch 130: Total Loss=0.0000\n",
      "Epoch 140: Total Loss=0.0000\n",
      "Epoch 150: Total Loss=0.0000\n",
      "Epoch 160: Total Loss=0.0000\n",
      "Epoch 170: Total Loss=0.0000\n",
      "Epoch 180: Total Loss=0.0000\n",
      "Epoch 190: Total Loss=0.0000\n",
      "Epoch 200: Total Loss=0.0000\n",
      "Epoch 210: Total Loss=0.0000\n",
      "Epoch 220: Total Loss=0.0000\n",
      "Epoch 230: Total Loss=0.0000\n",
      "Epoch 240: Total Loss=0.0000\n",
      "Epoch 250: Total Loss=0.0000\n",
      "Epoch 260: Total Loss=0.0000\n",
      "Epoch 270: Total Loss=0.0000\n",
      "Epoch 280: Total Loss=0.0000\n",
      "Epoch 290: Total Loss=0.0000\n",
      "Epoch 300: Total Loss=0.0000\n",
      "Epoch 310: Total Loss=0.0000\n",
      "Epoch 320: Total Loss=0.0000\n",
      "Epoch 330: Total Loss=0.0000\n",
      "Epoch 340: Total Loss=0.0000\n",
      "Epoch 350: Total Loss=0.0000\n",
      "Epoch 360: Total Loss=0.0000\n",
      "Epoch 370: Total Loss=0.0000\n",
      "Epoch 380: Total Loss=0.0000\n",
      "Epoch 390: Total Loss=0.0000\n",
      "Epoch 400: Total Loss=0.0000\n",
      "Epoch 410: Total Loss=0.0000\n",
      "Epoch 420: Total Loss=0.0000\n",
      "Epoch 430: Total Loss=0.0000\n",
      "Epoch 440: Total Loss=0.0000\n",
      "Epoch 450: Total Loss=0.0000\n",
      "Epoch 460: Total Loss=0.0000\n",
      "Epoch 470: Total Loss=0.0000\n",
      "Epoch 480: Total Loss=0.0000\n",
      "Epoch 490: Total Loss=0.0000\n",
      "Epoch 500: Total Loss=0.0000\n",
      "Epoch 510: Total Loss=0.0000\n",
      "Epoch 520: Total Loss=0.0000\n",
      "Epoch 530: Total Loss=0.0000\n",
      "Epoch 540: Total Loss=0.0000\n",
      "Epoch 550: Total Loss=0.0000\n",
      "Epoch 560: Total Loss=0.0000\n",
      "Epoch 570: Total Loss=0.0000\n",
      "Epoch 580: Total Loss=0.0000\n",
      "Epoch 590: Total Loss=0.0000\n",
      "Epoch 600: Total Loss=0.0000\n",
      "Epoch 610: Total Loss=0.0000\n",
      "Epoch 620: Total Loss=0.0000\n",
      "Epoch 630: Total Loss=0.0000\n",
      "Epoch 640: Total Loss=0.0000\n",
      "Epoch 650: Total Loss=0.0000\n",
      "Epoch 660: Total Loss=0.0000\n",
      "Epoch 670: Total Loss=0.0000\n",
      "Epoch 680: Total Loss=0.0000\n",
      "Epoch 690: Total Loss=0.0000\n",
      "Epoch 700: Total Loss=0.0000\n",
      "Epoch 710: Total Loss=0.0000\n",
      "Epoch 720: Total Loss=0.0000\n",
      "Epoch 730: Total Loss=0.0000\n",
      "Epoch 740: Total Loss=0.0000\n",
      "Epoch 750: Total Loss=0.0000\n",
      "Epoch 760: Total Loss=0.0000\n",
      "Epoch 770: Total Loss=0.0000\n",
      "Epoch 780: Total Loss=0.0000\n",
      "Epoch 790: Total Loss=0.0000\n",
      "Epoch 800: Total Loss=0.0000\n",
      "Epoch 810: Total Loss=0.0000\n",
      "Epoch 820: Total Loss=0.0000\n",
      "Epoch 830: Total Loss=0.0000\n",
      "Epoch 840: Total Loss=0.0000\n",
      "Epoch 850: Total Loss=0.0000\n",
      "Epoch 860: Total Loss=0.0000\n",
      "Epoch 870: Total Loss=0.0000\n",
      "Epoch 880: Total Loss=0.0000\n",
      "Epoch 890: Total Loss=0.0000\n",
      "Epoch 900: Total Loss=0.0000\n",
      "Epoch 910: Total Loss=0.0000\n",
      "Epoch 920: Total Loss=0.0000\n",
      "Epoch 930: Total Loss=0.0000\n",
      "Epoch 940: Total Loss=0.0000\n",
      "Epoch 950: Total Loss=0.0000\n",
      "Epoch 960: Total Loss=0.0000\n",
      "Epoch 970: Total Loss=0.0000\n",
      "Epoch 980: Total Loss=0.0000\n",
      "Epoch 990: Total Loss=0.0000\n",
      "Using previous population of size 100\n",
      "=================================================\n",
      "n_gen  |  n_eval  |     f_avg     |     f_min    \n",
      "=================================================\n",
      "     1 |      100 | -1.000091E+00 | -1.000179E+00\n",
      "     2 |      200 | -1.000118E+00 | -1.000224E+00\n",
      "     3 |      300 | -1.000145E+00 | -1.000225E+00\n",
      "TEMPOUT: 16.2375797\n",
      "The cost is 0.00\n",
      "TEMPOUT: 16.2375797\n",
      "The cost is 0.00\n",
      "TEMPOUT: 16.0951315\n",
      "The cost is 0.00\n",
      "TEMPOUT: 16.0755044\n",
      "The cost is 0.00\n",
      "TEMPOUT: 19.6168521\n",
      "The cost is 0.00\n",
      "TEMPOUT: 19.625246\n",
      "The cost is 0.00\n",
      "TEMPOUT: 19.7763058\n",
      "The cost is 0.00\n",
      "TEMPOUT: -43.5007221\n",
      "The cost is 0.00\n",
      "TEMPOUT: -44.0235101\n",
      "The cost is 0.00\n",
      "TEMPOUT: -43.5757411\n",
      "The cost is 0.00\n",
      "TEMPOUT: -43.6297623\n",
      "The cost is 0.00\n",
      "TEMPOUT: -42.9971856\n",
      "The cost is 0.00\n",
      "TEMPOUT: -44.2181549\n",
      "The cost is 0.00\n",
      "TEMPOUT: -44.2389043\n",
      "The cost is 0.00\n",
      "TEMPOUT: -43.4678411\n",
      "The cost is 0.00\n",
      "TEMPOUT: -44.2440623\n",
      "The cost is 0.00\n",
      "TEMPOUT: -41.1782287\n",
      "The cost is 0.00\n",
      "TEMPOUT: -41.0714797\n",
      "The cost is 0.00\n",
      "TEMPOUT: -41.0459865\n",
      "The cost is 0.00\n",
      "TEMPOUT: -45.4321525\n",
      "The cost is 0.00\n",
      "TEMPOUT: -46.1457457\n",
      "The cost is 0.00\n",
      "Iteration 6: Optimal input [14.20196  16.906706], output 0, dataset size (247, 3)\n",
      "Iteration 7: Training surrogate model...\n",
      "device cpu\n",
      "Epoch 0: Total Loss=0.0000\n",
      "Epoch 10: Total Loss=0.0000\n",
      "Epoch 20: Total Loss=0.0000\n",
      "Epoch 30: Total Loss=0.0000\n",
      "Epoch 40: Total Loss=0.0000\n",
      "Epoch 50: Total Loss=0.0000\n",
      "Epoch 60: Total Loss=0.0000\n",
      "Epoch 70: Total Loss=0.0000\n",
      "Epoch 80: Total Loss=0.0000\n",
      "Epoch 90: Total Loss=0.0000\n",
      "Epoch 100: Total Loss=0.0000\n",
      "Epoch 110: Total Loss=0.0000\n",
      "Epoch 120: Total Loss=0.0000\n",
      "Epoch 130: Total Loss=0.0000\n",
      "Epoch 140: Total Loss=0.0000\n",
      "Epoch 150: Total Loss=0.0000\n",
      "Epoch 160: Total Loss=0.0000\n",
      "Epoch 170: Total Loss=0.0000\n",
      "Epoch 180: Total Loss=0.0000\n",
      "Epoch 190: Total Loss=0.0000\n",
      "Epoch 200: Total Loss=0.0000\n",
      "Epoch 210: Total Loss=0.0000\n",
      "Epoch 220: Total Loss=0.0000\n",
      "Epoch 230: Total Loss=0.0000\n",
      "Epoch 240: Total Loss=0.0000\n",
      "Epoch 250: Total Loss=0.0000\n",
      "Epoch 260: Total Loss=0.0000\n",
      "Epoch 270: Total Loss=0.0000\n",
      "Epoch 280: Total Loss=0.0000\n",
      "Epoch 290: Total Loss=0.0000\n",
      "Epoch 300: Total Loss=0.0000\n",
      "Epoch 310: Total Loss=0.0000\n",
      "Epoch 320: Total Loss=0.0000\n",
      "Epoch 330: Total Loss=0.0000\n",
      "Epoch 340: Total Loss=0.0000\n",
      "Epoch 350: Total Loss=0.0000\n",
      "Epoch 360: Total Loss=0.0000\n",
      "Epoch 370: Total Loss=0.0000\n",
      "Epoch 380: Total Loss=0.0000\n",
      "Epoch 390: Total Loss=0.0000\n",
      "Epoch 400: Total Loss=0.0000\n",
      "Epoch 410: Total Loss=0.0000\n",
      "Epoch 420: Total Loss=0.0000\n",
      "Epoch 430: Total Loss=0.0000\n",
      "Epoch 440: Total Loss=0.0000\n",
      "Epoch 450: Total Loss=0.0000\n",
      "Epoch 460: Total Loss=0.0000\n",
      "Epoch 470: Total Loss=0.0000\n",
      "Epoch 480: Total Loss=0.0000\n",
      "Epoch 490: Total Loss=0.0000\n",
      "Epoch 500: Total Loss=0.0000\n",
      "Epoch 510: Total Loss=0.0000\n",
      "Epoch 520: Total Loss=0.0000\n",
      "Epoch 530: Total Loss=0.0000\n",
      "Epoch 540: Total Loss=0.0000\n",
      "Epoch 550: Total Loss=0.0000\n",
      "Epoch 560: Total Loss=0.0000\n",
      "Epoch 570: Total Loss=0.0000\n",
      "Epoch 580: Total Loss=0.0000\n",
      "Epoch 590: Total Loss=0.0000\n",
      "Epoch 600: Total Loss=0.0000\n",
      "Epoch 610: Total Loss=0.0000\n",
      "Epoch 620: Total Loss=0.0000\n",
      "Epoch 630: Total Loss=0.0000\n",
      "Epoch 640: Total Loss=0.0000\n",
      "Epoch 650: Total Loss=0.0000\n",
      "Epoch 660: Total Loss=0.0000\n",
      "Epoch 670: Total Loss=0.0000\n",
      "Epoch 680: Total Loss=0.0000\n",
      "Epoch 690: Total Loss=0.0000\n",
      "Epoch 700: Total Loss=0.0000\n",
      "Epoch 710: Total Loss=0.0000\n",
      "Epoch 720: Total Loss=0.0000\n",
      "Epoch 730: Total Loss=0.0000\n",
      "Epoch 740: Total Loss=0.0000\n",
      "Epoch 750: Total Loss=0.0000\n",
      "Epoch 760: Total Loss=0.0000\n",
      "Epoch 770: Total Loss=0.0000\n",
      "Epoch 780: Total Loss=0.0000\n",
      "Epoch 790: Total Loss=0.0000\n",
      "Epoch 800: Total Loss=0.0000\n",
      "Epoch 810: Total Loss=0.0000\n",
      "Epoch 820: Total Loss=0.0000\n",
      "Epoch 830: Total Loss=0.0000\n",
      "Epoch 840: Total Loss=0.0000\n",
      "Epoch 850: Total Loss=0.0000\n",
      "Epoch 860: Total Loss=0.0000\n",
      "Epoch 870: Total Loss=0.0000\n",
      "Epoch 880: Total Loss=0.0000\n",
      "Epoch 890: Total Loss=0.0000\n",
      "Epoch 900: Total Loss=0.0000\n",
      "Epoch 910: Total Loss=0.0000\n",
      "Epoch 920: Total Loss=0.0000\n",
      "Epoch 930: Total Loss=0.0000\n",
      "Epoch 940: Total Loss=0.0000\n",
      "Epoch 950: Total Loss=0.0000\n",
      "Epoch 960: Total Loss=0.0000\n",
      "Epoch 970: Total Loss=0.0000\n",
      "Epoch 980: Total Loss=0.0000\n",
      "Epoch 990: Total Loss=0.0000\n",
      "Using previous population of size 100\n",
      "=================================================\n",
      "n_gen  |  n_eval  |     f_avg     |     f_min    \n",
      "=================================================\n",
      "     1 |      100 | -1.000094E+00 | -1.000146E+00\n",
      "     2 |      200 | -1.000107E+00 | -1.000146E+00\n",
      "     3 |      300 | -1.000116E+00 | -1.000146E+00\n",
      "TEMPOUT: 15.0008384\n",
      "The cost is 0.00\n",
      "TEMPOUT: 15.0008384\n",
      "The cost is 0.00\n",
      "TEMPOUT: 32.0231603\n",
      "The cost is 0.00\n",
      "TEMPOUT: 32.0229807\n",
      "The cost is 0.00\n",
      "TEMPOUT: 16.0836418\n",
      "The cost is 0.00\n",
      "TEMPOUT: 32.0061333\n",
      "The cost is 0.00\n",
      "TEMPOUT: 32.0063285\n",
      "The cost is 0.00\n",
      "TEMPOUT: 21.3583699\n",
      "The cost is 0.00\n",
      "TEMPOUT: 32.0225581\n",
      "The cost is 0.00\n",
      "TEMPOUT: 21.2311858\n",
      "The cost is 0.00\n",
      "TEMPOUT: 20.5337558\n",
      "The cost is 0.00\n",
      "TEMPOUT: 20.5338699\n",
      "The cost is 0.00\n",
      "TEMPOUT: 15.611444\n",
      "The cost is 0.00\n",
      "TEMPOUT: 20.5326945\n",
      "The cost is 0.00\n",
      "TEMPOUT: 32.006021\n",
      "The cost is 0.00\n",
      "TEMPOUT: 32.0055773\n",
      "The cost is 0.00\n",
      "TEMPOUT: -41.9571936\n",
      "The cost is 0.00\n",
      "TEMPOUT: 21.520089\n",
      "The cost is 0.00\n",
      "TEMPOUT: 16.2395664\n",
      "The cost is 0.00\n",
      "TEMPOUT: 21.149205\n",
      "The cost is 0.00\n",
      "TEMPOUT: 21.2021031\n",
      "The cost is 0.00\n",
      "Iteration 7: Optimal input [13.808746 16.52508 ], output 0, dataset size (268, 3)\n",
      "Iteration 8: Training surrogate model...\n",
      "device cpu\n",
      "Epoch 0: Total Loss=0.0000\n",
      "Epoch 10: Total Loss=0.0000\n",
      "Epoch 20: Total Loss=0.0000\n",
      "Epoch 30: Total Loss=0.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40: Total Loss=0.0000\n",
      "Epoch 50: Total Loss=0.0000\n",
      "Epoch 60: Total Loss=0.0000\n",
      "Epoch 70: Total Loss=0.0000\n",
      "Epoch 80: Total Loss=0.0000\n",
      "Epoch 90: Total Loss=0.0000\n",
      "Epoch 100: Total Loss=0.0000\n",
      "Epoch 110: Total Loss=0.0000\n",
      "Epoch 120: Total Loss=0.0000\n",
      "Epoch 130: Total Loss=0.0000\n",
      "Epoch 140: Total Loss=0.0000\n",
      "Epoch 150: Total Loss=0.0000\n",
      "Epoch 160: Total Loss=0.0000\n",
      "Epoch 170: Total Loss=0.0000\n",
      "Epoch 180: Total Loss=0.0000\n",
      "Epoch 190: Total Loss=0.0000\n",
      "Epoch 200: Total Loss=0.0000\n",
      "Epoch 210: Total Loss=0.0000\n",
      "Epoch 220: Total Loss=0.0000\n",
      "Epoch 230: Total Loss=0.0000\n",
      "Epoch 240: Total Loss=0.0000\n",
      "Epoch 250: Total Loss=0.0000\n",
      "Epoch 260: Total Loss=0.0000\n",
      "Epoch 270: Total Loss=0.0000\n",
      "Epoch 280: Total Loss=0.0000\n",
      "Epoch 290: Total Loss=0.0000\n",
      "Epoch 300: Total Loss=0.0000\n",
      "Epoch 310: Total Loss=0.0000\n",
      "Epoch 320: Total Loss=0.0000\n",
      "Epoch 330: Total Loss=0.0000\n",
      "Epoch 340: Total Loss=0.0000\n",
      "Epoch 350: Total Loss=0.0000\n",
      "Epoch 360: Total Loss=0.0000\n",
      "Epoch 370: Total Loss=0.0000\n",
      "Epoch 380: Total Loss=0.0000\n",
      "Epoch 390: Total Loss=0.0000\n",
      "Epoch 400: Total Loss=0.0000\n",
      "Epoch 410: Total Loss=0.0000\n",
      "Epoch 420: Total Loss=0.0000\n",
      "Epoch 430: Total Loss=0.0000\n",
      "Epoch 440: Total Loss=0.0000\n",
      "Epoch 450: Total Loss=0.0000\n",
      "Epoch 460: Total Loss=0.0000\n",
      "Epoch 470: Total Loss=0.0000\n",
      "Epoch 480: Total Loss=0.0000\n",
      "Epoch 490: Total Loss=0.0000\n",
      "Epoch 500: Total Loss=0.0000\n",
      "Epoch 510: Total Loss=0.0000\n",
      "Epoch 520: Total Loss=0.0000\n",
      "Epoch 530: Total Loss=0.0000\n",
      "Epoch 540: Total Loss=0.0000\n",
      "Epoch 550: Total Loss=0.0000\n",
      "Epoch 560: Total Loss=0.0000\n",
      "Epoch 570: Total Loss=0.0000\n",
      "Epoch 580: Total Loss=0.0000\n",
      "Epoch 590: Total Loss=0.0000\n",
      "Epoch 600: Total Loss=0.0000\n",
      "Epoch 610: Total Loss=0.0000\n",
      "Epoch 620: Total Loss=0.0000\n",
      "Epoch 630: Total Loss=0.0000\n",
      "Epoch 640: Total Loss=0.0000\n",
      "Epoch 650: Total Loss=0.0000\n",
      "Epoch 660: Total Loss=0.0000\n",
      "Epoch 670: Total Loss=0.0000\n",
      "Epoch 680: Total Loss=0.0000\n",
      "Epoch 690: Total Loss=0.0000\n",
      "Epoch 700: Total Loss=0.0000\n",
      "Epoch 710: Total Loss=0.0000\n",
      "Epoch 720: Total Loss=0.0000\n",
      "Epoch 730: Total Loss=0.0000\n",
      "Epoch 740: Total Loss=0.0000\n",
      "Epoch 750: Total Loss=0.0000\n",
      "Epoch 760: Total Loss=0.0000\n",
      "Epoch 770: Total Loss=0.0000\n",
      "Epoch 780: Total Loss=0.0000\n",
      "Epoch 790: Total Loss=0.0000\n",
      "Epoch 800: Total Loss=0.0000\n",
      "Epoch 810: Total Loss=0.0000\n",
      "Epoch 820: Total Loss=0.0000\n",
      "Epoch 830: Total Loss=0.0000\n",
      "Epoch 840: Total Loss=0.0000\n",
      "Epoch 850: Total Loss=0.0000\n",
      "Epoch 860: Total Loss=0.0000\n",
      "Epoch 870: Total Loss=0.0000\n",
      "Epoch 880: Total Loss=0.0000\n",
      "Epoch 890: Total Loss=0.0000\n",
      "Epoch 900: Total Loss=0.0000\n",
      "Epoch 910: Total Loss=0.0000\n",
      "Epoch 920: Total Loss=0.0000\n",
      "Epoch 930: Total Loss=0.0000\n",
      "Epoch 940: Total Loss=0.0000\n",
      "Epoch 950: Total Loss=0.0000\n",
      "Epoch 960: Total Loss=0.0000\n",
      "Epoch 970: Total Loss=0.0000\n",
      "Epoch 980: Total Loss=0.0000\n",
      "Epoch 990: Total Loss=0.0000\n",
      "Using previous population of size 100\n",
      "=================================================\n",
      "n_gen  |  n_eval  |     f_avg     |     f_min    \n",
      "=================================================\n",
      "     1 |      100 | -1.000146E+00 | -1.000238E+00\n",
      "     2 |      200 | -1.000170E+00 | -1.000291E+00\n",
      "     3 |      300 | -1.000184E+00 | -1.000320E+00\n",
      "TEMPOUT: 20.0188432\n",
      "The cost is 0.00\n",
      "TEMPOUT: 20.0188432\n",
      "The cost is 0.00\n",
      "TEMPOUT: 22.2349447\n",
      "The cost is 0.00\n",
      "TEMPOUT: 23.743015\n",
      "The cost is 0.00\n",
      "TEMPOUT: 22.5171777\n",
      "The cost is 0.00\n",
      "TEMPOUT: 22.5152639\n",
      "The cost is 0.00\n",
      "TEMPOUT: -40.2411403\n",
      "The cost is 0.00\n",
      "TEMPOUT: -36.8851578\n",
      "The cost is 0.00\n",
      "TEMPOUT: -36.5483505\n",
      "The cost is 0.00\n",
      "TEMPOUT: 32.0357926\n",
      "The cost is 0.00\n",
      "TEMPOUT: -42.680219\n",
      "The cost is 0.00\n",
      "TEMPOUT: -41.7386639\n",
      "The cost is 0.00\n",
      "TEMPOUT: -41.8006882\n",
      "The cost is 0.00\n",
      "TEMPOUT: 32.024785\n",
      "The cost is 0.00\n",
      "TEMPOUT: 32.0230572\n",
      "The cost is 0.00\n",
      "TEMPOUT: -36.8652302\n",
      "The cost is 0.00\n",
      "TEMPOUT: -36.6221525\n",
      "The cost is 0.00\n",
      "TEMPOUT: -42.828893\n",
      "The cost is 0.00\n",
      "TEMPOUT: -42.9241978\n",
      "The cost is 0.00\n",
      "TEMPOUT: -36.4966893\n",
      "The cost is 0.00\n",
      "TEMPOUT: -35.1852615\n",
      "The cost is 0.00\n",
      "Iteration 8: Optimal input [15.428178 19.983719], output 0, dataset size (289, 3)\n",
      "Iteration 9: Training surrogate model...\n",
      "device cpu\n",
      "Epoch 0: Total Loss=0.0000\n",
      "Epoch 10: Total Loss=0.0000\n",
      "Epoch 20: Total Loss=0.0000\n",
      "Epoch 30: Total Loss=0.0000\n",
      "Epoch 40: Total Loss=0.0000\n",
      "Epoch 50: Total Loss=0.0000\n",
      "Epoch 60: Total Loss=0.0000\n",
      "Epoch 70: Total Loss=0.0000\n",
      "Epoch 80: Total Loss=0.0000\n",
      "Epoch 90: Total Loss=0.0000\n",
      "Epoch 100: Total Loss=0.0000\n",
      "Epoch 110: Total Loss=0.0000\n",
      "Epoch 120: Total Loss=0.0000\n",
      "Epoch 130: Total Loss=0.0000\n",
      "Epoch 140: Total Loss=0.0000\n",
      "Epoch 150: Total Loss=0.0000\n",
      "Epoch 160: Total Loss=0.0000\n",
      "Epoch 170: Total Loss=0.0000\n",
      "Epoch 180: Total Loss=0.0000\n",
      "Epoch 190: Total Loss=0.0000\n",
      "Epoch 200: Total Loss=0.0000\n",
      "Epoch 210: Total Loss=0.0000\n",
      "Epoch 220: Total Loss=0.0000\n",
      "Epoch 230: Total Loss=0.0000\n",
      "Epoch 240: Total Loss=0.0000\n",
      "Epoch 250: Total Loss=0.0000\n",
      "Epoch 260: Total Loss=0.0000\n",
      "Epoch 270: Total Loss=0.0000\n",
      "Epoch 280: Total Loss=0.0000\n",
      "Epoch 290: Total Loss=0.0000\n",
      "Epoch 300: Total Loss=0.0000\n",
      "Epoch 310: Total Loss=0.0000\n",
      "Epoch 320: Total Loss=0.0000\n",
      "Epoch 330: Total Loss=0.0000\n",
      "Epoch 340: Total Loss=0.0000\n",
      "Epoch 350: Total Loss=0.0000\n",
      "Epoch 360: Total Loss=0.0000\n",
      "Epoch 370: Total Loss=0.0000\n",
      "Epoch 380: Total Loss=0.0000\n",
      "Epoch 390: Total Loss=0.0000\n",
      "Epoch 400: Total Loss=0.0000\n",
      "Epoch 410: Total Loss=0.0000\n",
      "Epoch 420: Total Loss=0.0000\n",
      "Epoch 430: Total Loss=0.0000\n",
      "Epoch 440: Total Loss=0.0000\n",
      "Epoch 450: Total Loss=0.0000\n",
      "Epoch 460: Total Loss=0.0000\n",
      "Epoch 470: Total Loss=0.0000\n",
      "Epoch 480: Total Loss=0.0000\n",
      "Epoch 490: Total Loss=0.0000\n",
      "Epoch 500: Total Loss=0.0000\n",
      "Epoch 510: Total Loss=0.0000\n",
      "Epoch 520: Total Loss=0.0000\n",
      "Epoch 530: Total Loss=0.0000\n",
      "Epoch 540: Total Loss=0.0000\n",
      "Epoch 550: Total Loss=0.0000\n",
      "Epoch 560: Total Loss=0.0000\n",
      "Epoch 570: Total Loss=0.0000\n",
      "Epoch 580: Total Loss=0.0000\n",
      "Epoch 590: Total Loss=0.0000\n",
      "Epoch 600: Total Loss=0.0000\n",
      "Epoch 610: Total Loss=0.0000\n",
      "Epoch 620: Total Loss=0.0000\n",
      "Epoch 630: Total Loss=0.0000\n",
      "Epoch 640: Total Loss=0.0000\n",
      "Epoch 650: Total Loss=0.0000\n",
      "Epoch 660: Total Loss=0.0000\n",
      "Epoch 670: Total Loss=0.0000\n",
      "Epoch 680: Total Loss=0.0000\n",
      "Epoch 690: Total Loss=0.0000\n",
      "Epoch 700: Total Loss=0.0000\n",
      "Epoch 710: Total Loss=0.0000\n",
      "Epoch 720: Total Loss=0.0000\n",
      "Epoch 730: Total Loss=0.0000\n",
      "Epoch 740: Total Loss=0.0000\n",
      "Epoch 750: Total Loss=0.0000\n",
      "Epoch 760: Total Loss=0.0000\n",
      "Epoch 770: Total Loss=0.0000\n",
      "Epoch 780: Total Loss=0.0000\n",
      "Epoch 790: Total Loss=0.0000\n",
      "Epoch 800: Total Loss=0.0000\n",
      "Epoch 810: Total Loss=0.0000\n",
      "Epoch 820: Total Loss=0.0000\n",
      "Epoch 830: Total Loss=0.0000\n",
      "Epoch 840: Total Loss=0.0000\n",
      "Epoch 850: Total Loss=0.0000\n",
      "Epoch 860: Total Loss=0.0000\n",
      "Epoch 870: Total Loss=0.0000\n",
      "Epoch 880: Total Loss=0.0000\n",
      "Epoch 890: Total Loss=0.0000\n",
      "Epoch 900: Total Loss=0.0000\n",
      "Epoch 910: Total Loss=0.0000\n",
      "Epoch 920: Total Loss=0.0000\n",
      "Epoch 930: Total Loss=0.0000\n",
      "Epoch 940: Total Loss=0.0000\n",
      "Epoch 950: Total Loss=0.0000\n",
      "Epoch 960: Total Loss=0.0000\n",
      "Epoch 970: Total Loss=0.0000\n",
      "Epoch 980: Total Loss=0.0000\n",
      "Epoch 990: Total Loss=0.0000\n",
      "Using previous population of size 100\n",
      "=================================================\n",
      "n_gen  |  n_eval  |     f_avg     |     f_min    \n",
      "=================================================\n",
      "     1 |      100 | -1.000081E+00 | -1.000125E+00\n",
      "     2 |      200 | -1.000115E+00 | -1.000125E+00\n",
      "     3 |      300 | -1.000122E+00 | -1.000126E+00\n",
      "TEMPOUT: -43.4191841\n",
      "The cost is 0.00\n",
      "TEMPOUT: -43.4191841\n",
      "The cost is 0.00\n",
      "TEMPOUT: -42.049544\n",
      "The cost is 0.00\n",
      "TEMPOUT: -43.4207998\n",
      "The cost is 0.00\n",
      "TEMPOUT: -43.6069552\n",
      "The cost is 0.00\n",
      "TEMPOUT: -42.9662348\n",
      "The cost is 0.00\n",
      "TEMPOUT: -43.5313836\n",
      "The cost is 0.00\n",
      "TEMPOUT: -42.9934771\n",
      "The cost is 0.00\n",
      "TEMPOUT: -42.9955299\n",
      "The cost is 0.00\n",
      "TEMPOUT: -43.0604339\n",
      "The cost is 0.00\n",
      "TEMPOUT: -43.5138244\n",
      "The cost is 0.00\n",
      "TEMPOUT: -43.5078874\n",
      "The cost is 0.00\n",
      "TEMPOUT: -43.0665229\n",
      "The cost is 0.00\n",
      "TEMPOUT: -43.0693442\n",
      "The cost is 0.00\n",
      "TEMPOUT: -43.0654163\n",
      "The cost is 0.00\n",
      "TEMPOUT: -43.4595391\n",
      "The cost is 0.00\n",
      "TEMPOUT: -43.6133323\n",
      "The cost is 0.00\n",
      "TEMPOUT: -43.4620441\n",
      "The cost is 0.00\n",
      "TEMPOUT: -43.6118164\n",
      "The cost is 0.00\n",
      "TEMPOUT: -43.0693407\n",
      "The cost is 0.00\n",
      "TEMPOUT: -43.546593\n",
      "The cost is 0.00\n",
      "Iteration 9: Optimal input [ 2.6651247 17.230911 ], output 0, dataset size (310, 3)\n"
     ]
    }
   ],
   "source": [
    "out = optimize_surr_nsga_2(model=model,\n",
    "                   old_dataset=dataset,\n",
    "                   assSim=assSim,\n",
    "                   lr=1e-4, \n",
    "                   epoch=1000,\n",
    "                   min_vals=scaler.min_x,\n",
    "                   max_vals=scaler.max_x,\n",
    "                   scaler=scaler,\n",
    "                   device='cpu',\n",
    "                   iter=10,\n",
    "                   print_loss=True,\n",
    "                   print_it_data=True,\n",
    "                   lambda_mse=1,\n",
    "                   pop_size=100,\n",
    "                   n_gen = 3,\n",
    "                   new_data_size=20\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def func(x):\n",
    "    x1,x2 = x\n",
    "    # cost_value = (2 - x1)**2 + 100 * (x2 - x1**2)**2\n",
    "    cost_value = (x1)**2 + (x2)**2\n",
    "    return cost_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(out['y_path'], marker='o', label='Objective Value (y_path)', color='blue')\n",
    "plt.title('Objective Value Evolution', fontsize=14)\n",
    "plt.xlabel('Iteration', fontsize=12)\n",
    "plt.ylabel('Objective Value', fontsize=12)\n",
    "plt.grid(True, linestyle='--', alpha=0.7)\n",
    "plt.legend(fontsize=10)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Objective Value Path (y_path):\", out['y_path'])\n",
    "print(\"Decision Variable Path (x_path):\", out['x_path'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot x_path for x1 and x2\n",
    "x_path_array = np.array(out['x_path'])  # Convert the list of arrays to a NumPy array\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(x_path_array[:, 0], x_path_array[:, 1], marker='o', label='x_path')\n",
    "plt.title('Path of Decision Variables (x1, x2)', fontsize=14)\n",
    "plt.xlabel('x1', fontsize=12)\n",
    "plt.ylabel('x2', fontsize=12)\n",
    "plt.grid(True, linestyle='--', alpha=0.7)\n",
    "plt.legend(fontsize=10)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [2,4]\n",
    "input_tensor = torch.tensor(np.array(x), dtype=torch.float32)\n",
    "input_tensor_scaled = scaler.transform(input_tensor)\n",
    "print(\"input tensor scaled:\",input_tensor_scaled)\n",
    "print(\"expected out:\", func(x))\n",
    "output_scaled = model(input_tensor_scaled)\n",
    "input, output = scaler.inverse_transform(input_tensor_scaled, output_scaled)\n",
    "print(\"unscaled in out\", input,output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out['populations']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_population_evolution(all_pops, min, scaler):\n",
    "    for i, pop in enumerate(all_pops):\n",
    "        # Inverse transform the scaled population\n",
    "        pop = scaler.inverse_transform(pop)\n",
    "        # Extract x1 and x2 coordinates\n",
    "        x = pop[:, 0]\n",
    "        y = pop[:, 1]\n",
    "        plt.scatter(x, y, alpha=0.5, label=f'Iter {i}')\n",
    "    \n",
    "    plt.title(\"Population Distribution Over Iterations\")\n",
    "    plt.xlabel(\"x1\")\n",
    "    plt.ylabel(\"x2\")\n",
    "    #plot the true minimum point\n",
    "    plt.scatter(min[0], min[1], color='red', marker='*', s=150, label='True Optimal')\n",
    "    #plot the minimum point found by the model\n",
    "    plt.scatter(out['x_path'][-1][0], out['x_path'][-1][1], color='green', marker='*', s=150, label='Found Optimal')\n",
    "    \n",
    "\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "plot_population_evolution(out['populations'], [2,4], scaler)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot contour surface of the model\n",
    "x = np.linspace(-2, 5, 100)\n",
    "y = np.linspace(-2, 5, 100)\n",
    "X, Y = np.meshgrid(x, y)\n",
    "Z = np.zeros(X.shape)\n",
    "for i in range(X.shape[0]):\n",
    "    for j in range(X.shape[1]):\n",
    "        input_tensor = torch.tensor([X[i, j], Y[i, j]], dtype=torch.float32)\n",
    "        input_tensor_scaled = scaler.transform(input_tensor)\n",
    "        output_scaled = model(input_tensor_scaled)\n",
    "        input, output = scaler.inverse_transform(input_tensor_scaled, output_scaled)\n",
    "        Z[i, j] = output.item()\n",
    "#log transform Z\n",
    "Z = np.log(Z + 1e-10)  # Adding a small constant to avoid log(0)\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.contourf(X, Y, Z, levels=20, cmap='viridis')\n",
    "plt.colorbar(label='Objective Value')\n",
    "plt.title('Contour Plot of the Model Output')\n",
    "plt.xlabel('Flash 1')\n",
    "plt.ylabel('Flash 2')\n",
    "plt.scatter(out['x_path'][-1][0], out['x_path'][-1][1], color='red', marker='*', s=150, label='Final Point')\n",
    "#plot the true optimal point\n",
    "true_optimal = np.array([2, 4])\n",
    "plt.scatter(true_optimal[0], true_optimal[1], color='blue', zorder=5)\n",
    "plt.text(true_optimal[0], true_optimal[1], 'True Optimal', color='white', fontsize=10, ha='right')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rosenbrock function\n",
    "def rosenbrock(x):\n",
    "    x1, x2 = x\n",
    "    return (2 - x1)**2 + 100 * (x2 - x1**2)**2\n",
    "\n",
    "# Generate a grid of points\n",
    "x = np.linspace(-2, 5, 100)\n",
    "y = np.linspace(-2, 5, 100)\n",
    "X, Y = np.meshgrid(x, y)\n",
    "Z = np.zeros(X.shape)\n",
    "for i in range(X.shape[0]):\n",
    "    for j in range(X.shape[1]):\n",
    "        Z[i, j] = rosenbrock([X[i, j], Y[i, j]])\n",
    "\n",
    "#log scale the Z values\n",
    "Z = np.log(Z + 1e-10)  # Adding a small constant to avoid log(0)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.contourf(X, Y, Z, levels=20, cmap='viridis')\n",
    "plt.colorbar(label='Objective Value log_e')\n",
    "plt.title('Contour Plot of the Function in Log Scale')\n",
    "plt.xlabel('Flash 1')\n",
    "plt.ylabel('Flash 2')\n",
    "plt.scatter(out['x_path'][-1][0], out['x_path'][-1][1], color='red', marker='*', s=150, label='Final Point')\n",
    "#plot the true optimal point\n",
    "true_optimal = np.array([2, 4])\n",
    "plt.scatter(true_optimal[0], true_optimal[1], color='blue', zorder=5)\n",
    "plt.text(true_optimal[0], true_optimal[1], 'True Optimal', color='white', fontsize=10, ha='right')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1, x2 = 0.27312183, 0.5264797\n",
    "result = rosenbrock([x1, x2])\n",
    "print(\"Rosenbrock function result:\", result)\n",
    "#compare to 2,4\n",
    "print(\"True optimal:\", rosenbrock([2, 4]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
