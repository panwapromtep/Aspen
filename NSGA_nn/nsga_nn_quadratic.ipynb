{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added to sys.path: /Users/panwapromtep/Desktop/Aspen\n",
      "/Users/panwapromtep/Desktop/Aspen\n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "\n",
    "# Get the absolute path of the notebook's directory\n",
    "notebook_dir = os.getcwd()\n",
    "\n",
    "# Navigate to the parent directory\n",
    "parent_dir = os.path.abspath(os.path.join(notebook_dir, \"..\"))\n",
    "\n",
    "# Add the parent directory to sys.path so we can import modules\n",
    "sys.path.append(parent_dir)\n",
    "\n",
    "# Verify the path\n",
    "print(f\"Added to sys.path: {parent_dir}\")\n",
    "\n",
    "# Add it to sys.path\n",
    "sys.path.append(parent_dir)\n",
    "\n",
    "print(parent_dir)\n",
    "from localityaware.module import *\n",
    "from NSGA_nn.nsga import *\n",
    "from FlashOperation.Refrig2DrumHeatExConstrDummy import Refrig2DrumConstraintHeatExConstDummy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating new data...\n",
      "The cost is 450.00\n",
      "The cost is 361.11\n",
      "The cost is 294.44\n",
      "The cost is 250.00\n",
      "The cost is 227.78\n",
      "The cost is 227.78\n",
      "The cost is 250.00\n",
      "The cost is 294.44\n",
      "The cost is 361.11\n",
      "The cost is 450.00\n",
      "The cost is 361.11\n",
      "The cost is 272.22\n",
      "The cost is 205.56\n",
      "The cost is 161.11\n",
      "The cost is 138.89\n",
      "The cost is 138.89\n",
      "The cost is 161.11\n",
      "The cost is 205.56\n",
      "The cost is 272.22\n",
      "The cost is 361.11\n",
      "The cost is 294.44\n",
      "The cost is 205.56\n",
      "The cost is 138.89\n",
      "The cost is 94.44\n",
      "The cost is 72.22\n",
      "The cost is 72.22\n",
      "The cost is 94.44\n",
      "The cost is 138.89\n",
      "The cost is 205.56\n",
      "The cost is 294.44\n",
      "The cost is 250.00\n",
      "The cost is 161.11\n",
      "The cost is 94.44\n",
      "The cost is 50.00\n",
      "The cost is 27.78\n",
      "The cost is 27.78\n",
      "The cost is 50.00\n",
      "The cost is 94.44\n",
      "The cost is 161.11\n",
      "The cost is 250.00\n",
      "The cost is 227.78\n",
      "The cost is 138.89\n",
      "The cost is 72.22\n",
      "The cost is 27.78\n",
      "The cost is 5.56\n",
      "The cost is 5.56\n",
      "The cost is 27.78\n",
      "The cost is 72.22\n",
      "The cost is 138.89\n",
      "The cost is 227.78\n",
      "The cost is 227.78\n",
      "The cost is 138.89\n",
      "The cost is 72.22\n",
      "The cost is 27.78\n",
      "The cost is 5.56\n",
      "The cost is 5.56\n",
      "The cost is 27.78\n",
      "The cost is 72.22\n",
      "The cost is 138.89\n",
      "The cost is 227.78\n",
      "The cost is 250.00\n",
      "The cost is 161.11\n",
      "The cost is 94.44\n",
      "The cost is 50.00\n",
      "The cost is 27.78\n",
      "The cost is 27.78\n",
      "The cost is 50.00\n",
      "The cost is 94.44\n",
      "The cost is 161.11\n",
      "The cost is 250.00\n",
      "The cost is 294.44\n",
      "The cost is 205.56\n",
      "The cost is 138.89\n",
      "The cost is 94.44\n",
      "The cost is 72.22\n",
      "The cost is 72.22\n",
      "The cost is 94.44\n",
      "The cost is 138.89\n",
      "The cost is 205.56\n",
      "The cost is 294.44\n",
      "The cost is 361.11\n",
      "The cost is 272.22\n",
      "The cost is 205.56\n",
      "The cost is 161.11\n",
      "The cost is 138.89\n",
      "The cost is 138.89\n",
      "The cost is 161.11\n",
      "The cost is 205.56\n",
      "The cost is 272.22\n",
      "The cost is 361.11\n",
      "The cost is 450.00\n",
      "The cost is 361.11\n",
      "The cost is 294.44\n",
      "The cost is 250.00\n",
      "The cost is 227.78\n",
      "The cost is 227.78\n",
      "The cost is 250.00\n",
      "The cost is 294.44\n",
      "The cost is 361.11\n",
      "The cost is 450.00\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "import time\n",
    "\n",
    "# Define the file path for saving/loading the data\n",
    "data_file = \"flash_simulation_data_sim_new.pkl\"\n",
    "\n",
    "# Define parameter ranges\n",
    "flash_1_range_sim = np.linspace(-15, 15, 10)\n",
    "flash_2_range_sim = np.linspace(-15, 15, 10)\n",
    "\n",
    "print(\"Generating new data...\")\n",
    "assSim = Refrig2DrumConstraintHeatExConstDummy(AspenFile=\"../FlashOperation/FlashOperation_HeatExchanger.bkp\",\n",
    "                                        wdpath=\"../FlashOperation\",\n",
    "                                        visibility=False,\n",
    "                                        Penalty=1e3)\n",
    "\n",
    "start_time = time.time()  # Start timing\n",
    "data_sim = []\n",
    "for flash_1 in flash_1_range_sim:\n",
    "    for flash_2 in flash_2_range_sim:\n",
    "        x_unflat = assSim.unflatten_params([float(flash_1), float(flash_2)])\n",
    "        data_sim.append([flash_1, flash_2, assSim.run_obj(x_unflat)])\n",
    "\n",
    "data_sim = np.array(data_sim)\n",
    "data_gen_time = time.time() - start_time  # Total time to generate data\n",
    "total_original_assSim_calls = len(data_sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# import numpy as np\n",
    "# from scipy.interpolate import griddata\n",
    "\n",
    "# def plot_contour_surface(data, x_label, y_label, z_label, x_point=None, gradient=None):\n",
    "#     \"\"\"\n",
    "#     Generate a high-resolution heatmap with contour lines based on the given 3D data.\n",
    "#     Optionally overlays a single point (x_point) and its gradient vector on the plot.\n",
    "#     \"\"\"\n",
    "#     # Convert data to numpy array for easier manipulation\n",
    "#     data = np.array(data)\n",
    "#     x, y, z = data[:, 0], data[:, 1], data[:, 2]\n",
    "\n",
    "#     # Generate a finer grid for interpolation\n",
    "#     grid_x, grid_y = np.meshgrid(\n",
    "#         np.linspace(x.min(), x.max(), 200),\n",
    "#         np.linspace(y.min(), y.max(), 200)\n",
    "#     )\n",
    "    \n",
    "#     # Interpolate z values using cubic interpolation\n",
    "#     grid_z = griddata((x, y), z, (grid_x, grid_y), method='cubic')\n",
    "\n",
    "#     # Create the heatmap and add contour lines\n",
    "#     plt.figure(figsize=(8, 6))\n",
    "#     plt.imshow(grid_z, extent=[x.min(), x.max(), y.min(), y.max()], origin='lower', cmap='viridis', aspect='auto')\n",
    "#     plt.colorbar(label=z_label)\n",
    "\n",
    "#     contour_levels = np.linspace(np.nanmin(grid_z), np.nanmax(grid_z), 15)\n",
    "#     plt.contour(grid_x, grid_y, grid_z, levels=contour_levels, colors='black', linewidths=0.8)\n",
    "    \n",
    "#     # Plot the true optimal point\n",
    "#     true_optimal = np.array([-1.11, -0.5])\n",
    "#     plt.scatter(true_optimal[0], true_optimal[1], color='blue', zorder=5)\n",
    "#     plt.text(true_optimal[0], true_optimal[1], 'True Optimal', color='white', fontsize=10, ha='right')\n",
    "    \n",
    "#     # Plot the local minimum points\n",
    "#     local_minima = [np.array([0.84, -0.5]), np.array([0.27, -0.5])]\n",
    "#     for lm in local_minima:\n",
    "#         plt.scatter(lm[0], lm[1], color='orange', zorder=5)\n",
    "#         plt.text(lm[0], lm[1], 'Local Min', color='orange', fontsize=10, ha='right')\n",
    "    \n",
    "#     # Overlay the x point and gradient arrow if provided\n",
    "#     if x_point is not None and gradient is not None:\n",
    "#         # Convert the x and grad lists to NumPy arrays with float type\n",
    "#         gradient = np.asarray(gradient, dtype=float) # grad is grad_pred.tolist() passed in\n",
    "#         plt.quiver(\n",
    "#             x_point[0], x_point[1],\n",
    "#             gradient[0], gradient[1],\n",
    "#             color='red', angles='xy', scale_units='xy', scale=0.1, zorder=10\n",
    "#         )\n",
    "#         plt.scatter(x_point[0], x_point[1], color='red', zorder=10)  # Mark the point\n",
    "#         plt.text(x_point[0], x_point[1], 'x_point', color='red', fontsize=10, ha='left')\n",
    "    \n",
    "#     plt.xlabel(x_label)\n",
    "#     plt.ylabel(y_label)\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Extract columns\n",
    "# x, y, z = data_sim[:, 0], data_sim[:, 1], data_sim[:, 2]\n",
    "\n",
    "# # Generate a finer grid for interpolation\n",
    "# grid_x, grid_y = np.meshgrid(\n",
    "#     np.linspace(x.min(), x.max(), 200),  # Increased resolution\n",
    "#     np.linspace(y.min(), y.max(), 200)\n",
    "# )\n",
    "\n",
    "# # Interpolate z values using cubic interpolation\n",
    "# grid_z = griddata((x, y), z, (grid_x, grid_y), method='cubic')\n",
    "\n",
    "# # Create a high-resolution heatmap with contour lines\n",
    "# plt.figure(figsize=(8, 6))\n",
    "# plt.imshow(grid_z, extent=[x.min(), x.max(), y.min(), y.max()], origin='lower', cmap='viridis', aspect='auto')\n",
    "# plt.colorbar(label='Objective Value')\n",
    "\n",
    "# # Add contour lines\n",
    "# contour_levels = np.linspace(grid_z.min(), grid_z.max(), 15)  # Define contour levels\n",
    "# plt.contour(grid_x, grid_y, grid_z, levels=contour_levels, colors='black', linewidths=0.8)\n",
    "\n",
    "# # Add labels and title\n",
    "# plt.xlabel('Flash 1')\n",
    "# plt.ylabel('Flash 2')\n",
    "# plt.title('Fine-Grained Heatmap with Contour Lines')\n",
    "\n",
    "# # Show the plot\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "print(len(data_sim))\n",
    "scaler = TorchMinMaxScaler((-1, 1), \n",
    "                           max_vals=[15.0, 15.0],\n",
    "                           min_vals=[-15.0, -15.0],\n",
    "                           min_y=0,\n",
    "                           max_y=1e6 ,\n",
    "                           scale_y=True)\n",
    "#scale data_sim \n",
    "data_sim_xscaled, data_sim_yscaled = scaler.transform(data_sim[:, :2], data_sim[:, 2])\n",
    "\n",
    "#recombine the data\n",
    "data_sim_scaled = np.column_stack([data_sim_xscaled, data_sim_yscaled])\n",
    "\n",
    "# **Initialize Model & Datasets**\n",
    "dataset = DynamicDataset(data_sim_scaled)\n",
    "model = MLP(2, [20,20, 20], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0: Training surrogate model...\n",
      "Epoch 0: Total Loss=2.1054\n",
      "Epoch 50: Total Loss=0.1078\n",
      "Epoch 100: Total Loss=0.0215\n",
      "Epoch 150: Total Loss=0.0055\n",
      "Epoch 200: Total Loss=0.0020\n",
      "Epoch 250: Total Loss=0.0011\n",
      "Epoch 300: Total Loss=0.0007\n",
      "Epoch 350: Total Loss=0.0005\n",
      "Epoch 400: Total Loss=0.0003\n",
      "Epoch 450: Total Loss=0.0002\n",
      "Epoch 500: Total Loss=0.0002\n",
      "Epoch 550: Total Loss=0.0001\n",
      "Epoch 600: Total Loss=0.0001\n",
      "Epoch 650: Total Loss=0.0001\n",
      "Epoch 700: Total Loss=0.0001\n",
      "Epoch 750: Total Loss=0.0001\n",
      "Epoch 800: Total Loss=0.0000\n",
      "Epoch 850: Total Loss=0.0000\n",
      "Epoch 900: Total Loss=0.0000\n",
      "Epoch 950: Total Loss=0.0000\n",
      "=================================================\n",
      "n_gen  |  n_eval  |     f_avg     |     f_min    \n",
      "=================================================\n",
      "     1 |      100 | -1.000001E+00 | -1.008779E+00\n",
      "     2 |      200 | -1.003672E+00 | -1.008870E+00\n",
      "     3 |      300 | -1.006493E+00 | -1.008871E+00\n",
      "The cost is 46.15\n",
      "The cost is 46.15\n",
      "The cost is 43.78\n",
      "The cost is 51.26\n",
      "The cost is 47.92\n",
      "The cost is 52.91\n",
      "Iteration 0: Optimal input [ 1.7273293 -6.5700464], output 46.14917637713461, dataset size (106, 3)\n",
      "Iteration 1: Training surrogate model...\n",
      "Epoch 0: Total Loss=0.0361\n",
      "Epoch 50: Total Loss=0.0000\n",
      "Epoch 100: Total Loss=0.0000\n",
      "Epoch 150: Total Loss=0.0000\n",
      "Using previous population of size 100\n",
      "=================================================\n",
      "n_gen  |  n_eval  |     f_avg     |     f_min    \n",
      "=================================================\n",
      "     1 |      100 | -1.000643E+00 | -1.002045E+00\n",
      "     2 |      200 | -1.001484E+00 | -1.002084E+00\n",
      "     3 |      300 | -1.001841E+00 | -1.002085E+00\n",
      "The cost is 92.92\n",
      "The cost is 92.92\n",
      "The cost is 101.02\n",
      "The cost is 94.52\n",
      "The cost is 110.88\n",
      "The cost is 94.33\n",
      "Iteration 1: Optimal input [ 6.635603 -6.992284], output 92.923259558881, dataset size (112, 3)\n",
      "Iteration 2: Training surrogate model...\n",
      "Epoch 0: Total Loss=0.0125\n",
      "Epoch 50: Total Loss=0.0000\n",
      "Epoch 100: Total Loss=0.0000\n",
      "Epoch 150: Total Loss=0.0000\n",
      "Using previous population of size 100\n",
      "=================================================\n",
      "n_gen  |  n_eval  |     f_avg     |     f_min    \n",
      "=================================================\n",
      "     1 |      100 | -1.000361E+00 | -1.000800E+00\n",
      "     2 |      200 | -1.000532E+00 | -1.000841E+00\n",
      "     3 |      300 | -1.000675E+00 | -1.000871E+00\n",
      "The cost is 54.91\n",
      "The cost is 54.91\n",
      "The cost is 77.82\n",
      "The cost is 76.92\n",
      "The cost is 71.79\n",
      "The cost is 71.88\n",
      "Iteration 2: Optimal input [6.7734146 3.0049152], output 54.908661087687506, dataset size (118, 3)\n",
      "Iteration 3: Training surrogate model...\n",
      "Epoch 0: Total Loss=0.0163\n",
      "Epoch 50: Total Loss=0.0000\n",
      "Epoch 100: Total Loss=0.0000\n",
      "Epoch 150: Total Loss=0.0000\n",
      "Using previous population of size 100\n",
      "=================================================\n",
      "n_gen  |  n_eval  |     f_avg     |     f_min    \n",
      "=================================================\n",
      "     1 |      100 | -9.996406E-01 | -1.000064E+00\n",
      "     2 |      200 | -9.998616E-01 | -1.000153E+00\n",
      "     3 |      300 | -1.000018E+00 | -1.000240E+00\n",
      "The cost is 157.92\n",
      "The cost is 157.92\n",
      "The cost is 153.45\n",
      "The cost is 133.95\n",
      "The cost is 138.45\n",
      "The cost is 138.35\n",
      "Iteration 3: Optimal input [  6.5587883 -10.7193165], output 157.92144981139063, dataset size (124, 3)\n",
      "Iteration 4: Training surrogate model...\n",
      "Epoch 0: Total Loss=0.0071\n",
      "Epoch 50: Total Loss=0.0000\n",
      "Epoch 100: Total Loss=0.0000\n",
      "Epoch 150: Total Loss=0.0000\n",
      "Using previous population of size 100\n",
      "=================================================\n",
      "n_gen  |  n_eval  |     f_avg     |     f_min    \n",
      "=================================================\n",
      "     1 |      100 | -1.000197E+00 | -1.000557E+00\n",
      "     2 |      200 | -1.000429E+00 | -1.000579E+00\n",
      "     3 |      300 | -1.000530E+00 | -1.000582E+00\n",
      "The cost is 155.94\n",
      "The cost is 155.94\n",
      "The cost is 155.73\n",
      "The cost is 157.02\n",
      "The cost is 149.40\n",
      "The cost is 158.92\n",
      "Iteration 4: Optimal input [10.257189  7.122221], output 155.93595389097027, dataset size (130, 3)\n",
      "Iteration 5: Training surrogate model...\n",
      "Epoch 0: Total Loss=0.0109\n",
      "Epoch 50: Total Loss=0.0000\n",
      "Epoch 100: Total Loss=0.0000\n",
      "Epoch 150: Total Loss=0.0000\n",
      "Using previous population of size 100\n",
      "=================================================\n",
      "n_gen  |  n_eval  |     f_avg     |     f_min    \n",
      "=================================================\n",
      "     1 |      100 | -9.997013E-01 | -9.999008E-01\n",
      "     2 |      200 | -9.997555E-01 | -1.000195E+00\n",
      "     3 |      300 | -9.998580E-01 | -1.000196E+00\n",
      "The cost is 26.52\n",
      "The cost is 26.52\n",
      "The cost is 26.63\n",
      "The cost is 21.60\n",
      "The cost is 35.30\n",
      "The cost is 56.30\n",
      "Iteration 5: Optimal input [4.25387   2.9024315], output 26.51951860792542, dataset size (136, 3)\n",
      "Iteration 6: Training surrogate model...\n",
      "Epoch 0: Total Loss=0.0071\n",
      "Epoch 50: Total Loss=0.0000\n",
      "Epoch 100: Total Loss=0.0000\n",
      "Epoch 150: Total Loss=0.0000\n",
      "Using previous population of size 100\n",
      "=================================================\n",
      "n_gen  |  n_eval  |     f_avg     |     f_min    \n",
      "=================================================\n",
      "     1 |      100 | -9.998052E-01 | -1.000254E+00\n",
      "     2 |      200 | -9.999884E-01 | -1.000254E+00\n",
      "     3 |      300 | -1.000143E+00 | -1.000254E+00\n",
      "The cost is 21.60\n",
      "The cost is 21.60\n",
      "The cost is 8.77\n",
      "The cost is 25.11\n",
      "The cost is 19.50\n",
      "The cost is 23.29\n",
      "Iteration 6: Optimal input [4.5558434 0.9162998], output 21.595314019581565, dataset size (142, 3)\n",
      "Iteration 7: Training surrogate model...\n",
      "Epoch 0: Total Loss=0.0062\n",
      "Epoch 50: Total Loss=0.0000\n",
      "Epoch 100: Total Loss=0.0000\n",
      "Epoch 150: Total Loss=0.0000\n",
      "Using previous population of size 100\n",
      "=================================================\n",
      "n_gen  |  n_eval  |     f_avg     |     f_min    \n",
      "=================================================\n",
      "     1 |      100 | -9.998864E-01 | -1.000036E+00\n",
      "     2 |      200 | -9.999679E-01 | -1.000037E+00\n",
      "     3 |      300 | -1.000003E+00 | -1.000038E+00\n",
      "The cost is 10.89\n",
      "The cost is 10.89\n",
      "The cost is 12.12\n",
      "The cost is 8.59\n",
      "The cost is 10.68\n",
      "The cost is 9.52\n",
      "Iteration 7: Optimal input [-0.5984459  3.2457619], output 10.893107611482264, dataset size (148, 3)\n",
      "Iteration 8: Training surrogate model...\n",
      "Epoch 0: Total Loss=0.0058\n",
      "Epoch 50: Total Loss=0.0000\n",
      "Epoch 100: Total Loss=0.0000\n",
      "Epoch 150: Total Loss=0.0000\n",
      "Using previous population of size 100\n",
      "=================================================\n",
      "n_gen  |  n_eval  |     f_avg     |     f_min    \n",
      "=================================================\n",
      "     1 |      100 | -1.000059E+00 | -1.000112E+00\n",
      "     2 |      200 | -1.000095E+00 | -1.000112E+00\n",
      "     3 |      300 | -1.000105E+00 | -1.000112E+00\n",
      "The cost is 18.82\n",
      "The cost is 18.82\n",
      "The cost is 20.32\n",
      "The cost is 18.19\n",
      "The cost is 17.79\n",
      "The cost is 18.20\n",
      "Iteration 8: Optimal input [4.219805  1.0043888], output 18.815549124592508, dataset size (154, 3)\n",
      "Iteration 9: Training surrogate model...\n",
      "Epoch 0: Total Loss=0.0059\n",
      "Epoch 50: Total Loss=0.0000\n",
      "Epoch 100: Total Loss=0.0000\n",
      "Epoch 150: Total Loss=0.0000\n",
      "Using previous population of size 100\n",
      "=================================================\n",
      "n_gen  |  n_eval  |     f_avg     |     f_min    \n",
      "=================================================\n",
      "     1 |      100 | -9.999308E-01 | -9.999502E-01\n",
      "     2 |      200 | -9.999416E-01 | -9.999534E-01\n",
      "     3 |      300 | -9.999462E-01 | -9.999537E-01\n",
      "The cost is 39.11\n",
      "The cost is 39.11\n",
      "The cost is 43.29\n",
      "The cost is 45.25\n",
      "The cost is 42.35\n",
      "The cost is 46.26\n",
      "Iteration 9: Optimal input [6.2123566 0.7167883], output 39.10715957575394, dataset size (160, 3)\n"
     ]
    }
   ],
   "source": [
    "out = optimize_surr_nsga(model=model,\n",
    "                   dataset=dataset,\n",
    "                   assSim=assSim,\n",
    "                   lrs={'first':1e-3, 'others':1e-2},\n",
    "                   epochs={'first':1000, 'others':200},\n",
    "                   min_vals=scaler.min_x,\n",
    "                   max_vals=scaler.max_x,\n",
    "                   scaler=scaler,\n",
    "                   device='cpu',\n",
    "                   iter=10,\n",
    "                   print_loss=True,\n",
    "                   print_it_data=True,\n",
    "                   pop_size=100,\n",
    "                   n_gen = 3,\n",
    "                   new_data_size=5,\n",
    "                   batch_size=50\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results will be saved in: results/quadratic/run_2025-04-11_18-22-01\n",
      "Saved all results in results/quadratic/run_2025-04-11_18-22-01\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import datetime\n",
    "import pickle\n",
    "\n",
    "# Get current notebook name manually (or hardcode it here)\n",
    "notebook_name = \"quadratic\"  # or os.path.basename(__file__).replace(\".py\", \"\")\n",
    "\n",
    "# Get timestamp\n",
    "now = datetime.datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "\n",
    "# Construct path: results/<notebook_name>/run_<timestamp>/\n",
    "base_dir = os.path.join(\"results\", notebook_name)\n",
    "save_dir = os.path.join(base_dir, f\"run_{now}\")\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "print(f\"Results will be saved in: {save_dir}\")\n",
    "\n",
    "# Save out.pkl\n",
    "out[\"data_gen_time\"] = data_gen_time\n",
    "out[\"total_original_assSim_calls\"] = total_original_assSim_calls\n",
    "with open(os.path.join(save_dir, \"out.pkl\"), \"wb\") as f:\n",
    "    pickle.dump(out, f)\n",
    "\n",
    "# Save scaler\n",
    "with open(os.path.join(save_dir, \"scaler.pkl\"), \"wb\") as f:\n",
    "    pickle.dump(scaler, f)\n",
    "\n",
    "# Save dataset\n",
    "with open(os.path.join(save_dir, \"dataset.pkl\"), \"wb\") as f:\n",
    "    pickle.dump(dataset, f)\n",
    "\n",
    "print(f\"Saved all results in {save_dir}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
