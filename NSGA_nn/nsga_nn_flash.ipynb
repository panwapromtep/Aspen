{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install torch\n",
    "# %pip install pymoo\n",
    "# %pip install pywin32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added to sys.path: /Users/panwapromtep/Library/CloudStorage/OneDrive-JohnsHopkins/Process Design/Aspen\n",
      "/Users/panwapromtep/Library/CloudStorage/OneDrive-JohnsHopkins/Process Design/Aspen\n",
      "['/Users/panwapromtep/miniforge3/envs/torch/lib/python312.zip', '/Users/panwapromtep/miniforge3/envs/torch/lib/python3.12', '/Users/panwapromtep/miniforge3/envs/torch/lib/python3.12/lib-dynload', '', '/Users/panwapromtep/miniforge3/envs/torch/lib/python3.12/site-packages', '/Users/panwapromtep/Library/CloudStorage/OneDrive-JohnsHopkins/Process Design/Aspen', '/Users/panwapromtep/Library/CloudStorage/OneDrive-JohnsHopkins/Process Design/Aspen', '/Users/panwapromtep/Library/CloudStorage/OneDrive-JohnsHopkins/Process Design/Aspen']\n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "\n",
    "# Get the absolute path of the notebook's directory\n",
    "notebook_dir = os.getcwd()\n",
    "\n",
    "# Navigate to the parent directory\n",
    "parent_dir = os.path.abspath(os.path.join(notebook_dir, \"..\"))\n",
    "\n",
    "# Add the parent directory to sys.path so we can import modules\n",
    "sys.path.append(parent_dir)\n",
    "\n",
    "# Verify the path\n",
    "print(f\"Added to sys.path: {parent_dir}\")\n",
    "\n",
    "# Add it to sys.path\n",
    "sys.path.append(parent_dir)\n",
    "\n",
    "print(parent_dir)\n",
    "from localityaware.module import *\n",
    "from NSGA_nn.nsga import *\n",
    "#from FlashOperation.Refrig2DrumHeatExConstr1 import Refrig2DrumConstraintHeatExConstrforNN, Refrig2Drumproblem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "import time\n",
    "\n",
    "# Define the file path for saving/loading the data\n",
    "data_file = \"flash_simulation_data_sim_new.pkl\"\n",
    "\n",
    "\n",
    "\n",
    "print(\"Generating new data...\")\n",
    "assSim = Refrig2DrumConstraintHeatExConstrforNN(AspenFile=\"../FlashOperation/FlashOperation_HeatExchanger.bkp\",\n",
    "                                        wdpath=\"../FlashOperation\",\n",
    "                                        visibility=False\n",
    "                                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "Loaded cache (shape=(49, 4), sim calls=49, gen time=20.15s)\n",
      "data shape: (49, 4)\n",
      "sim time (s): 20.154319047927856\n",
      "assSim calls: 49\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import pickle\n",
    "\n",
    "CACHE_FILE = \"../FlashOperation/results/flash/data_sim_cache.pkl\"\n",
    "print(os.path.exists(CACHE_FILE))\n",
    "# Try to load from pickle cache\n",
    "if os.path.exists(CACHE_FILE):\n",
    "    with open(CACHE_FILE, \"rb\") as f:\n",
    "        cache = pickle.load(f)\n",
    "    data_sim                    = cache[\"data\"]\n",
    "    data_gen_time               = cache[\"gen_time\"]\n",
    "    total_original_assSim_calls = cache[\"assSim_calls\"]\n",
    "    flash_1_range               = cache[\"flash_1_range\"]\n",
    "    flash_2_range               = cache[\"flash_2_range\"]\n",
    "    print(f\"Loaded cache (shape={data_sim.shape}, sim calls={total_original_assSim_calls}, gen time={data_gen_time:.2f}s)\")\n",
    "else:\n",
    "    # Define parameter ranges\n",
    "    flash_1_range = np.linspace(1, 20, 7)\n",
    "    flash_2_range = np.linspace(1, 20, 7)\n",
    "\n",
    "    start_time = time.time()\n",
    "    data_sim = []\n",
    "    for flash_1 in flash_1_range:\n",
    "        for flash_2 in flash_2_range:\n",
    "            print(flash_1, flash_2)\n",
    "            x_unflat = assSim.unflatten_params([float(flash_1), float(flash_2)])\n",
    "            f, g = assSim.run_obj(x_unflat)\n",
    "            data_sim.append([flash_1, flash_2, f, g])\n",
    "\n",
    "    data_sim = np.array(data_sim, dtype=float)\n",
    "    data_gen_time               = time.time() - start_time\n",
    "    total_original_assSim_calls = len(data_sim)\n",
    "\n",
    "    # Build cache dict\n",
    "    cache = {\n",
    "        \"data\": data_sim,\n",
    "        \"gen_time\": data_gen_time,\n",
    "        \"assSim_calls\": total_original_assSim_calls,\n",
    "        \"flash_1_range\": flash_1_range,\n",
    "        \"flash_2_range\": flash_2_range,\n",
    "    }\n",
    "    # Write to pickle\n",
    "    with open(CACHE_FILE, \"wb\") as f:\n",
    "        pickle.dump(cache, f)\n",
    "    print(f\"Simulation done in {data_gen_time:.2f}s → saved to {CACHE_FILE}\")\n",
    "\n",
    "print(\"data shape:\", data_sim.shape)\n",
    "print(\"sim time (s):\", data_gen_time)\n",
    "print(\"assSim calls:\", total_original_assSim_calls)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples: 49\n",
      "dtype: float64\n",
      "first 5 rows:\n",
      " [[ 1.00000000e+00  1.00000000e+00  2.30606519e+04 -6.50630049e+01]\n",
      " [ 1.00000000e+00  4.16666667e+00  3.84869866e+04 -6.54195554e+01]\n",
      " [ 1.00000000e+00  7.33333333e+00  5.67770989e+04 -6.35082882e+01]\n",
      " [ 1.00000000e+00  1.05000000e+01  6.19077758e+04 -6.58798164e+01]\n",
      " [ 1.00000000e+00  1.36666667e+01  6.64762071e+04 -6.62571315e+01]]\n",
      "Found 3 NaNs in column 3 – replacing with 30.0\n",
      "Scaled data shape: (49, 4)\n",
      "First 5 rows scaled:\n",
      " [[-1.         -1.         -0.8894203  -0.46250772]\n",
      " [-1.         -0.6666667  -0.8120953  -0.46799314]\n",
      " [-1.         -0.3333333  -0.7204156  -0.4385891 ]\n",
      " [-1.          0.         -0.69469786 -0.47507405]\n",
      " [-1.          0.33333337 -0.67179847 -0.48087895]]\n",
      "✅ Dataset and model ready. No NaNs remain, and scaling is applied correctly.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# ---- Inspect original data ----\n",
    "print(\"Number of samples:\", len(data_sim))\n",
    "data_sim = data_sim.astype(float)\n",
    "print(\"dtype:\", data_sim.dtype)\n",
    "print(\"first 5 rows:\\n\", data_sim[:5])\n",
    "\n",
    "# ---- 1) Replace NaNs in the fourth column with 30 ----\n",
    "#    (column index 3 since Python is zero‑based)\n",
    "nan_mask = np.isnan(data_sim[:, 3])\n",
    "if np.any(nan_mask):\n",
    "    print(f\"Found {nan_mask.sum()} NaNs in column 3 – replacing with 30.0\")\n",
    "    data_sim[nan_mask, 3] = 30.0\n",
    "\n",
    "# ---- 2) Scale inputs & outputs correctly ----\n",
    "scaler = TorchMinMaxScaler(\n",
    "    feature_range=(-1, 1), \n",
    "    min_vals=[1, 1],\n",
    "    max_vals=[20, 20],\n",
    "    scale_y=True,\n",
    "    min_y=[1000, -100],\n",
    "    max_y=[4e5, 30]\n",
    ")\n",
    "\n",
    "# Prepare tensors\n",
    "X_raw = torch.tensor(data_sim[:, :2], dtype=torch.float32)\n",
    "Y_raw = torch.tensor(data_sim[:, 2:], dtype=torch.float32)\n",
    "\n",
    "# Transform\n",
    "X_scaled_t, Y_scaled_t = scaler.transform(X_raw, Y_raw)\n",
    "\n",
    "# Convert back to NumPy for your dataset\n",
    "X_scaled = X_scaled_t.detach().cpu().numpy()\n",
    "Y_scaled = Y_scaled_t.detach().cpu().numpy()\n",
    "\n",
    "# Combine into one array\n",
    "data_sim_scaled = np.hstack([X_scaled, Y_scaled])\n",
    "print(\"Scaled data shape:\", data_sim_scaled.shape)\n",
    "print(\"First 5 rows scaled:\\n\", data_sim_scaled[:5])\n",
    "\n",
    "# ---- Initialize your dataset & model ----\n",
    "dataset = DynamicDataset(data_sim_scaled, num_inputs=2)\n",
    "model   = MLP(2, [20, 20, 20], 2)\n",
    "\n",
    "print(\"✅ Dataset and model ready. No NaNs remain, and scaling is applied correctly.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "problem = Refrig2Drumproblem(model, scaler)\n",
    "def my_ga_factory(it, prev_pop):\n",
    "    if prev_pop is None:\n",
    "        return GA(\n",
    "            pop_size=1000,\n",
    "            sampling=LHS(),\n",
    "            eliminate_duplicates=False\n",
    "        )\n",
    "    else:\n",
    "        return GA(\n",
    "            pop_size=1000,\n",
    "            sampling=ResumeFromPopulation(prev_pop),\n",
    "            eliminate_duplicates=False\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0: Training surrogate model...\n",
      "data_point: [tensor([[ 0.0000, -1.0000],\n",
      "        [-0.6667,  0.6667],\n",
      "        [-1.0000,  0.0000],\n",
      "        [ 1.0000,  0.0000],\n",
      "        [ 0.3333, -1.0000],\n",
      "        [-0.3333,  0.6667],\n",
      "        [ 1.0000, -1.0000],\n",
      "        [ 0.0000,  1.0000],\n",
      "        [-0.6667, -1.0000],\n",
      "        [ 0.0000,  0.3333],\n",
      "        [ 0.0000, -0.3333],\n",
      "        [ 0.6667, -0.3333],\n",
      "        [-1.0000, -0.3333],\n",
      "        [ 0.3333,  1.0000],\n",
      "        [ 0.0000,  0.0000],\n",
      "        [ 1.0000, -0.3333],\n",
      "        [-0.3333,  0.3333],\n",
      "        [-0.3333,  0.0000],\n",
      "        [ 0.6667,  0.6667],\n",
      "        [-0.6667, -0.3333],\n",
      "        [ 0.6667,  1.0000],\n",
      "        [-0.6667, -0.6667],\n",
      "        [ 0.6667, -1.0000],\n",
      "        [ 0.0000,  0.6667],\n",
      "        [-1.0000,  0.6667],\n",
      "        [ 0.3333, -0.3333],\n",
      "        [ 0.3333,  0.3333],\n",
      "        [-0.6667,  0.3333],\n",
      "        [ 0.6667,  0.3333],\n",
      "        [-0.3333, -1.0000],\n",
      "        [-0.3333, -0.6667],\n",
      "        [ 0.3333, -0.6667],\n",
      "        [ 0.3333,  0.0000],\n",
      "        [-0.3333, -0.3333],\n",
      "        [ 0.6667, -0.6667],\n",
      "        [ 1.0000,  0.6667],\n",
      "        [-1.0000,  1.0000],\n",
      "        [ 1.0000,  0.3333],\n",
      "        [-1.0000,  0.3333],\n",
      "        [ 1.0000,  1.0000],\n",
      "        [-1.0000, -0.6667],\n",
      "        [ 0.6667,  0.0000],\n",
      "        [-0.3333,  1.0000],\n",
      "        [-1.0000, -1.0000],\n",
      "        [-0.6667,  1.0000],\n",
      "        [-0.6667,  0.0000],\n",
      "        [ 0.0000, -0.6667],\n",
      "        [ 1.0000, -0.6667],\n",
      "        [ 0.3333,  0.6667]]), tensor([[-0.9703, -0.4887],\n",
      "        [-0.9957,  0.0777],\n",
      "        [-0.6947, -0.4751],\n",
      "        [-1.0033,  0.5909],\n",
      "        [-0.9769, -0.4855],\n",
      "        [-1.0016,  0.3770],\n",
      "        [-0.9777, -0.4872],\n",
      "        [-1.0034,  0.5919],\n",
      "        [-0.6943,  1.0000],\n",
      "        [-1.0034,  0.5913],\n",
      "        [-1.0022,  0.3783],\n",
      "        [-1.0021,  0.3783],\n",
      "        [-0.7204, -0.4386],\n",
      "        [-1.0042,  0.7636],\n",
      "        [-1.0034,  0.5909],\n",
      "        [-1.0016,  0.3783],\n",
      "        [-1.0016,  0.3775],\n",
      "        [-1.0016,  0.3779],\n",
      "        [-1.0047,  0.9052],\n",
      "        [-0.7097,  1.0000],\n",
      "        [-1.0047,  0.9075],\n",
      "        [-0.7724,  1.0000],\n",
      "        [-0.9776, -0.4865],\n",
      "        [-1.0034,  0.5917],\n",
      "        [-0.6459, -0.4830],\n",
      "        [-1.0023,  0.3783],\n",
      "        [-1.0042,  0.7611],\n",
      "        [-0.9958,  0.0789],\n",
      "        [-1.0043,  0.7611],\n",
      "        [-0.9635, -0.4864],\n",
      "        [-0.9984,  0.0825],\n",
      "        [-0.9991,  0.0821],\n",
      "        [-1.0036,  0.5909],\n",
      "        [-1.0016,  0.3783],\n",
      "        [-0.9987,  0.0841],\n",
      "        [-1.0047,  0.9052],\n",
      "        [-0.6199, -0.4852],\n",
      "        [-1.0042,  0.7611],\n",
      "        [-0.6718, -0.4809],\n",
      "        [-1.0050,  1.0314],\n",
      "        [-0.8121, -0.4680],\n",
      "        [-1.0035,  0.5909],\n",
      "        [-1.0016,  0.3765],\n",
      "        [-0.8894, -0.4625],\n",
      "        [-0.9957,  0.0764],\n",
      "        [-0.9437, -0.0355],\n",
      "        [-0.9991,  0.0825],\n",
      "        [-0.9979,  0.0825],\n",
      "        [-1.0042,  0.7624]])]\n",
      "tensor(0.6016, grad_fn=<MseLossBackward0>)\n",
      "Epoch 0: Total Loss=0.0000\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'bounds'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43moptimize_surr_ga\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m                   \u001b[49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m                   \u001b[49m\u001b[43massSim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43massSim\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m                   \u001b[49m\u001b[43mproblem\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproblem\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m                   \u001b[49m\u001b[43malgo_factory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmy_ga_factory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m                   \u001b[49m\u001b[43mlrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfirst\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m1e-4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mothers\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m1e-4\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m                   \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfirst\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m3000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mothers\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m500\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m                   \u001b[49m\u001b[43mscaler\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscaler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m                   \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcpu\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m                   \u001b[49m\u001b[38;5;28;43miter\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m                   \u001b[49m\u001b[43mprint_loss\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m                   \u001b[49m\u001b[43mprint_it_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m                   \u001b[49m\u001b[43mpop_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m                   \u001b[49m\u001b[43mn_gen\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m                   \u001b[49m\u001b[43mnew_data_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m15\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m                   \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m128\u001b[39;49m\n\u001b[1;32m     17\u001b[0m \u001b[43m                   \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/CloudStorage/OneDrive-JohnsHopkins/Process Design/Aspen/NSGA_nn/nsga.py:431\u001b[0m, in \u001b[0;36moptimize_surr_ga\u001b[0;34m(model, dataset, assSim, problem, algo_factory, lrs, epochs, batch_size, scaler, device, iter, pop_size, n_gen, new_data_size, print_loss, print_it_data)\u001b[0m\n\u001b[1;32m    428\u001b[0m algorithm \u001b[38;5;241m=\u001b[39m algo_factory(it, current_pop)\n\u001b[1;32m    430\u001b[0m \u001b[38;5;66;03m# run GA\u001b[39;00m\n\u001b[0;32m--> 431\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mminimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    432\u001b[0m \u001b[43m    \u001b[49m\u001b[43mproblem\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    433\u001b[0m \u001b[43m    \u001b[49m\u001b[43malgorithm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    434\u001b[0m \u001b[43m    \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mn_gen\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_gen\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    435\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    436\u001b[0m \u001b[43m    \u001b[49m\u001b[43msave_history\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[1;32m    437\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    439\u001b[0m \u001b[38;5;66;03m# update population\u001b[39;00m\n\u001b[1;32m    440\u001b[0m current_pop \u001b[38;5;241m=\u001b[39m res\u001b[38;5;241m.\u001b[39mpop\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniforge3/envs/torch/lib/python3.12/site-packages/pymoo/optimize.py:67\u001b[0m, in \u001b[0;36mminimize\u001b[0;34m(problem, algorithm, termination, copy_algorithm, copy_termination, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m     algorithm\u001b[38;5;241m.\u001b[39msetup(problem, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m     66\u001b[0m \u001b[38;5;66;03m# actually execute the algorithm\u001b[39;00m\n\u001b[0;32m---> 67\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43malgorithm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;66;03m# store the deep copied algorithm in the result object\u001b[39;00m\n\u001b[1;32m     70\u001b[0m res\u001b[38;5;241m.\u001b[39malgorithm \u001b[38;5;241m=\u001b[39m algorithm\n",
      "File \u001b[0;32m~/miniforge3/envs/torch/lib/python3.12/site-packages/pymoo/core/algorithm.py:138\u001b[0m, in \u001b[0;36mAlgorithm.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    137\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhas_next():\n\u001b[0;32m--> 138\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnext\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    139\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresult()\n",
      "File \u001b[0;32m~/miniforge3/envs/torch/lib/python3.12/site-packages/pymoo/core/algorithm.py:154\u001b[0m, in \u001b[0;36mAlgorithm.next\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mnext\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    152\u001b[0m \n\u001b[1;32m    153\u001b[0m     \u001b[38;5;66;03m# get the infill solutions\u001b[39;00m\n\u001b[0;32m--> 154\u001b[0m     infills \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minfill\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    156\u001b[0m     \u001b[38;5;66;03m# call the advance with them after evaluation\u001b[39;00m\n\u001b[1;32m    157\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m infills \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniforge3/envs/torch/lib/python3.12/site-packages/pymoo/core/algorithm.py:186\u001b[0m, in \u001b[0;36mAlgorithm.infill\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    183\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_initialize()\n\u001b[1;32m    185\u001b[0m     \u001b[38;5;66;03m# execute the initialization infill of the algorithm\u001b[39;00m\n\u001b[0;32m--> 186\u001b[0m     infills \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_initialize_infill\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    188\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    189\u001b[0m     \u001b[38;5;66;03m# request the infill solutions if the algorithm has implemented it\u001b[39;00m\n\u001b[1;32m    190\u001b[0m     infills \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_infill()\n",
      "File \u001b[0;32m~/miniforge3/envs/torch/lib/python3.12/site-packages/pymoo/algorithms/base/genetic.py:75\u001b[0m, in \u001b[0;36mGeneticAlgorithm._initialize_infill\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_initialize_infill\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m---> 75\u001b[0m     pop \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minitialization\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdo\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mproblem\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpop_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malgorithm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     76\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m pop\n",
      "File \u001b[0;32m~/miniforge3/envs/torch/lib/python3.12/site-packages/pymoo/core/initialization.py:32\u001b[0m, in \u001b[0;36mInitialization.do\u001b[0;34m(self, problem, n_samples, **kwargs)\u001b[0m\n\u001b[1;32m     30\u001b[0m         pop \u001b[38;5;241m=\u001b[39m Population\u001b[38;5;241m.\u001b[39mnew(X\u001b[38;5;241m=\u001b[39msampling)\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 32\u001b[0m         pop \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msampling\u001b[49m\u001b[43m(\u001b[49m\u001b[43mproblem\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_samples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;66;03m# repair all solutions that are not already evaluated\u001b[39;00m\n\u001b[1;32m     35\u001b[0m not_eval_yet \u001b[38;5;241m=\u001b[39m [k \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(pop)) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(pop[k]\u001b[38;5;241m.\u001b[39mevaluated) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/miniforge3/envs/torch/lib/python3.12/site-packages/pymoo/core/operator.py:27\u001b[0m, in \u001b[0;36mOperator.__call__\u001b[0;34m(self, problem, elem, to_numpy, *args, **kwargs)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, problem, elem, \u001b[38;5;241m*\u001b[39margs, to_numpy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m---> 27\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdo\u001b[49m\u001b[43m(\u001b[49m\u001b[43mproblem\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43melem\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     29\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     30\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m ind \u001b[38;5;129;01min\u001b[39;00m out:\n",
      "File \u001b[0;32m~/miniforge3/envs/torch/lib/python3.12/site-packages/pymoo/core/sampling.py:35\u001b[0m, in \u001b[0;36mSampling.do\u001b[0;34m(self, problem, n_samples, **kwargs)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdo\u001b[39m(\u001b[38;5;28mself\u001b[39m, problem, n_samples, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     17\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;124;03m    Sample new points with problem information if necessary.\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     33\u001b[0m \n\u001b[1;32m     34\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 35\u001b[0m     val \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do\u001b[49m\u001b[43m(\u001b[49m\u001b[43mproblem\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_samples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     36\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Population\u001b[38;5;241m.\u001b[39mnew(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m, val)\n",
      "File \u001b[0;32m~/miniforge3/envs/torch/lib/python3.12/site-packages/pymoo/operators/sampling/lhs.py:64\u001b[0m, in \u001b[0;36mLatinHypercubeSampling._do\u001b[0;34m(self, problem, n_samples, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_do\u001b[39m(\u001b[38;5;28mself\u001b[39m, problem, n_samples, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m---> 64\u001b[0m     xl, xu \u001b[38;5;241m=\u001b[39m \u001b[43mproblem\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbounds\u001b[49m()\n\u001b[1;32m     66\u001b[0m     X \u001b[38;5;241m=\u001b[39m sampling_lhs(n_samples, problem\u001b[38;5;241m.\u001b[39mn_var, xl\u001b[38;5;241m=\u001b[39mxl, xu\u001b[38;5;241m=\u001b[39mxu, smooth\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msmooth,\n\u001b[1;32m     67\u001b[0m                      criterion\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcriterion, n_iter\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miterations)\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m X\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'bounds'"
     ]
    }
   ],
   "source": [
    "out = optimize_surr_ga(model=model,\n",
    "                   dataset=dataset,\n",
    "                   assSim=assSim,\n",
    "                   problem=problem,\n",
    "                   algo_factory=my_ga_factory,\n",
    "                   lrs={'first':1e-4, 'others':1e-4},\n",
    "                   epochs={'first':3000, 'others':500},\n",
    "                   scaler=scaler,\n",
    "                   device='cpu',\n",
    "                   iter=10,\n",
    "                   print_loss=True,\n",
    "                   print_it_data=True,\n",
    "                   pop_size=1000,\n",
    "                   n_gen = 3,\n",
    "                   new_data_size=15,\n",
    "                   batch_size=128\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import datetime\n",
    "import pickle\n",
    "\n",
    "print(os.getcwd())\n",
    "# Get current notebook name manually (or hardcode it here)\n",
    "notebook_name = \"flash\"  # or os.path.basename(__file__).replace(\".py\", \"\")\n",
    "\n",
    "# Get timestamp\n",
    "now = datetime.datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "\n",
    "# Construct path: results/<notebook_name>/run_<timestamp>/\n",
    "base_dir = os.path.join(\"../NSGA_nn/results\", notebook_name)\n",
    "save_dir = os.path.join(base_dir, f\"run_{now}\")\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "print(save_dir)\n",
    "\n",
    "print(f\"Results will be saved in: {save_dir}\")\n",
    "\n",
    "# Save out.pkl\n",
    "out[\"data_gen_time\"] = data_gen_time\n",
    "out[\"total_original_assSim_calls\"] = total_original_assSim_calls\n",
    "with open(os.path.join(save_dir, \"out.pkl\"), \"wb\") as f:\n",
    "    pickle.dump(out, f)\n",
    "\n",
    "# Save scaler\n",
    "with open(os.path.join(save_dir, \"scaler.pkl\"), \"wb\") as f:\n",
    "    pickle.dump(scaler, f)\n",
    "\n",
    "# Save dataset\n",
    "with open(os.path.join(save_dir, \"dataset.pkl\"), \"wb\") as f:\n",
    "    pickle.dump(dataset, f)\n",
    "\n",
    "print(f\"Saved all results in {save_dir}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
