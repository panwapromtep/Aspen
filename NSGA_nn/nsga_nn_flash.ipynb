{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install torch\n",
    "# %pip install pymoo\n",
    "# %pip install pywin32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added to sys.path: C:\\Users\\conno\\OneDrive\\Desktop\\Aspen\\Aspen\n",
      "C:\\Users\\conno\\OneDrive\\Desktop\\Aspen\\Aspen\n",
      "['C:\\\\Program Files\\\\WindowsApps\\\\PythonSoftwareFoundation.Python.3.13_3.13.1008.0_x64__qbz5n2kfra8p0\\\\python313.zip', 'C:\\\\Program Files\\\\WindowsApps\\\\PythonSoftwareFoundation.Python.3.13_3.13.1008.0_x64__qbz5n2kfra8p0\\\\DLLs', 'C:\\\\Program Files\\\\WindowsApps\\\\PythonSoftwareFoundation.Python.3.13_3.13.1008.0_x64__qbz5n2kfra8p0\\\\Lib', 'C:\\\\Program Files\\\\WindowsApps\\\\PythonSoftwareFoundation.Python.3.13_3.13.1008.0_x64__qbz5n2kfra8p0', '', 'C:\\\\Users\\\\conno\\\\AppData\\\\Local\\\\Packages\\\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\\\LocalCache\\\\local-packages\\\\Python313\\\\site-packages', 'C:\\\\Users\\\\conno\\\\AppData\\\\Local\\\\Packages\\\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\\\LocalCache\\\\local-packages\\\\Python313\\\\site-packages\\\\win32', 'C:\\\\Users\\\\conno\\\\AppData\\\\Local\\\\Packages\\\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\\\LocalCache\\\\local-packages\\\\Python313\\\\site-packages\\\\win32\\\\lib', 'C:\\\\Users\\\\conno\\\\AppData\\\\Local\\\\Packages\\\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\\\LocalCache\\\\local-packages\\\\Python313\\\\site-packages\\\\Pythonwin', 'C:\\\\Program Files\\\\WindowsApps\\\\PythonSoftwareFoundation.Python.3.13_3.13.1008.0_x64__qbz5n2kfra8p0\\\\Lib\\\\site-packages', 'C:\\\\Users\\\\conno\\\\OneDrive\\\\Desktop\\\\Aspen\\\\Aspen', 'C:\\\\Users\\\\conno\\\\OneDrive\\\\Desktop\\\\Aspen\\\\Aspen', 'C:\\\\Users\\\\conno\\\\OneDrive\\\\Desktop\\\\Aspen\\\\Aspen']\n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "\n",
    "# Get the absolute path of the notebook's directory\n",
    "notebook_dir = os.getcwd()\n",
    "\n",
    "# Navigate to the parent directory\n",
    "parent_dir = os.path.abspath(os.path.join(notebook_dir, \"..\"))\n",
    "\n",
    "# Add the parent directory to sys.path so we can import modules\n",
    "sys.path.append(parent_dir)\n",
    "\n",
    "# Verify the path\n",
    "print(f\"Added to sys.path: {parent_dir}\")\n",
    "\n",
    "# Add it to sys.path\n",
    "sys.path.append(parent_dir)\n",
    "\n",
    "print(parent_dir)\n",
    "from localityaware.module import *\n",
    "from NSGA_nn.nsga import *\n",
    "from FlashOperation.Refrig2DrumHeatExConstr1 import Refrig2DrumConstraintHeatExConstrforNN, Refrig2Drumproblem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "import time\n",
    "\n",
    "# Define the file path for saving/loading the data\n",
    "data_file = \"flash_simulation_data_sim_new.pkl\"\n",
    "\n",
    "\n",
    "\n",
    "print(\"Generating new data...\")\n",
    "assSim = Refrig2DrumConstraintHeatExConstrforNN(AspenFile=\"../FlashOperation/FlashOperation_HeatExchanger.bkp\",\n",
    "                                        wdpath=\"../FlashOperation\",\n",
    "                                        visibility=False\n",
    "                                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import pickle\n",
    "\n",
    "CACHE_FILE = \"./results/flash/data_sim_cache.pkl\"\n",
    "print(os.path.exists(CACHE_FILE))\n",
    "# Try to load from pickle cache\n",
    "if os.path.exists(CACHE_FILE):\n",
    "    with open(CACHE_FILE, \"rb\") as f:\n",
    "        cache = pickle.load(f)\n",
    "    data_sim                    = cache[\"data\"]\n",
    "    data_gen_time               = cache[\"gen_time\"]\n",
    "    total_original_assSim_calls = cache[\"assSim_calls\"]\n",
    "    flash_1_range               = cache[\"flash_1_range\"]\n",
    "    flash_2_range               = cache[\"flash_2_range\"]\n",
    "    print(f\"Loaded cache (shape={data_sim.shape}, sim calls={total_original_assSim_calls}, gen time={data_gen_time:.2f}s)\")\n",
    "else:\n",
    "    # Define parameter ranges\n",
    "    flash_1_range = np.linspace(1, 20, 7)\n",
    "    flash_2_range = np.linspace(1, 20, 7)\n",
    "\n",
    "    start_time = time.time()\n",
    "    data_sim = []\n",
    "    for flash_1 in flash_1_range:\n",
    "        for flash_2 in flash_2_range:\n",
    "            print(flash_1, flash_2)\n",
    "            x_unflat = assSim.unflatten_params([float(flash_1), float(flash_2)])\n",
    "            f, g = assSim.run_obj(x_unflat)\n",
    "            data_sim.append([flash_1, flash_2, f, g])\n",
    "\n",
    "    data_sim = np.array(data_sim, dtype=float)\n",
    "    data_gen_time               = time.time() - start_time\n",
    "    total_original_assSim_calls = len(data_sim)\n",
    "\n",
    "    # Build cache dict\n",
    "    cache = {\n",
    "        \"data\": data_sim,\n",
    "        \"gen_time\": data_gen_time,\n",
    "        \"assSim_calls\": total_original_assSim_calls,\n",
    "        \"flash_1_range\": flash_1_range,\n",
    "        \"flash_2_range\": flash_2_range,\n",
    "    }\n",
    "    # Write to pickle\n",
    "    with open(CACHE_FILE, \"wb\") as f:\n",
    "        pickle.dump(cache, f)\n",
    "    print(f\"Simulation done in {data_gen_time:.2f}s â†’ saved to {CACHE_FILE}\")\n",
    "\n",
    "print(\"data shape:\", data_sim.shape)\n",
    "print(\"sim time (s):\", data_gen_time)\n",
    "print(\"assSim calls:\", total_original_assSim_calls)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(data_sim))\n",
    "scaler = TorchMinMaxScaler((-1, 1), \n",
    "                           max_vals=[20, 6],\n",
    "                           min_vals=[1, 1],\n",
    "                           min_y=[1000, -100],\n",
    "                           max_y=[4e5 ,30],\n",
    "                           scale_y=True)\n",
    "#scale data_sim \n",
    "data_sim = data_sim.astype(float)\n",
    "print(\"dtype:\", data_sim.dtype)\n",
    "print(\"first 5 rows:\\n\", data_sim[:5])\n",
    "\n",
    "data_sim_x = torch.tensor(data_sim[:,:2],dtype=torch.float32)\n",
    "data_sim_xscaled, data_sim_yscaled = scaler.transform(data_sim[:, :2], data_sim[:, 2:])\n",
    "\n",
    "#recombine the data\n",
    "data_sim_scaled = np.column_stack([data_sim_xscaled, data_sim_yscaled])\n",
    "\n",
    "# **Initialize Model & Datasets**\n",
    "dataset = DynamicDataset(data_sim_scaled)\n",
    "model = MLP(2, [20,20, 20], 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "problem = Refrig2Drumproblem(model, scaler)\n",
    "def my_ga_factory(it, prev_pop):\n",
    "    if prev_pop is None:\n",
    "        return GA(\n",
    "            pop_size=1000,\n",
    "            sampling=LHS(),\n",
    "            eliminate_duplicates=False\n",
    "        )\n",
    "    else:\n",
    "        return GA(\n",
    "            pop_size=1000,\n",
    "            sampling=ResumeFromPopulation(prev_pop),\n",
    "            eliminate_duplicates=False\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = optimize_surr_ga(model=model,\n",
    "                   dataset=dataset,\n",
    "                   assSim=assSim,\n",
    "                   problem=problem,\n",
    "                   algo_factory=my_ga_factory,\n",
    "                   lrs={'first':1e-4, 'others':1e-4},\n",
    "                   epochs={'first':3000, 'others':500},\n",
    "                   scaler=scaler,\n",
    "                   device='cpu',\n",
    "                   iter=10,\n",
    "                   print_loss=True,\n",
    "                   print_it_data=True,\n",
    "                   pop_size=1000,\n",
    "                   n_gen = 3,\n",
    "                   new_data_size=15,\n",
    "                   batch_size=128\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import datetime\n",
    "import pickle\n",
    "\n",
    "print(os.getcwd())\n",
    "# Get current notebook name manually (or hardcode it here)\n",
    "notebook_name = \"flash\"  # or os.path.basename(__file__).replace(\".py\", \"\")\n",
    "\n",
    "# Get timestamp\n",
    "now = datetime.datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "\n",
    "# Construct path: results/<notebook_name>/run_<timestamp>/\n",
    "base_dir = os.path.join(\"../NSGA_nn/results\", notebook_name)\n",
    "save_dir = os.path.join(base_dir, f\"run_{now}\")\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "print(save_dir)\n",
    "\n",
    "print(f\"Results will be saved in: {save_dir}\")\n",
    "\n",
    "# Save out.pkl\n",
    "out[\"data_gen_time\"] = data_gen_time\n",
    "out[\"total_original_assSim_calls\"] = total_original_assSim_calls\n",
    "with open(os.path.join(save_dir, \"out.pkl\"), \"wb\") as f:\n",
    "    pickle.dump(out, f)\n",
    "\n",
    "# Save scaler\n",
    "with open(os.path.join(save_dir, \"scaler.pkl\"), \"wb\") as f:\n",
    "    pickle.dump(scaler, f)\n",
    "\n",
    "# Save dataset\n",
    "with open(os.path.join(save_dir, \"dataset.pkl\"), \"wb\") as f:\n",
    "    pickle.dump(dataset, f)\n",
    "\n",
    "print(f\"Saved all results in {save_dir}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
