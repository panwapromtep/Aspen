{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added to sys.path: /Users/panwapromtep/Library/CloudStorage/OneDrive-JohnsHopkins/Process Design/Aspen\n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "\n",
    "# Get the absolute path of the notebook's directory\n",
    "notebook_dir = os.getcwd()\n",
    "\n",
    "# Navigate to the parent directory\n",
    "parent_dir = os.path.abspath(os.path.join(notebook_dir, \"..\"))\n",
    "\n",
    "# Add the parent directory to sys.path so we can import modules\n",
    "sys.path.append(parent_dir)\n",
    "\n",
    "# Verify the path\n",
    "print(f\"Added to sys.path: {parent_dir}\")\n",
    "\n",
    "# Add it to sys.path\n",
    "sys.path.append(parent_dir)\n",
    "\n",
    "from FlashOperation.Refrig2DrumHeatExConstrDummy import Refrig2DrumConstraintHeatExConstDummy\n",
    "from module import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ Dummy Mode: Skipping Aspen simulation initialization.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "flash_1_range = np.linspace(-1, 1, 20)\n",
    "flash_2_range = np.linspace(-1, 1, 20)\n",
    "\n",
    "assSim = Refrig2DrumConstraintHeatExConstDummy(AspenFile = \"./FlashOperation/FlashOperation.bkp\", \n",
    "                                   wdpath = \"./FlashOperation\", \n",
    "                                   visibility=False,\n",
    "                                   Penalty=1e4\n",
    "                                   )\n",
    "\n",
    "data = []\n",
    "for flash_1 in flash_1_range:\n",
    "    for flash_2 in flash_2_range:\n",
    "        x_unflat = assSim.unflatten_params([flash_1, flash_2])\n",
    "        data.append([flash_1, flash_2, assSim.run_obj(x_unflat)])\n",
    "data = np.array(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "flash_1_range = np.linspace(-1, 1, 100)\n",
    "flash_2_range = np.linspace(-1, 1, 100)\n",
    "\n",
    "\n",
    "data_big = []\n",
    "for flash_1 in flash_1_range:\n",
    "    for flash_2 in flash_2_range:\n",
    "        x_unflat = assSim.unflatten_params([flash_1, flash_2])\n",
    "        data_big.append([flash_1, flash_2, assSim.run_obj(x_unflat)])\n",
    "data_big = np.array(data_big)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "flash_1_range = np.linspace(-1, 1, 5)\n",
    "flash_2_range = np.linspace(-1, 1, 5)\n",
    "\n",
    "\n",
    "data_small = []\n",
    "for flash_1 in flash_1_range:\n",
    "    for flash_2 in flash_2_range:\n",
    "        x_unflat = assSim.unflatten_params([flash_1, flash_2])\n",
    "        data_small.append([flash_1, flash_2, assSim.run_obj(x_unflat)])\n",
    "data_small = np.array(data_small)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "def optimize_surrogate_model(\n",
    "    model, old_dataset, new_dataset, assSim, \n",
    "    optim_steps=40, N_s=5, lr=0.001, merge_interval=10,\n",
    "    x_init=torch.tensor([0.9, -0.9], dtype=torch.float32, requires_grad=True)\n",
    "):\n",
    "    \"\"\"\n",
    "    Performs online optimization using a surrogate model.\n",
    "\n",
    "    Args:\n",
    "    - model: Neural network model (MLP instance)\n",
    "    - old_dataset (OldDataSet): Historical dataset\n",
    "    - new_dataset (NewDataSet): New data storage\n",
    "    - assSim: Object with run_obj() function for objective evaluation\n",
    "    - optim_steps (int): Number of optimization steps\n",
    "    - N_s (int): Number of local samples per step\n",
    "    - lr (float): Learning rate for x updates\n",
    "    - merge_interval (int): Steps after which new data merges with old dataset\n",
    "\n",
    "    Returns:\n",
    "    - x_path (list): History of `x` points explored\n",
    "    - y_path (list): Corresponding objective function values\n",
    "    \"\"\"\n",
    "\n",
    "    # **Initialize Optimization Variables** \n",
    "    optimizer = torch.optim.Adam([x_init], lr=lr)\n",
    "\n",
    "    x_path, y_path = [], []\n",
    "\n",
    "    # **Optimization Loop**\n",
    "    for step in range(optim_steps):\n",
    "        print(f\"\\nStep {step + 1}/{optim_steps}\")\n",
    "\n",
    "        new_samples = []\n",
    "        \n",
    "        # Generate new local samples\n",
    "        for _ in range(N_s):\n",
    "            x = x_init.detach() + torch.randn_like(x_init) * 0.1\n",
    "            y = assSim.run_obj(assSim.unflatten_params(x))\n",
    "            new_samples.append(torch.cat((x, y.unsqueeze(0))).numpy())\n",
    "\n",
    "        # Add new samples to `NewDataSet`\n",
    "        new_dataset.add_samples(np.stack(new_samples))\n",
    "\n",
    "        # Train surrogate model\n",
    "        model = train_model(model, old_dataset, new_dataset)\n",
    "\n",
    "        # Merge new samples into old dataset every `merge_interval` steps\n",
    "        if step % merge_interval == 0:\n",
    "            old_dataset.merge(new_dataset.data)\n",
    "            new_dataset.clear()\n",
    "\n",
    "        # **Select Best Sample from Generated Samples**\n",
    "        new_samples_array = np.stack(new_samples)\n",
    "        best_sample_idx = np.argmin(new_samples_array[:, -1])  # Minimize objective function\n",
    "        x_init = torch.tensor(new_samples_array[best_sample_idx][:2], dtype=torch.float32, requires_grad=True)\n",
    "\n",
    "        # **Track Optimization Path**\n",
    "        x_path.append(x_init.tolist())\n",
    "        y_path.append(new_samples_array[best_sample_idx, -1])\n",
    "\n",
    "        # **Gradient-Based Update Using Surrogate Model**\n",
    "        optimizer.zero_grad()\n",
    "        y_pred = model(x_init)\n",
    "        grad = torch.autograd.grad(y_pred, x_init)[0]\n",
    "        optimizer.step()\n",
    "\n",
    "        print(f\"Updated x: {x_init.tolist()}, Function Value: {y_path[-1]}, Gradient: {grad.tolist()}\")\n",
    "\n",
    "    return x_path, y_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 1/40\n",
      "Epoch 0: Total Loss=6.1124\n",
      "Epoch 1: Total Loss=7.1633\n",
      "Epoch 2: Total Loss=6.2287\n",
      "Epoch 3: Total Loss=5.8909\n",
      "Epoch 4: Total Loss=6.9220\n",
      "Epoch 5: Total Loss=6.0147\n",
      "Epoch 6: Total Loss=5.6922\n",
      "Epoch 7: Total Loss=6.7033\n",
      "Epoch 8: Total Loss=5.8155\n",
      "Epoch 9: Total Loss=5.5083\n",
      "Updated x: [0.9160996675491333, -0.7360634207725525], Function Value: 1.3810279369354248, Gradient: [0.024571888148784637, -0.04308870807290077]\n",
      "\n",
      "Step 2/40\n",
      "Epoch 0: Total Loss=4.1546\n",
      "Epoch 1: Total Loss=3.9496\n",
      "Epoch 2: Total Loss=3.4490\n",
      "Epoch 3: Total Loss=4.0270\n",
      "Epoch 4: Total Loss=3.8213\n",
      "Epoch 5: Total Loss=3.3392\n",
      "Epoch 6: Total Loss=3.8946\n",
      "Epoch 7: Total Loss=3.6885\n",
      "Epoch 8: Total Loss=3.2231\n",
      "Epoch 9: Total Loss=3.7545\n",
      "Updated x: [0.8062655925750732, -0.7122756838798523], Function Value: 1.1574008464813232, Gradient: [0.05587337538599968, -0.17038433253765106]\n",
      "\n",
      "Step 3/40\n",
      "Epoch 0: Total Loss=0.3154\n",
      "Epoch 1: Total Loss=0.2205\n",
      "Epoch 2: Total Loss=0.3433\n",
      "Epoch 3: Total Loss=0.2856\n",
      "Epoch 4: Total Loss=0.3104\n",
      "Epoch 5: Total Loss=0.3101\n",
      "Epoch 6: Total Loss=0.2147\n",
      "Epoch 7: Total Loss=0.3384\n",
      "Epoch 8: Total Loss=0.2833\n",
      "Epoch 9: Total Loss=0.3057\n",
      "Updated x: [0.661819577217102, -0.6540660262107849], Function Value: 0.8658075332641602, Gradient: [0.07774915546178818, -0.18919013440608978]\n",
      "\n",
      "Step 4/40\n",
      "Epoch 0: Total Loss=0.1936\n",
      "Epoch 1: Total Loss=0.2667\n",
      "Epoch 2: Total Loss=0.3797\n",
      "Epoch 3: Total Loss=0.1692\n",
      "Epoch 4: Total Loss=0.1941\n",
      "Epoch 5: Total Loss=0.2670\n",
      "Epoch 6: Total Loss=0.3736\n",
      "Epoch 7: Total Loss=0.1668\n",
      "Epoch 8: Total Loss=0.1918\n",
      "Epoch 9: Total Loss=0.2659\n",
      "Updated x: [0.6740880012512207, -0.4249117374420166], Function Value: 0.6349446177482605, Gradient: [0.06805668771266937, -0.1591930389404297]\n",
      "\n",
      "Step 5/40\n",
      "Epoch 0: Total Loss=0.2684\n",
      "Epoch 1: Total Loss=0.2317\n",
      "Epoch 2: Total Loss=0.2848\n",
      "Epoch 3: Total Loss=0.2162\n",
      "Epoch 4: Total Loss=0.2182\n",
      "Epoch 5: Total Loss=0.2652\n",
      "Epoch 6: Total Loss=0.2314\n",
      "Epoch 7: Total Loss=0.2844\n",
      "Epoch 8: Total Loss=0.2156\n",
      "Epoch 9: Total Loss=0.2189\n",
      "Updated x: [0.640200138092041, -0.2436738759279251], Function Value: 0.4692331850528717, Gradient: [0.0373833030462265, -0.04047905281186104]\n",
      "\n",
      "Step 6/40\n",
      "Epoch 0: Total Loss=0.2949\n",
      "Epoch 1: Total Loss=0.1709\n",
      "Epoch 2: Total Loss=0.2516\n",
      "Epoch 3: Total Loss=0.1826\n",
      "Epoch 4: Total Loss=0.1573\n",
      "Epoch 5: Total Loss=0.2191\n",
      "Epoch 6: Total Loss=0.1971\n",
      "Epoch 7: Total Loss=0.2641\n",
      "Epoch 8: Total Loss=0.1988\n",
      "Epoch 9: Total Loss=0.1825\n",
      "Updated x: [0.6018614172935486, -0.10971197485923767], Function Value: 0.3742738664150238, Gradient: [0.01564641483128071, 0.05992020294070244]\n",
      "\n",
      "Step 7/40\n",
      "Epoch 0: Total Loss=0.1634\n",
      "Epoch 1: Total Loss=0.2342\n",
      "Epoch 2: Total Loss=0.1720\n",
      "Epoch 3: Total Loss=0.2944\n",
      "Epoch 4: Total Loss=0.1163\n",
      "Epoch 5: Total Loss=0.1805\n",
      "Epoch 6: Total Loss=0.1845\n",
      "Epoch 7: Total Loss=0.1672\n",
      "Epoch 8: Total Loss=0.1381\n",
      "Epoch 9: Total Loss=0.2575\n",
      "Updated x: [0.44358402490615845, 0.016260623931884766], Function Value: 0.1970311999320984, Gradient: [0.006917777005583048, 0.06825610995292664]\n",
      "\n",
      "Step 8/40\n",
      "Epoch 0: Total Loss=0.1445\n",
      "Epoch 1: Total Loss=0.1697\n",
      "Epoch 2: Total Loss=0.2209\n",
      "Epoch 3: Total Loss=0.1984\n",
      "Epoch 4: Total Loss=0.1824\n",
      "Epoch 5: Total Loss=0.2216\n",
      "Epoch 6: Total Loss=0.1884\n",
      "Epoch 7: Total Loss=0.1311\n",
      "Epoch 8: Total Loss=0.1151\n",
      "Epoch 9: Total Loss=0.1464\n",
      "Updated x: [0.3403835594654083, -0.13535337150096893], Function Value: 0.13418149948120117, Gradient: [0.006622523069381714, 0.06975679844617844]\n",
      "\n",
      "Step 9/40\n",
      "Epoch 0: Total Loss=0.1219\n",
      "Epoch 1: Total Loss=0.1106\n",
      "Epoch 2: Total Loss=0.1307\n",
      "Epoch 3: Total Loss=0.1693\n",
      "Epoch 4: Total Loss=0.2305\n",
      "Epoch 5: Total Loss=0.1367\n",
      "Epoch 6: Total Loss=0.1838\n",
      "Epoch 7: Total Loss=0.1347\n",
      "Epoch 8: Total Loss=0.2105\n",
      "Epoch 9: Total Loss=0.1964\n",
      "Updated x: [0.1888793408870697, -0.13062146306037903], Function Value: 0.05273737385869026, Gradient: [0.0020713612902909517, 0.06448911875486374]\n",
      "\n",
      "Step 10/40\n",
      "Epoch 0: Total Loss=0.0950\n",
      "Epoch 1: Total Loss=0.1266\n",
      "Epoch 2: Total Loss=0.2329\n",
      "Epoch 3: Total Loss=0.1013\n",
      "Epoch 4: Total Loss=0.2036\n",
      "Epoch 5: Total Loss=0.2072\n",
      "Epoch 6: Total Loss=0.1404\n",
      "Epoch 7: Total Loss=0.1950\n",
      "Epoch 8: Total Loss=0.1063\n",
      "Epoch 9: Total Loss=0.1314\n",
      "Updated x: [0.09372175484895706, -0.06332295387983322], Function Value: 0.012793563306331635, Gradient: [-0.00033725163666531444, 0.06383182853460312]\n",
      "\n",
      "Step 11/40\n",
      "Epoch 0: Total Loss=0.0761\n",
      "Epoch 1: Total Loss=0.0879\n",
      "Epoch 2: Total Loss=0.1058\n",
      "Epoch 3: Total Loss=0.1538\n",
      "Epoch 4: Total Loss=0.1331\n",
      "Epoch 5: Total Loss=0.1560\n",
      "Epoch 6: Total Loss=0.1547\n",
      "Epoch 7: Total Loss=0.1061\n",
      "Epoch 8: Total Loss=0.2583\n",
      "Epoch 9: Total Loss=0.1819\n",
      "Updated x: [0.09494531899690628, -0.09529930353164673], Function Value: 0.018096569925546646, Gradient: [0.0005377875058911741, 0.04271279647946358]\n",
      "\n",
      "Step 12/40\n",
      "Epoch 0: Total Loss=0.0663\n",
      "Epoch 1: Total Loss=0.0660\n",
      "Epoch 2: Total Loss=0.0620\n",
      "Epoch 3: Total Loss=0.0656\n",
      "Epoch 4: Total Loss=0.0651\n",
      "Epoch 5: Total Loss=0.0618\n",
      "Epoch 6: Total Loss=0.0652\n",
      "Epoch 7: Total Loss=0.0649\n",
      "Epoch 8: Total Loss=0.0614\n",
      "Epoch 9: Total Loss=0.0648\n",
      "Updated x: [-0.01096537709236145, -0.02299310266971588], Function Value: 0.0006489222869277, Gradient: [-0.002117787254974246, 0.034650832414627075]\n",
      "\n",
      "Step 13/40\n",
      "Epoch 0: Total Loss=0.0654\n",
      "Epoch 1: Total Loss=0.0622\n",
      "Epoch 2: Total Loss=0.0624\n",
      "Epoch 3: Total Loss=0.0648\n",
      "Epoch 4: Total Loss=0.0626\n",
      "Epoch 5: Total Loss=0.0643\n",
      "Epoch 6: Total Loss=0.0623\n",
      "Epoch 7: Total Loss=0.0623\n",
      "Epoch 8: Total Loss=0.0645\n",
      "Epoch 9: Total Loss=0.0619\n",
      "Updated x: [-0.005180089268833399, 0.004011055454611778], Function Value: 4.2921892600134015e-05, Gradient: [-0.0006996922311373055, 0.01569526270031929]\n",
      "\n",
      "Step 14/40\n",
      "Epoch 0: Total Loss=0.0635\n",
      "Epoch 1: Total Loss=0.0611\n",
      "Epoch 2: Total Loss=0.0613\n",
      "Epoch 3: Total Loss=0.0615\n",
      "Epoch 4: Total Loss=0.0631\n",
      "Epoch 5: Total Loss=0.0613\n",
      "Epoch 6: Total Loss=0.0615\n",
      "Epoch 7: Total Loss=0.0609\n",
      "Epoch 8: Total Loss=0.0637\n",
      "Epoch 9: Total Loss=0.0614\n",
      "Updated x: [0.08385103195905685, 0.03837994486093521], Function Value: 0.008504015393555164, Gradient: [0.0011205750051885843, 0.015210442245006561]\n",
      "\n",
      "Step 15/40\n",
      "Epoch 0: Total Loss=0.0621\n",
      "Epoch 1: Total Loss=0.0612\n",
      "Epoch 2: Total Loss=0.0637\n",
      "Epoch 3: Total Loss=0.0633\n",
      "Epoch 4: Total Loss=0.0608\n",
      "Epoch 5: Total Loss=0.0619\n",
      "Epoch 6: Total Loss=0.0613\n",
      "Epoch 7: Total Loss=0.0641\n",
      "Epoch 8: Total Loss=0.0631\n",
      "Epoch 9: Total Loss=0.0616\n",
      "Updated x: [-0.023456797003746033, 0.03469439223408699], Function Value: 0.0017539222026243806, Gradient: [0.0009545322391204536, 0.01175845880061388]\n",
      "\n",
      "Step 16/40\n",
      "Epoch 0: Total Loss=0.0607\n",
      "Epoch 1: Total Loss=0.0617\n",
      "Epoch 2: Total Loss=0.0614\n",
      "Epoch 3: Total Loss=0.0634\n",
      "Epoch 4: Total Loss=0.0611\n",
      "Epoch 5: Total Loss=0.0635\n",
      "Epoch 6: Total Loss=0.0603\n",
      "Epoch 7: Total Loss=0.0614\n",
      "Epoch 8: Total Loss=0.0623\n",
      "Epoch 9: Total Loss=0.0610\n",
      "Updated x: [0.005605621263384819, -0.05835247412323952], Function Value: 0.0034364343155175447, Gradient: [-0.0008198024588637054, 0.012203301303088665]\n",
      "\n",
      "Step 17/40\n",
      "Epoch 0: Total Loss=0.0607\n",
      "Epoch 1: Total Loss=0.0638\n",
      "Epoch 2: Total Loss=0.0610\n",
      "Epoch 3: Total Loss=0.0620\n",
      "Epoch 4: Total Loss=0.0607\n",
      "Epoch 5: Total Loss=0.0634\n",
      "Epoch 6: Total Loss=0.0611\n",
      "Epoch 7: Total Loss=0.0608\n",
      "Epoch 8: Total Loss=0.0631\n",
      "Epoch 9: Total Loss=0.0605\n",
      "Updated x: [-0.015609053894877434, 0.01427522674202919], Function Value: 0.0004474246525205672, Gradient: [0.001592613640241325, 0.011823571287095547]\n",
      "\n",
      "Step 18/40\n",
      "Epoch 0: Total Loss=0.0622\n",
      "Epoch 1: Total Loss=0.0608\n",
      "Epoch 2: Total Loss=0.0609\n",
      "Epoch 3: Total Loss=0.0619\n",
      "Epoch 4: Total Loss=0.0616\n",
      "Epoch 5: Total Loss=0.0610\n",
      "Epoch 6: Total Loss=0.0610\n",
      "Epoch 7: Total Loss=0.0631\n",
      "Epoch 8: Total Loss=0.0654\n",
      "Epoch 9: Total Loss=0.0625\n",
      "Updated x: [0.021178917959332466, -0.020520519465208054], Function Value: 0.0008696382865309715, Gradient: [0.001527351443655789, 0.01198351476341486]\n",
      "\n",
      "Step 19/40\n",
      "Epoch 0: Total Loss=0.0629\n",
      "Epoch 1: Total Loss=0.0610\n",
      "Epoch 2: Total Loss=0.0609\n",
      "Epoch 3: Total Loss=0.0625\n",
      "Epoch 4: Total Loss=0.0620\n",
      "Epoch 5: Total Loss=0.0608\n",
      "Epoch 6: Total Loss=0.0614\n",
      "Epoch 7: Total Loss=0.0611\n",
      "Epoch 8: Total Loss=0.0623\n",
      "Epoch 9: Total Loss=0.0609\n",
      "Updated x: [0.012881018221378326, 0.0016510188579559326], Function Value: 0.00016864649660419673, Gradient: [0.0027130490634590387, 0.01083260029554367]\n",
      "\n",
      "Step 20/40\n",
      "Epoch 0: Total Loss=0.0614\n",
      "Epoch 1: Total Loss=0.0606\n",
      "Epoch 2: Total Loss=0.0611\n",
      "Epoch 3: Total Loss=0.0633\n",
      "Epoch 4: Total Loss=0.0605\n",
      "Epoch 5: Total Loss=0.0622\n",
      "Epoch 6: Total Loss=0.0625\n",
      "Epoch 7: Total Loss=0.0609\n",
      "Epoch 8: Total Loss=0.0610\n",
      "Epoch 9: Total Loss=0.0629\n",
      "Updated x: [0.06209368258714676, 0.04013892263174057], Function Value: 0.005466758273541927, Gradient: [0.004176380578428507, 0.010386201553046703]\n",
      "\n",
      "Step 21/40\n",
      "Epoch 0: Total Loss=0.0617\n",
      "Epoch 1: Total Loss=0.0608\n",
      "Epoch 2: Total Loss=0.0603\n",
      "Epoch 3: Total Loss=0.0611\n",
      "Epoch 4: Total Loss=0.0625\n",
      "Epoch 5: Total Loss=0.0604\n",
      "Epoch 6: Total Loss=0.0626\n",
      "Epoch 7: Total Loss=0.0610\n",
      "Epoch 8: Total Loss=0.0610\n",
      "Epoch 9: Total Loss=0.0624\n",
      "Updated x: [-0.05250124633312225, -0.03732828050851822], Function Value: 0.0041497815400362015, Gradient: [0.001016508787870407, 0.008497663773596287]\n",
      "\n",
      "Step 22/40\n",
      "Epoch 0: Total Loss=0.0591\n",
      "Epoch 1: Total Loss=0.0591\n",
      "Epoch 2: Total Loss=0.0541\n",
      "Epoch 3: Total Loss=0.0589\n",
      "Epoch 4: Total Loss=0.0590\n",
      "Epoch 5: Total Loss=0.0540\n",
      "Epoch 6: Total Loss=0.0589\n",
      "Epoch 7: Total Loss=0.0590\n",
      "Epoch 8: Total Loss=0.0540\n",
      "Epoch 9: Total Loss=0.0588\n",
      "Updated x: [-0.04873272031545639, 0.024549048393964767], Function Value: 0.002977533731609583, Gradient: [2.1250640202197246e-05, -0.0004875848244410008]\n",
      "\n",
      "Step 23/40\n",
      "Epoch 0: Total Loss=0.0582\n",
      "Epoch 1: Total Loss=0.0568\n",
      "Epoch 2: Total Loss=0.0594\n",
      "Epoch 3: Total Loss=0.0570\n",
      "Epoch 4: Total Loss=0.0584\n",
      "Epoch 5: Total Loss=0.0582\n",
      "Epoch 6: Total Loss=0.0568\n",
      "Epoch 7: Total Loss=0.0594\n",
      "Epoch 8: Total Loss=0.0570\n",
      "Epoch 9: Total Loss=0.0584\n",
      "Updated x: [-0.036805346608161926, 0.10583755373954773], Function Value: 0.012556221336126328, Gradient: [0.00014049408491700888, -0.00079112418461591]\n",
      "\n",
      "Step 24/40\n",
      "Epoch 0: Total Loss=0.0587\n",
      "Epoch 1: Total Loss=0.0576\n",
      "Epoch 2: Total Loss=0.0575\n",
      "Epoch 3: Total Loss=0.0561\n",
      "Epoch 4: Total Loss=0.0586\n",
      "Epoch 5: Total Loss=0.0576\n",
      "Epoch 6: Total Loss=0.0575\n",
      "Epoch 7: Total Loss=0.0560\n",
      "Epoch 8: Total Loss=0.0586\n",
      "Epoch 9: Total Loss=0.0575\n",
      "Updated x: [0.013499375432729721, 0.0466180145740509], Function Value: 0.002355472417548299, Gradient: [-0.0005405236152000725, 0.006025243550539017]\n",
      "\n",
      "Step 25/40\n",
      "Epoch 0: Total Loss=0.0587\n",
      "Epoch 1: Total Loss=0.0555\n",
      "Epoch 2: Total Loss=0.0579\n",
      "Epoch 3: Total Loss=0.0571\n",
      "Epoch 4: Total Loss=0.0559\n",
      "Epoch 5: Total Loss=0.0586\n",
      "Epoch 6: Total Loss=0.0555\n",
      "Epoch 7: Total Loss=0.0578\n",
      "Epoch 8: Total Loss=0.0572\n",
      "Epoch 9: Total Loss=0.0558\n",
      "Updated x: [-0.03150390088558197, 0.009577326476573944], Function Value: 0.001084220944903791, Gradient: [-0.0017687543295323849, 0.007473093923181295]\n",
      "\n",
      "Step 26/40\n",
      "Epoch 0: Total Loss=0.0548\n",
      "Epoch 1: Total Loss=0.0554\n",
      "Epoch 2: Total Loss=0.0554\n",
      "Epoch 3: Total Loss=0.0570\n",
      "Epoch 4: Total Loss=0.0598\n",
      "Epoch 5: Total Loss=0.0558\n",
      "Epoch 6: Total Loss=0.0547\n",
      "Epoch 7: Total Loss=0.0547\n",
      "Epoch 8: Total Loss=0.0552\n",
      "Epoch 9: Total Loss=0.0555\n",
      "Updated x: [-0.04189835488796234, -0.004797029308974743], Function Value: 0.0017784836236387491, Gradient: [-0.0018846337916329503, 0.007275309879332781]\n",
      "\n",
      "Step 27/40\n",
      "Epoch 0: Total Loss=0.0584\n",
      "Epoch 1: Total Loss=0.0539\n",
      "Epoch 2: Total Loss=0.0582\n",
      "Epoch 3: Total Loss=0.0551\n",
      "Epoch 4: Total Loss=0.0547\n",
      "Epoch 5: Total Loss=0.0556\n",
      "Epoch 6: Total Loss=0.0557\n",
      "Epoch 7: Total Loss=0.0545\n",
      "Epoch 8: Total Loss=0.0584\n",
      "Epoch 9: Total Loss=0.0548\n",
      "Updated x: [0.04881565272808075, -0.029817938804626465], Function Value: 0.003272077301517129, Gradient: [-0.001377451466396451, 0.00508294440805912]\n",
      "\n",
      "Step 28/40\n",
      "Epoch 0: Total Loss=0.0579\n",
      "Epoch 1: Total Loss=0.0571\n",
      "Epoch 2: Total Loss=0.0544\n",
      "Epoch 3: Total Loss=0.0561\n",
      "Epoch 4: Total Loss=0.0553\n",
      "Epoch 5: Total Loss=0.0540\n",
      "Epoch 6: Total Loss=0.0542\n",
      "Epoch 7: Total Loss=0.0542\n",
      "Epoch 8: Total Loss=0.0587\n",
      "Epoch 9: Total Loss=0.0577\n",
      "Updated x: [-0.0003362782299518585, 0.0011968258768320084], Function Value: 1.5454752428922802e-06, Gradient: [-0.0007901982171460986, 0.008419571444392204]\n",
      "\n",
      "Step 29/40\n",
      "Epoch 0: Total Loss=0.0541\n",
      "Epoch 1: Total Loss=0.0545\n",
      "Epoch 2: Total Loss=0.0592\n",
      "Epoch 3: Total Loss=0.0540\n",
      "Epoch 4: Total Loss=0.0550\n",
      "Epoch 5: Total Loss=0.0543\n",
      "Epoch 6: Total Loss=0.0549\n",
      "Epoch 7: Total Loss=0.0576\n",
      "Epoch 8: Total Loss=0.0541\n",
      "Epoch 9: Total Loss=0.0552\n",
      "Updated x: [0.017583148553967476, -0.03417804837226868], Function Value: 0.0014773061266168952, Gradient: [-0.0005796775803901255, 0.006919748615473509]\n",
      "\n",
      "Step 30/40\n",
      "Epoch 0: Total Loss=0.0543\n",
      "Epoch 1: Total Loss=0.0548\n",
      "Epoch 2: Total Loss=0.0547\n",
      "Epoch 3: Total Loss=0.0550\n",
      "Epoch 4: Total Loss=0.0542\n",
      "Epoch 5: Total Loss=0.0544\n",
      "Epoch 6: Total Loss=0.0563\n",
      "Epoch 7: Total Loss=0.0546\n",
      "Epoch 8: Total Loss=0.0570\n",
      "Epoch 9: Total Loss=0.0538\n",
      "Updated x: [-0.03536296635866165, 0.03643286973237991], Function Value: 0.0025778934359550476, Gradient: [0.00017548502364661545, 0.004534516017884016]\n",
      "\n",
      "Step 31/40\n",
      "Epoch 0: Total Loss=0.0551\n",
      "Epoch 1: Total Loss=0.0574\n",
      "Epoch 2: Total Loss=0.0539\n",
      "Epoch 3: Total Loss=0.0540\n",
      "Epoch 4: Total Loss=0.0540\n",
      "Epoch 5: Total Loss=0.0542\n",
      "Epoch 6: Total Loss=0.0546\n",
      "Epoch 7: Total Loss=0.0541\n",
      "Epoch 8: Total Loss=0.0571\n",
      "Epoch 9: Total Loss=0.0565\n",
      "Updated x: [-0.0339549221098423, 0.03932761028409004], Function Value: 0.0026995977386832237, Gradient: [0.0008527578902430832, 0.005693922750651836]\n",
      "\n",
      "Step 32/40\n",
      "Epoch 0: Total Loss=0.0689\n",
      "Epoch 1: Total Loss=0.0745\n",
      "Epoch 2: Total Loss=0.0735\n",
      "Epoch 3: Total Loss=0.0778\n",
      "Epoch 4: Total Loss=0.0763\n",
      "Epoch 5: Total Loss=0.0766\n",
      "Epoch 6: Total Loss=0.0770\n",
      "Epoch 7: Total Loss=0.0706\n",
      "Epoch 8: Total Loss=0.0787\n",
      "Epoch 9: Total Loss=0.0745\n",
      "Updated x: [-0.04573856294155121, 0.1135760247707367], Function Value: 0.014991529285907745, Gradient: [0.0003404443268664181, 0.004878441337496042]\n",
      "\n",
      "Step 33/40\n",
      "Epoch 0: Total Loss=0.0728\n",
      "Epoch 1: Total Loss=0.0756\n",
      "Epoch 2: Total Loss=0.0759\n",
      "Epoch 3: Total Loss=0.0818\n",
      "Epoch 4: Total Loss=0.0783\n",
      "Epoch 5: Total Loss=0.0763\n",
      "Epoch 6: Total Loss=0.0767\n",
      "Epoch 7: Total Loss=0.0797\n",
      "Epoch 8: Total Loss=0.0773\n",
      "Epoch 9: Total Loss=0.0807\n",
      "Updated x: [-0.04215463250875473, -0.06300093233585358], Function Value: 0.005746130831539631, Gradient: [-0.0014196204720064998, 0.014025921933352947]\n",
      "\n",
      "Step 34/40\n",
      "Epoch 0: Total Loss=0.0722\n",
      "Epoch 1: Total Loss=0.0758\n",
      "Epoch 2: Total Loss=0.0803\n",
      "Epoch 3: Total Loss=0.0755\n",
      "Epoch 4: Total Loss=0.0772\n",
      "Epoch 5: Total Loss=0.0710\n",
      "Epoch 6: Total Loss=0.0663\n",
      "Epoch 7: Total Loss=0.0726\n",
      "Epoch 8: Total Loss=0.0770\n",
      "Epoch 9: Total Loss=0.0720\n",
      "Updated x: [0.049727581441402435, -0.05934959277510643], Function Value: 0.005995206534862518, Gradient: [-0.0006323016132228076, 0.0170072503387928]\n",
      "\n",
      "Step 35/40\n",
      "Epoch 0: Total Loss=0.0824\n",
      "Epoch 1: Total Loss=0.0856\n",
      "Epoch 2: Total Loss=0.0823\n",
      "Epoch 3: Total Loss=0.0726\n",
      "Epoch 4: Total Loss=0.0766\n",
      "Epoch 5: Total Loss=0.0742\n",
      "Epoch 6: Total Loss=0.0747\n",
      "Epoch 7: Total Loss=0.0831\n",
      "Epoch 8: Total Loss=0.0765\n",
      "Epoch 9: Total Loss=0.0743\n",
      "Updated x: [-0.0017480924725532532, -0.0039130039513111115], Function Value: 1.836742740124464e-05, Gradient: [0.00011658661242108792, 0.013148886151611805]\n",
      "\n",
      "Step 36/40\n",
      "Epoch 0: Total Loss=0.0795\n",
      "Epoch 1: Total Loss=0.0755\n",
      "Epoch 2: Total Loss=0.0745\n",
      "Epoch 3: Total Loss=0.0749\n",
      "Epoch 4: Total Loss=0.0763\n",
      "Epoch 5: Total Loss=0.0788\n",
      "Epoch 6: Total Loss=0.0740\n",
      "Epoch 7: Total Loss=0.0848\n",
      "Epoch 8: Total Loss=0.0753\n",
      "Epoch 9: Total Loss=0.0699\n",
      "Updated x: [0.01867864280939102, 0.006062728352844715], Function Value: 0.00038564836722798645, Gradient: [4.836876905756071e-05, 0.007110681384801865]\n",
      "\n",
      "Step 37/40\n",
      "Epoch 0: Total Loss=0.0726\n",
      "Epoch 1: Total Loss=0.0749\n",
      "Epoch 2: Total Loss=0.0689\n",
      "Epoch 3: Total Loss=0.0777\n",
      "Epoch 4: Total Loss=0.0767\n",
      "Epoch 5: Total Loss=0.0786\n",
      "Epoch 6: Total Loss=0.0700\n",
      "Epoch 7: Total Loss=0.0786\n",
      "Epoch 8: Total Loss=0.0728\n",
      "Epoch 9: Total Loss=0.0720\n",
      "Updated x: [-0.07016905397176743, -0.002270958386361599], Function Value: 0.004928853362798691, Gradient: [0.0005177483544684947, 0.011835387907922268]\n",
      "\n",
      "Step 38/40\n",
      "Epoch 0: Total Loss=0.0796\n",
      "Epoch 1: Total Loss=0.0734\n",
      "Epoch 2: Total Loss=0.0732\n",
      "Epoch 3: Total Loss=0.0698\n",
      "Epoch 4: Total Loss=0.0739\n",
      "Epoch 5: Total Loss=0.0734\n",
      "Epoch 6: Total Loss=0.0743\n",
      "Epoch 7: Total Loss=0.0717\n",
      "Epoch 8: Total Loss=0.0805\n",
      "Epoch 9: Total Loss=0.0752\n",
      "Updated x: [0.030769824981689453, -0.04456629976630211], Function Value: 0.002932937117293477, Gradient: [0.0008965187589637935, 0.014629763551056385]\n",
      "\n",
      "Step 39/40\n",
      "Epoch 0: Total Loss=0.0734\n",
      "Epoch 1: Total Loss=0.0787\n",
      "Epoch 2: Total Loss=0.0731\n",
      "Epoch 3: Total Loss=0.0794\n",
      "Epoch 4: Total Loss=0.0770\n",
      "Epoch 5: Total Loss=0.0744\n",
      "Epoch 6: Total Loss=0.0769\n",
      "Epoch 7: Total Loss=0.0763\n",
      "Epoch 8: Total Loss=0.0723\n",
      "Epoch 9: Total Loss=0.0742\n",
      "Updated x: [0.02311529591679573, 0.015005599707365036], Function Value: 0.0007594849448651075, Gradient: [0.0012272924650460482, 0.004527338780462742]\n",
      "\n",
      "Step 40/40\n",
      "Epoch 0: Total Loss=0.0731\n",
      "Epoch 1: Total Loss=0.0782\n",
      "Epoch 2: Total Loss=0.0740\n",
      "Epoch 3: Total Loss=0.0710\n",
      "Epoch 4: Total Loss=0.0780\n",
      "Epoch 5: Total Loss=0.0754\n",
      "Epoch 6: Total Loss=0.0795\n",
      "Epoch 7: Total Loss=0.0726\n",
      "Epoch 8: Total Loss=0.0714\n",
      "Epoch 9: Total Loss=0.0776\n",
      "Updated x: [-0.019815601408481598, -0.01730206236243248], Function Value: 0.000692019413691014, Gradient: [0.001163544482551515, 0.008098499849438667]\n"
     ]
    }
   ],
   "source": [
    "# **Initialize Model & Datasets**\n",
    "old_dataset = OldDataSet(data, k=10)\n",
    "new_dataset = NewDataSet(k=10)\n",
    "model = MLP(2, [5, 5, 5], 1)\n",
    "\n",
    "# **Run Optimization**\n",
    "x_path, y_path = optimize_surrogate_model(model, old_dataset, new_dataset, assSim, optim_steps=40, N_s=5, lr=0.001, merge_interval=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 1/40\n",
      "Epoch 0: Total Loss=4.9762\n",
      "Epoch 1: Total Loss=4.9534\n",
      "Epoch 2: Total Loss=4.9283\n",
      "Epoch 3: Total Loss=4.9048\n",
      "Epoch 4: Total Loss=4.8841\n",
      "Epoch 5: Total Loss=4.8572\n",
      "Epoch 6: Total Loss=4.8312\n",
      "Epoch 7: Total Loss=4.8038\n",
      "Epoch 8: Total Loss=4.7777\n",
      "Epoch 9: Total Loss=4.7485\n",
      "Updated x: [0.8997719883918762, -0.8655495047569275], Function Value: 1.5587656497955322, Gradient: [-0.015557564795017242, -0.1180882379412651]\n",
      "\n",
      "Step 2/40\n",
      "Epoch 0: Total Loss=4.1325\n",
      "Epoch 1: Total Loss=4.1050\n",
      "Epoch 2: Total Loss=4.0759\n",
      "Epoch 3: Total Loss=4.0478\n",
      "Epoch 4: Total Loss=4.0122\n",
      "Epoch 5: Total Loss=3.9815\n",
      "Epoch 6: Total Loss=3.9480\n",
      "Epoch 7: Total Loss=3.9100\n",
      "Epoch 8: Total Loss=3.8738\n",
      "Epoch 9: Total Loss=3.8316\n",
      "Updated x: [0.7780316472053528, -0.9291114807128906], Function Value: 1.4685814380645752, Gradient: [0.030875520780682564, -0.20416085422039032]\n",
      "\n",
      "Step 3/40\n",
      "Epoch 0: Total Loss=3.5758\n",
      "Epoch 1: Total Loss=3.5353\n",
      "Epoch 2: Total Loss=3.4980\n",
      "Epoch 3: Total Loss=3.4566\n",
      "Epoch 4: Total Loss=3.4137\n",
      "Epoch 5: Total Loss=3.3695\n",
      "Epoch 6: Total Loss=3.3254\n",
      "Epoch 7: Total Loss=3.2759\n",
      "Epoch 8: Total Loss=3.2274\n",
      "Epoch 9: Total Loss=3.1772\n",
      "Updated x: [0.8300632834434509, -0.8221424221992493], Function Value: 1.3649232387542725, Gradient: [0.09059686958789825, -0.3032912611961365]\n",
      "\n",
      "Step 4/40\n",
      "Epoch 0: Total Loss=3.1171\n",
      "Epoch 1: Total Loss=3.0658\n",
      "Epoch 2: Total Loss=3.0135\n",
      "Epoch 3: Total Loss=2.9584\n",
      "Epoch 4: Total Loss=2.9008\n",
      "Epoch 5: Total Loss=2.8405\n",
      "Epoch 6: Total Loss=2.7843\n",
      "Epoch 7: Total Loss=2.7210\n",
      "Epoch 8: Total Loss=2.6568\n",
      "Epoch 9: Total Loss=2.5889\n",
      "Updated x: [0.8565173745155334, -0.7883602976799011], Function Value: 1.3551340103149414, Gradient: [0.18933890759944916, -0.4518294334411621]\n",
      "\n",
      "Step 5/40\n",
      "Epoch 0: Total Loss=2.3589\n",
      "Epoch 1: Total Loss=2.3004\n",
      "Epoch 2: Total Loss=2.2395\n",
      "Epoch 3: Total Loss=2.1779\n",
      "Epoch 4: Total Loss=2.1161\n",
      "Epoch 5: Total Loss=2.0524\n",
      "Epoch 6: Total Loss=1.9878\n",
      "Epoch 7: Total Loss=1.9228\n",
      "Epoch 8: Total Loss=1.8524\n",
      "Epoch 9: Total Loss=1.7941\n",
      "Updated x: [0.8040774464607239, -0.7666618824005127], Function Value: 1.2343109846115112, Gradient: [0.3311692178249359, -0.6284644603729248]\n",
      "\n",
      "Step 6/40\n",
      "Epoch 0: Total Loss=1.6476\n",
      "Epoch 1: Total Loss=1.5329\n",
      "Epoch 2: Total Loss=1.3828\n",
      "Epoch 3: Total Loss=1.4660\n",
      "Epoch 4: Total Loss=1.3548\n",
      "Epoch 5: Total Loss=1.2250\n",
      "Epoch 6: Total Loss=1.2950\n",
      "Epoch 7: Total Loss=1.1782\n",
      "Epoch 8: Total Loss=1.0837\n",
      "Epoch 9: Total Loss=1.1267\n",
      "Updated x: [0.6974321603775024, -0.7498213052749634], Function Value: 1.0486435890197754, Gradient: [0.506316602230072, -0.8165416717529297]\n",
      "\n",
      "Step 7/40\n",
      "Epoch 0: Total Loss=0.9694\n",
      "Epoch 1: Total Loss=0.9035\n",
      "Epoch 2: Total Loss=0.9827\n",
      "Epoch 3: Total Loss=0.8449\n",
      "Epoch 4: Total Loss=0.7842\n",
      "Epoch 5: Total Loss=0.8312\n",
      "Epoch 6: Total Loss=0.7264\n",
      "Epoch 7: Total Loss=0.7091\n",
      "Epoch 8: Total Loss=0.7461\n",
      "Epoch 9: Total Loss=0.6536\n",
      "Updated x: [0.7377685308456421, -0.7900927066802979], Function Value: 1.168548822402954, Gradient: [0.7428832054138184, -1.0839990377426147]\n",
      "\n",
      "Step 8/40\n",
      "Epoch 0: Total Loss=0.6731\n",
      "Epoch 1: Total Loss=0.6683\n",
      "Epoch 2: Total Loss=0.6411\n",
      "Epoch 3: Total Loss=0.6067\n",
      "Epoch 4: Total Loss=0.6035\n",
      "Epoch 5: Total Loss=0.6169\n",
      "Epoch 6: Total Loss=0.6247\n",
      "Epoch 7: Total Loss=0.6419\n",
      "Epoch 8: Total Loss=0.6046\n",
      "Epoch 9: Total Loss=0.5919\n",
      "Updated x: [0.8814025521278381, -0.7128421664237976], Function Value: 1.2850143909454346, Gradient: [0.9045469164848328, -1.223996877670288]\n",
      "\n",
      "Step 9/40\n",
      "Epoch 0: Total Loss=0.5858\n",
      "Epoch 1: Total Loss=0.6507\n",
      "Epoch 2: Total Loss=0.5891\n",
      "Epoch 3: Total Loss=0.6153\n",
      "Epoch 4: Total Loss=0.5747\n",
      "Epoch 5: Total Loss=0.6286\n",
      "Epoch 6: Total Loss=0.5673\n",
      "Epoch 7: Total Loss=0.6251\n",
      "Epoch 8: Total Loss=0.5696\n",
      "Epoch 9: Total Loss=0.5929\n",
      "Updated x: [0.9468112587928772, -0.8563283681869507], Function Value: 1.6297497749328613, Gradient: [1.0045015811920166, -1.244089961051941]\n",
      "\n",
      "Step 10/40\n",
      "Epoch 0: Total Loss=0.5677\n",
      "Epoch 1: Total Loss=0.6375\n",
      "Epoch 2: Total Loss=0.5225\n",
      "Epoch 3: Total Loss=0.6134\n",
      "Epoch 4: Total Loss=0.6167\n",
      "Epoch 5: Total Loss=0.5460\n",
      "Epoch 6: Total Loss=0.6590\n",
      "Epoch 7: Total Loss=0.5214\n",
      "Epoch 8: Total Loss=0.5683\n",
      "Epoch 9: Total Loss=0.6142\n",
      "Updated x: [0.8367323279380798, -0.8991260528564453], Function Value: 1.508548617362976, Gradient: [1.1218708753585815, -1.2314473390579224]\n",
      "\n",
      "Step 11/40\n",
      "Epoch 0: Total Loss=0.5349\n",
      "Epoch 1: Total Loss=0.5370\n",
      "Epoch 2: Total Loss=0.4838\n",
      "Epoch 3: Total Loss=0.4946\n",
      "Epoch 4: Total Loss=0.3968\n",
      "Epoch 5: Total Loss=0.4308\n",
      "Epoch 6: Total Loss=0.4313\n",
      "Epoch 7: Total Loss=0.3965\n",
      "Epoch 8: Total Loss=0.3862\n",
      "Epoch 9: Total Loss=0.3297\n",
      "Updated x: [0.8672482371330261, -0.7268166542053223], Function Value: 1.2803819179534912, Gradient: [0.8208156824111938, -0.9394291639328003]\n",
      "\n",
      "Step 12/40\n",
      "Epoch 0: Total Loss=1.1654\n",
      "Epoch 1: Total Loss=1.0993\n",
      "Epoch 2: Total Loss=1.0332\n",
      "Epoch 3: Total Loss=0.9782\n",
      "Epoch 4: Total Loss=0.9267\n",
      "Epoch 5: Total Loss=0.8776\n",
      "Epoch 6: Total Loss=0.8235\n",
      "Epoch 7: Total Loss=0.7717\n",
      "Epoch 8: Total Loss=0.7491\n",
      "Epoch 9: Total Loss=0.7184\n",
      "Updated x: [1.020634651184082, -0.763865053653717], Function Value: 1.6251850128173828, Gradient: [1.0771985054016113, -1.2262195348739624]\n",
      "\n",
      "Step 13/40\n",
      "Epoch 0: Total Loss=0.7984\n",
      "Epoch 1: Total Loss=0.7723\n",
      "Epoch 2: Total Loss=0.7687\n",
      "Epoch 3: Total Loss=0.7593\n",
      "Epoch 4: Total Loss=0.7042\n",
      "Epoch 5: Total Loss=0.7295\n",
      "Epoch 6: Total Loss=0.7414\n",
      "Epoch 7: Total Loss=0.7372\n",
      "Epoch 8: Total Loss=0.7318\n",
      "Epoch 9: Total Loss=0.7040\n",
      "Updated x: [1.0414243936538696, -0.8730399012565613], Function Value: 1.8467634916305542, Gradient: [1.2421444654464722, -1.3203462362289429]\n",
      "\n",
      "Step 14/40\n",
      "Epoch 0: Total Loss=0.6856\n",
      "Epoch 1: Total Loss=0.6692\n",
      "Epoch 2: Total Loss=0.6867\n",
      "Epoch 3: Total Loss=0.6511\n",
      "Epoch 4: Total Loss=0.6628\n",
      "Epoch 5: Total Loss=0.6660\n",
      "Epoch 6: Total Loss=0.6291\n",
      "Epoch 7: Total Loss=0.6579\n",
      "Epoch 8: Total Loss=0.6724\n",
      "Epoch 9: Total Loss=0.6397\n",
      "Updated x: [0.943859338760376, -0.8064582943916321], Function Value: 1.541245460510254, Gradient: [1.3610496520996094, -1.2840207815170288]\n",
      "\n",
      "Step 15/40\n",
      "Epoch 0: Total Loss=0.6828\n",
      "Epoch 1: Total Loss=0.6935\n",
      "Epoch 2: Total Loss=0.6832\n",
      "Epoch 3: Total Loss=0.6933\n",
      "Epoch 4: Total Loss=0.6946\n",
      "Epoch 5: Total Loss=0.6742\n",
      "Epoch 6: Total Loss=0.6843\n",
      "Epoch 7: Total Loss=0.6694\n",
      "Epoch 8: Total Loss=0.6626\n",
      "Epoch 9: Total Loss=0.6402\n",
      "Updated x: [0.9282763600349426, -0.7378718852996826], Function Value: 1.4061520099639893, Gradient: [1.4390392303466797, -1.1971960067749023]\n",
      "\n",
      "Step 16/40\n",
      "Epoch 0: Total Loss=0.6612\n",
      "Epoch 1: Total Loss=0.5712\n",
      "Epoch 2: Total Loss=0.6236\n",
      "Epoch 3: Total Loss=0.6792\n",
      "Epoch 4: Total Loss=0.5670\n",
      "Epoch 5: Total Loss=0.6215\n",
      "Epoch 6: Total Loss=0.6435\n",
      "Epoch 7: Total Loss=0.5518\n",
      "Epoch 8: Total Loss=0.6364\n",
      "Epoch 9: Total Loss=0.6839\n",
      "Updated x: [0.8772846460342407, -0.5869866609573364], Function Value: 1.1141817569732666, Gradient: [1.4216824769973755, -1.056442379951477]\n",
      "\n",
      "Step 17/40\n",
      "Epoch 0: Total Loss=0.6523\n",
      "Epoch 1: Total Loss=0.5871\n",
      "Epoch 2: Total Loss=0.6089\n",
      "Epoch 3: Total Loss=0.6543\n",
      "Epoch 4: Total Loss=0.5695\n",
      "Epoch 5: Total Loss=0.5800\n",
      "Epoch 6: Total Loss=0.6393\n",
      "Epoch 7: Total Loss=0.5510\n",
      "Epoch 8: Total Loss=0.6154\n",
      "Epoch 9: Total Loss=0.6286\n",
      "Updated x: [0.9495677351951599, -0.6484824419021606], Function Value: 1.3222084045410156, Gradient: [1.5255497694015503, -1.1046029329299927]\n",
      "\n",
      "Step 18/40\n",
      "Epoch 0: Total Loss=0.7081\n",
      "Epoch 1: Total Loss=0.7605\n",
      "Epoch 2: Total Loss=0.7219\n",
      "Epoch 3: Total Loss=0.7197\n",
      "Epoch 4: Total Loss=0.7049\n",
      "Epoch 5: Total Loss=0.7549\n",
      "Epoch 6: Total Loss=0.6980\n",
      "Epoch 7: Total Loss=0.7604\n",
      "Epoch 8: Total Loss=0.6824\n",
      "Epoch 9: Total Loss=0.7488\n",
      "Updated x: [0.8761305809020996, -0.42449331283569336], Function Value: 0.9477993249893188, Gradient: [1.4095803499221802, -0.8765915632247925]\n",
      "\n",
      "Step 19/40\n",
      "Epoch 0: Total Loss=0.7227\n",
      "Epoch 1: Total Loss=0.5502\n",
      "Epoch 2: Total Loss=0.7459\n",
      "Epoch 3: Total Loss=0.5358\n",
      "Epoch 4: Total Loss=0.7234\n",
      "Epoch 5: Total Loss=0.5380\n",
      "Epoch 6: Total Loss=0.6890\n",
      "Epoch 7: Total Loss=0.5290\n",
      "Epoch 8: Total Loss=0.7498\n",
      "Epoch 9: Total Loss=0.5354\n",
      "Updated x: [0.9295220375061035, -0.3804132044315338], Function Value: 1.0087254047393799, Gradient: [1.458240032196045, -0.8552317023277283]\n",
      "\n",
      "Step 20/40\n",
      "Epoch 0: Total Loss=0.7746\n",
      "Epoch 1: Total Loss=0.6640\n",
      "Epoch 2: Total Loss=0.6005\n",
      "Epoch 3: Total Loss=0.7078\n",
      "Epoch 4: Total Loss=0.6785\n",
      "Epoch 5: Total Loss=0.7582\n",
      "Epoch 6: Total Loss=0.6455\n",
      "Epoch 7: Total Loss=0.5945\n",
      "Epoch 8: Total Loss=0.7019\n",
      "Epoch 9: Total Loss=0.6593\n",
      "Updated x: [1.056077480316162, -0.4203568696975708], Function Value: 1.2919995784759521, Gradient: [1.5631825923919678, -0.892333447933197]\n",
      "\n",
      "Step 21/40\n",
      "Epoch 0: Total Loss=0.7003\n",
      "Epoch 1: Total Loss=0.4669\n",
      "Epoch 2: Total Loss=0.6896\n",
      "Epoch 3: Total Loss=0.4908\n",
      "Epoch 4: Total Loss=0.4795\n",
      "Epoch 5: Total Loss=0.5744\n",
      "Epoch 6: Total Loss=0.3538\n",
      "Epoch 7: Total Loss=0.5733\n",
      "Epoch 8: Total Loss=0.4049\n",
      "Epoch 9: Total Loss=0.4118\n",
      "Updated x: [1.1081047058105469, -0.40294820070266724], Function Value: 1.390263319015503, Gradient: [1.2282018661499023, -0.6796950697898865]\n",
      "\n",
      "Step 22/40\n",
      "Epoch 0: Total Loss=0.5820\n",
      "Epoch 1: Total Loss=0.5605\n",
      "Epoch 2: Total Loss=0.5463\n",
      "Epoch 3: Total Loss=0.5242\n",
      "Epoch 4: Total Loss=0.5188\n",
      "Epoch 5: Total Loss=0.4979\n",
      "Epoch 6: Total Loss=0.5079\n",
      "Epoch 7: Total Loss=0.5144\n",
      "Epoch 8: Total Loss=0.5017\n",
      "Epoch 9: Total Loss=0.5022\n",
      "Updated x: [0.9379879832267761, -0.3904421329498291], Function Value: 1.0322664976119995, Gradient: [1.4328688383102417, -0.7298540472984314]\n",
      "\n",
      "Step 23/40\n",
      "Epoch 0: Total Loss=0.5870\n",
      "Epoch 1: Total Loss=0.5701\n",
      "Epoch 2: Total Loss=0.5547\n",
      "Epoch 3: Total Loss=0.5382\n",
      "Epoch 4: Total Loss=0.5463\n",
      "Epoch 5: Total Loss=0.5507\n",
      "Epoch 6: Total Loss=0.5423\n",
      "Epoch 7: Total Loss=0.5465\n",
      "Epoch 8: Total Loss=0.5462\n",
      "Epoch 9: Total Loss=0.5468\n",
      "Updated x: [0.7249173521995544, -0.42358195781707764], Function Value: 0.7049268484115601, Gradient: [1.1017131805419922, -0.5098130106925964]\n",
      "\n",
      "Step 24/40\n",
      "Epoch 0: Total Loss=0.4818\n",
      "Epoch 1: Total Loss=0.4805\n",
      "Epoch 2: Total Loss=0.4866\n",
      "Epoch 3: Total Loss=0.4773\n",
      "Epoch 4: Total Loss=0.4703\n",
      "Epoch 5: Total Loss=0.4766\n",
      "Epoch 6: Total Loss=0.4672\n",
      "Epoch 7: Total Loss=0.4704\n",
      "Epoch 8: Total Loss=0.4687\n",
      "Epoch 9: Total Loss=0.4629\n",
      "Updated x: [0.7128956913948059, -0.4618297517299652], Function Value: 0.7215069532394409, Gradient: [1.081969141960144, -0.4647235572338104]\n",
      "\n",
      "Step 25/40\n",
      "Epoch 0: Total Loss=0.4911\n",
      "Epoch 1: Total Loss=0.4871\n",
      "Epoch 2: Total Loss=0.4814\n",
      "Epoch 3: Total Loss=0.4830\n",
      "Epoch 4: Total Loss=0.4871\n",
      "Epoch 5: Total Loss=0.4720\n",
      "Epoch 6: Total Loss=0.4732\n",
      "Epoch 7: Total Loss=0.4756\n",
      "Epoch 8: Total Loss=0.4760\n",
      "Epoch 9: Total Loss=0.4723\n",
      "Updated x: [0.8492276668548584, -0.4093319773674011], Function Value: 0.8887403011322021, Gradient: [1.1885348558425903, -0.45385634899139404]\n",
      "\n",
      "Step 26/40\n",
      "Epoch 0: Total Loss=0.4214\n",
      "Epoch 1: Total Loss=0.4517\n",
      "Epoch 2: Total Loss=0.4644\n",
      "Epoch 3: Total Loss=0.4221\n",
      "Epoch 4: Total Loss=0.4375\n",
      "Epoch 5: Total Loss=0.4430\n",
      "Epoch 6: Total Loss=0.4175\n",
      "Epoch 7: Total Loss=0.4432\n",
      "Epoch 8: Total Loss=0.4457\n",
      "Epoch 9: Total Loss=0.4310\n",
      "Updated x: [0.7794954180717468, -0.4290432929992676], Function Value: 0.791691243648529, Gradient: [1.1959092617034912, -0.41854128241539]\n",
      "\n",
      "Step 27/40\n",
      "Epoch 0: Total Loss=0.4523\n",
      "Epoch 1: Total Loss=0.4082\n",
      "Epoch 2: Total Loss=0.4580\n",
      "Epoch 3: Total Loss=0.4421\n",
      "Epoch 4: Total Loss=0.4069\n",
      "Epoch 5: Total Loss=0.4546\n",
      "Epoch 6: Total Loss=0.4480\n",
      "Epoch 7: Total Loss=0.3962\n",
      "Epoch 8: Total Loss=0.4547\n",
      "Epoch 9: Total Loss=0.4478\n",
      "Updated x: [0.7148232460021973, -0.5562576055526733], Function Value: 0.82039475440979, Gradient: [1.1503643989562988, -0.4217372536659241]\n",
      "\n",
      "Step 28/40\n",
      "Epoch 0: Total Loss=0.4594\n",
      "Epoch 1: Total Loss=0.4420\n",
      "Epoch 2: Total Loss=0.4500\n",
      "Epoch 3: Total Loss=0.4328\n",
      "Epoch 4: Total Loss=0.4495\n",
      "Epoch 5: Total Loss=0.4291\n",
      "Epoch 6: Total Loss=0.4439\n",
      "Epoch 7: Total Loss=0.4341\n",
      "Epoch 8: Total Loss=0.4382\n",
      "Epoch 9: Total Loss=0.4409\n",
      "Updated x: [0.5622219443321228, -0.6063216328620911], Function Value: 0.6837193965911865, Gradient: [1.004126787185669, -0.3893393874168396]\n",
      "\n",
      "Step 29/40\n",
      "Epoch 0: Total Loss=0.4719\n",
      "Epoch 1: Total Loss=0.4205\n",
      "Epoch 2: Total Loss=0.4744\n",
      "Epoch 3: Total Loss=0.4163\n",
      "Epoch 4: Total Loss=0.4713\n",
      "Epoch 5: Total Loss=0.4187\n",
      "Epoch 6: Total Loss=0.4623\n",
      "Epoch 7: Total Loss=0.4147\n",
      "Epoch 8: Total Loss=0.4692\n",
      "Epoch 9: Total Loss=0.4049\n",
      "Updated x: [0.6060625314712524, -0.5218902826309204], Function Value: 0.6396812796592712, Gradient: [0.9675183892250061, -0.38443523645401]\n",
      "\n",
      "Step 30/40\n",
      "Epoch 0: Total Loss=0.4140\n",
      "Epoch 1: Total Loss=0.4470\n",
      "Epoch 2: Total Loss=0.3954\n",
      "Epoch 3: Total Loss=0.3880\n",
      "Epoch 4: Total Loss=0.4507\n",
      "Epoch 5: Total Loss=0.4097\n",
      "Epoch 6: Total Loss=0.4486\n",
      "Epoch 7: Total Loss=0.3907\n",
      "Epoch 8: Total Loss=0.3864\n",
      "Epoch 9: Total Loss=0.4387\n",
      "Updated x: [0.6343686580657959, -0.5274264812469482], Function Value: 0.6806023120880127, Gradient: [0.9626810550689697, -0.390973299741745]\n",
      "\n",
      "Step 31/40\n",
      "Epoch 0: Total Loss=0.3157\n",
      "Epoch 1: Total Loss=0.2877\n",
      "Epoch 2: Total Loss=0.3369\n",
      "Epoch 3: Total Loss=0.2834\n",
      "Epoch 4: Total Loss=0.3106\n",
      "Epoch 5: Total Loss=0.2535\n",
      "Epoch 6: Total Loss=0.2275\n",
      "Epoch 7: Total Loss=0.2741\n",
      "Epoch 8: Total Loss=0.2327\n",
      "Epoch 9: Total Loss=0.2565\n",
      "Updated x: [0.5030148029327393, -0.4611937999725342], Function Value: 0.4657236337661743, Gradient: [0.6224271655082703, -0.21955955028533936]\n",
      "\n",
      "Step 32/40\n",
      "Epoch 0: Total Loss=0.4320\n",
      "Epoch 1: Total Loss=0.4215\n",
      "Epoch 2: Total Loss=0.4177\n",
      "Epoch 3: Total Loss=0.4128\n",
      "Epoch 4: Total Loss=0.4092\n",
      "Epoch 5: Total Loss=0.4030\n",
      "Epoch 6: Total Loss=0.3916\n",
      "Epoch 7: Total Loss=0.3951\n",
      "Epoch 8: Total Loss=0.3911\n",
      "Epoch 9: Total Loss=0.3868\n",
      "Updated x: [0.3619558811187744, -0.6344773769378662], Function Value: 0.5335736274719238, Gradient: [0.6005160212516785, -0.3173254728317261]\n",
      "\n",
      "Step 33/40\n",
      "Epoch 0: Total Loss=0.4088\n",
      "Epoch 1: Total Loss=0.4048\n",
      "Epoch 2: Total Loss=0.4037\n",
      "Epoch 3: Total Loss=0.3983\n",
      "Epoch 4: Total Loss=0.3963\n",
      "Epoch 5: Total Loss=0.3879\n",
      "Epoch 6: Total Loss=0.3951\n",
      "Epoch 7: Total Loss=0.3775\n",
      "Epoch 8: Total Loss=0.3855\n",
      "Epoch 9: Total Loss=0.3790\n",
      "Updated x: [0.4763011932373047, -0.6460638642311096], Function Value: 0.644261360168457, Gradient: [0.673051118850708, -0.44167590141296387]\n",
      "\n",
      "Step 34/40\n",
      "Epoch 0: Total Loss=0.4024\n",
      "Epoch 1: Total Loss=0.3972\n",
      "Epoch 2: Total Loss=0.3970\n",
      "Epoch 3: Total Loss=0.3989\n",
      "Epoch 4: Total Loss=0.3935\n",
      "Epoch 5: Total Loss=0.3944\n",
      "Epoch 6: Total Loss=0.3879\n",
      "Epoch 7: Total Loss=0.3841\n",
      "Epoch 8: Total Loss=0.3898\n",
      "Epoch 9: Total Loss=0.3815\n",
      "Updated x: [0.6771131157875061, -0.5508794784545898], Function Value: 0.7619503736495972, Gradient: [0.6658108830451965, -0.5157317519187927]\n",
      "\n",
      "Step 35/40\n",
      "Epoch 0: Total Loss=0.3798\n",
      "Epoch 1: Total Loss=0.3723\n",
      "Epoch 2: Total Loss=0.3700\n",
      "Epoch 3: Total Loss=0.3734\n",
      "Epoch 4: Total Loss=0.3648\n",
      "Epoch 5: Total Loss=0.3637\n",
      "Epoch 6: Total Loss=0.3683\n",
      "Epoch 7: Total Loss=0.3629\n",
      "Epoch 8: Total Loss=0.3704\n",
      "Epoch 9: Total Loss=0.3652\n",
      "Updated x: [0.5318480730056763, -0.6286584138870239], Function Value: 0.6780737638473511, Gradient: [0.6619109511375427, -0.5347195267677307]\n",
      "\n",
      "Step 36/40\n",
      "Epoch 0: Total Loss=0.3741\n",
      "Epoch 1: Total Loss=0.3327\n",
      "Epoch 2: Total Loss=0.3198\n",
      "Epoch 3: Total Loss=0.3702\n",
      "Epoch 4: Total Loss=0.3330\n",
      "Epoch 5: Total Loss=0.3097\n",
      "Epoch 6: Total Loss=0.3651\n",
      "Epoch 7: Total Loss=0.3304\n",
      "Epoch 8: Total Loss=0.3154\n",
      "Epoch 9: Total Loss=0.3642\n",
      "Updated x: [0.5418751239776611, -0.4689979553222656], Function Value: 0.5135877132415771, Gradient: [0.5788868069648743, -0.4545753002166748]\n",
      "\n",
      "Step 37/40\n",
      "Epoch 0: Total Loss=0.3382\n",
      "Epoch 1: Total Loss=0.3894\n",
      "Epoch 2: Total Loss=0.3482\n",
      "Epoch 3: Total Loss=0.3334\n",
      "Epoch 4: Total Loss=0.3821\n",
      "Epoch 5: Total Loss=0.3488\n",
      "Epoch 6: Total Loss=0.3287\n",
      "Epoch 7: Total Loss=0.3747\n",
      "Epoch 8: Total Loss=0.3394\n",
      "Epoch 9: Total Loss=0.3250\n",
      "Updated x: [0.5753004550933838, -0.7022547721862793], Function Value: 0.8241323828697205, Gradient: [0.6385802626609802, -0.5557092428207397]\n",
      "\n",
      "Step 38/40\n",
      "Epoch 0: Total Loss=0.3614\n",
      "Epoch 1: Total Loss=0.3253\n",
      "Epoch 2: Total Loss=0.3614\n",
      "Epoch 3: Total Loss=0.3207\n",
      "Epoch 4: Total Loss=0.3583\n",
      "Epoch 5: Total Loss=0.3193\n",
      "Epoch 6: Total Loss=0.3548\n",
      "Epoch 7: Total Loss=0.3144\n",
      "Epoch 8: Total Loss=0.3545\n",
      "Epoch 9: Total Loss=0.3167\n",
      "Updated x: [0.46315309405326843, -0.6693938970565796], Function Value: 0.6625989675521851, Gradient: [0.6021500825881958, -0.5283083915710449]\n",
      "\n",
      "Step 39/40\n",
      "Epoch 0: Total Loss=0.3263\n",
      "Epoch 1: Total Loss=0.3276\n",
      "Epoch 2: Total Loss=0.3235\n",
      "Epoch 3: Total Loss=0.3274\n",
      "Epoch 4: Total Loss=0.3204\n",
      "Epoch 5: Total Loss=0.3188\n",
      "Epoch 6: Total Loss=0.3185\n",
      "Epoch 7: Total Loss=0.3240\n",
      "Epoch 8: Total Loss=0.3180\n",
      "Epoch 9: Total Loss=0.3202\n",
      "Updated x: [0.4348081648349762, -0.5971710681915283], Function Value: 0.5456714034080505, Gradient: [0.594521701335907, -0.5130624771118164]\n",
      "\n",
      "Step 40/40\n",
      "Epoch 0: Total Loss=0.3498\n",
      "Epoch 1: Total Loss=0.2833\n",
      "Epoch 2: Total Loss=0.3070\n",
      "Epoch 3: Total Loss=0.3213\n",
      "Epoch 4: Total Loss=0.2766\n",
      "Epoch 5: Total Loss=0.3444\n",
      "Epoch 6: Total Loss=0.2719\n",
      "Epoch 7: Total Loss=0.2990\n",
      "Epoch 8: Total Loss=0.3100\n",
      "Epoch 9: Total Loss=0.2672\n",
      "Updated x: [0.3836970925331116, -0.6399051547050476], Function Value: 0.5567020773887634, Gradient: [0.57304447889328, -0.5098453760147095]\n",
      "\n",
      "Step 1/40\n",
      "Epoch 0: Total Loss=6.6792\n",
      "Epoch 1: Total Loss=6.5966\n",
      "Epoch 2: Total Loss=6.5177\n",
      "Epoch 3: Total Loss=6.4380\n",
      "Epoch 4: Total Loss=6.3579\n",
      "Epoch 5: Total Loss=6.2845\n",
      "Epoch 6: Total Loss=6.2114\n",
      "Epoch 7: Total Loss=6.1377\n",
      "Epoch 8: Total Loss=6.0682\n",
      "Epoch 9: Total Loss=5.9957\n",
      "Updated x: [0.8995251655578613, -0.8491489291191101], Function Value: 1.530199408531189, Gradient: [0.18976610898971558, -0.08154390007257462]\n",
      "\n",
      "Step 2/40\n",
      "Epoch 0: Total Loss=3.7952\n",
      "Epoch 1: Total Loss=3.7404\n",
      "Epoch 2: Total Loss=3.6888\n",
      "Epoch 3: Total Loss=3.6366\n",
      "Epoch 4: Total Loss=3.5875\n",
      "Epoch 5: Total Loss=3.5346\n",
      "Epoch 6: Total Loss=3.4872\n",
      "Epoch 7: Total Loss=3.4382\n",
      "Epoch 8: Total Loss=3.3870\n",
      "Epoch 9: Total Loss=3.3420\n",
      "Updated x: [0.8005692958831787, -0.7861692905426025], Function Value: 1.2589733600616455, Gradient: [0.26304197311401367, -0.09968118369579315]\n",
      "\n",
      "Step 3/40\n",
      "Epoch 0: Total Loss=2.7864\n",
      "Epoch 1: Total Loss=2.2288\n",
      "Epoch 2: Total Loss=2.7158\n",
      "Epoch 3: Total Loss=2.6628\n",
      "Epoch 4: Total Loss=2.1202\n",
      "Epoch 5: Total Loss=2.5902\n",
      "Epoch 6: Total Loss=2.5408\n",
      "Epoch 7: Total Loss=2.0153\n",
      "Epoch 8: Total Loss=2.4642\n",
      "Epoch 9: Total Loss=2.4295\n",
      "Updated x: [0.6629518270492554, -0.6729325652122498], Function Value: 0.8923434019088745, Gradient: [0.3765519857406616, -0.1346551924943924]\n",
      "\n",
      "Step 4/40\n",
      "Epoch 0: Total Loss=2.0333\n",
      "Epoch 1: Total Loss=1.7605\n",
      "Epoch 2: Total Loss=1.2469\n",
      "Epoch 3: Total Loss=1.7130\n",
      "Epoch 4: Total Loss=1.3414\n",
      "Epoch 5: Total Loss=1.8662\n",
      "Epoch 6: Total Loss=1.6176\n",
      "Epoch 7: Total Loss=1.1344\n",
      "Epoch 8: Total Loss=1.5544\n",
      "Epoch 9: Total Loss=1.2256\n",
      "Updated x: [0.5952085852622986, -0.6648378968238831], Function Value: 0.7962826490402222, Gradient: [0.4761984944343567, -0.169404074549675]\n",
      "\n",
      "Step 5/40\n",
      "Epoch 0: Total Loss=0.3451\n",
      "Epoch 1: Total Loss=0.3863\n",
      "Epoch 2: Total Loss=0.4159\n",
      "Epoch 3: Total Loss=0.3342\n",
      "Epoch 4: Total Loss=0.3810\n",
      "Epoch 5: Total Loss=0.4101\n",
      "Epoch 6: Total Loss=0.3257\n",
      "Epoch 7: Total Loss=0.3703\n",
      "Epoch 8: Total Loss=0.3950\n",
      "Epoch 9: Total Loss=0.3209\n",
      "Updated x: [0.6006311178207397, -0.6736668348312378], Function Value: 0.8145847320556641, Gradient: [0.4114959239959717, -0.15893198549747467]\n",
      "\n",
      "Step 6/40\n",
      "Epoch 0: Total Loss=0.3267\n",
      "Epoch 1: Total Loss=0.3145\n",
      "Epoch 2: Total Loss=0.1508\n",
      "Epoch 3: Total Loss=0.3028\n",
      "Epoch 4: Total Loss=0.3205\n",
      "Epoch 5: Total Loss=0.3048\n",
      "Epoch 6: Total Loss=0.1440\n",
      "Epoch 7: Total Loss=0.2985\n",
      "Epoch 8: Total Loss=0.3086\n",
      "Epoch 9: Total Loss=0.2972\n",
      "Updated x: [0.5943024158477783, -0.4569760262966156], Function Value: 0.5620224475860596, Gradient: [0.32643184065818787, -0.13644850254058838]\n",
      "\n",
      "Step 7/40\n",
      "Epoch 0: Total Loss=0.2824\n",
      "Epoch 1: Total Loss=0.2356\n",
      "Epoch 2: Total Loss=0.2852\n",
      "Epoch 3: Total Loss=0.2452\n",
      "Epoch 4: Total Loss=0.2705\n",
      "Epoch 5: Total Loss=0.2532\n",
      "Epoch 6: Total Loss=0.1305\n",
      "Epoch 7: Total Loss=0.3275\n",
      "Epoch 8: Total Loss=0.2064\n",
      "Epoch 9: Total Loss=0.2739\n",
      "Updated x: [0.45950305461883545, -0.45087119936943054], Function Value: 0.41442790627479553, Gradient: [0.21085946261882782, -0.10694851726293564]\n",
      "\n",
      "Step 8/40\n",
      "Epoch 0: Total Loss=0.2975\n",
      "Epoch 1: Total Loss=0.2368\n",
      "Epoch 2: Total Loss=0.1733\n",
      "Epoch 3: Total Loss=0.2028\n",
      "Epoch 4: Total Loss=0.1587\n",
      "Epoch 5: Total Loss=0.4732\n",
      "Epoch 6: Total Loss=0.1961\n",
      "Epoch 7: Total Loss=0.1679\n",
      "Epoch 8: Total Loss=0.1997\n",
      "Epoch 9: Total Loss=0.1792\n",
      "Updated x: [0.38982677459716797, -0.34286075830459595], Function Value: 0.2695184350013733, Gradient: [0.14162717759609222, -0.07947738468647003]\n",
      "\n",
      "Step 9/40\n",
      "Epoch 0: Total Loss=0.2794\n",
      "Epoch 1: Total Loss=0.2036\n",
      "Epoch 2: Total Loss=0.2677\n",
      "Epoch 3: Total Loss=0.1352\n",
      "Epoch 4: Total Loss=0.1729\n",
      "Epoch 5: Total Loss=0.2220\n",
      "Epoch 6: Total Loss=0.2792\n",
      "Epoch 7: Total Loss=0.2045\n",
      "Epoch 8: Total Loss=0.2640\n",
      "Epoch 9: Total Loss=0.1327\n",
      "Updated x: [0.27172788977622986, -0.29713279008865356], Function Value: 0.16212394833564758, Gradient: [0.058098528534173965, -0.049682021141052246]\n",
      "\n",
      "Step 10/40\n",
      "Epoch 0: Total Loss=0.2865\n",
      "Epoch 1: Total Loss=0.1933\n",
      "Epoch 2: Total Loss=0.1756\n",
      "Epoch 3: Total Loss=0.2690\n",
      "Epoch 4: Total Loss=0.1175\n",
      "Epoch 5: Total Loss=0.1334\n",
      "Epoch 6: Total Loss=0.1165\n",
      "Epoch 7: Total Loss=0.2859\n",
      "Epoch 8: Total Loss=0.1884\n",
      "Epoch 9: Total Loss=0.1747\n",
      "Updated x: [0.16854339838027954, -0.3775444030761719], Function Value: 0.1709466427564621, Gradient: [0.003426831215620041, -0.028678882867097855]\n",
      "\n",
      "Step 11/40\n",
      "Epoch 0: Total Loss=0.1748\n",
      "Epoch 1: Total Loss=0.1147\n",
      "Epoch 2: Total Loss=0.2233\n",
      "Epoch 3: Total Loss=0.1940\n",
      "Epoch 4: Total Loss=0.2633\n",
      "Epoch 5: Total Loss=0.1074\n",
      "Epoch 6: Total Loss=0.1622\n",
      "Epoch 7: Total Loss=0.1591\n",
      "Epoch 8: Total Loss=0.1388\n",
      "Epoch 9: Total Loss=0.1141\n",
      "Updated x: [0.05859961360692978, -0.27496764063835144], Function Value: 0.07904111593961716, Gradient: [-0.07196259498596191, 0.0038501170929521322]\n",
      "\n",
      "Step 12/40\n",
      "Epoch 0: Total Loss=0.1026\n",
      "Epoch 1: Total Loss=0.1034\n",
      "Epoch 2: Total Loss=0.1024\n",
      "Epoch 3: Total Loss=0.1023\n",
      "Epoch 4: Total Loss=0.1012\n",
      "Epoch 5: Total Loss=0.1009\n",
      "Epoch 6: Total Loss=0.0995\n",
      "Epoch 7: Total Loss=0.1004\n",
      "Epoch 8: Total Loss=0.0999\n",
      "Epoch 9: Total Loss=0.0969\n",
      "Updated x: [-0.05973058193922043, -0.3086984157562256], Function Value: 0.09886245429515839, Gradient: [-0.06872265785932541, -0.011404459364712238]\n",
      "\n",
      "Step 13/40\n",
      "Epoch 0: Total Loss=0.1097\n",
      "Epoch 1: Total Loss=0.1097\n",
      "Epoch 2: Total Loss=0.0915\n",
      "Epoch 3: Total Loss=0.1088\n",
      "Epoch 4: Total Loss=0.1084\n",
      "Epoch 5: Total Loss=0.0898\n",
      "Epoch 6: Total Loss=0.1060\n",
      "Epoch 7: Total Loss=0.1068\n",
      "Epoch 8: Total Loss=0.0912\n",
      "Epoch 9: Total Loss=0.1046\n",
      "Updated x: [-0.03940533101558685, -0.27237263321876526], Function Value: 0.07573963701725006, Gradient: [-0.04905836284160614, -0.030213341116905212]\n",
      "\n",
      "Step 14/40\n",
      "Epoch 0: Total Loss=0.0897\n",
      "Epoch 1: Total Loss=0.1081\n",
      "Epoch 2: Total Loss=0.0824\n",
      "Epoch 3: Total Loss=0.0995\n",
      "Epoch 4: Total Loss=0.0824\n",
      "Epoch 5: Total Loss=0.0893\n",
      "Epoch 6: Total Loss=0.1060\n",
      "Epoch 7: Total Loss=0.0831\n",
      "Epoch 8: Total Loss=0.0979\n",
      "Epoch 9: Total Loss=0.0825\n",
      "Updated x: [-0.029281072318553925, -0.09819383919239044], Function Value: 0.010499411262571812, Gradient: [-0.046121373772621155, -0.03145933896303177]\n",
      "\n",
      "Step 15/40\n",
      "Epoch 0: Total Loss=0.0830\n",
      "Epoch 1: Total Loss=0.0784\n",
      "Epoch 2: Total Loss=0.0810\n",
      "Epoch 3: Total Loss=0.0817\n",
      "Epoch 4: Total Loss=0.0787\n",
      "Epoch 5: Total Loss=0.0807\n",
      "Epoch 6: Total Loss=0.0815\n",
      "Epoch 7: Total Loss=0.0772\n",
      "Epoch 8: Total Loss=0.0805\n",
      "Epoch 9: Total Loss=0.0805\n",
      "Updated x: [0.0012367051094770432, -0.025819405913352966], Function Value: 0.0006681712111458182, Gradient: [-0.03115176036953926, -0.015821360051631927]\n",
      "\n",
      "Step 16/40\n",
      "Epoch 0: Total Loss=0.0763\n",
      "Epoch 1: Total Loss=0.0739\n",
      "Epoch 2: Total Loss=0.0776\n",
      "Epoch 3: Total Loss=0.0721\n",
      "Epoch 4: Total Loss=0.0750\n",
      "Epoch 5: Total Loss=0.0725\n",
      "Epoch 6: Total Loss=0.0775\n",
      "Epoch 7: Total Loss=0.0736\n",
      "Epoch 8: Total Loss=0.0752\n",
      "Epoch 9: Total Loss=0.0733\n",
      "Updated x: [-0.09687655419111252, 0.013494346290826797], Function Value: 0.009567164815962315, Gradient: [-0.00926672387868166, -0.010479966178536415]\n",
      "\n",
      "Step 17/40\n",
      "Epoch 0: Total Loss=0.0749\n",
      "Epoch 1: Total Loss=0.0682\n",
      "Epoch 2: Total Loss=0.0738\n",
      "Epoch 3: Total Loss=0.0722\n",
      "Epoch 4: Total Loss=0.0723\n",
      "Epoch 5: Total Loss=0.0699\n",
      "Epoch 6: Total Loss=0.0731\n",
      "Epoch 7: Total Loss=0.0691\n",
      "Epoch 8: Total Loss=0.0698\n",
      "Epoch 9: Total Loss=0.0760\n",
      "Updated x: [-0.18760666251182556, -0.07891519367694855], Function Value: 0.041423868387937546, Gradient: [0.0023984131403267384, -0.010186362080276012]\n",
      "\n",
      "Step 18/40\n",
      "Epoch 0: Total Loss=0.0677\n",
      "Epoch 1: Total Loss=0.0728\n",
      "Epoch 2: Total Loss=0.0705\n",
      "Epoch 3: Total Loss=0.0683\n",
      "Epoch 4: Total Loss=0.0702\n",
      "Epoch 5: Total Loss=0.0724\n",
      "Epoch 6: Total Loss=0.0734\n",
      "Epoch 7: Total Loss=0.0717\n",
      "Epoch 8: Total Loss=0.0682\n",
      "Epoch 9: Total Loss=0.0685\n",
      "Updated x: [-0.12851428985595703, -0.006775431334972382], Function Value: 0.016561828553676605, Gradient: [-0.0019829559605568647, -0.010304702445864677]\n",
      "\n",
      "Step 19/40\n",
      "Epoch 0: Total Loss=0.0710\n",
      "Epoch 1: Total Loss=0.0682\n",
      "Epoch 2: Total Loss=0.0693\n",
      "Epoch 3: Total Loss=0.0695\n",
      "Epoch 4: Total Loss=0.0698\n",
      "Epoch 5: Total Loss=0.0715\n",
      "Epoch 6: Total Loss=0.0717\n",
      "Epoch 7: Total Loss=0.0686\n",
      "Epoch 8: Total Loss=0.0697\n",
      "Epoch 9: Total Loss=0.0677\n",
      "Updated x: [-0.21042299270629883, 0.014479933306574821], Function Value: 0.04448750242590904, Gradient: [-0.008137882687151432, -0.0028297624085098505]\n",
      "\n",
      "Step 20/40\n",
      "Epoch 0: Total Loss=0.0724\n",
      "Epoch 1: Total Loss=0.0666\n",
      "Epoch 2: Total Loss=0.0665\n",
      "Epoch 3: Total Loss=0.0674\n",
      "Epoch 4: Total Loss=0.0693\n",
      "Epoch 5: Total Loss=0.0707\n",
      "Epoch 6: Total Loss=0.0674\n",
      "Epoch 7: Total Loss=0.0737\n",
      "Epoch 8: Total Loss=0.0671\n",
      "Epoch 9: Total Loss=0.0671\n",
      "Updated x: [-0.11316201835870743, 0.041054073721170425], Function Value: 0.01449107937514782, Gradient: [-0.006160020362585783, -0.005360274109989405]\n",
      "\n",
      "Step 21/40\n",
      "Epoch 0: Total Loss=0.0728\n",
      "Epoch 1: Total Loss=0.0696\n",
      "Epoch 2: Total Loss=0.0715\n",
      "Epoch 3: Total Loss=0.0659\n",
      "Epoch 4: Total Loss=0.0656\n",
      "Epoch 5: Total Loss=0.0665\n",
      "Epoch 6: Total Loss=0.0696\n",
      "Epoch 7: Total Loss=0.0743\n",
      "Epoch 8: Total Loss=0.0690\n",
      "Epoch 9: Total Loss=0.0679\n",
      "Updated x: [-0.04740403592586517, -0.03984859213232994], Function Value: 0.003835052950307727, Gradient: [-1.048295871441951e-06, -0.01249722670763731]\n",
      "\n",
      "Step 22/40\n",
      "Epoch 0: Total Loss=0.0643\n",
      "Epoch 1: Total Loss=0.0642\n",
      "Epoch 2: Total Loss=0.0645\n",
      "Epoch 3: Total Loss=0.0638\n",
      "Epoch 4: Total Loss=0.0649\n",
      "Epoch 5: Total Loss=0.0638\n",
      "Epoch 6: Total Loss=0.0640\n",
      "Epoch 7: Total Loss=0.0641\n",
      "Epoch 8: Total Loss=0.0645\n",
      "Epoch 9: Total Loss=0.0641\n",
      "Updated x: [-0.05051245167851448, 0.03787577524781227], Function Value: 0.003986082039773464, Gradient: [-0.028019888326525688, -0.011680408380925655]\n",
      "\n",
      "Step 23/40\n",
      "Epoch 0: Total Loss=0.0623\n",
      "Epoch 1: Total Loss=0.0634\n",
      "Epoch 2: Total Loss=0.0621\n",
      "Epoch 3: Total Loss=0.0611\n",
      "Epoch 4: Total Loss=0.0635\n",
      "Epoch 5: Total Loss=0.0627\n",
      "Epoch 6: Total Loss=0.0620\n",
      "Epoch 7: Total Loss=0.0631\n",
      "Epoch 8: Total Loss=0.0626\n",
      "Epoch 9: Total Loss=0.0612\n",
      "Updated x: [-0.007841713726520538, -0.04629604145884514], Function Value: 0.0022048158571124077, Gradient: [-0.02228568121790886, -0.012041686102747917]\n",
      "\n",
      "Step 24/40\n",
      "Epoch 0: Total Loss=0.0625\n",
      "Epoch 1: Total Loss=0.0630\n",
      "Epoch 2: Total Loss=0.0610\n",
      "Epoch 3: Total Loss=0.0616\n",
      "Epoch 4: Total Loss=0.0633\n",
      "Epoch 5: Total Loss=0.0615\n",
      "Epoch 6: Total Loss=0.0627\n",
      "Epoch 7: Total Loss=0.0606\n",
      "Epoch 8: Total Loss=0.0621\n",
      "Epoch 9: Total Loss=0.0627\n",
      "Updated x: [0.1546206772327423, -0.0027447976171970367], Function Value: 0.023915087804198265, Gradient: [-0.020314529538154602, -0.01131821982562542]\n",
      "\n",
      "Step 25/40\n",
      "Epoch 0: Total Loss=0.0616\n",
      "Epoch 1: Total Loss=0.0620\n",
      "Epoch 2: Total Loss=0.0620\n",
      "Epoch 3: Total Loss=0.0615\n",
      "Epoch 4: Total Loss=0.0616\n",
      "Epoch 5: Total Loss=0.0618\n",
      "Epoch 6: Total Loss=0.0617\n",
      "Epoch 7: Total Loss=0.0612\n",
      "Epoch 8: Total Loss=0.0626\n",
      "Epoch 9: Total Loss=0.0610\n",
      "Updated x: [0.03414870798587799, -0.06669577956199646], Function Value: 0.005614461377263069, Gradient: [-0.01912817545235157, -0.010827331803739071]\n",
      "\n",
      "Step 26/40\n",
      "Epoch 0: Total Loss=0.0614\n",
      "Epoch 1: Total Loss=0.0620\n",
      "Epoch 2: Total Loss=0.0622\n",
      "Epoch 3: Total Loss=0.0618\n",
      "Epoch 4: Total Loss=0.0607\n",
      "Epoch 5: Total Loss=0.0617\n",
      "Epoch 6: Total Loss=0.0612\n",
      "Epoch 7: Total Loss=0.0622\n",
      "Epoch 8: Total Loss=0.0613\n",
      "Epoch 9: Total Loss=0.0615\n",
      "Updated x: [0.10279739648103714, -0.01202448457479477], Function Value: 0.010711892507970333, Gradient: [-0.018541987985372543, -0.006604836322367191]\n",
      "\n",
      "Step 27/40\n",
      "Epoch 0: Total Loss=0.0616\n",
      "Epoch 1: Total Loss=0.0611\n",
      "Epoch 2: Total Loss=0.0616\n",
      "Epoch 3: Total Loss=0.0621\n",
      "Epoch 4: Total Loss=0.0619\n",
      "Epoch 5: Total Loss=0.0617\n",
      "Epoch 6: Total Loss=0.0609\n",
      "Epoch 7: Total Loss=0.0603\n",
      "Epoch 8: Total Loss=0.0613\n",
      "Epoch 9: Total Loss=0.0608\n",
      "Updated x: [-0.04027695208787918, -0.07191064953804016], Function Value: 0.006793374195694923, Gradient: [-0.008519141934812069, -0.009946532547473907]\n",
      "\n",
      "Step 28/40\n",
      "Epoch 0: Total Loss=0.0623\n",
      "Epoch 1: Total Loss=0.0613\n",
      "Epoch 2: Total Loss=0.0617\n",
      "Epoch 3: Total Loss=0.0605\n",
      "Epoch 4: Total Loss=0.0607\n",
      "Epoch 5: Total Loss=0.0621\n",
      "Epoch 6: Total Loss=0.0615\n",
      "Epoch 7: Total Loss=0.0613\n",
      "Epoch 8: Total Loss=0.0610\n",
      "Epoch 9: Total Loss=0.0604\n",
      "Updated x: [-0.0785166323184967, -0.1040782481431961], Function Value: 0.016997143626213074, Gradient: [-0.006774124689400196, -0.012562989257276058]\n",
      "\n",
      "Step 29/40\n",
      "Epoch 0: Total Loss=0.0612\n",
      "Epoch 1: Total Loss=0.0611\n",
      "Epoch 2: Total Loss=0.0612\n",
      "Epoch 3: Total Loss=0.0609\n",
      "Epoch 4: Total Loss=0.0603\n",
      "Epoch 5: Total Loss=0.0625\n",
      "Epoch 6: Total Loss=0.0617\n",
      "Epoch 7: Total Loss=0.0613\n",
      "Epoch 8: Total Loss=0.0606\n",
      "Epoch 9: Total Loss=0.0607\n",
      "Updated x: [0.04336857050657272, 0.025299519300460815], Function Value: 0.002520898589864373, Gradient: [-0.013142039999365807, -0.005274064838886261]\n",
      "\n",
      "Step 30/40\n",
      "Epoch 0: Total Loss=0.0603\n",
      "Epoch 1: Total Loss=0.0626\n",
      "Epoch 2: Total Loss=0.0600\n",
      "Epoch 3: Total Loss=0.0604\n",
      "Epoch 4: Total Loss=0.0662\n",
      "Epoch 5: Total Loss=0.0617\n",
      "Epoch 6: Total Loss=0.0599\n",
      "Epoch 7: Total Loss=0.0605\n",
      "Epoch 8: Total Loss=0.0631\n",
      "Epoch 9: Total Loss=0.0613\n",
      "Updated x: [0.09248499572277069, 0.023433055728673935], Function Value: 0.00910258200019598, Gradient: [-0.012475471943616867, -0.005094645544886589]\n",
      "\n",
      "Step 31/40\n",
      "Epoch 0: Total Loss=0.0660\n",
      "Epoch 1: Total Loss=0.0624\n",
      "Epoch 2: Total Loss=0.0606\n",
      "Epoch 3: Total Loss=0.0606\n",
      "Epoch 4: Total Loss=0.0606\n",
      "Epoch 5: Total Loss=0.0597\n",
      "Epoch 6: Total Loss=0.0613\n",
      "Epoch 7: Total Loss=0.0657\n",
      "Epoch 8: Total Loss=0.0606\n",
      "Epoch 9: Total Loss=0.0623\n",
      "Updated x: [-0.0026674866676330566, -0.0070994142442941666], Function Value: 5.751716889790259e-05, Gradient: [-0.00459982268512249, -0.008901873603463173]\n",
      "\n",
      "Step 32/40\n",
      "Epoch 0: Total Loss=0.0567\n",
      "Epoch 1: Total Loss=0.0566\n",
      "Epoch 2: Total Loss=0.0567\n",
      "Epoch 3: Total Loss=0.0565\n",
      "Epoch 4: Total Loss=0.0565\n",
      "Epoch 5: Total Loss=0.0567\n",
      "Epoch 6: Total Loss=0.0566\n",
      "Epoch 7: Total Loss=0.0565\n",
      "Epoch 8: Total Loss=0.0562\n",
      "Epoch 9: Total Loss=0.0566\n",
      "Updated x: [0.01908939704298973, 0.004599281586706638], Function Value: 0.0003855584654957056, Gradient: [-0.007845292799174786, -0.007824447937309742]\n",
      "\n",
      "Step 33/40\n",
      "Epoch 0: Total Loss=0.0568\n",
      "Epoch 1: Total Loss=0.0570\n",
      "Epoch 2: Total Loss=0.0567\n",
      "Epoch 3: Total Loss=0.0567\n",
      "Epoch 4: Total Loss=0.0570\n",
      "Epoch 5: Total Loss=0.0571\n",
      "Epoch 6: Total Loss=0.0570\n",
      "Epoch 7: Total Loss=0.0571\n",
      "Epoch 8: Total Loss=0.0569\n",
      "Epoch 9: Total Loss=0.0569\n",
      "Updated x: [-0.02253955602645874, 0.02195841819047928], Function Value: 0.0009902036981657147, Gradient: [0.0010454541770741343, -0.008585791103541851]\n",
      "\n",
      "Step 34/40\n",
      "Epoch 0: Total Loss=0.0579\n",
      "Epoch 1: Total Loss=0.0590\n",
      "Epoch 2: Total Loss=0.0568\n",
      "Epoch 3: Total Loss=0.0577\n",
      "Epoch 4: Total Loss=0.0593\n",
      "Epoch 5: Total Loss=0.0578\n",
      "Epoch 6: Total Loss=0.0587\n",
      "Epoch 7: Total Loss=0.0568\n",
      "Epoch 8: Total Loss=0.0581\n",
      "Epoch 9: Total Loss=0.0590\n",
      "Updated x: [-0.08607976883649826, 0.00896935909986496], Function Value: 0.0074901762418448925, Gradient: [0.018725330010056496, -0.011178205721080303]\n",
      "\n",
      "Step 35/40\n",
      "Epoch 0: Total Loss=0.0589\n",
      "Epoch 1: Total Loss=0.0587\n",
      "Epoch 2: Total Loss=0.0577\n",
      "Epoch 3: Total Loss=0.0592\n",
      "Epoch 4: Total Loss=0.0585\n",
      "Epoch 5: Total Loss=0.0578\n",
      "Epoch 6: Total Loss=0.0593\n",
      "Epoch 7: Total Loss=0.0584\n",
      "Epoch 8: Total Loss=0.0579\n",
      "Epoch 9: Total Loss=0.0591\n",
      "Updated x: [-0.11600124835968018, -0.08690789341926575], Function Value: 0.02100927196443081, Gradient: [0.01742682047188282, -0.01128093246370554]\n",
      "\n",
      "Step 36/40\n",
      "Epoch 0: Total Loss=0.0588\n",
      "Epoch 1: Total Loss=0.0574\n",
      "Epoch 2: Total Loss=0.0574\n",
      "Epoch 3: Total Loss=0.0594\n",
      "Epoch 4: Total Loss=0.0586\n",
      "Epoch 5: Total Loss=0.0577\n",
      "Epoch 6: Total Loss=0.0575\n",
      "Epoch 7: Total Loss=0.0593\n",
      "Epoch 8: Total Loss=0.0584\n",
      "Epoch 9: Total Loss=0.0579\n",
      "Updated x: [-0.1348179131746292, -0.008719511330127716], Function Value: 0.018251899629831314, Gradient: [0.018613098189234734, -0.011652261018753052]\n",
      "\n",
      "Step 37/40\n",
      "Epoch 0: Total Loss=0.0586\n",
      "Epoch 1: Total Loss=0.0579\n",
      "Epoch 2: Total Loss=0.0579\n",
      "Epoch 3: Total Loss=0.0577\n",
      "Epoch 4: Total Loss=0.0586\n",
      "Epoch 5: Total Loss=0.0596\n",
      "Epoch 6: Total Loss=0.0571\n",
      "Epoch 7: Total Loss=0.0587\n",
      "Epoch 8: Total Loss=0.0587\n",
      "Epoch 9: Total Loss=0.0586\n",
      "Updated x: [-0.03304685652256012, -0.0017449692822992802], Function Value: 0.001095139654353261, Gradient: [-0.002757574897259474, -0.006459140684455633]\n",
      "\n",
      "Step 38/40\n",
      "Epoch 0: Total Loss=0.0575\n",
      "Epoch 1: Total Loss=0.0576\n",
      "Epoch 2: Total Loss=0.0585\n",
      "Epoch 3: Total Loss=0.0580\n",
      "Epoch 4: Total Loss=0.0609\n",
      "Epoch 5: Total Loss=0.0574\n",
      "Epoch 6: Total Loss=0.0579\n",
      "Epoch 7: Total Loss=0.0580\n",
      "Epoch 8: Total Loss=0.0578\n",
      "Epoch 9: Total Loss=0.0601\n",
      "Updated x: [0.10439875721931458, -0.00042405736166983843], Function Value: 0.010899280197918415, Gradient: [-0.019300956279039383, -0.0011502511333674192]\n",
      "\n",
      "Step 39/40\n",
      "Epoch 0: Total Loss=0.0584\n",
      "Epoch 1: Total Loss=0.0583\n",
      "Epoch 2: Total Loss=0.0569\n",
      "Epoch 3: Total Loss=0.0587\n",
      "Epoch 4: Total Loss=0.0581\n",
      "Epoch 5: Total Loss=0.0592\n",
      "Epoch 6: Total Loss=0.0585\n",
      "Epoch 7: Total Loss=0.0583\n",
      "Epoch 8: Total Loss=0.0571\n",
      "Epoch 9: Total Loss=0.0586\n",
      "Updated x: [0.07291329652070999, 0.12002899497747421], Function Value: 0.019723307341337204, Gradient: [-0.016574418172240257, 0.0031701489351689816]\n",
      "\n",
      "Step 40/40\n",
      "Epoch 0: Total Loss=0.0602\n",
      "Epoch 1: Total Loss=0.0621\n",
      "Epoch 2: Total Loss=0.0596\n",
      "Epoch 3: Total Loss=0.0575\n",
      "Epoch 4: Total Loss=0.0584\n",
      "Epoch 5: Total Loss=0.0578\n",
      "Epoch 6: Total Loss=0.0582\n",
      "Epoch 7: Total Loss=0.0600\n",
      "Epoch 8: Total Loss=0.0621\n",
      "Epoch 9: Total Loss=0.0596\n",
      "Updated x: [0.20005393028259277, 0.1967170387506485], Function Value: 0.07871916890144348, Gradient: [-0.022002898156642914, 0.009391152299940586]\n",
      "\n",
      "Step 1/40\n",
      "Epoch 0: Total Loss=6.0385\n",
      "Epoch 1: Total Loss=5.1262\n",
      "Epoch 2: Total Loss=5.2244\n",
      "Epoch 3: Total Loss=5.8129\n",
      "Epoch 4: Total Loss=4.9359\n",
      "Epoch 5: Total Loss=5.0397\n",
      "Epoch 6: Total Loss=5.6131\n",
      "Epoch 7: Total Loss=4.7677\n",
      "Epoch 8: Total Loss=4.8683\n",
      "Epoch 9: Total Loss=5.4307\n",
      "Updated x: [0.8187611103057861, -0.725340723991394], Function Value: 1.196488857269287, Gradient: [-0.1271224319934845, 0.17293620109558105]\n",
      "\n",
      "Step 2/40\n",
      "Epoch 0: Total Loss=3.3435\n",
      "Epoch 1: Total Loss=2.5691\n",
      "Epoch 2: Total Loss=3.1225\n",
      "Epoch 3: Total Loss=3.2265\n",
      "Epoch 4: Total Loss=2.4847\n",
      "Epoch 5: Total Loss=3.0164\n",
      "Epoch 6: Total Loss=3.1208\n",
      "Epoch 7: Total Loss=2.4045\n",
      "Epoch 8: Total Loss=2.9176\n",
      "Epoch 9: Total Loss=3.0209\n",
      "Updated x: [0.8103892207145691, -0.55387282371521], Function Value: 0.9635058045387268, Gradient: [-0.01940189115703106, 0.11986099928617477]\n",
      "\n",
      "Step 3/40\n",
      "Epoch 0: Total Loss=0.3131\n",
      "Epoch 1: Total Loss=0.4193\n",
      "Epoch 2: Total Loss=0.3188\n",
      "Epoch 3: Total Loss=0.2798\n",
      "Epoch 4: Total Loss=0.3908\n",
      "Epoch 5: Total Loss=0.3061\n",
      "Epoch 6: Total Loss=0.4125\n",
      "Epoch 7: Total Loss=0.3131\n",
      "Epoch 8: Total Loss=0.2734\n",
      "Epoch 9: Total Loss=0.3868\n",
      "Updated x: [0.5923281311988831, -0.5054827928543091], Function Value: 0.606365442276001, Gradient: [0.062227554619312286, 0.07661622017621994]\n",
      "\n",
      "Step 4/40\n",
      "Epoch 0: Total Loss=0.2687\n",
      "Epoch 1: Total Loss=0.2178\n",
      "Epoch 2: Total Loss=0.1498\n",
      "Epoch 3: Total Loss=0.1916\n",
      "Epoch 4: Total Loss=0.2638\n",
      "Epoch 5: Total Loss=0.2156\n",
      "Epoch 6: Total Loss=0.1462\n",
      "Epoch 7: Total Loss=0.1899\n",
      "Epoch 8: Total Loss=0.2608\n",
      "Epoch 9: Total Loss=0.2137\n",
      "Updated x: [0.5769821405410767, -0.5814048051834106], Function Value: 0.6709399223327637, Gradient: [0.061212699860334396, 0.05409630015492439]\n",
      "\n",
      "Step 5/40\n",
      "Epoch 0: Total Loss=0.1783\n",
      "Epoch 1: Total Loss=0.1787\n",
      "Epoch 2: Total Loss=0.1712\n",
      "Epoch 3: Total Loss=0.1365\n",
      "Epoch 4: Total Loss=0.2033\n",
      "Epoch 5: Total Loss=0.1782\n",
      "Epoch 6: Total Loss=0.1778\n",
      "Epoch 7: Total Loss=0.1715\n",
      "Epoch 8: Total Loss=0.1368\n",
      "Epoch 9: Total Loss=0.2005\n",
      "Updated x: [0.5122154355049133, -0.4481717348098755], Function Value: 0.46322256326675415, Gradient: [0.060849301517009735, 0.028401199728250504]\n",
      "\n",
      "Step 6/40\n",
      "Epoch 0: Total Loss=0.1470\n",
      "Epoch 1: Total Loss=0.1989\n",
      "Epoch 2: Total Loss=0.0996\n",
      "Epoch 3: Total Loss=0.1825\n",
      "Epoch 4: Total Loss=0.1631\n",
      "Epoch 5: Total Loss=0.1372\n",
      "Epoch 6: Total Loss=0.1060\n",
      "Epoch 7: Total Loss=0.1589\n",
      "Epoch 8: Total Loss=0.1782\n",
      "Epoch 9: Total Loss=0.1343\n",
      "Updated x: [0.31105273962020874, -0.5212231874465942], Function Value: 0.36842742562294006, Gradient: [0.032313376665115356, 0.01380428858101368]\n",
      "\n",
      "Step 7/40\n",
      "Epoch 0: Total Loss=0.1166\n",
      "Epoch 1: Total Loss=0.1142\n",
      "Epoch 2: Total Loss=0.2075\n",
      "Epoch 3: Total Loss=0.1300\n",
      "Epoch 4: Total Loss=0.1286\n",
      "Epoch 5: Total Loss=0.1486\n",
      "Epoch 6: Total Loss=0.1487\n",
      "Epoch 7: Total Loss=0.1936\n",
      "Epoch 8: Total Loss=0.1020\n",
      "Epoch 9: Total Loss=0.1895\n",
      "Updated x: [0.2678946852684021, -0.3482232689857483], Function Value: 0.19302700459957123, Gradient: [0.02578851953148842, 0.0037790262140333652]\n",
      "\n",
      "Step 8/40\n",
      "Epoch 0: Total Loss=0.1251\n",
      "Epoch 1: Total Loss=0.1193\n",
      "Epoch 2: Total Loss=0.1025\n",
      "Epoch 3: Total Loss=0.1276\n",
      "Epoch 4: Total Loss=0.1079\n",
      "Epoch 5: Total Loss=0.1176\n",
      "Epoch 6: Total Loss=0.1922\n",
      "Epoch 7: Total Loss=0.1905\n",
      "Epoch 8: Total Loss=0.1520\n",
      "Epoch 9: Total Loss=0.1240\n",
      "Updated x: [0.21786357462406158, -0.22393423318862915], Function Value: 0.09761108458042145, Gradient: [0.02412429079413414, -0.003089842153713107]\n",
      "\n",
      "Step 9/40\n",
      "Epoch 0: Total Loss=0.0996\n",
      "Epoch 1: Total Loss=0.0951\n",
      "Epoch 2: Total Loss=0.0946\n",
      "Epoch 3: Total Loss=0.1174\n",
      "Epoch 4: Total Loss=0.0885\n",
      "Epoch 5: Total Loss=0.0974\n",
      "Epoch 6: Total Loss=0.1525\n",
      "Epoch 7: Total Loss=0.1521\n",
      "Epoch 8: Total Loss=0.1421\n",
      "Epoch 9: Total Loss=0.2210\n",
      "Updated x: [0.1720065325498581, -0.1587611585855484], Function Value: 0.05479135364294052, Gradient: [0.018894173204898834, -0.0077754235826432705]\n",
      "\n",
      "Step 10/40\n",
      "Epoch 0: Total Loss=0.0942\n",
      "Epoch 1: Total Loss=0.1504\n",
      "Epoch 2: Total Loss=0.2295\n",
      "Epoch 3: Total Loss=0.0882\n",
      "Epoch 4: Total Loss=0.0891\n",
      "Epoch 5: Total Loss=0.1404\n",
      "Epoch 6: Total Loss=0.0830\n",
      "Epoch 7: Total Loss=0.1279\n",
      "Epoch 8: Total Loss=0.1035\n",
      "Epoch 9: Total Loss=0.1015\n",
      "Updated x: [0.035055652260780334, -0.13345980644226074], Function Value: 0.019040418788790703, Gradient: [0.009486338123679161, -0.00876289140433073]\n",
      "\n",
      "Step 11/40\n",
      "Epoch 0: Total Loss=0.1383\n",
      "Epoch 1: Total Loss=0.1356\n",
      "Epoch 2: Total Loss=0.0885\n",
      "Epoch 3: Total Loss=0.0998\n",
      "Epoch 4: Total Loss=0.0847\n",
      "Epoch 5: Total Loss=0.1797\n",
      "Epoch 6: Total Loss=0.1061\n",
      "Epoch 7: Total Loss=0.1129\n",
      "Epoch 8: Total Loss=0.0902\n",
      "Epoch 9: Total Loss=0.1381\n",
      "Updated x: [-0.027613453567028046, -0.05802581459283829], Function Value: 0.004129497800022364, Gradient: [0.0008432517061010003, -0.006292189471423626]\n",
      "\n",
      "Step 12/40\n",
      "Epoch 0: Total Loss=0.0637\n",
      "Epoch 1: Total Loss=0.0608\n",
      "Epoch 2: Total Loss=0.0624\n",
      "Epoch 3: Total Loss=0.0642\n",
      "Epoch 4: Total Loss=0.0612\n",
      "Epoch 5: Total Loss=0.0621\n",
      "Epoch 6: Total Loss=0.0637\n",
      "Epoch 7: Total Loss=0.0613\n",
      "Epoch 8: Total Loss=0.0612\n",
      "Epoch 9: Total Loss=0.0634\n",
      "Updated x: [0.022071026265621185, -0.0848044902086258], Function Value: 0.007678931578993797, Gradient: [-0.003963242284953594, -0.015698960050940514]\n",
      "\n",
      "Step 13/40\n",
      "Epoch 0: Total Loss=0.0647\n",
      "Epoch 1: Total Loss=0.0631\n",
      "Epoch 2: Total Loss=0.0629\n",
      "Epoch 3: Total Loss=0.0646\n",
      "Epoch 4: Total Loss=0.0623\n",
      "Epoch 5: Total Loss=0.0650\n",
      "Epoch 6: Total Loss=0.0624\n",
      "Epoch 7: Total Loss=0.0623\n",
      "Epoch 8: Total Loss=0.0643\n",
      "Epoch 9: Total Loss=0.0621\n",
      "Updated x: [-0.04697518050670624, -0.02092868834733963], Function Value: 0.002644677646458149, Gradient: [-0.006891189143061638, -0.013561313971877098]\n",
      "\n",
      "Step 14/40\n",
      "Epoch 0: Total Loss=0.0622\n",
      "Epoch 1: Total Loss=0.0634\n",
      "Epoch 2: Total Loss=0.0606\n",
      "Epoch 3: Total Loss=0.0613\n",
      "Epoch 4: Total Loss=0.0613\n",
      "Epoch 5: Total Loss=0.0634\n",
      "Epoch 6: Total Loss=0.0619\n",
      "Epoch 7: Total Loss=0.0609\n",
      "Epoch 8: Total Loss=0.0607\n",
      "Epoch 9: Total Loss=0.0626\n",
      "Updated x: [0.0029074884951114655, 0.011100132018327713], Function Value: 0.000131666412926279, Gradient: [-0.005437642335891724, -0.012401459738612175]\n",
      "\n",
      "Step 15/40\n",
      "Epoch 0: Total Loss=0.0601\n",
      "Epoch 1: Total Loss=0.0610\n",
      "Epoch 2: Total Loss=0.0599\n",
      "Epoch 3: Total Loss=0.0619\n",
      "Epoch 4: Total Loss=0.0626\n",
      "Epoch 5: Total Loss=0.0608\n",
      "Epoch 6: Total Loss=0.0618\n",
      "Epoch 7: Total Loss=0.0607\n",
      "Epoch 8: Total Loss=0.0614\n",
      "Epoch 9: Total Loss=0.0625\n",
      "Updated x: [-0.021432077512145042, 0.011858626268804073], Function Value: 0.0005999609711579978, Gradient: [-0.005557782016694546, -0.01369514875113964]\n",
      "\n",
      "Step 16/40\n",
      "Epoch 0: Total Loss=0.0600\n",
      "Epoch 1: Total Loss=0.0621\n",
      "Epoch 2: Total Loss=0.0609\n",
      "Epoch 3: Total Loss=0.0597\n",
      "Epoch 4: Total Loss=0.0609\n",
      "Epoch 5: Total Loss=0.0608\n",
      "Epoch 6: Total Loss=0.0595\n",
      "Epoch 7: Total Loss=0.0601\n",
      "Epoch 8: Total Loss=0.0626\n",
      "Epoch 9: Total Loss=0.0602\n",
      "Updated x: [0.019611136987805367, -0.06475600600242615], Function Value: 0.0045779370702803135, Gradient: [-0.004985544364899397, -0.012533911503851414]\n",
      "\n",
      "Step 17/40\n",
      "Epoch 0: Total Loss=0.0609\n",
      "Epoch 1: Total Loss=0.0601\n",
      "Epoch 2: Total Loss=0.0673\n",
      "Epoch 3: Total Loss=0.0617\n",
      "Epoch 4: Total Loss=0.0607\n",
      "Epoch 5: Total Loss=0.0602\n",
      "Epoch 6: Total Loss=0.0599\n",
      "Epoch 7: Total Loss=0.0606\n",
      "Epoch 8: Total Loss=0.0606\n",
      "Epoch 9: Total Loss=0.0663\n",
      "Updated x: [-0.003567218780517578, -0.037828266620635986], Function Value: 0.0014437027275562286, Gradient: [-0.0034634906332939863, -0.012890857644379139]\n",
      "\n",
      "Step 18/40\n",
      "Epoch 0: Total Loss=0.0592\n",
      "Epoch 1: Total Loss=0.0606\n",
      "Epoch 2: Total Loss=0.0602\n",
      "Epoch 3: Total Loss=0.0665\n",
      "Epoch 4: Total Loss=0.0618\n",
      "Epoch 5: Total Loss=0.0603\n",
      "Epoch 6: Total Loss=0.0605\n",
      "Epoch 7: Total Loss=0.0601\n",
      "Epoch 8: Total Loss=0.0595\n",
      "Epoch 9: Total Loss=0.0591\n",
      "Updated x: [-0.05223720148205757, -0.013048717752099037], Function Value: 0.002898994367569685, Gradient: [-0.004071803297847509, -0.012211593799293041]\n",
      "\n",
      "Step 19/40\n",
      "Epoch 0: Total Loss=0.0596\n",
      "Epoch 1: Total Loss=0.0600\n",
      "Epoch 2: Total Loss=0.0596\n",
      "Epoch 3: Total Loss=0.0595\n",
      "Epoch 4: Total Loss=0.0605\n",
      "Epoch 5: Total Loss=0.0622\n",
      "Epoch 6: Total Loss=0.0672\n",
      "Epoch 7: Total Loss=0.0601\n",
      "Epoch 8: Total Loss=0.0602\n",
      "Epoch 9: Total Loss=0.0595\n",
      "Updated x: [0.032637570053339005, 0.017587652429938316], Function Value: 0.0013745365431532264, Gradient: [-0.0027439564000815153, -0.011153015308082104]\n",
      "\n",
      "Step 20/40\n",
      "Epoch 0: Total Loss=0.0599\n",
      "Epoch 1: Total Loss=0.0611\n",
      "Epoch 2: Total Loss=0.0609\n",
      "Epoch 3: Total Loss=0.0605\n",
      "Epoch 4: Total Loss=0.0603\n",
      "Epoch 5: Total Loss=0.0599\n",
      "Epoch 6: Total Loss=0.0603\n",
      "Epoch 7: Total Loss=0.0601\n",
      "Epoch 8: Total Loss=0.0604\n",
      "Epoch 9: Total Loss=0.0603\n",
      "Updated x: [0.044626690447330475, -0.06645847111940384], Function Value: 0.0064082699827849865, Gradient: [-0.003117847489193082, -0.011542702093720436]\n",
      "\n",
      "Step 21/40\n",
      "Epoch 0: Total Loss=0.0600\n",
      "Epoch 1: Total Loss=0.0606\n",
      "Epoch 2: Total Loss=0.0606\n",
      "Epoch 3: Total Loss=0.0599\n",
      "Epoch 4: Total Loss=0.0674\n",
      "Epoch 5: Total Loss=0.0600\n",
      "Epoch 6: Total Loss=0.0596\n",
      "Epoch 7: Total Loss=0.0607\n",
      "Epoch 8: Total Loss=0.0597\n",
      "Epoch 9: Total Loss=0.0601\n",
      "Updated x: [0.015736453235149384, 0.0024838149547576904], Function Value: 0.0002538053086027503, Gradient: [-0.0022765593603253365, -0.011177499778568745]\n",
      "\n",
      "Step 22/40\n",
      "Epoch 0: Total Loss=0.0539\n",
      "Epoch 1: Total Loss=0.0539\n",
      "Epoch 2: Total Loss=0.0549\n",
      "Epoch 3: Total Loss=0.0538\n",
      "Epoch 4: Total Loss=0.0539\n",
      "Epoch 5: Total Loss=0.0549\n",
      "Epoch 6: Total Loss=0.0539\n",
      "Epoch 7: Total Loss=0.0539\n",
      "Epoch 8: Total Loss=0.0549\n",
      "Epoch 9: Total Loss=0.0539\n",
      "Updated x: [0.024384159594774246, -0.033992551267147064], Function Value: 0.0017500808462500572, Gradient: [-0.004825409967452288, -0.006988354958593845]\n",
      "\n",
      "Step 23/40\n",
      "Epoch 0: Total Loss=0.0539\n",
      "Epoch 1: Total Loss=0.0535\n",
      "Epoch 2: Total Loss=0.0538\n",
      "Epoch 3: Total Loss=0.0538\n",
      "Epoch 4: Total Loss=0.0536\n",
      "Epoch 5: Total Loss=0.0539\n",
      "Epoch 6: Total Loss=0.0535\n",
      "Epoch 7: Total Loss=0.0538\n",
      "Epoch 8: Total Loss=0.0538\n",
      "Epoch 9: Total Loss=0.0537\n",
      "Updated x: [-0.018050633370876312, 0.020627465099096298], Function Value: 0.0007513177115470171, Gradient: [-0.005385807249695063, -0.00798285473138094]\n",
      "\n",
      "Step 24/40\n",
      "Epoch 0: Total Loss=0.0553\n",
      "Epoch 1: Total Loss=0.0538\n",
      "Epoch 2: Total Loss=0.0538\n",
      "Epoch 3: Total Loss=0.0543\n",
      "Epoch 4: Total Loss=0.0553\n",
      "Epoch 5: Total Loss=0.0538\n",
      "Epoch 6: Total Loss=0.0538\n",
      "Epoch 7: Total Loss=0.0542\n",
      "Epoch 8: Total Loss=0.0552\n",
      "Epoch 9: Total Loss=0.0538\n",
      "Updated x: [-0.020397955551743507, -0.11081540584564209], Function Value: 0.012696131132543087, Gradient: [-0.0048266081139445305, -0.012138178572058678]\n",
      "\n",
      "Step 25/40\n",
      "Epoch 0: Total Loss=0.0536\n",
      "Epoch 1: Total Loss=0.0540\n",
      "Epoch 2: Total Loss=0.0537\n",
      "Epoch 3: Total Loss=0.0538\n",
      "Epoch 4: Total Loss=0.0552\n",
      "Epoch 5: Total Loss=0.0536\n",
      "Epoch 6: Total Loss=0.0541\n",
      "Epoch 7: Total Loss=0.0537\n",
      "Epoch 8: Total Loss=0.0539\n",
      "Epoch 9: Total Loss=0.0552\n",
      "Updated x: [-0.03944744914770126, 0.024788901209831238], Function Value: 0.002170590916648507, Gradient: [-0.005036497488617897, -0.010832973755896091]\n",
      "\n",
      "Step 26/40\n",
      "Epoch 0: Total Loss=0.0542\n",
      "Epoch 1: Total Loss=0.0537\n",
      "Epoch 2: Total Loss=0.0530\n",
      "Epoch 3: Total Loss=0.0551\n",
      "Epoch 4: Total Loss=0.0534\n",
      "Epoch 5: Total Loss=0.0535\n",
      "Epoch 6: Total Loss=0.0541\n",
      "Epoch 7: Total Loss=0.0538\n",
      "Epoch 8: Total Loss=0.0532\n",
      "Epoch 9: Total Loss=0.0552\n",
      "Updated x: [-0.07715948671102524, 0.04368787258863449], Function Value: 0.007862216793000698, Gradient: [-0.005629777908325195, -0.010451700538396835]\n",
      "\n",
      "Step 27/40\n",
      "Epoch 0: Total Loss=0.0533\n",
      "Epoch 1: Total Loss=0.0543\n",
      "Epoch 2: Total Loss=0.0546\n",
      "Epoch 3: Total Loss=0.0541\n",
      "Epoch 4: Total Loss=0.0532\n",
      "Epoch 5: Total Loss=0.0534\n",
      "Epoch 6: Total Loss=0.0530\n",
      "Epoch 7: Total Loss=0.0534\n",
      "Epoch 8: Total Loss=0.0539\n",
      "Epoch 9: Total Loss=0.0551\n",
      "Updated x: [0.09196705371141434, -0.05935114622116089], Function Value: 0.01198049820959568, Gradient: [-0.003916791174560785, -0.011457568034529686]\n",
      "\n",
      "Step 28/40\n",
      "Epoch 0: Total Loss=0.0538\n",
      "Epoch 1: Total Loss=0.0540\n",
      "Epoch 2: Total Loss=0.0538\n",
      "Epoch 3: Total Loss=0.0537\n",
      "Epoch 4: Total Loss=0.0533\n",
      "Epoch 5: Total Loss=0.0541\n",
      "Epoch 6: Total Loss=0.0530\n",
      "Epoch 7: Total Loss=0.0535\n",
      "Epoch 8: Total Loss=0.0535\n",
      "Epoch 9: Total Loss=0.0538\n",
      "Updated x: [0.11521917581558228, -0.08176541328430176], Function Value: 0.01996104046702385, Gradient: [-0.003939683083444834, -0.010780210606753826]\n",
      "\n",
      "Step 29/40\n",
      "Epoch 0: Total Loss=0.0537\n",
      "Epoch 1: Total Loss=0.0534\n",
      "Epoch 2: Total Loss=0.0532\n",
      "Epoch 3: Total Loss=0.0535\n",
      "Epoch 4: Total Loss=0.0538\n",
      "Epoch 5: Total Loss=0.0534\n",
      "Epoch 6: Total Loss=0.0536\n",
      "Epoch 7: Total Loss=0.0535\n",
      "Epoch 8: Total Loss=0.0541\n",
      "Epoch 9: Total Loss=0.0532\n",
      "Updated x: [0.0005043521523475647, -0.0062480345368385315], Function Value: 3.929230661015026e-05, Gradient: [-0.005302516743540764, -0.011366244405508041]\n",
      "\n",
      "Step 30/40\n",
      "Epoch 0: Total Loss=0.0536\n",
      "Epoch 1: Total Loss=0.0532\n",
      "Epoch 2: Total Loss=0.0530\n",
      "Epoch 3: Total Loss=0.0540\n",
      "Epoch 4: Total Loss=0.0535\n",
      "Epoch 5: Total Loss=0.0539\n",
      "Epoch 6: Total Loss=0.0530\n",
      "Epoch 7: Total Loss=0.0531\n",
      "Epoch 8: Total Loss=0.0537\n",
      "Epoch 9: Total Loss=0.0534\n",
      "Updated x: [-0.00040435296250507236, -0.050921209156513214], Function Value: 0.0025931329000741243, Gradient: [-0.005550449714064598, -0.01199541799724102]\n",
      "\n",
      "Step 31/40\n",
      "Epoch 0: Total Loss=0.0533\n",
      "Epoch 1: Total Loss=0.0535\n",
      "Epoch 2: Total Loss=0.0537\n",
      "Epoch 3: Total Loss=0.0532\n",
      "Epoch 4: Total Loss=0.0533\n",
      "Epoch 5: Total Loss=0.0535\n",
      "Epoch 6: Total Loss=0.0531\n",
      "Epoch 7: Total Loss=0.0541\n",
      "Epoch 8: Total Loss=0.0534\n",
      "Epoch 9: Total Loss=0.0529\n",
      "Updated x: [-0.02202734164893627, 0.036657027900218964], Function Value: 0.0018289415165781975, Gradient: [-0.004938832949846983, -0.011766103096306324]\n",
      "\n",
      "Step 32/40\n",
      "Epoch 0: Total Loss=0.0699\n",
      "Epoch 1: Total Loss=0.0773\n",
      "Epoch 2: Total Loss=0.0732\n",
      "Epoch 3: Total Loss=0.0710\n",
      "Epoch 4: Total Loss=0.0749\n",
      "Epoch 5: Total Loss=0.0768\n",
      "Epoch 6: Total Loss=0.0746\n",
      "Epoch 7: Total Loss=0.0687\n",
      "Epoch 8: Total Loss=0.0667\n",
      "Epoch 9: Total Loss=0.0808\n",
      "Updated x: [-0.04323139041662216, 0.03298278525471687], Function Value: 0.002956817392259836, Gradient: [-0.0055343033745884895, -0.008902248926460743]\n",
      "\n",
      "Step 33/40\n",
      "Epoch 0: Total Loss=0.0738\n",
      "Epoch 1: Total Loss=0.0773\n",
      "Epoch 2: Total Loss=0.0809\n",
      "Epoch 3: Total Loss=0.0782\n",
      "Epoch 4: Total Loss=0.0767\n",
      "Epoch 5: Total Loss=0.0798\n",
      "Epoch 6: Total Loss=0.0785\n",
      "Epoch 7: Total Loss=0.0757\n",
      "Epoch 8: Total Loss=0.0780\n",
      "Epoch 9: Total Loss=0.0801\n",
      "Updated x: [0.03105863183736801, 0.03521256521344185], Function Value: 0.0022045632358640432, Gradient: [-0.009944702498614788, -0.005743520334362984]\n",
      "\n",
      "Step 34/40\n",
      "Epoch 0: Total Loss=0.0781\n",
      "Epoch 1: Total Loss=0.0752\n",
      "Epoch 2: Total Loss=0.0746\n",
      "Epoch 3: Total Loss=0.0741\n",
      "Epoch 4: Total Loss=0.0800\n",
      "Epoch 5: Total Loss=0.0753\n",
      "Epoch 6: Total Loss=0.0765\n",
      "Epoch 7: Total Loss=0.0746\n",
      "Epoch 8: Total Loss=0.0700\n",
      "Epoch 9: Total Loss=0.0738\n",
      "Updated x: [0.04572012647986412, 0.022736642509698868], Function Value: 0.0026072850450873375, Gradient: [-0.007564223371446133, -0.008479876443743706]\n",
      "\n",
      "Step 35/40\n",
      "Epoch 0: Total Loss=0.0781\n",
      "Epoch 1: Total Loss=0.0704\n",
      "Epoch 2: Total Loss=0.0786\n",
      "Epoch 3: Total Loss=0.0725\n",
      "Epoch 4: Total Loss=0.0778\n",
      "Epoch 5: Total Loss=0.0776\n",
      "Epoch 6: Total Loss=0.0711\n",
      "Epoch 7: Total Loss=0.0807\n",
      "Epoch 8: Total Loss=0.0744\n",
      "Epoch 9: Total Loss=0.0694\n",
      "Updated x: [-0.014640960842370987, 0.030192704871296883], Function Value: 0.0011259571183472872, Gradient: [-0.008817404508590698, -0.00965840369462967]\n",
      "\n",
      "Step 36/40\n",
      "Epoch 0: Total Loss=0.0826\n",
      "Epoch 1: Total Loss=0.0788\n",
      "Epoch 2: Total Loss=0.0762\n",
      "Epoch 3: Total Loss=0.0731\n",
      "Epoch 4: Total Loss=0.0891\n",
      "Epoch 5: Total Loss=0.0756\n",
      "Epoch 6: Total Loss=0.0729\n",
      "Epoch 7: Total Loss=0.0769\n",
      "Epoch 8: Total Loss=0.0796\n",
      "Epoch 9: Total Loss=0.0714\n",
      "Updated x: [0.02816510573029518, 0.06761707365512848], Function Value: 0.005365341901779175, Gradient: [-0.008367530070245266, -0.007682314608246088]\n",
      "\n",
      "Step 37/40\n",
      "Epoch 0: Total Loss=0.0634\n",
      "Epoch 1: Total Loss=0.0865\n",
      "Epoch 2: Total Loss=0.0705\n",
      "Epoch 3: Total Loss=0.0822\n",
      "Epoch 4: Total Loss=0.0729\n",
      "Epoch 5: Total Loss=0.0714\n",
      "Epoch 6: Total Loss=0.0924\n",
      "Epoch 7: Total Loss=0.0712\n",
      "Epoch 8: Total Loss=0.0695\n",
      "Epoch 9: Total Loss=0.0709\n",
      "Updated x: [0.0530209094285965, 0.055656999349594116], Function Value: 0.00590891856700182, Gradient: [-0.008930336683988571, -0.0051232133992016315]\n",
      "\n",
      "Step 38/40\n",
      "Epoch 0: Total Loss=0.0728\n",
      "Epoch 1: Total Loss=0.0755\n",
      "Epoch 2: Total Loss=0.0689\n",
      "Epoch 3: Total Loss=0.0852\n",
      "Epoch 4: Total Loss=0.0740\n",
      "Epoch 5: Total Loss=0.0771\n",
      "Epoch 6: Total Loss=0.0709\n",
      "Epoch 7: Total Loss=0.0724\n",
      "Epoch 8: Total Loss=0.0722\n",
      "Epoch 9: Total Loss=0.0842\n",
      "Updated x: [0.07848286628723145, 0.04271874949336052], Function Value: 0.007984451949596405, Gradient: [-0.006483785342425108, -0.006433447822928429]\n",
      "\n",
      "Step 39/40\n",
      "Epoch 0: Total Loss=0.0698\n",
      "Epoch 1: Total Loss=0.0714\n",
      "Epoch 2: Total Loss=0.0762\n",
      "Epoch 3: Total Loss=0.0831\n",
      "Epoch 4: Total Loss=0.0785\n",
      "Epoch 5: Total Loss=0.0788\n",
      "Epoch 6: Total Loss=0.0742\n",
      "Epoch 7: Total Loss=0.0707\n",
      "Epoch 8: Total Loss=0.0780\n",
      "Epoch 9: Total Loss=0.0731\n",
      "Updated x: [-0.00924963504076004, 0.03340737521648407], Function Value: 0.0012016084510833025, Gradient: [-0.006747587583959103, -0.01179210189729929]\n",
      "\n",
      "Step 40/40\n",
      "Epoch 0: Total Loss=0.0741\n",
      "Epoch 1: Total Loss=0.0741\n",
      "Epoch 2: Total Loss=0.0737\n",
      "Epoch 3: Total Loss=0.0773\n",
      "Epoch 4: Total Loss=0.0756\n",
      "Epoch 5: Total Loss=0.0784\n",
      "Epoch 6: Total Loss=0.0733\n",
      "Epoch 7: Total Loss=0.0732\n",
      "Epoch 8: Total Loss=0.0780\n",
      "Epoch 9: Total Loss=0.0739\n",
      "Updated x: [0.028787780553102493, -0.06758376955986023], Function Value: 0.0053963023237884045, Gradient: [-0.008288362063467503, -0.008033204823732376]\n",
      "\n",
      "Step 1/40\n",
      "Epoch 0: Total Loss=6.6024\n",
      "Epoch 1: Total Loss=5.5210\n",
      "Epoch 2: Total Loss=6.5326\n",
      "Epoch 3: Total Loss=5.4653\n",
      "Epoch 4: Total Loss=6.4709\n",
      "Epoch 5: Total Loss=5.4123\n",
      "Epoch 6: Total Loss=6.4101\n",
      "Epoch 7: Total Loss=5.3681\n",
      "Epoch 8: Total Loss=6.3448\n",
      "Epoch 9: Total Loss=5.3179\n",
      "Updated x: [0.9176568388938904, -0.7303772568702698], Function Value: 1.3755450248718262, Gradient: [-0.019299929961562157, -0.06043875962495804]\n",
      "\n",
      "Step 2/40\n",
      "Epoch 0: Total Loss=3.9761\n",
      "Epoch 1: Total Loss=5.2767\n",
      "Epoch 2: Total Loss=3.9438\n",
      "Epoch 3: Total Loss=5.2379\n",
      "Epoch 4: Total Loss=3.9113\n",
      "Epoch 5: Total Loss=5.1967\n",
      "Epoch 6: Total Loss=3.8784\n",
      "Epoch 7: Total Loss=5.1583\n",
      "Epoch 8: Total Loss=3.8463\n",
      "Epoch 9: Total Loss=5.1184\n",
      "Updated x: [0.8305209279060364, -0.782982587814331], Function Value: 1.3028267621994019, Gradient: [-0.03947073966264725, -0.11429763585329056]\n",
      "\n",
      "Step 3/40\n",
      "Epoch 0: Total Loss=0.1334\n",
      "Epoch 1: Total Loss=0.1658\n",
      "Epoch 2: Total Loss=0.2039\n",
      "Epoch 3: Total Loss=0.1749\n",
      "Epoch 4: Total Loss=0.1546\n",
      "Epoch 5: Total Loss=0.1678\n",
      "Epoch 6: Total Loss=0.2084\n",
      "Epoch 7: Total Loss=0.1259\n",
      "Epoch 8: Total Loss=0.1609\n",
      "Epoch 9: Total Loss=0.1992\n",
      "Updated x: [0.6558308601379395, -0.7944043278694153], Function Value: 1.0611923933029175, Gradient: [-0.03289923071861267, -0.10341272503137589]\n",
      "\n",
      "Step 4/40\n",
      "Epoch 0: Total Loss=0.1475\n",
      "Epoch 1: Total Loss=0.2328\n",
      "Epoch 2: Total Loss=0.1759\n",
      "Epoch 3: Total Loss=0.1231\n",
      "Epoch 4: Total Loss=0.1620\n",
      "Epoch 5: Total Loss=0.1302\n",
      "Epoch 6: Total Loss=0.1944\n",
      "Epoch 7: Total Loss=0.1790\n",
      "Epoch 8: Total Loss=0.1678\n",
      "Epoch 9: Total Loss=0.1566\n",
      "Updated x: [0.5336402654647827, -0.6772946119308472], Function Value: 0.7434998750686646, Gradient: [-0.01953704282641411, -0.07446664571762085]\n",
      "\n",
      "Step 5/40\n",
      "Epoch 0: Total Loss=0.1405\n",
      "Epoch 1: Total Loss=0.1411\n",
      "Epoch 2: Total Loss=0.1175\n",
      "Epoch 3: Total Loss=0.1800\n",
      "Epoch 4: Total Loss=0.1078\n",
      "Epoch 5: Total Loss=0.1198\n",
      "Epoch 6: Total Loss=0.1714\n",
      "Epoch 7: Total Loss=0.1388\n",
      "Epoch 8: Total Loss=0.1405\n",
      "Epoch 9: Total Loss=0.1185\n",
      "Updated x: [0.40983831882476807, -0.6346705555915833], Function Value: 0.5707741379737854, Gradient: [-0.009912511333823204, -0.05535821244120598]\n",
      "\n",
      "Step 6/40\n",
      "Epoch 0: Total Loss=0.1183\n",
      "Epoch 1: Total Loss=0.2094\n",
      "Epoch 2: Total Loss=0.1139\n",
      "Epoch 3: Total Loss=0.1171\n",
      "Epoch 4: Total Loss=0.1288\n",
      "Epoch 5: Total Loss=0.1016\n",
      "Epoch 6: Total Loss=0.1971\n",
      "Epoch 7: Total Loss=0.1068\n",
      "Epoch 8: Total Loss=0.1140\n",
      "Epoch 9: Total Loss=0.1200\n",
      "Updated x: [0.23589590191841125, -0.5015843510627747], Function Value: 0.3072337210178375, Gradient: [-0.00969609897583723, -0.06412475556135178]\n",
      "\n",
      "Step 7/40\n",
      "Epoch 0: Total Loss=0.1098\n",
      "Epoch 1: Total Loss=0.1156\n",
      "Epoch 2: Total Loss=0.1213\n",
      "Epoch 3: Total Loss=0.1609\n",
      "Epoch 4: Total Loss=0.1221\n",
      "Epoch 5: Total Loss=0.1121\n",
      "Epoch 6: Total Loss=0.1787\n",
      "Epoch 7: Total Loss=0.1203\n",
      "Epoch 8: Total Loss=0.1463\n",
      "Epoch 9: Total Loss=0.1141\n",
      "Updated x: [0.3614514470100403, -0.4000341296195984], Function Value: 0.29067444801330566, Gradient: [-0.007230102550238371, -0.05962571129202843]\n",
      "\n",
      "Step 8/40\n",
      "Epoch 0: Total Loss=0.1120\n",
      "Epoch 1: Total Loss=0.1157\n",
      "Epoch 2: Total Loss=0.1201\n",
      "Epoch 3: Total Loss=0.1115\n",
      "Epoch 4: Total Loss=0.1457\n",
      "Epoch 5: Total Loss=0.1275\n",
      "Epoch 6: Total Loss=0.1127\n",
      "Epoch 7: Total Loss=0.1694\n",
      "Epoch 8: Total Loss=0.0977\n",
      "Epoch 9: Total Loss=0.1076\n",
      "Updated x: [0.1624586135149002, -0.2922598719596863], Function Value: 0.11180863529443741, Gradient: [-0.0009987613884732127, -0.04861971363425255]\n",
      "\n",
      "Step 9/40\n",
      "Epoch 0: Total Loss=0.0900\n",
      "Epoch 1: Total Loss=0.1214\n",
      "Epoch 2: Total Loss=0.1170\n",
      "Epoch 3: Total Loss=0.1233\n",
      "Epoch 4: Total Loss=0.1127\n",
      "Epoch 5: Total Loss=0.1491\n",
      "Epoch 6: Total Loss=0.1053\n",
      "Epoch 7: Total Loss=0.1534\n",
      "Epoch 8: Total Loss=0.1087\n",
      "Epoch 9: Total Loss=0.0962\n",
      "Updated x: [0.05328923463821411, -0.15199002623558044], Function Value: 0.025940710678696632, Gradient: [0.002966752042993903, -0.028859818354249]\n",
      "\n",
      "Step 10/40\n",
      "Epoch 0: Total Loss=0.0946\n",
      "Epoch 1: Total Loss=0.1035\n",
      "Epoch 2: Total Loss=0.0959\n",
      "Epoch 3: Total Loss=0.0932\n",
      "Epoch 4: Total Loss=0.1520\n",
      "Epoch 5: Total Loss=0.0978\n",
      "Epoch 6: Total Loss=0.0960\n",
      "Epoch 7: Total Loss=0.0983\n",
      "Epoch 8: Total Loss=0.1696\n",
      "Epoch 9: Total Loss=0.0954\n",
      "Updated x: [-0.04087590426206589, -0.06566695123910904], Function Value: 0.005982987582683563, Gradient: [0.001473825890570879, -0.01703059859573841]\n",
      "\n",
      "Step 11/40\n",
      "Epoch 0: Total Loss=0.1167\n",
      "Epoch 1: Total Loss=0.0992\n",
      "Epoch 2: Total Loss=0.0918\n",
      "Epoch 3: Total Loss=0.0999\n",
      "Epoch 4: Total Loss=0.0923\n",
      "Epoch 5: Total Loss=0.1078\n",
      "Epoch 6: Total Loss=0.1428\n",
      "Epoch 7: Total Loss=0.0892\n",
      "Epoch 8: Total Loss=0.0861\n",
      "Epoch 9: Total Loss=0.1087\n",
      "Updated x: [-0.04923703148961067, -0.022729292511940002], Function Value: 0.0029409059789031744, Gradient: [0.004258075263351202, -0.009187029674649239]\n",
      "\n",
      "Step 12/40\n",
      "Epoch 0: Total Loss=0.0601\n",
      "Epoch 1: Total Loss=0.0578\n",
      "Epoch 2: Total Loss=0.0599\n",
      "Epoch 3: Total Loss=0.0575\n",
      "Epoch 4: Total Loss=0.0602\n",
      "Epoch 5: Total Loss=0.0577\n",
      "Epoch 6: Total Loss=0.0602\n",
      "Epoch 7: Total Loss=0.0576\n",
      "Epoch 8: Total Loss=0.0600\n",
      "Epoch 9: Total Loss=0.0574\n",
      "Updated x: [0.030544932931661606, -0.07247909903526306], Function Value: 0.006186212878674269, Gradient: [0.002004405250772834, -0.006101100705564022]\n",
      "\n",
      "Step 13/40\n",
      "Epoch 0: Total Loss=0.0581\n",
      "Epoch 1: Total Loss=0.0593\n",
      "Epoch 2: Total Loss=0.0575\n",
      "Epoch 3: Total Loss=0.0578\n",
      "Epoch 4: Total Loss=0.0577\n",
      "Epoch 5: Total Loss=0.0598\n",
      "Epoch 6: Total Loss=0.0574\n",
      "Epoch 7: Total Loss=0.0583\n",
      "Epoch 8: Total Loss=0.0595\n",
      "Epoch 9: Total Loss=0.0577\n",
      "Updated x: [-0.05468186363577843, -0.03432580828666687], Function Value: 0.004168367013335228, Gradient: [0.00018765166169032454, -0.0025299370754510164]\n",
      "\n",
      "Step 14/40\n",
      "Epoch 0: Total Loss=0.0570\n",
      "Epoch 1: Total Loss=0.0604\n",
      "Epoch 2: Total Loss=0.0578\n",
      "Epoch 3: Total Loss=0.0568\n",
      "Epoch 4: Total Loss=0.0572\n",
      "Epoch 5: Total Loss=0.0582\n",
      "Epoch 6: Total Loss=0.0582\n",
      "Epoch 7: Total Loss=0.0604\n",
      "Epoch 8: Total Loss=0.0574\n",
      "Epoch 9: Total Loss=0.0567\n",
      "Updated x: [-0.009105980396270752, -0.04459943249821663], Function Value: 0.00207202835008502, Gradient: [-0.0009043278987519443, -0.002152689266949892]\n",
      "\n",
      "Step 15/40\n",
      "Epoch 0: Total Loss=0.0569\n",
      "Epoch 1: Total Loss=0.0594\n",
      "Epoch 2: Total Loss=0.0583\n",
      "Epoch 3: Total Loss=0.0574\n",
      "Epoch 4: Total Loss=0.0565\n",
      "Epoch 5: Total Loss=0.0568\n",
      "Epoch 6: Total Loss=0.0570\n",
      "Epoch 7: Total Loss=0.0567\n",
      "Epoch 8: Total Loss=0.0593\n",
      "Epoch 9: Total Loss=0.0584\n",
      "Updated x: [0.07337465137243271, -0.03491174057126045], Function Value: 0.006602669134736061, Gradient: [-0.002107911743223667, -0.002556496998295188]\n",
      "\n",
      "Step 16/40\n",
      "Epoch 0: Total Loss=0.0570\n",
      "Epoch 1: Total Loss=0.0568\n",
      "Epoch 2: Total Loss=0.0561\n",
      "Epoch 3: Total Loss=0.0564\n",
      "Epoch 4: Total Loss=0.0569\n",
      "Epoch 5: Total Loss=0.0576\n",
      "Epoch 6: Total Loss=0.0574\n",
      "Epoch 7: Total Loss=0.0589\n",
      "Epoch 8: Total Loss=0.0573\n",
      "Epoch 9: Total Loss=0.0570\n",
      "Updated x: [0.007321685552597046, -0.026214446872472763], Function Value: 0.0007408043020404875, Gradient: [-0.0007526749395765364, -0.0019942820072174072]\n",
      "\n",
      "Step 17/40\n",
      "Epoch 0: Total Loss=0.0570\n",
      "Epoch 1: Total Loss=0.0571\n",
      "Epoch 2: Total Loss=0.0561\n",
      "Epoch 3: Total Loss=0.0591\n",
      "Epoch 4: Total Loss=0.0565\n",
      "Epoch 5: Total Loss=0.0570\n",
      "Epoch 6: Total Loss=0.0569\n",
      "Epoch 7: Total Loss=0.0568\n",
      "Epoch 8: Total Loss=0.0561\n",
      "Epoch 9: Total Loss=0.0566\n",
      "Updated x: [0.015261808410286903, -0.020184535533189774], Function Value: 0.0006403382867574692, Gradient: [-0.0008578893030062318, -0.0036457411479204893]\n",
      "\n",
      "Step 18/40\n",
      "Epoch 0: Total Loss=0.0568\n",
      "Epoch 1: Total Loss=0.0589\n",
      "Epoch 2: Total Loss=0.0565\n",
      "Epoch 3: Total Loss=0.0572\n",
      "Epoch 4: Total Loss=0.0564\n",
      "Epoch 5: Total Loss=0.0565\n",
      "Epoch 6: Total Loss=0.0564\n",
      "Epoch 7: Total Loss=0.0564\n",
      "Epoch 8: Total Loss=0.0570\n",
      "Epoch 9: Total Loss=0.0568\n",
      "Updated x: [-0.0390055775642395, 0.046532999724149704], Function Value: 0.003686755197122693, Gradient: [-9.525615314487368e-05, -0.0035936220083385706]\n",
      "\n",
      "Step 19/40\n",
      "Epoch 0: Total Loss=0.0573\n",
      "Epoch 1: Total Loss=0.0564\n",
      "Epoch 2: Total Loss=0.0566\n",
      "Epoch 3: Total Loss=0.0575\n",
      "Epoch 4: Total Loss=0.0583\n",
      "Epoch 5: Total Loss=0.0565\n",
      "Epoch 6: Total Loss=0.0566\n",
      "Epoch 7: Total Loss=0.0562\n",
      "Epoch 8: Total Loss=0.0561\n",
      "Epoch 9: Total Loss=0.0590\n",
      "Updated x: [-0.018698010593652725, -0.03507715091109276], Function Value: 0.0015800220426172018, Gradient: [0.0007404161733575165, -0.004042020998895168]\n",
      "\n",
      "Step 20/40\n",
      "Epoch 0: Total Loss=0.0564\n",
      "Epoch 1: Total Loss=0.0568\n",
      "Epoch 2: Total Loss=0.0568\n",
      "Epoch 3: Total Loss=0.0564\n",
      "Epoch 4: Total Loss=0.0566\n",
      "Epoch 5: Total Loss=0.0564\n",
      "Epoch 6: Total Loss=0.0561\n",
      "Epoch 7: Total Loss=0.0576\n",
      "Epoch 8: Total Loss=0.0563\n",
      "Epoch 9: Total Loss=0.0570\n",
      "Updated x: [-0.004568181000649929, 0.05322052910923958], Function Value: 0.002853293204680085, Gradient: [0.0011999369598925114, -0.00394931435585022]\n",
      "\n",
      "Step 21/40\n",
      "Epoch 0: Total Loss=0.0561\n",
      "Epoch 1: Total Loss=0.0583\n",
      "Epoch 2: Total Loss=0.0560\n",
      "Epoch 3: Total Loss=0.0570\n",
      "Epoch 4: Total Loss=0.0567\n",
      "Epoch 5: Total Loss=0.0569\n",
      "Epoch 6: Total Loss=0.0588\n",
      "Epoch 7: Total Loss=0.0566\n",
      "Epoch 8: Total Loss=0.0564\n",
      "Epoch 9: Total Loss=0.0560\n",
      "Updated x: [-0.03926410153508186, 0.018785152584314346], Function Value: 0.0018945516785606742, Gradient: [0.002021089196205139, -0.002865523099899292]\n",
      "\n",
      "Step 22/40\n",
      "Epoch 0: Total Loss=0.0782\n",
      "Epoch 1: Total Loss=0.0730\n",
      "Epoch 2: Total Loss=0.0769\n",
      "Epoch 3: Total Loss=0.0848\n",
      "Epoch 4: Total Loss=0.0746\n",
      "Epoch 5: Total Loss=0.0762\n",
      "Epoch 6: Total Loss=0.0709\n",
      "Epoch 7: Total Loss=0.0782\n",
      "Epoch 8: Total Loss=0.0726\n",
      "Epoch 9: Total Loss=0.0789\n",
      "Updated x: [0.03600258007645607, -0.013023581355810165], Function Value: 0.0014657994033768773, Gradient: [-0.00314094009809196, -0.014883982948958874]\n",
      "\n",
      "Step 23/40\n",
      "Epoch 0: Total Loss=0.0716\n",
      "Epoch 1: Total Loss=0.0733\n",
      "Epoch 2: Total Loss=0.0770\n",
      "Epoch 3: Total Loss=0.0678\n",
      "Epoch 4: Total Loss=0.0772\n",
      "Epoch 5: Total Loss=0.0804\n",
      "Epoch 6: Total Loss=0.0758\n",
      "Epoch 7: Total Loss=0.0750\n",
      "Epoch 8: Total Loss=0.0742\n",
      "Epoch 9: Total Loss=0.0779\n",
      "Updated x: [0.02526128850877285, -0.0121749984100461], Function Value: 0.0007863632636144757, Gradient: [0.0005288877873681486, -0.01586601510643959]\n",
      "\n",
      "Step 24/40\n",
      "Epoch 0: Total Loss=0.0753\n",
      "Epoch 1: Total Loss=0.0757\n",
      "Epoch 2: Total Loss=0.0717\n",
      "Epoch 3: Total Loss=0.0741\n",
      "Epoch 4: Total Loss=0.0707\n",
      "Epoch 5: Total Loss=0.0707\n",
      "Epoch 6: Total Loss=0.0751\n",
      "Epoch 7: Total Loss=0.0705\n",
      "Epoch 8: Total Loss=0.0695\n",
      "Epoch 9: Total Loss=0.0727\n",
      "Updated x: [0.004253672435879707, 0.0614357627928257], Function Value: 0.0037924465723335743, Gradient: [0.0015427633188664913, -0.014266029931604862]\n",
      "\n",
      "Step 25/40\n",
      "Epoch 0: Total Loss=0.0759\n",
      "Epoch 1: Total Loss=0.0736\n",
      "Epoch 2: Total Loss=0.0757\n",
      "Epoch 3: Total Loss=0.0677\n",
      "Epoch 4: Total Loss=0.0769\n",
      "Epoch 5: Total Loss=0.0735\n",
      "Epoch 6: Total Loss=0.0790\n",
      "Epoch 7: Total Loss=0.0808\n",
      "Epoch 8: Total Loss=0.0743\n",
      "Epoch 9: Total Loss=0.0767\n",
      "Updated x: [0.007372130174189806, 0.02620244398713112], Function Value: 0.0007409164099954069, Gradient: [0.003036264795809984, -0.01849997416138649]\n",
      "\n",
      "Step 26/40\n",
      "Epoch 0: Total Loss=0.0757\n",
      "Epoch 1: Total Loss=0.0763\n",
      "Epoch 2: Total Loss=0.0757\n",
      "Epoch 3: Total Loss=0.0768\n",
      "Epoch 4: Total Loss=0.0747\n",
      "Epoch 5: Total Loss=0.0789\n",
      "Epoch 6: Total Loss=0.0693\n",
      "Epoch 7: Total Loss=0.0736\n",
      "Epoch 8: Total Loss=0.0705\n",
      "Epoch 9: Total Loss=0.0754\n",
      "Updated x: [-0.022043408825993538, 0.01310842577368021], Function Value: 0.0006577427266165614, Gradient: [0.004344316199421883, -0.014343442395329475]\n",
      "\n",
      "Step 27/40\n",
      "Epoch 0: Total Loss=0.0735\n",
      "Epoch 1: Total Loss=0.0686\n",
      "Epoch 2: Total Loss=0.0700\n",
      "Epoch 3: Total Loss=0.0833\n",
      "Epoch 4: Total Loss=0.0787\n",
      "Epoch 5: Total Loss=0.0759\n",
      "Epoch 6: Total Loss=0.0730\n",
      "Epoch 7: Total Loss=0.0726\n",
      "Epoch 8: Total Loss=0.0745\n",
      "Epoch 9: Total Loss=0.0828\n",
      "Updated x: [-0.08579734712839127, 0.06119539216160774], Function Value: 0.011106060817837715, Gradient: [0.005015966482460499, -0.014007577672600746]\n",
      "\n",
      "Step 28/40\n",
      "Epoch 0: Total Loss=0.0816\n",
      "Epoch 1: Total Loss=0.0812\n",
      "Epoch 2: Total Loss=0.0761\n",
      "Epoch 3: Total Loss=0.0762\n",
      "Epoch 4: Total Loss=0.0734\n",
      "Epoch 5: Total Loss=0.0697\n",
      "Epoch 6: Total Loss=0.0724\n",
      "Epoch 7: Total Loss=0.0687\n",
      "Epoch 8: Total Loss=0.0820\n",
      "Epoch 9: Total Loss=0.0757\n",
      "Updated x: [-0.0320158489048481, 0.00242454931139946], Function Value: 0.0010308929486200213, Gradient: [0.004366844892501831, -0.01139578502625227]\n",
      "\n",
      "Step 29/40\n",
      "Epoch 0: Total Loss=0.0744\n",
      "Epoch 1: Total Loss=0.0708\n",
      "Epoch 2: Total Loss=0.0716\n",
      "Epoch 3: Total Loss=0.0756\n",
      "Epoch 4: Total Loss=0.0765\n",
      "Epoch 5: Total Loss=0.0732\n",
      "Epoch 6: Total Loss=0.0811\n",
      "Epoch 7: Total Loss=0.0698\n",
      "Epoch 8: Total Loss=0.0738\n",
      "Epoch 9: Total Loss=0.0739\n",
      "Updated x: [-0.03723064810037613, -0.005728533491492271], Function Value: 0.0014189372304826975, Gradient: [0.0064260452054440975, -0.01209016889333725]\n",
      "\n",
      "Step 30/40\n",
      "Epoch 0: Total Loss=0.0703\n",
      "Epoch 1: Total Loss=0.0729\n",
      "Epoch 2: Total Loss=0.0730\n",
      "Epoch 3: Total Loss=0.0689\n",
      "Epoch 4: Total Loss=0.0778\n",
      "Epoch 5: Total Loss=0.0697\n",
      "Epoch 6: Total Loss=0.0778\n",
      "Epoch 7: Total Loss=0.0757\n",
      "Epoch 8: Total Loss=0.0757\n",
      "Epoch 9: Total Loss=0.0688\n",
      "Updated x: [0.05891373008489609, 0.005147905088961124], Function Value: 0.003497328609228134, Gradient: [0.0037784085143357515, -0.008845563046634197]\n",
      "\n",
      "Step 31/40\n",
      "Epoch 0: Total Loss=0.0738\n",
      "Epoch 1: Total Loss=0.0707\n",
      "Epoch 2: Total Loss=0.0729\n",
      "Epoch 3: Total Loss=0.0732\n",
      "Epoch 4: Total Loss=0.0732\n",
      "Epoch 5: Total Loss=0.0724\n",
      "Epoch 6: Total Loss=0.0661\n",
      "Epoch 7: Total Loss=0.0717\n",
      "Epoch 8: Total Loss=0.0689\n",
      "Epoch 9: Total Loss=0.0726\n",
      "Updated x: [-0.032198600471019745, -0.035079680383205414], Function Value: 0.002267333911731839, Gradient: [0.003984285052865744, -0.004309910349547863]\n",
      "\n",
      "Step 32/40\n",
      "Epoch 0: Total Loss=0.0645\n",
      "Epoch 1: Total Loss=0.0656\n",
      "Epoch 2: Total Loss=0.0659\n",
      "Epoch 3: Total Loss=0.0656\n",
      "Epoch 4: Total Loss=0.0642\n",
      "Epoch 5: Total Loss=0.0635\n",
      "Epoch 6: Total Loss=0.0657\n",
      "Epoch 7: Total Loss=0.0662\n",
      "Epoch 8: Total Loss=0.0648\n",
      "Epoch 9: Total Loss=0.0642\n",
      "Updated x: [0.03497479110956192, -0.02520338073372841], Function Value: 0.001858446397818625, Gradient: [0.0054530915804207325, -0.00823043193668127]\n",
      "\n",
      "Step 33/40\n",
      "Epoch 0: Total Loss=0.0671\n",
      "Epoch 1: Total Loss=0.0659\n",
      "Epoch 2: Total Loss=0.0632\n",
      "Epoch 3: Total Loss=0.0662\n",
      "Epoch 4: Total Loss=0.0660\n",
      "Epoch 5: Total Loss=0.0632\n",
      "Epoch 6: Total Loss=0.0652\n",
      "Epoch 7: Total Loss=0.0643\n",
      "Epoch 8: Total Loss=0.0637\n",
      "Epoch 9: Total Loss=0.0662\n",
      "Updated x: [-0.001968551427125931, 0.043894026428461075], Function Value: 0.0019305608002468944, Gradient: [0.0057147229090332985, -0.014003954827785492]\n",
      "\n",
      "Step 34/40\n",
      "Epoch 0: Total Loss=0.0646\n",
      "Epoch 1: Total Loss=0.0645\n",
      "Epoch 2: Total Loss=0.0645\n",
      "Epoch 3: Total Loss=0.0637\n",
      "Epoch 4: Total Loss=0.0665\n",
      "Epoch 5: Total Loss=0.0669\n",
      "Epoch 6: Total Loss=0.0620\n",
      "Epoch 7: Total Loss=0.0648\n",
      "Epoch 8: Total Loss=0.0668\n",
      "Epoch 9: Total Loss=0.0657\n",
      "Updated x: [0.017620665952563286, -0.0040853917598724365], Function Value: 0.00032717830617912114, Gradient: [0.005580937955528498, -0.008084217086434364]\n",
      "\n",
      "Step 35/40\n",
      "Epoch 0: Total Loss=0.0649\n",
      "Epoch 1: Total Loss=0.0642\n",
      "Epoch 2: Total Loss=0.0663\n",
      "Epoch 3: Total Loss=0.0670\n",
      "Epoch 4: Total Loss=0.0661\n",
      "Epoch 5: Total Loss=0.0655\n",
      "Epoch 6: Total Loss=0.0664\n",
      "Epoch 7: Total Loss=0.0636\n",
      "Epoch 8: Total Loss=0.0637\n",
      "Epoch 9: Total Loss=0.0652\n",
      "Updated x: [0.04536255821585655, 0.003643524833023548], Function Value: 0.002071036957204342, Gradient: [0.004798762034624815, -0.012132377363741398]\n",
      "\n",
      "Step 36/40\n",
      "Epoch 0: Total Loss=0.0659\n",
      "Epoch 1: Total Loss=0.0660\n",
      "Epoch 2: Total Loss=0.0669\n",
      "Epoch 3: Total Loss=0.0675\n",
      "Epoch 4: Total Loss=0.0651\n",
      "Epoch 5: Total Loss=0.0640\n",
      "Epoch 6: Total Loss=0.0651\n",
      "Epoch 7: Total Loss=0.0637\n",
      "Epoch 8: Total Loss=0.0645\n",
      "Epoch 9: Total Loss=0.0648\n",
      "Updated x: [0.017159095034003258, 0.02039879932999611], Function Value: 0.0007105455733835697, Gradient: [0.005096870474517345, -0.013844169676303864]\n",
      "\n",
      "Step 37/40\n",
      "Epoch 0: Total Loss=0.0651\n",
      "Epoch 1: Total Loss=0.0639\n",
      "Epoch 2: Total Loss=0.0646\n",
      "Epoch 3: Total Loss=0.0668\n",
      "Epoch 4: Total Loss=0.0656\n",
      "Epoch 5: Total Loss=0.0624\n",
      "Epoch 6: Total Loss=0.0657\n",
      "Epoch 7: Total Loss=0.0669\n",
      "Epoch 8: Total Loss=0.0677\n",
      "Epoch 9: Total Loss=0.0640\n",
      "Updated x: [0.016246343031525612, 0.021102847531437874], Function Value: 0.0007092738524079323, Gradient: [0.00538387056440115, -0.011456651613116264]\n",
      "\n",
      "Step 38/40\n",
      "Epoch 0: Total Loss=0.0658\n",
      "Epoch 1: Total Loss=0.0655\n",
      "Epoch 2: Total Loss=0.0676\n",
      "Epoch 3: Total Loss=0.0676\n",
      "Epoch 4: Total Loss=0.0652\n",
      "Epoch 5: Total Loss=0.0642\n",
      "Epoch 6: Total Loss=0.0641\n",
      "Epoch 7: Total Loss=0.0644\n",
      "Epoch 8: Total Loss=0.0645\n",
      "Epoch 9: Total Loss=0.0648\n",
      "Updated x: [0.05776708573102951, 0.03287961333990097], Function Value: 0.004418104887008667, Gradient: [0.0039610425010323524, -0.013160043396055698]\n",
      "\n",
      "Step 39/40\n",
      "Epoch 0: Total Loss=0.0646\n",
      "Epoch 1: Total Loss=0.0637\n",
      "Epoch 2: Total Loss=0.0664\n",
      "Epoch 3: Total Loss=0.0631\n",
      "Epoch 4: Total Loss=0.0673\n",
      "Epoch 5: Total Loss=0.0633\n",
      "Epoch 6: Total Loss=0.0648\n",
      "Epoch 7: Total Loss=0.0649\n",
      "Epoch 8: Total Loss=0.0639\n",
      "Epoch 9: Total Loss=0.0669\n",
      "Updated x: [-0.07864979654550552, -0.007893014699220657], Function Value: 0.006248090416193008, Gradient: [0.006186321377754211, -0.006894176360219717]\n",
      "\n",
      "Step 40/40\n",
      "Epoch 0: Total Loss=0.0647\n",
      "Epoch 1: Total Loss=0.0650\n",
      "Epoch 2: Total Loss=0.0629\n",
      "Epoch 3: Total Loss=0.0669\n",
      "Epoch 4: Total Loss=0.0658\n",
      "Epoch 5: Total Loss=0.0665\n",
      "Epoch 6: Total Loss=0.0682\n",
      "Epoch 7: Total Loss=0.0642\n",
      "Epoch 8: Total Loss=0.0672\n",
      "Epoch 9: Total Loss=0.0668\n",
      "Updated x: [0.0004593953490257263, 0.060680586844682693], Function Value: 0.003682344453409314, Gradient: [0.00474924361333251, -0.016878465190529823]\n",
      "\n",
      "Step 1/40\n",
      "Epoch 0: Total Loss=5.0284\n",
      "Epoch 1: Total Loss=6.0443\n",
      "Epoch 2: Total Loss=4.2144\n",
      "Epoch 3: Total Loss=5.2713\n",
      "Epoch 4: Total Loss=4.2108\n",
      "Epoch 5: Total Loss=4.9665\n",
      "Epoch 6: Total Loss=5.9737\n",
      "Epoch 7: Total Loss=4.1596\n",
      "Epoch 8: Total Loss=5.2031\n",
      "Epoch 9: Total Loss=4.1522\n",
      "Updated x: [0.7727769613265991, -0.7602852582931519], Function Value: 1.175217866897583, Gradient: [-0.03100116178393364, -0.08240395039319992]\n",
      "\n",
      "Step 2/40\n",
      "Epoch 0: Total Loss=2.7378\n",
      "Epoch 1: Total Loss=2.2640\n",
      "Epoch 2: Total Loss=2.6797\n",
      "Epoch 3: Total Loss=2.8376\n",
      "Epoch 4: Total Loss=2.3117\n",
      "Epoch 5: Total Loss=2.6878\n",
      "Epoch 6: Total Loss=2.2196\n",
      "Epoch 7: Total Loss=2.6245\n",
      "Epoch 8: Total Loss=2.7804\n",
      "Epoch 9: Total Loss=2.2612\n",
      "Updated x: [0.6056831479072571, -0.7270826697349548], Function Value: 0.8955012559890747, Gradient: [-0.017286214977502823, -0.09284384548664093]\n",
      "\n",
      "Step 3/40\n",
      "Epoch 0: Total Loss=0.1838\n",
      "Epoch 1: Total Loss=0.1909\n",
      "Epoch 2: Total Loss=0.1723\n",
      "Epoch 3: Total Loss=0.1340\n",
      "Epoch 4: Total Loss=0.1747\n",
      "Epoch 5: Total Loss=0.1625\n",
      "Epoch 6: Total Loss=0.1749\n",
      "Epoch 7: Total Loss=0.1584\n",
      "Epoch 8: Total Loss=0.1385\n",
      "Epoch 9: Total Loss=0.1811\n",
      "Updated x: [0.558811604976654, -0.5787749290466309], Function Value: 0.6472508311271667, Gradient: [-0.01966375671327114, -0.09096578508615494]\n",
      "\n",
      "Step 4/40\n",
      "Epoch 0: Total Loss=0.1295\n",
      "Epoch 1: Total Loss=0.1206\n",
      "Epoch 2: Total Loss=0.1348\n",
      "Epoch 3: Total Loss=0.1301\n",
      "Epoch 4: Total Loss=0.1671\n",
      "Epoch 5: Total Loss=0.1268\n",
      "Epoch 6: Total Loss=0.1217\n",
      "Epoch 7: Total Loss=0.1268\n",
      "Epoch 8: Total Loss=0.1198\n",
      "Epoch 9: Total Loss=0.1334\n",
      "Updated x: [0.4597311019897461, -0.5460494756698608], Function Value: 0.5095227360725403, Gradient: [-0.006940586492419243, -0.06733983010053635]\n",
      "\n",
      "Step 5/40\n",
      "Epoch 0: Total Loss=0.1254\n",
      "Epoch 1: Total Loss=0.1160\n",
      "Epoch 2: Total Loss=0.1469\n",
      "Epoch 3: Total Loss=0.1178\n",
      "Epoch 4: Total Loss=0.1062\n",
      "Epoch 5: Total Loss=0.1113\n",
      "Epoch 6: Total Loss=0.1561\n",
      "Epoch 7: Total Loss=0.1051\n",
      "Epoch 8: Total Loss=0.1191\n",
      "Epoch 9: Total Loss=0.1232\n",
      "Updated x: [0.28037428855895996, -0.44413238763809204], Function Value: 0.27586331963539124, Gradient: [0.002074029529467225, -0.048198144882917404]\n",
      "\n",
      "Step 6/40\n",
      "Epoch 0: Total Loss=0.1067\n",
      "Epoch 1: Total Loss=0.1026\n",
      "Epoch 2: Total Loss=0.1161\n",
      "Epoch 3: Total Loss=0.1001\n",
      "Epoch 4: Total Loss=0.0922\n",
      "Epoch 5: Total Loss=0.1142\n",
      "Epoch 6: Total Loss=0.0992\n",
      "Epoch 7: Total Loss=0.1434\n",
      "Epoch 8: Total Loss=0.1115\n",
      "Epoch 9: Total Loss=0.1098\n",
      "Updated x: [0.24322602152824402, -0.22453786432743073], Function Value: 0.10957615077495575, Gradient: [0.003711071563884616, -0.03264499828219414]\n",
      "\n",
      "Step 7/40\n",
      "Epoch 0: Total Loss=0.1130\n",
      "Epoch 1: Total Loss=0.0936\n",
      "Epoch 2: Total Loss=0.1104\n",
      "Epoch 3: Total Loss=0.0865\n",
      "Epoch 4: Total Loss=0.1059\n",
      "Epoch 5: Total Loss=0.0907\n",
      "Epoch 6: Total Loss=0.1216\n",
      "Epoch 7: Total Loss=0.0822\n",
      "Epoch 8: Total Loss=0.1237\n",
      "Epoch 9: Total Loss=0.1114\n",
      "Updated x: [0.18932436406612396, -0.19833755493164062], Function Value: 0.0751814991235733, Gradient: [0.0012974037090316415, -0.029308021068572998]\n",
      "\n",
      "Step 8/40\n",
      "Epoch 0: Total Loss=0.0929\n",
      "Epoch 1: Total Loss=0.1072\n",
      "Epoch 2: Total Loss=0.1135\n",
      "Epoch 3: Total Loss=0.0895\n",
      "Epoch 4: Total Loss=0.1075\n",
      "Epoch 5: Total Loss=0.0860\n",
      "Epoch 6: Total Loss=0.0925\n",
      "Epoch 7: Total Loss=0.0800\n",
      "Epoch 8: Total Loss=0.1132\n",
      "Epoch 9: Total Loss=0.0949\n",
      "Updated x: [0.1365862637758255, -0.0866057351231575], Function Value: 0.026156360283493996, Gradient: [0.0041632018983364105, -0.018536217510700226]\n",
      "\n",
      "Step 9/40\n",
      "Epoch 0: Total Loss=0.0871\n",
      "Epoch 1: Total Loss=0.0868\n",
      "Epoch 2: Total Loss=0.0921\n",
      "Epoch 3: Total Loss=0.0966\n",
      "Epoch 4: Total Loss=0.0808\n",
      "Epoch 5: Total Loss=0.0836\n",
      "Epoch 6: Total Loss=0.0910\n",
      "Epoch 7: Total Loss=0.1005\n",
      "Epoch 8: Total Loss=0.0887\n",
      "Epoch 9: Total Loss=0.1011\n",
      "Updated x: [0.04565571993589401, 0.03851629048585892], Function Value: 0.003567949403077364, Gradient: [0.004551802761852741, -0.007705890107899904]\n",
      "\n",
      "Step 10/40\n",
      "Epoch 0: Total Loss=0.0912\n",
      "Epoch 1: Total Loss=0.0682\n",
      "Epoch 2: Total Loss=0.0731\n",
      "Epoch 3: Total Loss=0.0799\n",
      "Epoch 4: Total Loss=0.0788\n",
      "Epoch 5: Total Loss=0.0830\n",
      "Epoch 6: Total Loss=0.0898\n",
      "Epoch 7: Total Loss=0.0802\n",
      "Epoch 8: Total Loss=0.0853\n",
      "Epoch 9: Total Loss=0.0820\n",
      "Updated x: [-0.04431566596031189, -0.004403021186590195], Function Value: 0.0019832649268209934, Gradient: [0.003271957626566291, -0.003735111327841878]\n",
      "\n",
      "Step 11/40\n",
      "Epoch 0: Total Loss=0.0785\n",
      "Epoch 1: Total Loss=0.0929\n",
      "Epoch 2: Total Loss=0.0796\n",
      "Epoch 3: Total Loss=0.0909\n",
      "Epoch 4: Total Loss=0.0835\n",
      "Epoch 5: Total Loss=0.0895\n",
      "Epoch 6: Total Loss=0.0860\n",
      "Epoch 7: Total Loss=0.1099\n",
      "Epoch 8: Total Loss=0.0725\n",
      "Epoch 9: Total Loss=0.0747\n",
      "Updated x: [-0.0027355775237083435, -0.01367464754730463], Function Value: 0.00019447936210781336, Gradient: [0.0032310127280652523, -0.009144825860857964]\n",
      "\n",
      "Step 12/40\n",
      "Epoch 0: Total Loss=0.0535\n",
      "Epoch 1: Total Loss=0.0536\n",
      "Epoch 2: Total Loss=0.0534\n",
      "Epoch 3: Total Loss=0.0536\n",
      "Epoch 4: Total Loss=0.0535\n",
      "Epoch 5: Total Loss=0.0534\n",
      "Epoch 6: Total Loss=0.0536\n",
      "Epoch 7: Total Loss=0.0534\n",
      "Epoch 8: Total Loss=0.0536\n",
      "Epoch 9: Total Loss=0.0534\n",
      "Updated x: [-0.05089340731501579, -0.04279468208551407], Function Value: 0.00442152377218008, Gradient: [0.002005277667194605, 0.0017046128632500768]\n",
      "\n",
      "Step 13/40\n",
      "Epoch 0: Total Loss=0.0552\n",
      "Epoch 1: Total Loss=0.0534\n",
      "Epoch 2: Total Loss=0.0537\n",
      "Epoch 3: Total Loss=0.0534\n",
      "Epoch 4: Total Loss=0.0553\n",
      "Epoch 5: Total Loss=0.0534\n",
      "Epoch 6: Total Loss=0.0535\n",
      "Epoch 7: Total Loss=0.0535\n",
      "Epoch 8: Total Loss=0.0534\n",
      "Epoch 9: Total Loss=0.0553\n",
      "Updated x: [0.03538046404719353, 0.037251561880111694], Function Value: 0.0026394561864435673, Gradient: [0.0028887588996440172, 0.0025387320201843977]\n",
      "\n",
      "Step 14/40\n",
      "Epoch 0: Total Loss=0.0534\n",
      "Epoch 1: Total Loss=0.0553\n",
      "Epoch 2: Total Loss=0.0533\n",
      "Epoch 3: Total Loss=0.0534\n",
      "Epoch 4: Total Loss=0.0535\n",
      "Epoch 5: Total Loss=0.0534\n",
      "Epoch 6: Total Loss=0.0535\n",
      "Epoch 7: Total Loss=0.0533\n",
      "Epoch 8: Total Loss=0.0553\n",
      "Epoch 9: Total Loss=0.0533\n",
      "Updated x: [-0.0573456697165966, -0.05159933865070343], Function Value: 0.00595101760700345, Gradient: [0.0031729897018522024, 0.0012365247821435332]\n",
      "\n",
      "Step 15/40\n",
      "Epoch 0: Total Loss=0.0535\n",
      "Epoch 1: Total Loss=0.0549\n",
      "Epoch 2: Total Loss=0.0541\n",
      "Epoch 3: Total Loss=0.0534\n",
      "Epoch 4: Total Loss=0.0536\n",
      "Epoch 5: Total Loss=0.0535\n",
      "Epoch 6: Total Loss=0.0534\n",
      "Epoch 7: Total Loss=0.0537\n",
      "Epoch 8: Total Loss=0.0534\n",
      "Epoch 9: Total Loss=0.0534\n",
      "Updated x: [0.010607372969388962, -0.018962912261486053], Function Value: 0.00047210839693434536, Gradient: [0.006142593454569578, 0.003728854237124324]\n",
      "\n",
      "Step 16/40\n",
      "Epoch 0: Total Loss=0.0546\n",
      "Epoch 1: Total Loss=0.0539\n",
      "Epoch 2: Total Loss=0.0534\n",
      "Epoch 3: Total Loss=0.0544\n",
      "Epoch 4: Total Loss=0.0535\n",
      "Epoch 5: Total Loss=0.0550\n",
      "Epoch 6: Total Loss=0.0537\n",
      "Epoch 7: Total Loss=0.0542\n",
      "Epoch 8: Total Loss=0.0533\n",
      "Epoch 9: Total Loss=0.0534\n",
      "Updated x: [-0.02910793572664261, -0.030988261103630066], Function Value: 0.001807544264011085, Gradient: [0.004936606157571077, 0.002866829512640834]\n",
      "\n",
      "Step 17/40\n",
      "Epoch 0: Total Loss=0.0535\n",
      "Epoch 1: Total Loss=0.0533\n",
      "Epoch 2: Total Loss=0.0534\n",
      "Epoch 3: Total Loss=0.0543\n",
      "Epoch 4: Total Loss=0.0540\n",
      "Epoch 5: Total Loss=0.0550\n",
      "Epoch 6: Total Loss=0.0534\n",
      "Epoch 7: Total Loss=0.0534\n",
      "Epoch 8: Total Loss=0.0537\n",
      "Epoch 9: Total Loss=0.0533\n",
      "Updated x: [-0.014891567640006542, 0.03345645219087601], Function Value: 0.00134109309874475, Gradient: [0.004122061189264059, 0.002871017437428236]\n",
      "\n",
      "Step 18/40\n",
      "Epoch 0: Total Loss=0.0534\n",
      "Epoch 1: Total Loss=0.0539\n",
      "Epoch 2: Total Loss=0.0541\n",
      "Epoch 3: Total Loss=0.0536\n",
      "Epoch 4: Total Loss=0.0535\n",
      "Epoch 5: Total Loss=0.0536\n",
      "Epoch 6: Total Loss=0.0537\n",
      "Epoch 7: Total Loss=0.0537\n",
      "Epoch 8: Total Loss=0.0533\n",
      "Epoch 9: Total Loss=0.0536\n",
      "Updated x: [0.02290237322449684, -0.00856853649020195], Function Value: 0.0005979385459795594, Gradient: [0.007463375572115183, 0.005019204691052437]\n",
      "\n",
      "Step 19/40\n",
      "Epoch 0: Total Loss=0.0537\n",
      "Epoch 1: Total Loss=0.0536\n",
      "Epoch 2: Total Loss=0.0534\n",
      "Epoch 3: Total Loss=0.0542\n",
      "Epoch 4: Total Loss=0.0533\n",
      "Epoch 5: Total Loss=0.0537\n",
      "Epoch 6: Total Loss=0.0535\n",
      "Epoch 7: Total Loss=0.0542\n",
      "Epoch 8: Total Loss=0.0534\n",
      "Epoch 9: Total Loss=0.0538\n",
      "Updated x: [0.008950143121182919, 0.026000048965215683], Function Value: 0.0007561076199635863, Gradient: [0.00713745690882206, 0.006364917848259211]\n",
      "\n",
      "Step 20/40\n",
      "Epoch 0: Total Loss=0.0538\n",
      "Epoch 1: Total Loss=0.0536\n",
      "Epoch 2: Total Loss=0.0540\n",
      "Epoch 3: Total Loss=0.0535\n",
      "Epoch 4: Total Loss=0.0531\n",
      "Epoch 5: Total Loss=0.0535\n",
      "Epoch 6: Total Loss=0.0535\n",
      "Epoch 7: Total Loss=0.0543\n",
      "Epoch 8: Total Loss=0.0534\n",
      "Epoch 9: Total Loss=0.0535\n",
      "Updated x: [0.042714789509773254, -0.02436460182070732], Function Value: 0.002418186981230974, Gradient: [0.008512734435498714, 0.005086170043796301]\n",
      "\n",
      "Step 21/40\n",
      "Epoch 0: Total Loss=0.0541\n",
      "Epoch 1: Total Loss=0.0534\n",
      "Epoch 2: Total Loss=0.0541\n",
      "Epoch 3: Total Loss=0.0543\n",
      "Epoch 4: Total Loss=0.0536\n",
      "Epoch 5: Total Loss=0.0535\n",
      "Epoch 6: Total Loss=0.0537\n",
      "Epoch 7: Total Loss=0.0536\n",
      "Epoch 8: Total Loss=0.0534\n",
      "Epoch 9: Total Loss=0.0533\n",
      "Updated x: [0.07972623407840729, -0.012015481479465961], Function Value: 0.006500644143670797, Gradient: [0.007323166821151972, 0.002766626188531518]\n",
      "\n",
      "Step 22/40\n",
      "Epoch 0: Total Loss=0.0660\n",
      "Epoch 1: Total Loss=0.0662\n",
      "Epoch 2: Total Loss=0.0693\n",
      "Epoch 3: Total Loss=0.0669\n",
      "Epoch 4: Total Loss=0.0704\n",
      "Epoch 5: Total Loss=0.0685\n",
      "Epoch 6: Total Loss=0.0677\n",
      "Epoch 7: Total Loss=0.0707\n",
      "Epoch 8: Total Loss=0.0656\n",
      "Epoch 9: Total Loss=0.0691\n",
      "Updated x: [0.029482688754796982, 0.021125666797161102], Function Value: 0.0013155227061361074, Gradient: [0.017851663753390312, 0.012637012638151646]\n",
      "\n",
      "Step 23/40\n",
      "Epoch 0: Total Loss=0.0692\n",
      "Epoch 1: Total Loss=0.0698\n",
      "Epoch 2: Total Loss=0.0667\n",
      "Epoch 3: Total Loss=0.0692\n",
      "Epoch 4: Total Loss=0.0710\n",
      "Epoch 5: Total Loss=0.0739\n",
      "Epoch 6: Total Loss=0.0661\n",
      "Epoch 7: Total Loss=0.0677\n",
      "Epoch 8: Total Loss=0.0662\n",
      "Epoch 9: Total Loss=0.0680\n",
      "Updated x: [0.00602092407643795, -0.0391388013958931], Function Value: 0.0015680972719565034, Gradient: [0.013847636990249157, 0.009972082450985909]\n",
      "\n",
      "Step 24/40\n",
      "Epoch 0: Total Loss=0.0660\n",
      "Epoch 1: Total Loss=0.0694\n",
      "Epoch 2: Total Loss=0.0686\n",
      "Epoch 3: Total Loss=0.0647\n",
      "Epoch 4: Total Loss=0.0691\n",
      "Epoch 5: Total Loss=0.0697\n",
      "Epoch 6: Total Loss=0.0690\n",
      "Epoch 7: Total Loss=0.0674\n",
      "Epoch 8: Total Loss=0.0681\n",
      "Epoch 9: Total Loss=0.0714\n",
      "Updated x: [0.029311802238225937, 0.0038415752351284027], Function Value: 0.0008739394252188504, Gradient: [0.009491924196481705, 0.006493235472589731]\n",
      "\n",
      "Step 25/40\n",
      "Epoch 0: Total Loss=0.0689\n",
      "Epoch 1: Total Loss=0.0712\n",
      "Epoch 2: Total Loss=0.0707\n",
      "Epoch 3: Total Loss=0.0675\n",
      "Epoch 4: Total Loss=0.0688\n",
      "Epoch 5: Total Loss=0.0682\n",
      "Epoch 6: Total Loss=0.0672\n",
      "Epoch 7: Total Loss=0.0698\n",
      "Epoch 8: Total Loss=0.0730\n",
      "Epoch 9: Total Loss=0.0699\n",
      "Updated x: [-0.017155766487121582, -0.03681432455778122], Function Value: 0.001649614772759378, Gradient: [0.013340737670660019, 0.01038436684757471]\n",
      "\n",
      "Step 26/40\n",
      "Epoch 0: Total Loss=0.0684\n",
      "Epoch 1: Total Loss=0.0716\n",
      "Epoch 2: Total Loss=0.0669\n",
      "Epoch 3: Total Loss=0.0702\n",
      "Epoch 4: Total Loss=0.0672\n",
      "Epoch 5: Total Loss=0.0694\n",
      "Epoch 6: Total Loss=0.0686\n",
      "Epoch 7: Total Loss=0.0701\n",
      "Epoch 8: Total Loss=0.0691\n",
      "Epoch 9: Total Loss=0.0716\n",
      "Updated x: [-0.009734376333653927, -0.06776897609233856], Function Value: 0.0046873921528458595, Gradient: [0.012016551569104195, 0.007066003978252411]\n",
      "\n",
      "Step 27/40\n",
      "Epoch 0: Total Loss=0.0698\n",
      "Epoch 1: Total Loss=0.0691\n",
      "Epoch 2: Total Loss=0.0666\n",
      "Epoch 3: Total Loss=0.0698\n",
      "Epoch 4: Total Loss=0.0739\n",
      "Epoch 5: Total Loss=0.0679\n",
      "Epoch 6: Total Loss=0.0620\n",
      "Epoch 7: Total Loss=0.0660\n",
      "Epoch 8: Total Loss=0.0696\n",
      "Epoch 9: Total Loss=0.0646\n",
      "Updated x: [0.017538607120513916, 0.007485494017601013], Function Value: 0.0003636353649199009, Gradient: [0.01213234756141901, 0.008368068374693394]\n",
      "\n",
      "Step 28/40\n",
      "Epoch 0: Total Loss=0.0669\n",
      "Epoch 1: Total Loss=0.0692\n",
      "Epoch 2: Total Loss=0.0647\n",
      "Epoch 3: Total Loss=0.0678\n",
      "Epoch 4: Total Loss=0.0728\n",
      "Epoch 5: Total Loss=0.0648\n",
      "Epoch 6: Total Loss=0.0723\n",
      "Epoch 7: Total Loss=0.0701\n",
      "Epoch 8: Total Loss=0.0670\n",
      "Epoch 9: Total Loss=0.0686\n",
      "Updated x: [-0.012254541739821434, -0.0063589876517653465], Function Value: 0.00019061050261370838, Gradient: [0.009426803328096867, 0.005441180430352688]\n",
      "\n",
      "Step 29/40\n",
      "Epoch 0: Total Loss=0.0704\n",
      "Epoch 1: Total Loss=0.0660\n",
      "Epoch 2: Total Loss=0.0678\n",
      "Epoch 3: Total Loss=0.0670\n",
      "Epoch 4: Total Loss=0.0682\n",
      "Epoch 5: Total Loss=0.0676\n",
      "Epoch 6: Total Loss=0.0692\n",
      "Epoch 7: Total Loss=0.0672\n",
      "Epoch 8: Total Loss=0.0690\n",
      "Epoch 9: Total Loss=0.0687\n",
      "Updated x: [0.01214773952960968, -0.02446809783577919], Function Value: 0.0007462553912773728, Gradient: [0.009931246750056744, 0.004934676922857761]\n",
      "\n",
      "Step 30/40\n",
      "Epoch 0: Total Loss=0.0673\n",
      "Epoch 1: Total Loss=0.0668\n",
      "Epoch 2: Total Loss=0.0657\n",
      "Epoch 3: Total Loss=0.0694\n",
      "Epoch 4: Total Loss=0.0698\n",
      "Epoch 5: Total Loss=0.0715\n",
      "Epoch 6: Total Loss=0.0700\n",
      "Epoch 7: Total Loss=0.0696\n",
      "Epoch 8: Total Loss=0.0678\n",
      "Epoch 9: Total Loss=0.0651\n",
      "Updated x: [0.01963689923286438, -0.004372021183371544], Function Value: 0.00040472240652889013, Gradient: [0.010945476591587067, 0.007398337125778198]\n",
      "\n",
      "Step 31/40\n",
      "Epoch 0: Total Loss=0.0670\n",
      "Epoch 1: Total Loss=0.0675\n",
      "Epoch 2: Total Loss=0.0688\n",
      "Epoch 3: Total Loss=0.0672\n",
      "Epoch 4: Total Loss=0.0699\n",
      "Epoch 5: Total Loss=0.0751\n",
      "Epoch 6: Total Loss=0.0670\n",
      "Epoch 7: Total Loss=0.0687\n",
      "Epoch 8: Total Loss=0.0654\n",
      "Epoch 9: Total Loss=0.0681\n",
      "Updated x: [-0.014287788420915604, -0.01192212663590908], Function Value: 0.00034627801505848765, Gradient: [0.010480795055627823, 0.0075787389650940895]\n",
      "\n",
      "Step 32/40\n",
      "Epoch 0: Total Loss=0.0601\n",
      "Epoch 1: Total Loss=0.0607\n",
      "Epoch 2: Total Loss=0.0611\n",
      "Epoch 3: Total Loss=0.0598\n",
      "Epoch 4: Total Loss=0.0613\n",
      "Epoch 5: Total Loss=0.0601\n",
      "Epoch 6: Total Loss=0.0611\n",
      "Epoch 7: Total Loss=0.0598\n",
      "Epoch 8: Total Loss=0.0590\n",
      "Epoch 9: Total Loss=0.0596\n",
      "Updated x: [0.010485706850886345, 0.0420399084687233], Function Value: 0.001877303933724761, Gradient: [0.004288568161427975, 0.002693549729883671]\n",
      "\n",
      "Step 33/40\n",
      "Epoch 0: Total Loss=0.0601\n",
      "Epoch 1: Total Loss=0.0613\n",
      "Epoch 2: Total Loss=0.0598\n",
      "Epoch 3: Total Loss=0.0608\n",
      "Epoch 4: Total Loss=0.0598\n",
      "Epoch 5: Total Loss=0.0586\n",
      "Epoch 6: Total Loss=0.0597\n",
      "Epoch 7: Total Loss=0.0602\n",
      "Epoch 8: Total Loss=0.0598\n",
      "Epoch 9: Total Loss=0.0597\n",
      "Updated x: [-0.0032466892153024673, -0.019942093640565872], Function Value: 0.000408228108426556, Gradient: [0.0076524969190359116, 0.005411029793322086]\n",
      "\n",
      "Step 34/40\n",
      "Epoch 0: Total Loss=0.0595\n",
      "Epoch 1: Total Loss=0.0595\n",
      "Epoch 2: Total Loss=0.0604\n",
      "Epoch 3: Total Loss=0.0610\n",
      "Epoch 4: Total Loss=0.0606\n",
      "Epoch 5: Total Loss=0.0600\n",
      "Epoch 6: Total Loss=0.0604\n",
      "Epoch 7: Total Loss=0.0609\n",
      "Epoch 8: Total Loss=0.0609\n",
      "Epoch 9: Total Loss=0.0601\n",
      "Updated x: [-0.06206157058477402, 0.004522746428847313], Function Value: 0.003872093977406621, Gradient: [0.008561131544411182, 0.00893917866051197]\n",
      "\n",
      "Step 35/40\n",
      "Epoch 0: Total Loss=0.0608\n",
      "Epoch 1: Total Loss=0.0596\n",
      "Epoch 2: Total Loss=0.0600\n",
      "Epoch 3: Total Loss=0.0590\n",
      "Epoch 4: Total Loss=0.0600\n",
      "Epoch 5: Total Loss=0.0618\n",
      "Epoch 6: Total Loss=0.0618\n",
      "Epoch 7: Total Loss=0.0595\n",
      "Epoch 8: Total Loss=0.0591\n",
      "Epoch 9: Total Loss=0.0594\n",
      "Updated x: [0.02990853786468506, -1.907162368297577e-05], Function Value: 0.0008945210138335824, Gradient: [0.006694173905998468, 0.0045181456953287125]\n",
      "\n",
      "Step 36/40\n",
      "Epoch 0: Total Loss=0.0600\n",
      "Epoch 1: Total Loss=0.0588\n",
      "Epoch 2: Total Loss=0.0594\n",
      "Epoch 3: Total Loss=0.0594\n",
      "Epoch 4: Total Loss=0.0605\n",
      "Epoch 5: Total Loss=0.0620\n",
      "Epoch 6: Total Loss=0.0603\n",
      "Epoch 7: Total Loss=0.0595\n",
      "Epoch 8: Total Loss=0.0593\n",
      "Epoch 9: Total Loss=0.0593\n",
      "Updated x: [-0.014346428215503693, 0.0469745397567749], Function Value: 0.0024124274495989084, Gradient: [0.005443892907351255, 0.005288674496114254]\n",
      "\n",
      "Step 37/40\n",
      "Epoch 0: Total Loss=0.0607\n",
      "Epoch 1: Total Loss=0.0604\n",
      "Epoch 2: Total Loss=0.0606\n",
      "Epoch 3: Total Loss=0.0592\n",
      "Epoch 4: Total Loss=0.0598\n",
      "Epoch 5: Total Loss=0.0595\n",
      "Epoch 6: Total Loss=0.0602\n",
      "Epoch 7: Total Loss=0.0609\n",
      "Epoch 8: Total Loss=0.0591\n",
      "Epoch 9: Total Loss=0.0609\n",
      "Updated x: [0.04059978574514389, -0.030940480530261993], Function Value: 0.0026056559290736914, Gradient: [0.007727960590273142, 0.00520583800971508]\n",
      "\n",
      "Step 38/40\n",
      "Epoch 0: Total Loss=0.0600\n",
      "Epoch 1: Total Loss=0.0593\n",
      "Epoch 2: Total Loss=0.0595\n",
      "Epoch 3: Total Loss=0.0610\n",
      "Epoch 4: Total Loss=0.0601\n",
      "Epoch 5: Total Loss=0.0598\n",
      "Epoch 6: Total Loss=0.0614\n",
      "Epoch 7: Total Loss=0.0588\n",
      "Epoch 8: Total Loss=0.0596\n",
      "Epoch 9: Total Loss=0.0597\n",
      "Updated x: [0.00870206207036972, -0.01171685941517353], Function Value: 0.00021301067317835987, Gradient: [0.006734749302268028, 0.003849917324259877]\n",
      "\n",
      "Step 39/40\n",
      "Epoch 0: Total Loss=0.0603\n",
      "Epoch 1: Total Loss=0.0642\n",
      "Epoch 2: Total Loss=0.0606\n",
      "Epoch 3: Total Loss=0.0616\n",
      "Epoch 4: Total Loss=0.0601\n",
      "Epoch 5: Total Loss=0.0587\n",
      "Epoch 6: Total Loss=0.0593\n",
      "Epoch 7: Total Loss=0.0616\n",
      "Epoch 8: Total Loss=0.0606\n",
      "Epoch 9: Total Loss=0.0598\n",
      "Updated x: [0.02220914512872696, 0.01832466945052147], Function Value: 0.0008290396071970463, Gradient: [0.006645032670348883, 0.003942006267607212]\n",
      "\n",
      "Step 40/40\n",
      "Epoch 0: Total Loss=0.0616\n",
      "Epoch 1: Total Loss=0.0609\n",
      "Epoch 2: Total Loss=0.0606\n",
      "Epoch 3: Total Loss=0.0613\n",
      "Epoch 4: Total Loss=0.0606\n",
      "Epoch 5: Total Loss=0.0583\n",
      "Epoch 6: Total Loss=0.0596\n",
      "Epoch 7: Total Loss=0.0599\n",
      "Epoch 8: Total Loss=0.0637\n",
      "Epoch 9: Total Loss=0.0599\n",
      "Updated x: [-0.029477227479219437, -0.03024429827928543], Function Value: 0.0017836245242506266, Gradient: [0.009671828709542751, 0.009260094724595547]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define the range of N_s values to test\n",
    "N_s_values = np.arange(1, 10, 2)  # Testing N_s in increments of 2\n",
    "optim_steps = 40\n",
    "\n",
    "# Dictionary to store results\n",
    "results = {}\n",
    "\n",
    "# Run optimization for each N_s and store the results\n",
    "for N_s in N_s_values:\n",
    "    # Initialize datasets and model\n",
    "    old_dataset = OldDataSet(data, k=10)\n",
    "    new_dataset = NewDataSet(k=10)\n",
    "    model = MLP(2, [5, 5, 5], 1)\n",
    "    \n",
    "    # Run optimization\n",
    "    x_path, y_path = optimize_surrogate_model(model, old_dataset, new_dataset, assSim, optim_steps=optim_steps, N_s=N_s, lr=0.001, merge_interval=10)\n",
    "    \n",
    "    # Store y_path for plotting\n",
    "    results[N_s] = y_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the results\n",
    "plt.figure(figsize=(10, 6))\n",
    "for N_s, y in results.items():\n",
    "    plt.plot(range(optim_steps), y, label=f\"N_s = {N_s}\")\n",
    "\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.ylabel(\"Objective y\")\n",
    "plt.title(\"Effect of N_s on y Objective Over Iterations\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 1/40\n",
      "Epoch 0: Total Loss=5.5168\n",
      "Epoch 1: Total Loss=5.5034\n",
      "Epoch 2: Total Loss=5.4916\n",
      "Epoch 3: Total Loss=5.4800\n",
      "Epoch 4: Total Loss=5.4683\n",
      "Epoch 5: Total Loss=5.4575\n",
      "Epoch 6: Total Loss=5.4463\n",
      "Epoch 7: Total Loss=5.4342\n",
      "Epoch 8: Total Loss=5.4267\n",
      "Epoch 9: Total Loss=5.4160\n",
      "Updated x: [0.7924132943153381, -0.7985142469406128], Function Value: 1.265543818473816, Gradient: [-0.030707500874996185, -0.009736382402479649]\n",
      "\n",
      "Step 2/40\n",
      "Epoch 0: Total Loss=3.1871\n",
      "Epoch 1: Total Loss=3.1776\n",
      "Epoch 2: Total Loss=3.1703\n",
      "Epoch 3: Total Loss=3.1623\n",
      "Epoch 4: Total Loss=3.1534\n",
      "Epoch 5: Total Loss=3.1480\n",
      "Epoch 6: Total Loss=3.1376\n",
      "Epoch 7: Total Loss=3.1294\n",
      "Epoch 8: Total Loss=3.1198\n",
      "Epoch 9: Total Loss=3.1121\n",
      "Updated x: [0.8656539916992188, -0.6741025447845459], Function Value: 1.2037711143493652, Gradient: [-0.03291081637144089, -0.014611996710300446]\n",
      "\n",
      "Step 3/40\n",
      "Epoch 0: Total Loss=3.1460\n",
      "Epoch 1: Total Loss=3.1362\n",
      "Epoch 2: Total Loss=3.1275\n",
      "Epoch 3: Total Loss=3.1196\n",
      "Epoch 4: Total Loss=3.1088\n",
      "Epoch 5: Total Loss=3.0981\n",
      "Epoch 6: Total Loss=3.0883\n",
      "Epoch 7: Total Loss=3.0788\n",
      "Epoch 8: Total Loss=3.0662\n",
      "Epoch 9: Total Loss=3.0559\n",
      "Updated x: [0.8572551012039185, -0.6695243120193481], Function Value: 1.1831490993499756, Gradient: [-0.02859218418598175, -0.02048664167523384]\n",
      "\n",
      "Step 4/40\n",
      "Epoch 0: Total Loss=3.0440\n",
      "Epoch 1: Total Loss=2.9489\n",
      "Epoch 2: Total Loss=2.8945\n",
      "Epoch 3: Total Loss=3.0082\n",
      "Epoch 4: Total Loss=2.9137\n",
      "Epoch 5: Total Loss=2.8588\n",
      "Epoch 6: Total Loss=2.9695\n",
      "Epoch 7: Total Loss=2.8772\n",
      "Epoch 8: Total Loss=2.8182\n",
      "Epoch 9: Total Loss=2.9285\n",
      "Updated x: [0.8475170731544495, -0.6304576396942139], Function Value: 1.1157619953155518, Gradient: [-0.02103363163769245, -0.02874789759516716]\n",
      "\n",
      "Step 5/40\n",
      "Epoch 0: Total Loss=3.0245\n",
      "Epoch 1: Total Loss=2.0868\n",
      "Epoch 2: Total Loss=2.9939\n",
      "Epoch 3: Total Loss=2.0654\n",
      "Epoch 4: Total Loss=2.9655\n",
      "Epoch 5: Total Loss=2.0373\n",
      "Epoch 6: Total Loss=2.9326\n",
      "Epoch 7: Total Loss=2.0115\n",
      "Epoch 8: Total Loss=2.8966\n",
      "Epoch 9: Total Loss=1.9855\n",
      "Updated x: [0.7853404879570007, -0.5230139493942261], Function Value: 0.8903032541275024, Gradient: [0.0024229418486356735, -0.04102864861488342]\n",
      "\n",
      "Step 6/40\n",
      "Epoch 0: Total Loss=0.2354\n",
      "Epoch 1: Total Loss=0.1988\n",
      "Epoch 2: Total Loss=0.2495\n",
      "Epoch 3: Total Loss=0.2045\n",
      "Epoch 4: Total Loss=0.2188\n",
      "Epoch 5: Total Loss=0.2297\n",
      "Epoch 6: Total Loss=0.1965\n",
      "Epoch 7: Total Loss=0.2473\n",
      "Epoch 8: Total Loss=0.2022\n",
      "Epoch 9: Total Loss=0.2143\n",
      "Updated x: [0.7543744444847107, -0.49022966623306274], Function Value: 0.8094059228897095, Gradient: [0.00039422756526619196, -0.043942686170339584]\n",
      "\n",
      "Step 7/40\n",
      "Epoch 0: Total Loss=0.2098\n",
      "Epoch 1: Total Loss=0.2672\n",
      "Epoch 2: Total Loss=0.2216\n",
      "Epoch 3: Total Loss=0.2088\n",
      "Epoch 4: Total Loss=0.2638\n",
      "Epoch 5: Total Loss=0.2205\n",
      "Epoch 6: Total Loss=0.2077\n",
      "Epoch 7: Total Loss=0.2624\n",
      "Epoch 8: Total Loss=0.2193\n",
      "Epoch 9: Total Loss=0.2076\n",
      "Updated x: [0.6951237320899963, -0.5780153870582581], Function Value: 0.8172987699508667, Gradient: [0.01202803198248148, -0.04129644110798836]\n",
      "\n",
      "Step 8/40\n",
      "Epoch 0: Total Loss=0.2803\n",
      "Epoch 1: Total Loss=0.2055\n",
      "Epoch 2: Total Loss=0.2443\n",
      "Epoch 3: Total Loss=0.2393\n",
      "Epoch 4: Total Loss=0.2249\n",
      "Epoch 5: Total Loss=0.2492\n",
      "Epoch 6: Total Loss=0.1946\n",
      "Epoch 7: Total Loss=0.2801\n",
      "Epoch 8: Total Loss=0.2012\n",
      "Epoch 9: Total Loss=0.2442\n",
      "Updated x: [0.6390337347984314, -0.3796950578689575], Function Value: 0.552532434463501, Gradient: [0.024426229298114777, -0.04797346889972687]\n",
      "\n",
      "Step 9/40\n",
      "Epoch 0: Total Loss=0.2455\n",
      "Epoch 1: Total Loss=0.2156\n",
      "Epoch 2: Total Loss=0.1979\n",
      "Epoch 3: Total Loss=0.2216\n",
      "Epoch 4: Total Loss=0.2437\n",
      "Epoch 5: Total Loss=0.2157\n",
      "Epoch 6: Total Loss=0.1948\n",
      "Epoch 7: Total Loss=0.2178\n",
      "Epoch 8: Total Loss=0.2435\n",
      "Epoch 9: Total Loss=0.2135\n",
      "Updated x: [0.6281071305274963, -0.2603239417076111], Function Value: 0.4622870981693268, Gradient: [0.028384070843458176, -0.050983723253011703]\n",
      "\n",
      "Step 10/40\n",
      "Epoch 0: Total Loss=0.1995\n",
      "Epoch 1: Total Loss=0.2597\n",
      "Epoch 2: Total Loss=0.1535\n",
      "Epoch 3: Total Loss=0.1830\n",
      "Epoch 4: Total Loss=0.1837\n",
      "Epoch 5: Total Loss=0.2253\n",
      "Epoch 6: Total Loss=0.2058\n",
      "Epoch 7: Total Loss=0.1863\n",
      "Epoch 8: Total Loss=0.1538\n",
      "Epoch 9: Total Loss=0.1984\n",
      "Updated x: [0.6337435841560364, -0.33297374844551086], Function Value: 0.5125024318695068, Gradient: [0.02635326236486435, -0.04732806235551834]\n",
      "\n",
      "Step 11/40\n",
      "Epoch 0: Total Loss=0.1389\n",
      "Epoch 1: Total Loss=0.1678\n",
      "Epoch 2: Total Loss=0.2017\n",
      "Epoch 3: Total Loss=0.2780\n",
      "Epoch 4: Total Loss=0.1771\n",
      "Epoch 5: Total Loss=0.1377\n",
      "Epoch 6: Total Loss=0.1667\n",
      "Epoch 7: Total Loss=0.2015\n",
      "Epoch 8: Total Loss=0.2799\n",
      "Epoch 9: Total Loss=0.1776\n",
      "Updated x: [0.512885570526123, -0.2939082980155945], Function Value: 0.34943369030952454, Gradient: [0.03339363634586334, -0.04310411587357521]\n",
      "\n",
      "Step 12/40\n",
      "Epoch 0: Total Loss=0.3359\n",
      "Epoch 1: Total Loss=0.3344\n",
      "Epoch 2: Total Loss=0.3318\n",
      "Epoch 3: Total Loss=0.3301\n",
      "Epoch 4: Total Loss=0.3266\n",
      "Epoch 5: Total Loss=0.3240\n",
      "Epoch 6: Total Loss=0.3196\n",
      "Epoch 7: Total Loss=0.3185\n",
      "Epoch 8: Total Loss=0.3133\n",
      "Epoch 9: Total Loss=0.3114\n",
      "Updated x: [0.4855268597602844, -0.3087015748023987], Function Value: 0.33103299140930176, Gradient: [0.06426240503787994, -0.05914193391799927]\n",
      "\n",
      "Step 13/40\n",
      "Epoch 0: Total Loss=0.2461\n",
      "Epoch 1: Total Loss=0.2431\n",
      "Epoch 2: Total Loss=0.2417\n",
      "Epoch 3: Total Loss=0.2401\n",
      "Epoch 4: Total Loss=0.2378\n",
      "Epoch 5: Total Loss=0.2355\n",
      "Epoch 6: Total Loss=0.2325\n",
      "Epoch 7: Total Loss=0.2308\n",
      "Epoch 8: Total Loss=0.2291\n",
      "Epoch 9: Total Loss=0.2274\n",
      "Updated x: [0.39958325028419495, -0.217854842543602], Function Value: 0.20712751150131226, Gradient: [0.10394071787595749, -0.07730887830257416]\n",
      "\n",
      "Step 14/40\n",
      "Epoch 0: Total Loss=0.2030\n",
      "Epoch 1: Total Loss=0.1510\n",
      "Epoch 2: Total Loss=0.2250\n",
      "Epoch 3: Total Loss=0.1964\n",
      "Epoch 4: Total Loss=0.1481\n",
      "Epoch 5: Total Loss=0.2206\n",
      "Epoch 6: Total Loss=0.1935\n",
      "Epoch 7: Total Loss=0.1468\n",
      "Epoch 8: Total Loss=0.2139\n",
      "Epoch 9: Total Loss=0.1884\n",
      "Updated x: [0.36902251839637756, -0.29199737310409546], Function Value: 0.22144007682800293, Gradient: [0.15137484669685364, -0.09783592075109482]\n",
      "\n",
      "Step 15/40\n",
      "Epoch 0: Total Loss=0.2163\n",
      "Epoch 1: Total Loss=0.1588\n",
      "Epoch 2: Total Loss=0.2106\n",
      "Epoch 3: Total Loss=0.1580\n",
      "Epoch 4: Total Loss=0.2084\n",
      "Epoch 5: Total Loss=0.1569\n",
      "Epoch 6: Total Loss=0.2041\n",
      "Epoch 7: Total Loss=0.1554\n",
      "Epoch 8: Total Loss=0.2014\n",
      "Epoch 9: Total Loss=0.1563\n",
      "Updated x: [0.4664413630962372, -0.23597444593906403], Function Value: 0.273251473903656, Gradient: [0.1930101066827774, -0.12512211501598358]\n",
      "\n",
      "Step 16/40\n",
      "Epoch 0: Total Loss=0.1098\n",
      "Epoch 1: Total Loss=0.1178\n",
      "Epoch 2: Total Loss=0.1062\n",
      "Epoch 3: Total Loss=0.1138\n",
      "Epoch 4: Total Loss=0.1031\n",
      "Epoch 5: Total Loss=0.1001\n",
      "Epoch 6: Total Loss=0.1086\n",
      "Epoch 7: Total Loss=0.0973\n",
      "Epoch 8: Total Loss=0.1052\n",
      "Epoch 9: Total Loss=0.0981\n",
      "Updated x: [0.47899678349494934, -0.11756759881973267], Function Value: 0.24326005578041077, Gradient: [0.13072188198566437, -0.0955883115530014]\n",
      "\n",
      "Step 17/40\n",
      "Epoch 0: Total Loss=0.0946\n",
      "Epoch 1: Total Loss=0.0932\n",
      "Epoch 2: Total Loss=0.1016\n",
      "Epoch 3: Total Loss=0.0913\n",
      "Epoch 4: Total Loss=0.0908\n",
      "Epoch 5: Total Loss=0.0995\n",
      "Epoch 6: Total Loss=0.0893\n",
      "Epoch 7: Total Loss=0.0901\n",
      "Epoch 8: Total Loss=0.0976\n",
      "Epoch 9: Total Loss=0.0873\n",
      "Updated x: [0.44497743248939514, -0.047099143266677856], Function Value: 0.20022325217723846, Gradient: [0.08373067528009415, -0.06770868599414825]\n",
      "\n",
      "Step 18/40\n",
      "Epoch 0: Total Loss=0.0908\n",
      "Epoch 1: Total Loss=0.0809\n",
      "Epoch 2: Total Loss=0.0852\n",
      "Epoch 3: Total Loss=0.1009\n",
      "Epoch 4: Total Loss=0.0828\n",
      "Epoch 5: Total Loss=0.0794\n",
      "Epoch 6: Total Loss=0.0947\n",
      "Epoch 7: Total Loss=0.0893\n",
      "Epoch 8: Total Loss=0.0797\n",
      "Epoch 9: Total Loss=0.0825\n",
      "Updated x: [0.39896994829177856, 0.002859998494386673], Function Value: 0.15918520092964172, Gradient: [0.04866731911897659, -0.04610712081193924]\n",
      "\n",
      "Step 19/40\n",
      "Epoch 0: Total Loss=0.0799\n",
      "Epoch 1: Total Loss=0.0815\n",
      "Epoch 2: Total Loss=0.0834\n",
      "Epoch 3: Total Loss=0.0998\n",
      "Epoch 4: Total Loss=0.0814\n",
      "Epoch 5: Total Loss=0.0810\n",
      "Epoch 6: Total Loss=0.0831\n",
      "Epoch 7: Total Loss=0.1008\n",
      "Epoch 8: Total Loss=0.0801\n",
      "Epoch 9: Total Loss=0.0803\n",
      "Updated x: [0.36299675703048706, 0.06719167530536652], Function Value: 0.13628137111663818, Gradient: [0.03097034990787506, -0.032139040529727936]\n",
      "\n",
      "Step 20/40\n",
      "Epoch 0: Total Loss=0.0802\n",
      "Epoch 1: Total Loss=0.0965\n",
      "Epoch 2: Total Loss=0.0855\n",
      "Epoch 3: Total Loss=0.0786\n",
      "Epoch 4: Total Loss=0.0814\n",
      "Epoch 5: Total Loss=0.0833\n",
      "Epoch 6: Total Loss=0.0955\n",
      "Epoch 7: Total Loss=0.0808\n",
      "Epoch 8: Total Loss=0.0817\n",
      "Epoch 9: Total Loss=0.0817\n",
      "Updated x: [0.3659530282020569, 0.1990136206150055], Function Value: 0.1735280454158783, Gradient: [0.022118953987956047, -0.02017262578010559]\n",
      "\n",
      "Step 21/40\n",
      "Epoch 0: Total Loss=0.0771\n",
      "Epoch 1: Total Loss=0.0967\n",
      "Epoch 2: Total Loss=0.0797\n",
      "Epoch 3: Total Loss=0.0840\n",
      "Epoch 4: Total Loss=0.0802\n",
      "Epoch 5: Total Loss=0.0752\n",
      "Epoch 6: Total Loss=0.0982\n",
      "Epoch 7: Total Loss=0.0802\n",
      "Epoch 8: Total Loss=0.0837\n",
      "Epoch 9: Total Loss=0.0801\n",
      "Updated x: [0.41189882159233093, 0.1375707983970642], Function Value: 0.18858636915683746, Gradient: [0.03183489292860031, -0.017485281452536583]\n",
      "\n",
      "Step 22/40\n",
      "Epoch 0: Total Loss=0.1244\n",
      "Epoch 1: Total Loss=0.1243\n",
      "Epoch 2: Total Loss=0.1228\n",
      "Epoch 3: Total Loss=0.1225\n",
      "Epoch 4: Total Loss=0.1221\n",
      "Epoch 5: Total Loss=0.1202\n",
      "Epoch 6: Total Loss=0.1205\n",
      "Epoch 7: Total Loss=0.1198\n",
      "Epoch 8: Total Loss=0.1189\n",
      "Epoch 9: Total Loss=0.1181\n",
      "Updated x: [0.29684334993362427, 0.2427864670753479], Function Value: 0.14706124365329742, Gradient: [0.05815025791525841, -0.00496226642280817]\n",
      "\n",
      "Step 23/40\n",
      "Epoch 0: Total Loss=0.1268\n",
      "Epoch 1: Total Loss=0.1270\n",
      "Epoch 2: Total Loss=0.1269\n",
      "Epoch 3: Total Loss=0.1243\n",
      "Epoch 4: Total Loss=0.1247\n",
      "Epoch 5: Total Loss=0.1244\n",
      "Epoch 6: Total Loss=0.1238\n",
      "Epoch 7: Total Loss=0.1233\n",
      "Epoch 8: Total Loss=0.1234\n",
      "Epoch 9: Total Loss=0.1231\n",
      "Updated x: [0.28310060501098633, 0.28241291642189026], Function Value: 0.15990301966667175, Gradient: [0.09122876077890396, 0.013701336458325386]\n",
      "\n",
      "Step 24/40\n",
      "Epoch 0: Total Loss=0.1446\n",
      "Epoch 1: Total Loss=0.1558\n",
      "Epoch 2: Total Loss=0.1264\n",
      "Epoch 3: Total Loss=0.1422\n",
      "Epoch 4: Total Loss=0.1533\n",
      "Epoch 5: Total Loss=0.1244\n",
      "Epoch 6: Total Loss=0.1406\n",
      "Epoch 7: Total Loss=0.1508\n",
      "Epoch 8: Total Loss=0.1242\n",
      "Epoch 9: Total Loss=0.1400\n",
      "Updated x: [0.11386807262897491, 0.3935920000076294], Function Value: 0.1678805947303772, Gradient: [0.09660929441452026, 0.05336395651102066]\n",
      "\n",
      "Step 25/40\n",
      "Epoch 0: Total Loss=0.1231\n",
      "Epoch 1: Total Loss=0.1854\n",
      "Epoch 2: Total Loss=0.1229\n",
      "Epoch 3: Total Loss=0.1844\n",
      "Epoch 4: Total Loss=0.1234\n",
      "Epoch 5: Total Loss=0.1831\n",
      "Epoch 6: Total Loss=0.1218\n",
      "Epoch 7: Total Loss=0.1814\n",
      "Epoch 8: Total Loss=0.1214\n",
      "Epoch 9: Total Loss=0.1799\n",
      "Updated x: [0.13625264167785645, 0.46270743012428284], Function Value: 0.23266294598579407, Gradient: [0.1089065745472908, 0.09118170291185379]\n",
      "\n",
      "Step 26/40\n",
      "Epoch 0: Total Loss=0.0971\n",
      "Epoch 1: Total Loss=0.0968\n",
      "Epoch 2: Total Loss=0.0913\n",
      "Epoch 3: Total Loss=0.0989\n",
      "Epoch 4: Total Loss=0.0838\n",
      "Epoch 5: Total Loss=0.0914\n",
      "Epoch 6: Total Loss=0.0923\n",
      "Epoch 7: Total Loss=0.0862\n",
      "Epoch 8: Total Loss=0.0948\n",
      "Epoch 9: Total Loss=0.0803\n",
      "Updated x: [0.1565651297569275, 0.405254065990448], Function Value: 0.1887434870004654, Gradient: [0.0707792341709137, 0.051067523658275604]\n",
      "\n",
      "Step 27/40\n",
      "Epoch 0: Total Loss=0.0851\n",
      "Epoch 1: Total Loss=0.0965\n",
      "Epoch 2: Total Loss=0.0938\n",
      "Epoch 3: Total Loss=0.0840\n",
      "Epoch 4: Total Loss=0.0947\n",
      "Epoch 5: Total Loss=0.0931\n",
      "Epoch 6: Total Loss=0.0828\n",
      "Epoch 7: Total Loss=0.0938\n",
      "Epoch 8: Total Loss=0.0925\n",
      "Epoch 9: Total Loss=0.0819\n",
      "Updated x: [0.11278504133224487, 0.4483386278152466], Function Value: 0.21372799575328827, Gradient: [0.03635760396718979, 0.04315805807709694]\n",
      "\n",
      "Step 28/40\n",
      "Epoch 0: Total Loss=0.0875\n",
      "Epoch 1: Total Loss=0.0840\n",
      "Epoch 2: Total Loss=0.0786\n",
      "Epoch 3: Total Loss=0.0995\n",
      "Epoch 4: Total Loss=0.0844\n",
      "Epoch 5: Total Loss=0.0793\n",
      "Epoch 6: Total Loss=0.0940\n",
      "Epoch 7: Total Loss=0.0862\n",
      "Epoch 8: Total Loss=0.0845\n",
      "Epoch 9: Total Loss=0.0795\n",
      "Updated x: [0.09098929166793823, 0.36655744910240173], Function Value: 0.14264342188835144, Gradient: [0.028167976066470146, 0.023563280701637268]\n",
      "\n",
      "Step 29/40\n",
      "Epoch 0: Total Loss=0.0713\n",
      "Epoch 1: Total Loss=0.0836\n",
      "Epoch 2: Total Loss=0.0789\n",
      "Epoch 3: Total Loss=0.0881\n",
      "Epoch 4: Total Loss=0.0714\n",
      "Epoch 5: Total Loss=0.0834\n",
      "Epoch 6: Total Loss=0.0797\n",
      "Epoch 7: Total Loss=0.0872\n",
      "Epoch 8: Total Loss=0.0714\n",
      "Epoch 9: Total Loss=0.0837\n",
      "Updated x: [0.22153086960315704, 0.35611382126808167], Function Value: 0.17589297890663147, Gradient: [0.03180021420121193, 0.02332371659576893]\n",
      "\n",
      "Step 30/40\n",
      "Epoch 0: Total Loss=0.0858\n",
      "Epoch 1: Total Loss=0.0768\n",
      "Epoch 2: Total Loss=0.0794\n",
      "Epoch 3: Total Loss=0.0753\n",
      "Epoch 4: Total Loss=0.0710\n",
      "Epoch 5: Total Loss=0.0899\n",
      "Epoch 6: Total Loss=0.0769\n",
      "Epoch 7: Total Loss=0.0721\n",
      "Epoch 8: Total Loss=0.0764\n",
      "Epoch 9: Total Loss=0.0840\n",
      "Updated x: [0.18890896439552307, 0.4640403389930725], Function Value: 0.25102001428604126, Gradient: [0.021930191665887833, 0.03356057405471802]\n",
      "\n",
      "Step 31/40\n",
      "Epoch 0: Total Loss=0.0717\n",
      "Epoch 1: Total Loss=0.0758\n",
      "Epoch 2: Total Loss=0.0721\n",
      "Epoch 3: Total Loss=0.0831\n",
      "Epoch 4: Total Loss=0.0761\n",
      "Epoch 5: Total Loss=0.0721\n",
      "Epoch 6: Total Loss=0.0759\n",
      "Epoch 7: Total Loss=0.0724\n",
      "Epoch 8: Total Loss=0.0842\n",
      "Epoch 9: Total Loss=0.0768\n",
      "Updated x: [0.2335340976715088, 0.5033466219902039], Function Value: 0.3078960180282593, Gradient: [0.020893750712275505, 0.03713209182024002]\n",
      "\n",
      "Step 32/40\n",
      "Epoch 0: Total Loss=0.2500\n",
      "Epoch 1: Total Loss=0.2483\n",
      "Epoch 2: Total Loss=0.2464\n",
      "Epoch 3: Total Loss=0.2435\n",
      "Epoch 4: Total Loss=0.2423\n",
      "Epoch 5: Total Loss=0.2396\n",
      "Epoch 6: Total Loss=0.2378\n",
      "Epoch 7: Total Loss=0.2361\n",
      "Epoch 8: Total Loss=0.2332\n",
      "Epoch 9: Total Loss=0.2324\n",
      "Updated x: [0.07170052826404572, 0.42737704515457153], Function Value: 0.1877920925617218, Gradient: [0.037988606840372086, 0.07250736653804779]\n",
      "\n",
      "Step 33/40\n",
      "Epoch 0: Total Loss=0.1773\n",
      "Epoch 1: Total Loss=0.1760\n",
      "Epoch 2: Total Loss=0.1741\n",
      "Epoch 3: Total Loss=0.1737\n",
      "Epoch 4: Total Loss=0.1722\n",
      "Epoch 5: Total Loss=0.1712\n",
      "Epoch 6: Total Loss=0.1698\n",
      "Epoch 7: Total Loss=0.1685\n",
      "Epoch 8: Total Loss=0.1675\n",
      "Epoch 9: Total Loss=0.1661\n",
      "Updated x: [0.12336772680282593, 0.40525132417678833], Function Value: 0.1794482320547104, Gradient: [0.05948732793331146, 0.11680841445922852]\n",
      "\n",
      "Step 34/40\n",
      "Epoch 0: Total Loss=0.1724\n",
      "Epoch 1: Total Loss=0.1621\n",
      "Epoch 2: Total Loss=0.1149\n",
      "Epoch 3: Total Loss=0.1698\n",
      "Epoch 4: Total Loss=0.1588\n",
      "Epoch 5: Total Loss=0.1144\n",
      "Epoch 6: Total Loss=0.1663\n",
      "Epoch 7: Total Loss=0.1577\n",
      "Epoch 8: Total Loss=0.1136\n",
      "Epoch 9: Total Loss=0.1647\n",
      "Updated x: [0.19323521852493286, 0.3720409870147705], Function Value: 0.1757543534040451, Gradient: [0.07367401570081711, 0.15658727288246155]\n",
      "\n",
      "Step 35/40\n",
      "Epoch 0: Total Loss=0.1007\n",
      "Epoch 1: Total Loss=0.1706\n",
      "Epoch 2: Total Loss=0.1000\n",
      "Epoch 3: Total Loss=0.1699\n",
      "Epoch 4: Total Loss=0.0998\n",
      "Epoch 5: Total Loss=0.1684\n",
      "Epoch 6: Total Loss=0.0999\n",
      "Epoch 7: Total Loss=0.1667\n",
      "Epoch 8: Total Loss=0.0995\n",
      "Epoch 9: Total Loss=0.1659\n",
      "Updated x: [0.11087463796138763, 0.2970786988735199], Function Value: 0.10054893791675568, Gradient: [0.07300462573766708, 0.16380208730697632]\n",
      "\n",
      "Step 36/40\n",
      "Epoch 0: Total Loss=0.1154\n",
      "Epoch 1: Total Loss=0.0887\n",
      "Epoch 2: Total Loss=0.0939\n",
      "Epoch 3: Total Loss=0.1051\n",
      "Epoch 4: Total Loss=0.0840\n",
      "Epoch 5: Total Loss=0.1087\n",
      "Epoch 6: Total Loss=0.0829\n",
      "Epoch 7: Total Loss=0.0889\n",
      "Epoch 8: Total Loss=0.1007\n",
      "Epoch 9: Total Loss=0.0809\n",
      "Updated x: [0.3376578390598297, 0.17990191280841827], Function Value: 0.14637751877307892, Gradient: [0.060194578021764755, 0.07439811527729034]\n",
      "\n",
      "Step 37/40\n",
      "Epoch 0: Total Loss=0.0827\n",
      "Epoch 1: Total Loss=0.1216\n",
      "Epoch 2: Total Loss=0.0813\n",
      "Epoch 3: Total Loss=0.0820\n",
      "Epoch 4: Total Loss=0.1196\n",
      "Epoch 5: Total Loss=0.0804\n",
      "Epoch 6: Total Loss=0.0809\n",
      "Epoch 7: Total Loss=0.1184\n",
      "Epoch 8: Total Loss=0.0799\n",
      "Epoch 9: Total Loss=0.0817\n",
      "Updated x: [0.3992117941379547, 0.2443263828754425], Function Value: 0.21906542778015137, Gradient: [0.04607382416725159, 0.04943236708641052]\n",
      "\n",
      "Step 38/40\n",
      "Epoch 0: Total Loss=0.0989\n",
      "Epoch 1: Total Loss=0.0798\n",
      "Epoch 2: Total Loss=0.0908\n",
      "Epoch 3: Total Loss=0.0784\n",
      "Epoch 4: Total Loss=0.0989\n",
      "Epoch 5: Total Loss=0.0924\n",
      "Epoch 6: Total Loss=0.0762\n",
      "Epoch 7: Total Loss=0.0990\n",
      "Epoch 8: Total Loss=0.0797\n",
      "Epoch 9: Total Loss=0.0915\n",
      "Updated x: [0.15247562527656555, 0.3019258379936218], Function Value: 0.11440802365541458, Gradient: [0.044498197734355927, 0.051463667303323746]\n",
      "\n",
      "Step 39/40\n",
      "Epoch 0: Total Loss=0.0769\n",
      "Epoch 1: Total Loss=0.0987\n",
      "Epoch 2: Total Loss=0.0784\n",
      "Epoch 3: Total Loss=0.0901\n",
      "Epoch 4: Total Loss=0.0769\n",
      "Epoch 5: Total Loss=0.0976\n",
      "Epoch 6: Total Loss=0.0792\n",
      "Epoch 7: Total Loss=0.0905\n",
      "Epoch 8: Total Loss=0.0775\n",
      "Epoch 9: Total Loss=0.0981\n",
      "Updated x: [0.22064727544784546, 0.1462625414133072], Function Value: 0.07007794827222824, Gradient: [0.03486538678407669, 0.02433851547539234]\n",
      "\n",
      "Step 40/40\n",
      "Epoch 0: Total Loss=0.0778\n",
      "Epoch 1: Total Loss=0.0944\n",
      "Epoch 2: Total Loss=0.0760\n",
      "Epoch 3: Total Loss=0.0932\n",
      "Epoch 4: Total Loss=0.0769\n",
      "Epoch 5: Total Loss=0.0781\n",
      "Epoch 6: Total Loss=0.0903\n",
      "Epoch 7: Total Loss=0.0788\n",
      "Epoch 8: Total Loss=0.0904\n",
      "Epoch 9: Total Loss=0.0777\n",
      "Updated x: [0.18870598077774048, 0.1058388352394104], Function Value: 0.04681180417537689, Gradient: [0.03512132540345192, 0.02262219600379467]\n",
      "\n",
      "Step 1/40\n",
      "Epoch 0: Total Loss=1.6746\n",
      "Epoch 1: Total Loss=0.0799\n",
      "Epoch 2: Total Loss=0.0785\n",
      "Epoch 3: Total Loss=1.2173\n",
      "Epoch 4: Total Loss=0.0981\n",
      "Epoch 5: Total Loss=1.6302\n",
      "Epoch 6: Total Loss=0.0784\n",
      "Epoch 7: Total Loss=0.0768\n",
      "Epoch 8: Total Loss=1.1924\n",
      "Epoch 9: Total Loss=0.0983\n",
      "Updated x: [0.713714599609375, -1.0970234870910645], Function Value: 1.7128491401672363, Gradient: [-0.017639635130763054, -0.013844233937561512]\n",
      "\n",
      "Step 2/40\n",
      "Epoch 0: Total Loss=4.5515\n",
      "Epoch 1: Total Loss=4.4535\n",
      "Epoch 2: Total Loss=4.3574\n",
      "Epoch 3: Total Loss=4.2608\n",
      "Epoch 4: Total Loss=4.1639\n",
      "Epoch 5: Total Loss=4.0655\n",
      "Epoch 6: Total Loss=3.9639\n",
      "Epoch 7: Total Loss=3.8597\n",
      "Epoch 8: Total Loss=3.7508\n",
      "Epoch 9: Total Loss=3.6364\n",
      "Updated x: [0.4495764374732971, -1.0455228090286255], Function Value: 1.2952369451522827, Gradient: [-0.029982274398207664, -0.23732906579971313]\n",
      "\n",
      "Step 3/40\n",
      "Epoch 0: Total Loss=2.4931\n",
      "Epoch 1: Total Loss=2.4100\n",
      "Epoch 2: Total Loss=2.3248\n",
      "Epoch 3: Total Loss=2.2385\n",
      "Epoch 4: Total Loss=2.1486\n",
      "Epoch 5: Total Loss=2.0563\n",
      "Epoch 6: Total Loss=1.9637\n",
      "Epoch 7: Total Loss=1.8690\n",
      "Epoch 8: Total Loss=1.7746\n",
      "Epoch 9: Total Loss=1.6790\n",
      "Updated x: [0.41408053040504456, -0.8707842230796814], Function Value: 0.9297277927398682, Gradient: [0.032845478504896164, -0.545709490776062]\n",
      "\n",
      "Step 4/40\n",
      "Epoch 0: Total Loss=1.1437\n",
      "Epoch 1: Total Loss=1.4549\n",
      "Epoch 2: Total Loss=1.3704\n",
      "Epoch 3: Total Loss=0.9437\n",
      "Epoch 4: Total Loss=1.2119\n",
      "Epoch 5: Total Loss=1.1481\n",
      "Epoch 6: Total Loss=0.7888\n",
      "Epoch 7: Total Loss=1.0222\n",
      "Epoch 8: Total Loss=0.9894\n",
      "Epoch 9: Total Loss=0.7022\n",
      "Updated x: [0.3790844678878784, -0.9042426943778992], Function Value: 0.9613598585128784, Gradient: [0.11678044497966766, -1.0895191431045532]\n",
      "\n",
      "Step 5/40\n",
      "Epoch 0: Total Loss=0.9797\n",
      "Epoch 1: Total Loss=0.5991\n",
      "Epoch 2: Total Loss=0.9407\n",
      "Epoch 3: Total Loss=0.5708\n",
      "Epoch 4: Total Loss=0.9079\n",
      "Epoch 5: Total Loss=0.5404\n",
      "Epoch 6: Total Loss=0.8790\n",
      "Epoch 7: Total Loss=0.5112\n",
      "Epoch 8: Total Loss=0.8531\n",
      "Epoch 9: Total Loss=0.4862\n",
      "Updated x: [0.33219414949417114, -0.8227437734603882], Function Value: 0.7872602343559265, Gradient: [0.14928007125854492, -1.2164896726608276]\n",
      "\n",
      "Step 6/40\n",
      "Epoch 0: Total Loss=0.6004\n",
      "Epoch 1: Total Loss=0.4077\n",
      "Epoch 2: Total Loss=0.4120\n",
      "Epoch 3: Total Loss=0.4719\n",
      "Epoch 4: Total Loss=0.3261\n",
      "Epoch 5: Total Loss=0.4609\n",
      "Epoch 6: Total Loss=0.2879\n",
      "Epoch 7: Total Loss=0.3068\n",
      "Epoch 8: Total Loss=0.4097\n",
      "Epoch 9: Total Loss=0.2581\n",
      "Updated x: [0.21622425317764282, -0.8606842160224915], Function Value: 0.787530243396759, Gradient: [0.1405627727508545, -0.673355758190155]\n",
      "\n",
      "Step 7/40\n",
      "Epoch 0: Total Loss=0.3080\n",
      "Epoch 1: Total Loss=0.3762\n",
      "Epoch 2: Total Loss=0.1697\n",
      "Epoch 3: Total Loss=0.2805\n",
      "Epoch 4: Total Loss=0.3648\n",
      "Epoch 5: Total Loss=0.1579\n",
      "Epoch 6: Total Loss=0.2691\n",
      "Epoch 7: Total Loss=0.3614\n",
      "Epoch 8: Total Loss=0.1535\n",
      "Epoch 9: Total Loss=0.2647\n",
      "Updated x: [0.3201281428337097, -0.7799918055534363], Function Value: 0.7108692526817322, Gradient: [0.08194973319768906, -0.411532461643219]\n",
      "\n",
      "Step 8/40\n",
      "Epoch 0: Total Loss=0.3925\n",
      "Epoch 1: Total Loss=0.1622\n",
      "Epoch 2: Total Loss=0.2656\n",
      "Epoch 3: Total Loss=0.3899\n",
      "Epoch 4: Total Loss=0.1273\n",
      "Epoch 5: Total Loss=0.1595\n",
      "Epoch 6: Total Loss=0.2622\n",
      "Epoch 7: Total Loss=0.3890\n",
      "Epoch 8: Total Loss=0.1582\n",
      "Epoch 9: Total Loss=0.2596\n",
      "Updated x: [0.29194462299346924, -0.6189426779747009], Function Value: 0.46832171082496643, Gradient: [0.05671550706028938, -0.26771456003189087]\n",
      "\n",
      "Step 9/40\n",
      "Epoch 0: Total Loss=0.4091\n",
      "Epoch 1: Total Loss=0.1261\n",
      "Epoch 2: Total Loss=0.1897\n",
      "Epoch 3: Total Loss=0.1757\n",
      "Epoch 4: Total Loss=0.4082\n",
      "Epoch 5: Total Loss=0.1251\n",
      "Epoch 6: Total Loss=0.1873\n",
      "Epoch 7: Total Loss=0.1751\n",
      "Epoch 8: Total Loss=0.4061\n",
      "Epoch 9: Total Loss=0.1242\n",
      "Updated x: [0.24238935112953186, -0.7057712078094482], Function Value: 0.5568655729293823, Gradient: [0.07154673337936401, -0.3271964490413666]\n",
      "\n",
      "Step 10/40\n",
      "Epoch 0: Total Loss=0.1454\n",
      "Epoch 1: Total Loss=0.3849\n",
      "Epoch 2: Total Loss=0.1470\n",
      "Epoch 3: Total Loss=0.1618\n",
      "Epoch 4: Total Loss=0.1291\n",
      "Epoch 5: Total Loss=0.1382\n",
      "Epoch 6: Total Loss=0.3715\n",
      "Epoch 7: Total Loss=0.1918\n",
      "Epoch 8: Total Loss=0.1216\n",
      "Epoch 9: Total Loss=0.1387\n",
      "Updated x: [0.11663143336772919, -0.7085157036781311], Function Value: 0.515597403049469, Gradient: [0.021159695461392403, -0.4276997148990631]\n",
      "\n",
      "Step 11/40\n",
      "Epoch 0: Total Loss=0.1385\n",
      "Epoch 1: Total Loss=0.1888\n",
      "Epoch 2: Total Loss=0.2271\n",
      "Epoch 3: Total Loss=0.4395\n",
      "Epoch 4: Total Loss=0.0965\n",
      "Epoch 5: Total Loss=0.1387\n",
      "Epoch 6: Total Loss=0.1832\n",
      "Epoch 7: Total Loss=0.2256\n",
      "Epoch 8: Total Loss=0.4310\n",
      "Epoch 9: Total Loss=0.0953\n",
      "Updated x: [0.146485835313797, -0.4049031734466553], Function Value: 0.1854046881198883, Gradient: [0.010119136422872543, -0.10374049097299576]\n",
      "\n",
      "Step 12/40\n",
      "Epoch 0: Total Loss=0.1265\n",
      "Epoch 1: Total Loss=0.1225\n",
      "Epoch 2: Total Loss=0.1194\n",
      "Epoch 3: Total Loss=0.1177\n",
      "Epoch 4: Total Loss=0.1165\n",
      "Epoch 5: Total Loss=0.1154\n",
      "Epoch 6: Total Loss=0.1143\n",
      "Epoch 7: Total Loss=0.1133\n",
      "Epoch 8: Total Loss=0.1121\n",
      "Epoch 9: Total Loss=0.1112\n",
      "Updated x: [0.12033671885728836, -0.3325858414173126], Function Value: 0.12509426474571228, Gradient: [0.05603570491075516, -0.12469732761383057]\n",
      "\n",
      "Step 13/40\n",
      "Epoch 0: Total Loss=0.1062\n",
      "Epoch 1: Total Loss=0.1052\n",
      "Epoch 2: Total Loss=0.1041\n",
      "Epoch 3: Total Loss=0.1036\n",
      "Epoch 4: Total Loss=0.1028\n",
      "Epoch 5: Total Loss=0.1021\n",
      "Epoch 6: Total Loss=0.1016\n",
      "Epoch 7: Total Loss=0.1009\n",
      "Epoch 8: Total Loss=0.1005\n",
      "Epoch 9: Total Loss=0.1000\n",
      "Updated x: [0.14028987288475037, -0.3838096261024475], Function Value: 0.16699106991291046, Gradient: [0.0458117313683033, -0.1557573676109314]\n",
      "\n",
      "Step 14/40\n",
      "Epoch 0: Total Loss=0.0984\n",
      "Epoch 1: Total Loss=0.1063\n",
      "Epoch 2: Total Loss=0.1145\n",
      "Epoch 3: Total Loss=0.0965\n",
      "Epoch 4: Total Loss=0.1044\n",
      "Epoch 5: Total Loss=0.1122\n",
      "Epoch 6: Total Loss=0.0956\n",
      "Epoch 7: Total Loss=0.1023\n",
      "Epoch 8: Total Loss=0.1104\n",
      "Epoch 9: Total Loss=0.0944\n",
      "Updated x: [0.08001740276813507, -0.37351807951927185], Function Value: 0.14591854810714722, Gradient: [0.02050059288740158, -0.21226292848587036]\n",
      "\n",
      "Step 15/40\n",
      "Epoch 0: Total Loss=0.0996\n",
      "Epoch 1: Total Loss=0.0949\n",
      "Epoch 2: Total Loss=0.0983\n",
      "Epoch 3: Total Loss=0.0937\n",
      "Epoch 4: Total Loss=0.0976\n",
      "Epoch 5: Total Loss=0.0929\n",
      "Epoch 6: Total Loss=0.0968\n",
      "Epoch 7: Total Loss=0.0920\n",
      "Epoch 8: Total Loss=0.0958\n",
      "Epoch 9: Total Loss=0.0912\n",
      "Updated x: [0.059834074229002, -0.3396989107131958], Function Value: 0.11897546797990799, Gradient: [0.016676556318998337, -0.22051963210105896]\n",
      "\n",
      "Step 16/40\n",
      "Epoch 0: Total Loss=0.0742\n",
      "Epoch 1: Total Loss=0.0686\n",
      "Epoch 2: Total Loss=0.0797\n",
      "Epoch 3: Total Loss=0.0680\n",
      "Epoch 4: Total Loss=0.0774\n",
      "Epoch 5: Total Loss=0.0688\n",
      "Epoch 6: Total Loss=0.0651\n",
      "Epoch 7: Total Loss=0.0775\n",
      "Epoch 8: Total Loss=0.0662\n",
      "Epoch 9: Total Loss=0.0759\n",
      "Updated x: [0.02721506729722023, -0.27465584874153137], Function Value: 0.07617649435997009, Gradient: [0.05091346427798271, -0.07205705344676971]\n",
      "\n",
      "Step 17/40\n",
      "Epoch 0: Total Loss=0.0685\n",
      "Epoch 1: Total Loss=0.0719\n",
      "Epoch 2: Total Loss=0.0649\n",
      "Epoch 3: Total Loss=0.0681\n",
      "Epoch 4: Total Loss=0.0716\n",
      "Epoch 5: Total Loss=0.0647\n",
      "Epoch 6: Total Loss=0.0679\n",
      "Epoch 7: Total Loss=0.0712\n",
      "Epoch 8: Total Loss=0.0644\n",
      "Epoch 9: Total Loss=0.0677\n",
      "Updated x: [-0.02687474712729454, -0.24661147594451904], Function Value: 0.06153947114944458, Gradient: [0.05687575414776802, -0.052796706557273865]\n",
      "\n",
      "Step 18/40\n",
      "Epoch 0: Total Loss=0.0620\n",
      "Epoch 1: Total Loss=0.0648\n",
      "Epoch 2: Total Loss=0.0647\n",
      "Epoch 3: Total Loss=0.0719\n",
      "Epoch 4: Total Loss=0.0641\n",
      "Epoch 5: Total Loss=0.0612\n",
      "Epoch 6: Total Loss=0.0747\n",
      "Epoch 7: Total Loss=0.0615\n",
      "Epoch 8: Total Loss=0.0644\n",
      "Epoch 9: Total Loss=0.0646\n",
      "Updated x: [-0.07072864472866058, -0.06383764743804932], Function Value: 0.009077785536646843, Gradient: [0.0469842292368412, -0.025855151936411858]\n",
      "\n",
      "Step 19/40\n",
      "Epoch 0: Total Loss=0.0646\n",
      "Epoch 1: Total Loss=0.0654\n",
      "Epoch 2: Total Loss=0.0596\n",
      "Epoch 3: Total Loss=0.0741\n",
      "Epoch 4: Total Loss=0.0644\n",
      "Epoch 5: Total Loss=0.0656\n",
      "Epoch 6: Total Loss=0.0595\n",
      "Epoch 7: Total Loss=0.0738\n",
      "Epoch 8: Total Loss=0.0646\n",
      "Epoch 9: Total Loss=0.0653\n",
      "Updated x: [-0.07061371952295303, 0.013068519532680511], Function Value: 0.005157083738595247, Gradient: [0.04772542044520378, -0.012794415466487408]\n",
      "\n",
      "Step 20/40\n",
      "Epoch 0: Total Loss=0.0597\n",
      "Epoch 1: Total Loss=0.0614\n",
      "Epoch 2: Total Loss=0.0633\n",
      "Epoch 3: Total Loss=0.0719\n",
      "Epoch 4: Total Loss=0.0617\n",
      "Epoch 5: Total Loss=0.0609\n",
      "Epoch 6: Total Loss=0.0623\n",
      "Epoch 7: Total Loss=0.0717\n",
      "Epoch 8: Total Loss=0.0624\n",
      "Epoch 9: Total Loss=0.0595\n",
      "Updated x: [-0.02059752866625786, -0.08519476652145386], Function Value: 0.007682406343519688, Gradient: [0.05139356479048729, -0.020329564809799194]\n",
      "\n",
      "Step 21/40\n",
      "Epoch 0: Total Loss=0.0719\n",
      "Epoch 1: Total Loss=0.0651\n",
      "Epoch 2: Total Loss=0.0603\n",
      "Epoch 3: Total Loss=0.0601\n",
      "Epoch 4: Total Loss=0.0618\n",
      "Epoch 5: Total Loss=0.0714\n",
      "Epoch 6: Total Loss=0.0652\n",
      "Epoch 7: Total Loss=0.0601\n",
      "Epoch 8: Total Loss=0.0597\n",
      "Epoch 9: Total Loss=0.0617\n",
      "Updated x: [0.007720200344920158, 0.0442265123128891], Function Value: 0.0020155857782810926, Gradient: [0.0384184792637825, -0.004982726648449898]\n",
      "\n",
      "Step 22/40\n",
      "Epoch 0: Total Loss=0.0719\n",
      "Epoch 1: Total Loss=0.0812\n",
      "Epoch 2: Total Loss=0.0785\n",
      "Epoch 3: Total Loss=0.0706\n",
      "Epoch 4: Total Loss=0.0783\n",
      "Epoch 5: Total Loss=0.0747\n",
      "Epoch 6: Total Loss=0.0895\n",
      "Epoch 7: Total Loss=0.0788\n",
      "Epoch 8: Total Loss=0.0796\n",
      "Epoch 9: Total Loss=0.0757\n",
      "Updated x: [0.14129728078842163, 0.009022973477840424], Function Value: 0.020046336576342583, Gradient: [0.03877223655581474, -0.0084573645144701]\n",
      "\n",
      "Step 23/40\n",
      "Epoch 0: Total Loss=0.1213\n",
      "Epoch 1: Total Loss=0.0944\n",
      "Epoch 2: Total Loss=0.1171\n",
      "Epoch 3: Total Loss=0.1049\n",
      "Epoch 4: Total Loss=0.1380\n",
      "Epoch 5: Total Loss=0.0965\n",
      "Epoch 6: Total Loss=0.1228\n",
      "Epoch 7: Total Loss=0.0984\n",
      "Epoch 8: Total Loss=0.1219\n",
      "Epoch 9: Total Loss=0.0984\n",
      "Updated x: [0.16787058115005493, 0.0610530711710453], Function Value: 0.03190800920128822, Gradient: [0.09284959733486176, 0.010995008051395416]\n",
      "\n",
      "Step 24/40\n",
      "Epoch 0: Total Loss=0.1105\n",
      "Epoch 1: Total Loss=0.0970\n",
      "Epoch 2: Total Loss=0.0957\n",
      "Epoch 3: Total Loss=0.0974\n",
      "Epoch 4: Total Loss=0.1013\n",
      "Epoch 5: Total Loss=0.0982\n",
      "Epoch 6: Total Loss=0.1045\n",
      "Epoch 7: Total Loss=0.0905\n",
      "Epoch 8: Total Loss=0.0880\n",
      "Epoch 9: Total Loss=0.0901\n",
      "Updated x: [0.2325049638748169, -0.0014271363615989685], Function Value: 0.054060596972703934, Gradient: [0.10056295990943909, 0.017443586140871048]\n",
      "\n",
      "Step 25/40\n",
      "Epoch 0: Total Loss=0.1109\n",
      "Epoch 1: Total Loss=0.0723\n",
      "Epoch 2: Total Loss=0.0919\n",
      "Epoch 3: Total Loss=0.1049\n",
      "Epoch 4: Total Loss=0.0997\n",
      "Epoch 5: Total Loss=0.0958\n",
      "Epoch 6: Total Loss=0.0984\n",
      "Epoch 7: Total Loss=0.0924\n",
      "Epoch 8: Total Loss=0.0993\n",
      "Epoch 9: Total Loss=0.1009\n",
      "Updated x: [0.308316707611084, -0.1015753522515297], Function Value: 0.10537674278020859, Gradient: [0.11475955694913864, 0.0191691555082798]\n",
      "\n",
      "Step 26/40\n",
      "Epoch 0: Total Loss=0.1236\n",
      "Epoch 1: Total Loss=0.1271\n",
      "Epoch 2: Total Loss=0.1355\n",
      "Epoch 3: Total Loss=0.1161\n",
      "Epoch 4: Total Loss=0.1098\n",
      "Epoch 5: Total Loss=0.1212\n",
      "Epoch 6: Total Loss=0.1021\n",
      "Epoch 7: Total Loss=0.1274\n",
      "Epoch 8: Total Loss=0.1149\n",
      "Epoch 9: Total Loss=0.1072\n",
      "Updated x: [0.295723557472229, -0.14357629418373108], Function Value: 0.10806657373905182, Gradient: [0.13294368982315063, 0.018279731273651123]\n",
      "\n",
      "Step 27/40\n",
      "Epoch 0: Total Loss=0.1327\n",
      "Epoch 1: Total Loss=0.1238\n",
      "Epoch 2: Total Loss=0.1154\n",
      "Epoch 3: Total Loss=0.1180\n",
      "Epoch 4: Total Loss=0.1343\n",
      "Epoch 5: Total Loss=0.1201\n",
      "Epoch 6: Total Loss=0.1274\n",
      "Epoch 7: Total Loss=0.1203\n",
      "Epoch 8: Total Loss=0.1222\n",
      "Epoch 9: Total Loss=0.1171\n",
      "Updated x: [0.32650235295295715, -0.23829083144664764], Function Value: 0.16338631510734558, Gradient: [0.13576187193393707, -0.02522672340273857]\n",
      "\n",
      "Step 28/40\n",
      "Epoch 0: Total Loss=0.1050\n",
      "Epoch 1: Total Loss=0.1243\n",
      "Epoch 2: Total Loss=0.1013\n",
      "Epoch 3: Total Loss=0.1323\n",
      "Epoch 4: Total Loss=0.0959\n",
      "Epoch 5: Total Loss=0.1488\n",
      "Epoch 6: Total Loss=0.1041\n",
      "Epoch 7: Total Loss=0.1131\n",
      "Epoch 8: Total Loss=0.1533\n",
      "Epoch 9: Total Loss=0.1000\n",
      "Updated x: [0.2762504518032074, -0.18789516389369965], Function Value: 0.11161890625953674, Gradient: [0.09492956846952438, -0.03341325744986534]\n",
      "\n",
      "Step 29/40\n",
      "Epoch 0: Total Loss=0.1263\n",
      "Epoch 1: Total Loss=0.0927\n",
      "Epoch 2: Total Loss=0.1174\n",
      "Epoch 3: Total Loss=0.1453\n",
      "Epoch 4: Total Loss=0.0956\n",
      "Epoch 5: Total Loss=0.1143\n",
      "Epoch 6: Total Loss=0.1061\n",
      "Epoch 7: Total Loss=0.1182\n",
      "Epoch 8: Total Loss=0.1395\n",
      "Epoch 9: Total Loss=0.1016\n",
      "Updated x: [0.32975873351097107, -0.13218078017234802], Function Value: 0.12621258199214935, Gradient: [0.07635926455259323, -0.013350713066756725]\n",
      "\n",
      "Step 30/40\n",
      "Epoch 0: Total Loss=0.1055\n",
      "Epoch 1: Total Loss=0.0985\n",
      "Epoch 2: Total Loss=0.1036\n",
      "Epoch 3: Total Loss=0.1069\n",
      "Epoch 4: Total Loss=0.1155\n",
      "Epoch 5: Total Loss=0.0967\n",
      "Epoch 6: Total Loss=0.1042\n",
      "Epoch 7: Total Loss=0.0933\n",
      "Epoch 8: Total Loss=0.1004\n",
      "Epoch 9: Total Loss=0.0953\n",
      "Updated x: [0.29262667894363403, -0.08811136335134506], Function Value: 0.09339398145675659, Gradient: [0.07241882383823395, -0.0027323898393660784]\n",
      "\n",
      "Step 31/40\n",
      "Epoch 0: Total Loss=0.0975\n",
      "Epoch 1: Total Loss=0.0967\n",
      "Epoch 2: Total Loss=0.1266\n",
      "Epoch 3: Total Loss=0.0844\n",
      "Epoch 4: Total Loss=0.0847\n",
      "Epoch 5: Total Loss=0.0938\n",
      "Epoch 6: Total Loss=0.1130\n",
      "Epoch 7: Total Loss=0.1095\n",
      "Epoch 8: Total Loss=0.0859\n",
      "Epoch 9: Total Loss=0.0874\n",
      "Updated x: [0.40478217601776123, -0.011134326457977295], Function Value: 0.16397258639335632, Gradient: [0.06316014379262924, 0.011888532899320126]\n",
      "\n",
      "Step 32/40\n",
      "Epoch 0: Total Loss=0.1843\n",
      "Epoch 1: Total Loss=0.1640\n",
      "Epoch 2: Total Loss=0.1579\n",
      "Epoch 3: Total Loss=0.1484\n",
      "Epoch 4: Total Loss=0.1425\n",
      "Epoch 5: Total Loss=0.1374\n",
      "Epoch 6: Total Loss=0.1284\n",
      "Epoch 7: Total Loss=0.1335\n",
      "Epoch 8: Total Loss=0.1351\n",
      "Epoch 9: Total Loss=0.1393\n",
      "Updated x: [0.4512326419353485, 0.0010898355394601822], Function Value: 0.2036120891571045, Gradient: [0.28601112961769104, 0.044003862887620926]\n",
      "\n",
      "Step 33/40\n",
      "Epoch 0: Total Loss=0.1342\n",
      "Epoch 1: Total Loss=0.1213\n",
      "Epoch 2: Total Loss=0.1235\n",
      "Epoch 3: Total Loss=0.1243\n",
      "Epoch 4: Total Loss=0.1205\n",
      "Epoch 5: Total Loss=0.1110\n",
      "Epoch 6: Total Loss=0.1078\n",
      "Epoch 7: Total Loss=0.1078\n",
      "Epoch 8: Total Loss=0.1103\n",
      "Epoch 9: Total Loss=0.1156\n",
      "Updated x: [0.3700702488422394, 0.042137131094932556], Function Value: 0.13872751593589783, Gradient: [0.3214036226272583, 0.02400290220975876]\n",
      "\n",
      "Step 34/40\n",
      "Epoch 0: Total Loss=0.1099\n",
      "Epoch 1: Total Loss=0.1087\n",
      "Epoch 2: Total Loss=0.1112\n",
      "Epoch 3: Total Loss=0.1096\n",
      "Epoch 4: Total Loss=0.1056\n",
      "Epoch 5: Total Loss=0.1038\n",
      "Epoch 6: Total Loss=0.1159\n",
      "Epoch 7: Total Loss=0.1020\n",
      "Epoch 8: Total Loss=0.1037\n",
      "Epoch 9: Total Loss=0.1083\n",
      "Updated x: [0.2522018551826477, 0.11656861752271652], Function Value: 0.07719402015209198, Gradient: [0.3530714511871338, 0.05989830568432808]\n",
      "\n",
      "Step 35/40\n",
      "Epoch 0: Total Loss=0.1118\n",
      "Epoch 1: Total Loss=0.1005\n",
      "Epoch 2: Total Loss=0.1105\n",
      "Epoch 3: Total Loss=0.1106\n",
      "Epoch 4: Total Loss=0.1041\n",
      "Epoch 5: Total Loss=0.1079\n",
      "Epoch 6: Total Loss=0.1038\n",
      "Epoch 7: Total Loss=0.1025\n",
      "Epoch 8: Total Loss=0.1041\n",
      "Epoch 9: Total Loss=0.1057\n",
      "Updated x: [0.29179123044013977, 0.21633505821228027], Function Value: 0.1319429874420166, Gradient: [0.3189103603363037, 0.0563848502933979]\n",
      "\n",
      "Step 36/40\n",
      "Epoch 0: Total Loss=0.1153\n",
      "Epoch 1: Total Loss=0.0976\n",
      "Epoch 2: Total Loss=0.1065\n",
      "Epoch 3: Total Loss=0.0989\n",
      "Epoch 4: Total Loss=0.0881\n",
      "Epoch 5: Total Loss=0.1066\n",
      "Epoch 6: Total Loss=0.0899\n",
      "Epoch 7: Total Loss=0.0913\n",
      "Epoch 8: Total Loss=0.1011\n",
      "Epoch 9: Total Loss=0.1021\n",
      "Updated x: [0.3198326826095581, 0.2600374221801758], Function Value: 0.1699123978614807, Gradient: [0.1536460518836975, 0.007324191741645336]\n",
      "\n",
      "Step 37/40\n",
      "Epoch 0: Total Loss=0.0944\n",
      "Epoch 1: Total Loss=0.0953\n",
      "Epoch 2: Total Loss=0.0958\n",
      "Epoch 3: Total Loss=0.0935\n",
      "Epoch 4: Total Loss=0.0983\n",
      "Epoch 5: Total Loss=0.0949\n",
      "Epoch 6: Total Loss=0.0887\n",
      "Epoch 7: Total Loss=0.0921\n",
      "Epoch 8: Total Loss=0.0976\n",
      "Epoch 9: Total Loss=0.0914\n",
      "Updated x: [0.3392714858055115, 0.15690645575523376], Function Value: 0.13972477614879608, Gradient: [0.14433130621910095, 0.018466047942638397]\n",
      "\n",
      "Step 38/40\n",
      "Epoch 0: Total Loss=0.0999\n",
      "Epoch 1: Total Loss=0.0949\n",
      "Epoch 2: Total Loss=0.0957\n",
      "Epoch 3: Total Loss=0.0954\n",
      "Epoch 4: Total Loss=0.0949\n",
      "Epoch 5: Total Loss=0.0928\n",
      "Epoch 6: Total Loss=0.0905\n",
      "Epoch 7: Total Loss=0.0911\n",
      "Epoch 8: Total Loss=0.0936\n",
      "Epoch 9: Total Loss=0.0916\n",
      "Updated x: [0.30271387100219727, 0.08456539362668991], Function Value: 0.09878699481487274, Gradient: [0.1367778331041336, 0.029871826991438866]\n",
      "\n",
      "Step 39/40\n",
      "Epoch 0: Total Loss=0.0859\n",
      "Epoch 1: Total Loss=0.0908\n",
      "Epoch 2: Total Loss=0.0882\n",
      "Epoch 3: Total Loss=0.0993\n",
      "Epoch 4: Total Loss=0.0901\n",
      "Epoch 5: Total Loss=0.0921\n",
      "Epoch 6: Total Loss=0.0891\n",
      "Epoch 7: Total Loss=0.0867\n",
      "Epoch 8: Total Loss=0.0860\n",
      "Epoch 9: Total Loss=0.0917\n",
      "Updated x: [0.2924860119819641, 0.09115060418844223], Function Value: 0.09385649859905243, Gradient: [0.13785243034362793, 0.0367666594684124]\n",
      "\n",
      "Step 40/40\n",
      "Epoch 0: Total Loss=0.0890\n",
      "Epoch 1: Total Loss=0.1012\n",
      "Epoch 2: Total Loss=0.0845\n",
      "Epoch 3: Total Loss=0.0974\n",
      "Epoch 4: Total Loss=0.0993\n",
      "Epoch 5: Total Loss=0.0913\n",
      "Epoch 6: Total Loss=0.0916\n",
      "Epoch 7: Total Loss=0.0819\n",
      "Epoch 8: Total Loss=0.0899\n",
      "Epoch 9: Total Loss=0.0973\n",
      "Updated x: [0.28598710894584656, 0.05109316110610962], Function Value: 0.08439914137125015, Gradient: [0.13198545575141907, 0.05211740359663963]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define the number of optimization steps\n",
    "optim_steps = 40\n",
    "N_s = 2  # Keep N_s constant\n",
    "\n",
    "# Dictionary to store results\n",
    "results = {}\n",
    "\n",
    "# Small network\n",
    "old_dataset = OldDataSet(data, k=10)\n",
    "new_dataset = NewDataSet(k=10)\n",
    "model_small = MLP(2, [5, 5, 5], 1)  # Original network\n",
    "\n",
    "x_path_small, y_path_small = optimize_surrogate_model(\n",
    "    model_small, old_dataset, new_dataset, assSim, \n",
    "    optim_steps=optim_steps, N_s=N_s, lr=0.001, merge_interval=10\n",
    ")\n",
    "\n",
    "results[\"Small Network\"] = y_path_small\n",
    "\n",
    "# Large network (quadrupled neurons)\n",
    "model_large = MLP(2, [20, 20, 20], 1)  # Quadrupled neurons\n",
    "\n",
    "x_path_large, y_path_large = optimize_surrogate_model(\n",
    "    model_large, old_dataset, new_dataset, assSim, \n",
    "    optim_steps=optim_steps, N_s=N_s, lr=0.001, merge_interval=10\n",
    ")\n",
    "\n",
    "results[\"Large Network\"] = y_path_large\n",
    "\n",
    "# Plot the results\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "plt.plot(range(optim_steps), results[\"Small Network\"], linestyle=\"--\", label=\"Small Network\")\n",
    "plt.plot(range(optim_steps), results[\"Large Network\"], linestyle=\"-\", label=\"Large Network\")\n",
    "\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.ylabel(\"Objective y\")\n",
    "plt.title(\"Comparison of Small and Large Networks on y Objective Over Iterations\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 1/40\n",
      "Epoch 0: Total Loss=1.6477\n",
      "Epoch 1: Total Loss=1.6225\n",
      "Epoch 2: Total Loss=1.5974\n",
      "Epoch 3: Total Loss=1.5725\n",
      "Epoch 4: Total Loss=1.5478\n",
      "Epoch 5: Total Loss=1.5233\n",
      "Epoch 6: Total Loss=1.4989\n",
      "Epoch 7: Total Loss=1.4748\n",
      "Epoch 8: Total Loss=1.4509\n",
      "Epoch 9: Total Loss=1.4272\n",
      "Updated x: [0.7157641053199768, -0.8853240013122559], Function Value: 1.296116828918457, Gradient: [0.5974026322364807, -0.8388539552688599]\n",
      "\n",
      "Step 2/40\n",
      "Epoch 0: Total Loss=1.3524\n",
      "Epoch 1: Total Loss=1.3304\n",
      "Epoch 2: Total Loss=1.3087\n",
      "Epoch 3: Total Loss=1.2874\n",
      "Epoch 4: Total Loss=1.2664\n",
      "Epoch 5: Total Loss=1.2458\n",
      "Epoch 6: Total Loss=1.2257\n",
      "Epoch 7: Total Loss=1.2059\n",
      "Epoch 8: Total Loss=1.1866\n",
      "Epoch 9: Total Loss=1.1678\n",
      "Updated x: [0.6643960475921631, -1.002299189567566], Function Value: 1.4460257291793823, Gradient: [0.7353987097740173, -0.9973020553588867]\n",
      "\n",
      "Step 3/40\n",
      "Epoch 0: Total Loss=1.1495\n",
      "Epoch 1: Total Loss=1.2463\n",
      "Epoch 2: Total Loss=1.1137\n",
      "Epoch 3: Total Loss=1.2108\n",
      "Epoch 4: Total Loss=1.0800\n",
      "Epoch 5: Total Loss=1.1775\n",
      "Epoch 6: Total Loss=1.0486\n",
      "Epoch 7: Total Loss=1.1467\n",
      "Epoch 8: Total Loss=1.0197\n",
      "Epoch 9: Total Loss=1.1186\n",
      "Updated x: [0.7960730195045471, -0.7709746956825256], Function Value: 1.2281341552734375, Gradient: [0.8134027123451233, -1.0579701662063599]\n",
      "\n",
      "Step 4/40\n",
      "Epoch 0: Total Loss=0.9814\n",
      "Epoch 1: Total Loss=0.9966\n",
      "Epoch 2: Total Loss=1.0532\n",
      "Epoch 3: Total Loss=0.9532\n",
      "Epoch 4: Total Loss=0.9830\n",
      "Epoch 5: Total Loss=1.0175\n",
      "Epoch 6: Total Loss=0.9315\n",
      "Epoch 7: Total Loss=0.9746\n",
      "Epoch 8: Total Loss=0.9893\n",
      "Epoch 9: Total Loss=0.9161\n",
      "Updated x: [0.6931439638137817, -0.6410716772079468], Function Value: 0.8914214372634888, Gradient: [0.9395888447761536, -1.1000345945358276]\n",
      "\n",
      "Step 5/40\n",
      "Epoch 0: Total Loss=1.0765\n",
      "Epoch 1: Total Loss=0.8909\n",
      "Epoch 2: Total Loss=0.8838\n",
      "Epoch 3: Total Loss=0.9084\n",
      "Epoch 4: Total Loss=1.0661\n",
      "Epoch 5: Total Loss=0.8818\n",
      "Epoch 6: Total Loss=0.8872\n",
      "Epoch 7: Total Loss=0.9037\n",
      "Epoch 8: Total Loss=1.0621\n",
      "Epoch 9: Total Loss=0.8775\n",
      "Updated x: [0.8065176010131836, -0.6573328971862793], Function Value: 1.082557201385498, Gradient: [0.9865741729736328, -1.193241834640503]\n",
      "\n",
      "Step 6/40\n",
      "Epoch 0: Total Loss=0.8414\n",
      "Epoch 1: Total Loss=0.8453\n",
      "Epoch 2: Total Loss=0.8484\n",
      "Epoch 3: Total Loss=0.8187\n",
      "Epoch 4: Total Loss=0.9016\n",
      "Epoch 5: Total Loss=0.7990\n",
      "Epoch 6: Total Loss=0.8043\n",
      "Epoch 7: Total Loss=0.8104\n",
      "Epoch 8: Total Loss=0.7837\n",
      "Epoch 9: Total Loss=0.8634\n",
      "Updated x: [0.6970071196556091, -0.6643944382667542], Function Value: 0.9272388815879822, Gradient: [0.864652693271637, -1.039868950843811]\n",
      "\n",
      "Step 7/40\n",
      "Epoch 0: Total Loss=0.7534\n",
      "Epoch 1: Total Loss=0.7510\n",
      "Epoch 2: Total Loss=0.9149\n",
      "Epoch 3: Total Loss=0.7778\n",
      "Epoch 4: Total Loss=0.8812\n",
      "Epoch 5: Total Loss=0.8158\n",
      "Epoch 6: Total Loss=0.7226\n",
      "Epoch 7: Total Loss=0.7188\n",
      "Epoch 8: Total Loss=0.8802\n",
      "Epoch 9: Total Loss=0.7479\n",
      "Updated x: [0.6793939471244812, -0.5633087754249573], Function Value: 0.7788928747177124, Gradient: [0.715045154094696, -0.8252950310707092]\n",
      "\n",
      "Step 8/40\n",
      "Epoch 0: Total Loss=1.0319\n",
      "Epoch 1: Total Loss=0.7270\n",
      "Epoch 2: Total Loss=0.7342\n",
      "Epoch 3: Total Loss=0.6871\n",
      "Epoch 4: Total Loss=0.6869\n",
      "Epoch 5: Total Loss=0.6960\n",
      "Epoch 6: Total Loss=0.7640\n",
      "Epoch 7: Total Loss=0.9945\n",
      "Epoch 8: Total Loss=0.7060\n",
      "Epoch 9: Total Loss=0.7228\n",
      "Updated x: [0.6221736073493958, -0.4601731300354004], Function Value: 0.5988593101501465, Gradient: [0.583787202835083, -0.6128968000411987]\n",
      "\n",
      "Step 9/40\n",
      "Epoch 0: Total Loss=0.7824\n",
      "Epoch 1: Total Loss=0.7821\n",
      "Epoch 2: Total Loss=0.6951\n",
      "Epoch 3: Total Loss=0.6680\n",
      "Epoch 4: Total Loss=0.7351\n",
      "Epoch 5: Total Loss=0.7306\n",
      "Epoch 6: Total Loss=0.6582\n",
      "Epoch 7: Total Loss=0.6810\n",
      "Epoch 8: Total Loss=0.7603\n",
      "Epoch 9: Total Loss=0.7739\n",
      "Updated x: [0.582034170627594, -0.49528685212135315], Function Value: 0.5840728282928467, Gradient: [0.5021942853927612, -0.5502009391784668]\n",
      "\n",
      "Step 10/40\n",
      "Epoch 0: Total Loss=0.8230\n",
      "Epoch 1: Total Loss=0.7687\n",
      "Epoch 2: Total Loss=0.7398\n",
      "Epoch 3: Total Loss=0.7051\n",
      "Epoch 4: Total Loss=0.9600\n",
      "Epoch 5: Total Loss=0.6715\n",
      "Epoch 6: Total Loss=0.6501\n",
      "Epoch 7: Total Loss=0.6803\n",
      "Epoch 8: Total Loss=0.6944\n",
      "Epoch 9: Total Loss=0.7992\n",
      "Updated x: [0.5770628452301025, -0.5128517150878906], Function Value: 0.5960184335708618, Gradient: [0.4280426502227783, -0.4833225905895233]\n",
      "\n",
      "Step 11/40\n",
      "Epoch 0: Total Loss=0.6416\n",
      "Epoch 1: Total Loss=0.6733\n",
      "Epoch 2: Total Loss=0.7481\n",
      "Epoch 3: Total Loss=0.8012\n",
      "Epoch 4: Total Loss=0.6431\n",
      "Epoch 5: Total Loss=0.6349\n",
      "Epoch 6: Total Loss=0.6741\n",
      "Epoch 7: Total Loss=0.6877\n",
      "Epoch 8: Total Loss=0.6673\n",
      "Epoch 9: Total Loss=0.9028\n",
      "Updated x: [0.5356712937355042, -0.4133608341217041], Function Value: 0.4578109085559845, Gradient: [0.34612491726875305, -0.3421940505504608]\n",
      "\n",
      "Step 12/40\n",
      "Epoch 0: Total Loss=0.4338\n",
      "Epoch 1: Total Loss=0.4323\n",
      "Epoch 2: Total Loss=0.4308\n",
      "Epoch 3: Total Loss=0.4293\n",
      "Epoch 4: Total Loss=0.4278\n",
      "Epoch 5: Total Loss=0.4264\n",
      "Epoch 6: Total Loss=0.4250\n",
      "Epoch 7: Total Loss=0.4236\n",
      "Epoch 8: Total Loss=0.4222\n",
      "Epoch 9: Total Loss=0.4209\n",
      "Updated x: [0.33016109466552734, -0.28249281644821167], Function Value: 0.18880853056907654, Gradient: [0.17677904665470123, -0.1519995629787445]\n",
      "\n",
      "Step 13/40\n",
      "Epoch 0: Total Loss=0.4164\n",
      "Epoch 1: Total Loss=0.3484\n",
      "Epoch 2: Total Loss=0.4142\n",
      "Epoch 3: Total Loss=0.3460\n",
      "Epoch 4: Total Loss=0.4122\n",
      "Epoch 5: Total Loss=0.3439\n",
      "Epoch 6: Total Loss=0.4103\n",
      "Epoch 7: Total Loss=0.3419\n",
      "Epoch 8: Total Loss=0.4086\n",
      "Epoch 9: Total Loss=0.3401\n",
      "Updated x: [0.3171325623989105, -0.15984749794006348], Function Value: 0.1261242926120758, Gradient: [0.10723671317100525, -0.04474588483572006]\n",
      "\n",
      "Step 14/40\n",
      "Epoch 0: Total Loss=0.4106\n",
      "Epoch 1: Total Loss=0.3300\n",
      "Epoch 2: Total Loss=0.3487\n",
      "Epoch 3: Total Loss=0.4078\n",
      "Epoch 4: Total Loss=0.3280\n",
      "Epoch 5: Total Loss=0.3466\n",
      "Epoch 6: Total Loss=0.4056\n",
      "Epoch 7: Total Loss=0.3260\n",
      "Epoch 8: Total Loss=0.3445\n",
      "Epoch 9: Total Loss=0.4035\n",
      "Updated x: [0.21934854984283447, -0.053106702864170074], Function Value: 0.05093410611152649, Gradient: [0.0093054985627532, 0.047199495136737823]\n",
      "\n",
      "Step 15/40\n",
      "Epoch 0: Total Loss=0.3288\n",
      "Epoch 1: Total Loss=0.3987\n",
      "Epoch 2: Total Loss=0.3534\n",
      "Epoch 3: Total Loss=0.3155\n",
      "Epoch 4: Total Loss=0.3260\n",
      "Epoch 5: Total Loss=0.3960\n",
      "Epoch 6: Total Loss=0.3505\n",
      "Epoch 7: Total Loss=0.3135\n",
      "Epoch 8: Total Loss=0.3235\n",
      "Epoch 9: Total Loss=0.3935\n",
      "Updated x: [0.31921324133872986, -0.13505671918392181], Function Value: 0.12013740837574005, Gradient: [0.13025149703025818, -0.02665344998240471]\n",
      "\n",
      "Step 16/40\n",
      "Epoch 0: Total Loss=0.3223\n",
      "Epoch 1: Total Loss=0.3091\n",
      "Epoch 2: Total Loss=0.3069\n",
      "Epoch 3: Total Loss=0.3395\n",
      "Epoch 4: Total Loss=0.3064\n",
      "Epoch 5: Total Loss=0.3198\n",
      "Epoch 6: Total Loss=0.3070\n",
      "Epoch 7: Total Loss=0.3049\n",
      "Epoch 8: Total Loss=0.3383\n",
      "Epoch 9: Total Loss=0.3047\n",
      "Updated x: [0.3044317662715912, -0.2284640520811081], Function Value: 0.14487452805042267, Gradient: [0.12758789956569672, -0.05679741129279137]\n",
      "\n",
      "Step 17/40\n",
      "Epoch 0: Total Loss=0.3343\n",
      "Epoch 1: Total Loss=0.3006\n",
      "Epoch 2: Total Loss=0.3010\n",
      "Epoch 3: Total Loss=0.3000\n",
      "Epoch 4: Total Loss=0.3044\n",
      "Epoch 5: Total Loss=0.3013\n",
      "Epoch 6: Total Loss=0.3329\n",
      "Epoch 7: Total Loss=0.2991\n",
      "Epoch 8: Total Loss=0.2997\n",
      "Epoch 9: Total Loss=0.2987\n",
      "Updated x: [0.22815978527069092, -0.3015056252479553], Function Value: 0.1429625302553177, Gradient: [0.10101693123579025, -0.08049314469099045]\n",
      "\n",
      "Step 18/40\n",
      "Epoch 0: Total Loss=0.2987\n",
      "Epoch 1: Total Loss=0.2959\n",
      "Epoch 2: Total Loss=0.2948\n",
      "Epoch 3: Total Loss=0.2949\n",
      "Epoch 4: Total Loss=0.2975\n",
      "Epoch 5: Total Loss=0.3278\n",
      "Epoch 6: Total Loss=0.2991\n",
      "Epoch 7: Total Loss=0.2973\n",
      "Epoch 8: Total Loss=0.2946\n",
      "Epoch 9: Total Loss=0.2935\n",
      "Updated x: [0.2573002278804779, -0.29199808835983276], Function Value: 0.15146629512310028, Gradient: [0.13778288662433624, -0.09652377665042877]\n",
      "\n",
      "Step 19/40\n",
      "Epoch 0: Total Loss=0.3247\n",
      "Epoch 1: Total Loss=0.2921\n",
      "Epoch 2: Total Loss=0.2932\n",
      "Epoch 3: Total Loss=0.2970\n",
      "Epoch 4: Total Loss=0.2975\n",
      "Epoch 5: Total Loss=0.2937\n",
      "Epoch 6: Total Loss=0.2923\n",
      "Epoch 7: Total Loss=0.2991\n",
      "Epoch 8: Total Loss=0.3230\n",
      "Epoch 9: Total Loss=0.2909\n",
      "Updated x: [0.0020567476749420166, -0.16376490890979767], Function Value: 0.026823176071047783, Gradient: [-0.05648695304989815, 0.038000695407390594]\n",
      "\n",
      "Step 20/40\n",
      "Epoch 0: Total Loss=0.2911\n",
      "Epoch 1: Total Loss=0.2920\n",
      "Epoch 2: Total Loss=0.2918\n",
      "Epoch 3: Total Loss=0.2937\n",
      "Epoch 4: Total Loss=0.2914\n",
      "Epoch 5: Total Loss=0.2906\n",
      "Epoch 6: Total Loss=0.2987\n",
      "Epoch 7: Total Loss=0.3183\n",
      "Epoch 8: Total Loss=0.2935\n",
      "Epoch 9: Total Loss=0.2896\n",
      "Updated x: [0.16410323977470398, -0.11567503213882446], Function Value: 0.040310587733983994, Gradient: [0.05335811898112297, 0.01795314997434616]\n",
      "\n",
      "Step 21/40\n",
      "Epoch 0: Total Loss=0.3321\n",
      "Epoch 1: Total Loss=0.2941\n",
      "Epoch 2: Total Loss=0.2897\n",
      "Epoch 3: Total Loss=0.2894\n",
      "Epoch 4: Total Loss=0.2901\n",
      "Epoch 5: Total Loss=0.2910\n",
      "Epoch 6: Total Loss=0.2938\n",
      "Epoch 7: Total Loss=0.2906\n",
      "Epoch 8: Total Loss=0.2889\n",
      "Epoch 9: Total Loss=0.2907\n",
      "Updated x: [0.18825051188468933, -0.0893012285232544], Function Value: 0.043412964791059494, Gradient: [0.061733804643154144, 0.025214925408363342]\n",
      "\n",
      "Step 22/40\n",
      "Epoch 0: Total Loss=0.2429\n",
      "Epoch 1: Total Loss=0.2423\n",
      "Epoch 2: Total Loss=0.2418\n",
      "Epoch 3: Total Loss=0.2413\n",
      "Epoch 4: Total Loss=0.2408\n",
      "Epoch 5: Total Loss=0.2403\n",
      "Epoch 6: Total Loss=0.2398\n",
      "Epoch 7: Total Loss=0.2393\n",
      "Epoch 8: Total Loss=0.2389\n",
      "Epoch 9: Total Loss=0.2384\n",
      "Updated x: [0.19607454538345337, -0.1559949815273285], Function Value: 0.06277966499328613, Gradient: [0.11527013033628464, -0.03548945114016533]\n",
      "\n",
      "Step 23/40\n",
      "Epoch 0: Total Loss=0.2380\n",
      "Epoch 1: Total Loss=0.2249\n",
      "Epoch 2: Total Loss=0.2372\n",
      "Epoch 3: Total Loss=0.2243\n",
      "Epoch 4: Total Loss=0.2365\n",
      "Epoch 5: Total Loss=0.2238\n",
      "Epoch 6: Total Loss=0.2358\n",
      "Epoch 7: Total Loss=0.2233\n",
      "Epoch 8: Total Loss=0.2352\n",
      "Epoch 9: Total Loss=0.2229\n",
      "Updated x: [0.14717723429203033, -0.018645599484443665], Function Value: 0.022008797153830528, Gradient: [0.06477422267198563, 0.045948103070259094]\n",
      "\n",
      "Step 24/40\n",
      "Epoch 0: Total Loss=0.2226\n",
      "Epoch 1: Total Loss=0.2340\n",
      "Epoch 2: Total Loss=0.2213\n",
      "Epoch 3: Total Loss=0.2220\n",
      "Epoch 4: Total Loss=0.2332\n",
      "Epoch 5: Total Loss=0.2208\n",
      "Epoch 6: Total Loss=0.2215\n",
      "Epoch 7: Total Loss=0.2325\n",
      "Epoch 8: Total Loss=0.2204\n",
      "Epoch 9: Total Loss=0.2211\n",
      "Updated x: [0.055888451635837555, -0.12889862060546875], Function Value: 0.019738372415304184, Gradient: [0.04558488354086876, -0.01833370514214039]\n",
      "\n",
      "Step 25/40\n",
      "Epoch 0: Total Loss=0.2200\n",
      "Epoch 1: Total Loss=0.2210\n",
      "Epoch 2: Total Loss=0.2332\n",
      "Epoch 3: Total Loss=0.2208\n",
      "Epoch 4: Total Loss=0.2195\n",
      "Epoch 5: Total Loss=0.2204\n",
      "Epoch 6: Total Loss=0.2327\n",
      "Epoch 7: Total Loss=0.2204\n",
      "Epoch 8: Total Loss=0.2190\n",
      "Epoch 9: Total Loss=0.2199\n",
      "Updated x: [-0.000493515282869339, -0.0544874370098114], Function Value: 0.0029691243544220924, Gradient: [0.020615477114915848, 0.004914614837616682]\n",
      "\n",
      "Step 26/40\n",
      "Epoch 0: Total Loss=0.2203\n",
      "Epoch 1: Total Loss=0.2207\n",
      "Epoch 2: Total Loss=0.2197\n",
      "Epoch 3: Total Loss=0.2294\n",
      "Epoch 4: Total Loss=0.2196\n",
      "Epoch 5: Total Loss=0.2197\n",
      "Epoch 6: Total Loss=0.2201\n",
      "Epoch 7: Total Loss=0.2191\n",
      "Epoch 8: Total Loss=0.2288\n",
      "Epoch 9: Total Loss=0.2191\n",
      "Updated x: [0.0515078529715538, 0.007218938320875168], Function Value: 0.002705171937122941, Gradient: [0.06520166248083115, 0.011983039788901806]\n",
      "\n",
      "Step 27/40\n",
      "Epoch 0: Total Loss=0.2179\n",
      "Epoch 1: Total Loss=0.2191\n",
      "Epoch 2: Total Loss=0.2281\n",
      "Epoch 3: Total Loss=0.2185\n",
      "Epoch 4: Total Loss=0.2175\n",
      "Epoch 5: Total Loss=0.2183\n",
      "Epoch 6: Total Loss=0.2174\n",
      "Epoch 7: Total Loss=0.2186\n",
      "Epoch 8: Total Loss=0.2275\n",
      "Epoch 9: Total Loss=0.2179\n",
      "Updated x: [-0.0037739239633083344, -0.09245802462100983], Function Value: 0.008562728762626648, Gradient: [0.06743142008781433, -0.057055115699768066]\n",
      "\n",
      "Step 28/40\n",
      "Epoch 0: Total Loss=0.2182\n",
      "Epoch 1: Total Loss=0.2169\n",
      "Epoch 2: Total Loss=0.2166\n",
      "Epoch 3: Total Loss=0.2165\n",
      "Epoch 4: Total Loss=0.2173\n",
      "Epoch 5: Total Loss=0.2166\n",
      "Epoch 6: Total Loss=0.2237\n",
      "Epoch 7: Total Loss=0.2176\n",
      "Epoch 8: Total Loss=0.2162\n",
      "Epoch 9: Total Loss=0.2159\n",
      "Updated x: [-0.08518736064434052, -0.020152918994426727], Function Value: 0.007663026452064514, Gradient: [0.02973318099975586, -0.029501743614673615]\n",
      "\n",
      "Step 29/40\n",
      "Epoch 0: Total Loss=0.2261\n",
      "Epoch 1: Total Loss=0.2170\n",
      "Epoch 2: Total Loss=0.2164\n",
      "Epoch 3: Total Loss=0.2155\n",
      "Epoch 4: Total Loss=0.2168\n",
      "Epoch 5: Total Loss=0.2155\n",
      "Epoch 6: Total Loss=0.2156\n",
      "Epoch 7: Total Loss=0.2156\n",
      "Epoch 8: Total Loss=0.2253\n",
      "Epoch 9: Total Loss=0.2164\n",
      "Updated x: [-0.007998943328857422, 0.04453977942466736], Function Value: 0.0020477750804275274, Gradient: [0.06282869726419449, -0.01973583921790123]\n",
      "\n",
      "Step 30/40\n",
      "Epoch 0: Total Loss=0.2148\n",
      "Epoch 1: Total Loss=0.2157\n",
      "Epoch 2: Total Loss=0.2149\n",
      "Epoch 3: Total Loss=0.2147\n",
      "Epoch 4: Total Loss=0.2245\n",
      "Epoch 5: Total Loss=0.2147\n",
      "Epoch 6: Total Loss=0.2157\n",
      "Epoch 7: Total Loss=0.2145\n",
      "Epoch 8: Total Loss=0.2151\n",
      "Epoch 9: Total Loss=0.2140\n",
      "Updated x: [0.0956464633345604, 0.0986795574426651], Function Value: 0.0188859011977911, Gradient: [0.1314576119184494, -0.019587544724345207]\n",
      "\n",
      "Step 31/40\n",
      "Epoch 0: Total Loss=0.2147\n",
      "Epoch 1: Total Loss=0.2139\n",
      "Epoch 2: Total Loss=0.2145\n",
      "Epoch 3: Total Loss=0.2145\n",
      "Epoch 4: Total Loss=0.2137\n",
      "Epoch 5: Total Loss=0.2145\n",
      "Epoch 6: Total Loss=0.2150\n",
      "Epoch 7: Total Loss=0.2139\n",
      "Epoch 8: Total Loss=0.2133\n",
      "Epoch 9: Total Loss=0.2249\n",
      "Updated x: [0.01209971308708191, 0.16109779477119446], Function Value: 0.02609890326857567, Gradient: [0.06628488749265671, 0.027955187484622]\n",
      "\n",
      "Step 32/40\n",
      "Epoch 0: Total Loss=0.1913\n",
      "Epoch 1: Total Loss=0.1910\n",
      "Epoch 2: Total Loss=0.1907\n",
      "Epoch 3: Total Loss=0.1905\n",
      "Epoch 4: Total Loss=0.1904\n",
      "Epoch 5: Total Loss=0.1902\n",
      "Epoch 6: Total Loss=0.1901\n",
      "Epoch 7: Total Loss=0.1900\n",
      "Epoch 8: Total Loss=0.1899\n",
      "Epoch 9: Total Loss=0.1898\n",
      "Updated x: [-0.07302369922399521, 0.16732937097549438], Function Value: 0.033331580460071564, Gradient: [0.022268885746598244, 0.0384361557662487]\n",
      "\n",
      "Step 33/40\n",
      "Epoch 0: Total Loss=0.1894\n",
      "Epoch 1: Total Loss=0.1896\n",
      "Epoch 2: Total Loss=0.1893\n",
      "Epoch 3: Total Loss=0.1894\n",
      "Epoch 4: Total Loss=0.1892\n",
      "Epoch 5: Total Loss=0.1893\n",
      "Epoch 6: Total Loss=0.1892\n",
      "Epoch 7: Total Loss=0.1893\n",
      "Epoch 8: Total Loss=0.1891\n",
      "Epoch 9: Total Loss=0.1892\n",
      "Updated x: [-0.07086210697889328, 0.14878298342227936], Function Value: 0.02715781331062317, Gradient: [0.044466327875852585, 0.012783917598426342]\n",
      "\n",
      "Step 34/40\n",
      "Epoch 0: Total Loss=0.1870\n",
      "Epoch 1: Total Loss=0.1903\n",
      "Epoch 2: Total Loss=0.1877\n",
      "Epoch 3: Total Loss=0.1869\n",
      "Epoch 4: Total Loss=0.1902\n",
      "Epoch 5: Total Loss=0.1876\n",
      "Epoch 6: Total Loss=0.1869\n",
      "Epoch 7: Total Loss=0.1902\n",
      "Epoch 8: Total Loss=0.1875\n",
      "Epoch 9: Total Loss=0.1868\n",
      "Updated x: [0.09252095967531204, 0.0772855132818222], Function Value: 0.014533177949488163, Gradient: [0.1661701649427414, -0.05937834829092026]\n",
      "\n",
      "Step 35/40\n",
      "Epoch 0: Total Loss=0.1890\n",
      "Epoch 1: Total Loss=0.1900\n",
      "Epoch 2: Total Loss=0.1855\n",
      "Epoch 3: Total Loss=0.1862\n",
      "Epoch 4: Total Loss=0.1889\n",
      "Epoch 5: Total Loss=0.1900\n",
      "Epoch 6: Total Loss=0.1853\n",
      "Epoch 7: Total Loss=0.1861\n",
      "Epoch 8: Total Loss=0.1888\n",
      "Epoch 9: Total Loss=0.1900\n",
      "Updated x: [0.03148868307471275, 0.12862271070480347], Function Value: 0.017535338178277016, Gradient: [0.13114115595817566, -0.02388778142631054]\n",
      "\n",
      "Step 36/40\n",
      "Epoch 0: Total Loss=0.1856\n",
      "Epoch 1: Total Loss=0.1859\n",
      "Epoch 2: Total Loss=0.1862\n",
      "Epoch 3: Total Loss=0.1870\n",
      "Epoch 4: Total Loss=0.1860\n",
      "Epoch 5: Total Loss=0.1854\n",
      "Epoch 6: Total Loss=0.1857\n",
      "Epoch 7: Total Loss=0.1860\n",
      "Epoch 8: Total Loss=0.1869\n",
      "Epoch 9: Total Loss=0.1858\n",
      "Updated x: [0.041076939553022385, 0.008485063910484314], Function Value: 0.001759311300702393, Gradient: [0.1745823472738266, -0.11240275204181671]\n",
      "\n",
      "Step 37/40\n",
      "Epoch 0: Total Loss=0.1862\n",
      "Epoch 1: Total Loss=0.1856\n",
      "Epoch 2: Total Loss=0.1857\n",
      "Epoch 3: Total Loss=0.1860\n",
      "Epoch 4: Total Loss=0.1859\n",
      "Epoch 5: Total Loss=0.1851\n",
      "Epoch 6: Total Loss=0.1860\n",
      "Epoch 7: Total Loss=0.1854\n",
      "Epoch 8: Total Loss=0.1855\n",
      "Epoch 9: Total Loss=0.1858\n",
      "Updated x: [0.05444371700286865, 0.01118979137390852], Function Value: 0.003089329693466425, Gradient: [0.19498975574970245, -0.12571105360984802]\n",
      "\n",
      "Step 38/40\n",
      "Epoch 0: Total Loss=0.1848\n",
      "Epoch 1: Total Loss=0.1850\n",
      "Epoch 2: Total Loss=0.1847\n",
      "Epoch 3: Total Loss=0.1853\n",
      "Epoch 4: Total Loss=0.1851\n",
      "Epoch 5: Total Loss=0.1848\n",
      "Epoch 6: Total Loss=0.1851\n",
      "Epoch 7: Total Loss=0.1846\n",
      "Epoch 8: Total Loss=0.1847\n",
      "Epoch 9: Total Loss=0.1845\n",
      "Updated x: [-0.007928844541311264, 0.030606232583522797], Function Value: 0.00099960807710886, Gradient: [0.18441428244113922, -0.12845486402511597]\n",
      "\n",
      "Step 39/40\n",
      "Epoch 0: Total Loss=0.1847\n",
      "Epoch 1: Total Loss=0.1844\n",
      "Epoch 2: Total Loss=0.1853\n",
      "Epoch 3: Total Loss=0.1845\n",
      "Epoch 4: Total Loss=0.1838\n",
      "Epoch 5: Total Loss=0.1837\n",
      "Epoch 6: Total Loss=0.1834\n",
      "Epoch 7: Total Loss=0.1843\n",
      "Epoch 8: Total Loss=0.1845\n",
      "Epoch 9: Total Loss=0.1841\n",
      "Updated x: [0.04210253804922104, 0.046539824455976486], Function Value: 0.003938579000532627, Gradient: [0.220145583152771, -0.14248736202716827]\n",
      "\n",
      "Step 40/40\n",
      "Epoch 0: Total Loss=0.1851\n",
      "Epoch 1: Total Loss=0.1844\n",
      "Epoch 2: Total Loss=0.1832\n",
      "Epoch 3: Total Loss=0.1835\n",
      "Epoch 4: Total Loss=0.1840\n",
      "Epoch 5: Total Loss=0.1839\n",
      "Epoch 6: Total Loss=0.1830\n",
      "Epoch 7: Total Loss=0.1841\n",
      "Epoch 8: Total Loss=0.1827\n",
      "Epoch 9: Total Loss=0.1849\n",
      "Updated x: [0.02637363225221634, -0.05815684422850609], Function Value: 0.004077787045389414, Gradient: [0.22719725966453552, -0.1934106945991516]\n",
      "\n",
      "Step 1/40\n",
      "Epoch 0: Total Loss=5.0534\n",
      "Epoch 1: Total Loss=5.0274\n",
      "Epoch 2: Total Loss=5.0039\n",
      "Epoch 3: Total Loss=4.9792\n",
      "Epoch 4: Total Loss=4.9565\n",
      "Epoch 5: Total Loss=4.9360\n",
      "Epoch 6: Total Loss=4.9131\n",
      "Epoch 7: Total Loss=4.8947\n",
      "Epoch 8: Total Loss=4.8741\n",
      "Epoch 9: Total Loss=4.8553\n",
      "Updated x: [0.7493206262588501, -0.909947395324707], Function Value: 1.3894855976104736, Gradient: [-0.005428890231996775, -0.05135592445731163]\n",
      "\n",
      "Step 2/40\n",
      "Epoch 0: Total Loss=3.6009\n",
      "Epoch 1: Total Loss=3.5861\n",
      "Epoch 2: Total Loss=3.5732\n",
      "Epoch 3: Total Loss=3.5578\n",
      "Epoch 4: Total Loss=3.5462\n",
      "Epoch 5: Total Loss=3.5310\n",
      "Epoch 6: Total Loss=3.5185\n",
      "Epoch 7: Total Loss=3.5096\n",
      "Epoch 8: Total Loss=3.4973\n",
      "Epoch 9: Total Loss=3.4835\n",
      "Updated x: [0.5553374290466309, -0.7876542210578918], Function Value: 0.9287987947463989, Gradient: [-0.015319066122174263, -0.044369086623191833]\n",
      "\n",
      "Step 3/40\n",
      "Epoch 0: Total Loss=2.6061\n",
      "Epoch 1: Total Loss=2.5986\n",
      "Epoch 2: Total Loss=2.5889\n",
      "Epoch 3: Total Loss=2.5813\n",
      "Epoch 4: Total Loss=2.5739\n",
      "Epoch 5: Total Loss=2.5648\n",
      "Epoch 6: Total Loss=2.5575\n",
      "Epoch 7: Total Loss=2.5502\n",
      "Epoch 8: Total Loss=2.5448\n",
      "Epoch 9: Total Loss=2.5374\n",
      "Updated x: [0.49650514125823975, -0.6006028056144714], Function Value: 0.6072410941123962, Gradient: [-0.011285578832030296, -0.0369093082845211]\n",
      "\n",
      "Step 4/40\n",
      "Epoch 0: Total Loss=2.6010\n",
      "Epoch 1: Total Loss=1.4708\n",
      "Epoch 2: Total Loss=1.9023\n",
      "Epoch 3: Total Loss=2.5818\n",
      "Epoch 4: Total Loss=1.4532\n",
      "Epoch 5: Total Loss=1.8841\n",
      "Epoch 6: Total Loss=2.5581\n",
      "Epoch 7: Total Loss=1.4387\n",
      "Epoch 8: Total Loss=1.8695\n",
      "Epoch 9: Total Loss=2.5381\n",
      "Updated x: [0.45352262258529663, -0.5932430624961853], Function Value: 0.557620108127594, Gradient: [-0.007568668574094772, -0.04982205480337143]\n",
      "\n",
      "Step 5/40\n",
      "Epoch 0: Total Loss=1.2195\n",
      "Epoch 1: Total Loss=2.1977\n",
      "Epoch 2: Total Loss=1.2094\n",
      "Epoch 3: Total Loss=2.1844\n",
      "Epoch 4: Total Loss=1.1971\n",
      "Epoch 5: Total Loss=2.1699\n",
      "Epoch 6: Total Loss=1.1900\n",
      "Epoch 7: Total Loss=2.1565\n",
      "Epoch 8: Total Loss=1.1785\n",
      "Epoch 9: Total Loss=2.1387\n",
      "Updated x: [0.42769941687583923, -0.6717958450317383], Function Value: 0.6342364549636841, Gradient: [-0.0011428026482462883, -0.07002349942922592]\n",
      "\n",
      "Step 6/40\n",
      "Epoch 0: Total Loss=0.3393\n",
      "Epoch 1: Total Loss=0.6571\n",
      "Epoch 2: Total Loss=0.3244\n",
      "Epoch 3: Total Loss=0.6605\n",
      "Epoch 4: Total Loss=0.3436\n",
      "Epoch 5: Total Loss=0.3336\n",
      "Epoch 6: Total Loss=0.6521\n",
      "Epoch 7: Total Loss=0.3220\n",
      "Epoch 8: Total Loss=0.6558\n",
      "Epoch 9: Total Loss=0.3369\n",
      "Updated x: [0.3698928952217102, -0.6460919380187988], Function Value: 0.5542555451393127, Gradient: [0.015606848523020744, -0.08365771919488907]\n",
      "\n",
      "Step 7/40\n",
      "Epoch 0: Total Loss=0.2833\n",
      "Epoch 1: Total Loss=0.4896\n",
      "Epoch 2: Total Loss=0.2203\n",
      "Epoch 3: Total Loss=0.2818\n",
      "Epoch 4: Total Loss=0.4899\n",
      "Epoch 5: Total Loss=0.2196\n",
      "Epoch 6: Total Loss=0.2822\n",
      "Epoch 7: Total Loss=0.4877\n",
      "Epoch 8: Total Loss=0.2196\n",
      "Epoch 9: Total Loss=0.2824\n",
      "Updated x: [0.27803879976272583, -0.520744800567627], Function Value: 0.3484807312488556, Gradient: [0.025521311908960342, -0.09648604691028595]\n",
      "\n",
      "Step 8/40\n",
      "Epoch 0: Total Loss=0.2301\n",
      "Epoch 1: Total Loss=0.1927\n",
      "Epoch 2: Total Loss=0.5519\n",
      "Epoch 3: Total Loss=0.1325\n",
      "Epoch 4: Total Loss=0.2537\n",
      "Epoch 5: Total Loss=0.5464\n",
      "Epoch 6: Total Loss=0.1681\n",
      "Epoch 7: Total Loss=0.2279\n",
      "Epoch 8: Total Loss=0.1900\n",
      "Epoch 9: Total Loss=0.5500\n",
      "Updated x: [0.27182209491729736, -0.48032039403915405], Function Value: 0.3045949339866638, Gradient: [0.041463423520326614, -0.10928436368703842]\n",
      "\n",
      "Step 9/40\n",
      "Epoch 0: Total Loss=0.2086\n",
      "Epoch 1: Total Loss=0.1969\n",
      "Epoch 2: Total Loss=0.1416\n",
      "Epoch 3: Total Loss=0.4605\n",
      "Epoch 4: Total Loss=0.2094\n",
      "Epoch 5: Total Loss=0.1951\n",
      "Epoch 6: Total Loss=0.1390\n",
      "Epoch 7: Total Loss=0.4566\n",
      "Epoch 8: Total Loss=0.2073\n",
      "Epoch 9: Total Loss=0.1958\n",
      "Updated x: [0.32589632272720337, -0.3941684663295746], Function Value: 0.26157718896865845, Gradient: [0.06313426047563553, -0.1116756722331047]\n",
      "\n",
      "Step 10/40\n",
      "Epoch 0: Total Loss=0.4682\n",
      "Epoch 1: Total Loss=0.1467\n",
      "Epoch 2: Total Loss=0.2012\n",
      "Epoch 3: Total Loss=0.1391\n",
      "Epoch 4: Total Loss=0.4550\n",
      "Epoch 5: Total Loss=0.1509\n",
      "Epoch 6: Total Loss=0.1305\n",
      "Epoch 7: Total Loss=0.2119\n",
      "Epoch 8: Total Loss=0.1240\n",
      "Epoch 9: Total Loss=0.4612\n",
      "Updated x: [0.3534408509731293, -0.3435901701450348], Function Value: 0.2429746389389038, Gradient: [0.07805739343166351, -0.12294331938028336]\n",
      "\n",
      "Step 11/40\n",
      "Epoch 0: Total Loss=0.1455\n",
      "Epoch 1: Total Loss=0.1259\n",
      "Epoch 2: Total Loss=0.1235\n",
      "Epoch 3: Total Loss=0.4674\n",
      "Epoch 4: Total Loss=0.2418\n",
      "Epoch 5: Total Loss=0.1466\n",
      "Epoch 6: Total Loss=0.1261\n",
      "Epoch 7: Total Loss=0.1227\n",
      "Epoch 8: Total Loss=0.4678\n",
      "Epoch 9: Total Loss=0.2441\n",
      "Updated x: [0.3078233599662781, -0.21208743751049042], Function Value: 0.13973629474639893, Gradient: [0.06228305399417877, -0.07864786684513092]\n",
      "\n",
      "Step 12/40\n",
      "Epoch 0: Total Loss=0.1311\n",
      "Epoch 1: Total Loss=0.1308\n",
      "Epoch 2: Total Loss=0.1315\n",
      "Epoch 3: Total Loss=0.1287\n",
      "Epoch 4: Total Loss=0.1283\n",
      "Epoch 5: Total Loss=0.1269\n",
      "Epoch 6: Total Loss=0.1259\n",
      "Epoch 7: Total Loss=0.1261\n",
      "Epoch 8: Total Loss=0.1252\n",
      "Epoch 9: Total Loss=0.1249\n",
      "Updated x: [0.3469655215740204, -0.1737537831068039], Function Value: 0.1505754441022873, Gradient: [0.09725815802812576, -0.1036139726638794]\n",
      "\n",
      "Step 13/40\n",
      "Epoch 0: Total Loss=0.1496\n",
      "Epoch 1: Total Loss=0.1469\n",
      "Epoch 2: Total Loss=0.1468\n",
      "Epoch 3: Total Loss=0.1457\n",
      "Epoch 4: Total Loss=0.1434\n",
      "Epoch 5: Total Loss=0.1443\n",
      "Epoch 6: Total Loss=0.1427\n",
      "Epoch 7: Total Loss=0.1429\n",
      "Epoch 8: Total Loss=0.1427\n",
      "Epoch 9: Total Loss=0.1393\n",
      "Updated x: [0.4664991796016693, -0.027865856885910034], Function Value: 0.21839798986911774, Gradient: [0.1539323776960373, -0.0766126960515976]\n",
      "\n",
      "Step 14/40\n",
      "Epoch 0: Total Loss=0.1403\n",
      "Epoch 1: Total Loss=0.1537\n",
      "Epoch 2: Total Loss=0.1317\n",
      "Epoch 3: Total Loss=0.1388\n",
      "Epoch 4: Total Loss=0.1509\n",
      "Epoch 5: Total Loss=0.1307\n",
      "Epoch 6: Total Loss=0.1374\n",
      "Epoch 7: Total Loss=0.1507\n",
      "Epoch 8: Total Loss=0.1296\n",
      "Epoch 9: Total Loss=0.1351\n",
      "Updated x: [0.32308074831962585, -0.058491647243499756], Function Value: 0.10780243575572968, Gradient: [0.16080722212791443, -0.06882920116186142]\n",
      "\n",
      "Step 15/40\n",
      "Epoch 0: Total Loss=0.1502\n",
      "Epoch 1: Total Loss=0.1020\n",
      "Epoch 2: Total Loss=0.1479\n",
      "Epoch 3: Total Loss=0.1008\n",
      "Epoch 4: Total Loss=0.1487\n",
      "Epoch 5: Total Loss=0.1023\n",
      "Epoch 6: Total Loss=0.1486\n",
      "Epoch 7: Total Loss=0.0999\n",
      "Epoch 8: Total Loss=0.1458\n",
      "Epoch 9: Total Loss=0.1003\n",
      "Updated x: [0.21244563162326813, -0.056728970259428024], Function Value: 0.04835132509469986, Gradient: [0.1400900036096573, -0.058420464396476746]\n",
      "\n",
      "Step 16/40\n",
      "Epoch 0: Total Loss=0.1093\n",
      "Epoch 1: Total Loss=0.1098\n",
      "Epoch 2: Total Loss=0.1027\n",
      "Epoch 3: Total Loss=0.1150\n",
      "Epoch 4: Total Loss=0.0965\n",
      "Epoch 5: Total Loss=0.1053\n",
      "Epoch 6: Total Loss=0.1067\n",
      "Epoch 7: Total Loss=0.0977\n",
      "Epoch 8: Total Loss=0.1113\n",
      "Epoch 9: Total Loss=0.0943\n",
      "Updated x: [0.20129315555095673, -0.14284498989582062], Function Value: 0.06092362850904465, Gradient: [0.09562823921442032, -0.05773088335990906]\n",
      "\n",
      "Step 17/40\n",
      "Epoch 0: Total Loss=0.0953\n",
      "Epoch 1: Total Loss=0.1027\n",
      "Epoch 2: Total Loss=0.0962\n",
      "Epoch 3: Total Loss=0.0944\n",
      "Epoch 4: Total Loss=0.1017\n",
      "Epoch 5: Total Loss=0.0945\n",
      "Epoch 6: Total Loss=0.0928\n",
      "Epoch 7: Total Loss=0.1005\n",
      "Epoch 8: Total Loss=0.0962\n",
      "Epoch 9: Total Loss=0.0912\n",
      "Updated x: [0.0888013169169426, -0.06141124665737152], Function Value: 0.011657015420496464, Gradient: [0.03334974870085716, -0.014629463665187359]\n",
      "\n",
      "Step 18/40\n",
      "Epoch 0: Total Loss=0.0922\n",
      "Epoch 1: Total Loss=0.0942\n",
      "Epoch 2: Total Loss=0.0871\n",
      "Epoch 3: Total Loss=0.0807\n",
      "Epoch 4: Total Loss=0.0914\n",
      "Epoch 5: Total Loss=0.0920\n",
      "Epoch 6: Total Loss=0.0860\n",
      "Epoch 7: Total Loss=0.0907\n",
      "Epoch 8: Total Loss=0.0935\n",
      "Epoch 9: Total Loss=0.0858\n",
      "Updated x: [-0.055540017783641815, -0.01580929011106491], Function Value: 0.003334627253934741, Gradient: [0.0034733382053673267, 0.0045073372311890125]\n",
      "\n",
      "Step 19/40\n",
      "Epoch 0: Total Loss=0.0804\n",
      "Epoch 1: Total Loss=0.0866\n",
      "Epoch 2: Total Loss=0.0820\n",
      "Epoch 3: Total Loss=0.0905\n",
      "Epoch 4: Total Loss=0.0802\n",
      "Epoch 5: Total Loss=0.0866\n",
      "Epoch 6: Total Loss=0.0831\n",
      "Epoch 7: Total Loss=0.0910\n",
      "Epoch 8: Total Loss=0.0801\n",
      "Epoch 9: Total Loss=0.0876\n",
      "Updated x: [-0.16026601195335388, -0.10328201204538345], Function Value: 0.03635236993432045, Gradient: [-0.024020789191126823, -0.003294306807219982]\n",
      "\n",
      "Step 20/40\n",
      "Epoch 0: Total Loss=0.0748\n",
      "Epoch 1: Total Loss=0.0907\n",
      "Epoch 2: Total Loss=0.0928\n",
      "Epoch 3: Total Loss=0.0783\n",
      "Epoch 4: Total Loss=0.0732\n",
      "Epoch 5: Total Loss=0.0760\n",
      "Epoch 6: Total Loss=0.0983\n",
      "Epoch 7: Total Loss=0.0804\n",
      "Epoch 8: Total Loss=0.0785\n",
      "Epoch 9: Total Loss=0.0744\n",
      "Updated x: [-0.16350625455379486, -0.05395978316664696], Function Value: 0.029645953327417374, Gradient: [-0.025850215926766396, 0.007521023042500019]\n",
      "\n",
      "Step 21/40\n",
      "Epoch 0: Total Loss=0.0712\n",
      "Epoch 1: Total Loss=0.0912\n",
      "Epoch 2: Total Loss=0.0725\n",
      "Epoch 3: Total Loss=0.0777\n",
      "Epoch 4: Total Loss=0.0899\n",
      "Epoch 5: Total Loss=0.0710\n",
      "Epoch 6: Total Loss=0.0906\n",
      "Epoch 7: Total Loss=0.0723\n",
      "Epoch 8: Total Loss=0.0774\n",
      "Epoch 9: Total Loss=0.0895\n",
      "Updated x: [-0.24837937951087952, -0.08382946252822876], Function Value: 0.06871969252824783, Gradient: [-0.030771074816584587, 0.002496896078810096]\n",
      "\n",
      "Step 22/40\n",
      "Epoch 0: Total Loss=0.0843\n",
      "Epoch 1: Total Loss=0.0841\n",
      "Epoch 2: Total Loss=0.0835\n",
      "Epoch 3: Total Loss=0.0825\n",
      "Epoch 4: Total Loss=0.0824\n",
      "Epoch 5: Total Loss=0.0828\n",
      "Epoch 6: Total Loss=0.0822\n",
      "Epoch 7: Total Loss=0.0811\n",
      "Epoch 8: Total Loss=0.0824\n",
      "Epoch 9: Total Loss=0.0813\n",
      "Updated x: [-0.24390627443790436, -0.04817743971943855], Function Value: 0.061811335384845734, Gradient: [-0.06723948568105698, -0.01356962975114584]\n",
      "\n",
      "Step 23/40\n",
      "Epoch 0: Total Loss=0.0797\n",
      "Epoch 1: Total Loss=0.0789\n",
      "Epoch 2: Total Loss=0.0799\n",
      "Epoch 3: Total Loss=0.0792\n",
      "Epoch 4: Total Loss=0.0792\n",
      "Epoch 5: Total Loss=0.0790\n",
      "Epoch 6: Total Loss=0.0789\n",
      "Epoch 7: Total Loss=0.0786\n",
      "Epoch 8: Total Loss=0.0785\n",
      "Epoch 9: Total Loss=0.0792\n",
      "Updated x: [-0.10814665257930756, -0.003156140446662903], Function Value: 0.01170566026121378, Gradient: [-0.06343839317560196, -0.00010495883907424286]\n",
      "\n",
      "Step 24/40\n",
      "Epoch 0: Total Loss=0.0793\n",
      "Epoch 1: Total Loss=0.0782\n",
      "Epoch 2: Total Loss=0.0661\n",
      "Epoch 3: Total Loss=0.0786\n",
      "Epoch 4: Total Loss=0.0776\n",
      "Epoch 5: Total Loss=0.0660\n",
      "Epoch 6: Total Loss=0.0768\n",
      "Epoch 7: Total Loss=0.0775\n",
      "Epoch 8: Total Loss=0.0649\n",
      "Epoch 9: Total Loss=0.0780\n",
      "Updated x: [-0.14394712448120117, -0.07137012481689453], Function Value: 0.025814469903707504, Gradient: [-0.07293933629989624, -0.0024878953117877245]\n",
      "\n",
      "Step 25/40\n",
      "Epoch 0: Total Loss=0.0732\n",
      "Epoch 1: Total Loss=0.0712\n",
      "Epoch 2: Total Loss=0.0741\n",
      "Epoch 3: Total Loss=0.0716\n",
      "Epoch 4: Total Loss=0.0745\n",
      "Epoch 5: Total Loss=0.0709\n",
      "Epoch 6: Total Loss=0.0732\n",
      "Epoch 7: Total Loss=0.0718\n",
      "Epoch 8: Total Loss=0.0742\n",
      "Epoch 9: Total Loss=0.0718\n",
      "Updated x: [0.05300894379615784, -0.20902007818222046], Function Value: 0.0464993417263031, Gradient: [-0.024944277480244637, -0.028186429291963577]\n",
      "\n",
      "Step 26/40\n",
      "Epoch 0: Total Loss=0.0694\n",
      "Epoch 1: Total Loss=0.0688\n",
      "Epoch 2: Total Loss=0.0699\n",
      "Epoch 3: Total Loss=0.0664\n",
      "Epoch 4: Total Loss=0.0680\n",
      "Epoch 5: Total Loss=0.0680\n",
      "Epoch 6: Total Loss=0.0692\n",
      "Epoch 7: Total Loss=0.0694\n",
      "Epoch 8: Total Loss=0.0663\n",
      "Epoch 9: Total Loss=0.0686\n",
      "Updated x: [0.04750419035553932, -0.17812398076057434], Function Value: 0.033984798938035965, Gradient: [-0.015982696786522865, -0.01724979281425476]\n",
      "\n",
      "Step 27/40\n",
      "Epoch 0: Total Loss=0.0708\n",
      "Epoch 1: Total Loss=0.0656\n",
      "Epoch 2: Total Loss=0.0653\n",
      "Epoch 3: Total Loss=0.0705\n",
      "Epoch 4: Total Loss=0.0654\n",
      "Epoch 5: Total Loss=0.0656\n",
      "Epoch 6: Total Loss=0.0704\n",
      "Epoch 7: Total Loss=0.0668\n",
      "Epoch 8: Total Loss=0.0655\n",
      "Epoch 9: Total Loss=0.0703\n",
      "Updated x: [0.09852603077888489, 0.00822417438030243], Function Value: 0.009775016456842422, Gradient: [-0.0222124345600605, 0.0009717310313135386]\n",
      "\n",
      "Step 28/40\n",
      "Epoch 0: Total Loss=0.0682\n",
      "Epoch 1: Total Loss=0.0696\n",
      "Epoch 2: Total Loss=0.0643\n",
      "Epoch 3: Total Loss=0.0682\n",
      "Epoch 4: Total Loss=0.0690\n",
      "Epoch 5: Total Loss=0.0650\n",
      "Epoch 6: Total Loss=0.0643\n",
      "Epoch 7: Total Loss=0.0680\n",
      "Epoch 8: Total Loss=0.0697\n",
      "Epoch 9: Total Loss=0.0647\n",
      "Updated x: [-0.032359614968299866, 0.004774749279022217], Function Value: 0.001069942838512361, Gradient: [-0.02384631708264351, -0.0017063528066501021]\n",
      "\n",
      "Step 29/40\n",
      "Epoch 0: Total Loss=0.0689\n",
      "Epoch 1: Total Loss=0.0674\n",
      "Epoch 2: Total Loss=0.0639\n",
      "Epoch 3: Total Loss=0.0636\n",
      "Epoch 4: Total Loss=0.0688\n",
      "Epoch 5: Total Loss=0.0676\n",
      "Epoch 6: Total Loss=0.0646\n",
      "Epoch 7: Total Loss=0.0636\n",
      "Epoch 8: Total Loss=0.0694\n",
      "Epoch 9: Total Loss=0.0678\n",
      "Updated x: [0.02320677414536476, 0.08345701545476913], Function Value: 0.007503627799451351, Gradient: [-0.024136608466506004, 0.012968374416232109]\n",
      "\n",
      "Step 30/40\n",
      "Epoch 0: Total Loss=0.0623\n",
      "Epoch 1: Total Loss=0.0636\n",
      "Epoch 2: Total Loss=0.0631\n",
      "Epoch 3: Total Loss=0.0691\n",
      "Epoch 4: Total Loss=0.0680\n",
      "Epoch 5: Total Loss=0.0639\n",
      "Epoch 6: Total Loss=0.0628\n",
      "Epoch 7: Total Loss=0.0671\n",
      "Epoch 8: Total Loss=0.0692\n",
      "Epoch 9: Total Loss=0.0633\n",
      "Updated x: [0.10905550420284271, -0.10307993739843369], Function Value: 0.022518575191497803, Gradient: [-0.009542549028992653, -0.009750522673130035]\n",
      "\n",
      "Step 31/40\n",
      "Epoch 0: Total Loss=0.0641\n",
      "Epoch 1: Total Loss=0.0624\n",
      "Epoch 2: Total Loss=0.0634\n",
      "Epoch 3: Total Loss=0.0685\n",
      "Epoch 4: Total Loss=0.0681\n",
      "Epoch 5: Total Loss=0.0630\n",
      "Epoch 6: Total Loss=0.0633\n",
      "Epoch 7: Total Loss=0.0635\n",
      "Epoch 8: Total Loss=0.0684\n",
      "Epoch 9: Total Loss=0.0674\n",
      "Updated x: [0.1864367574453354, -0.10114052891731262], Function Value: 0.04498807340860367, Gradient: [-0.0006721063400618732, -0.0148705979809165]\n",
      "\n",
      "Step 32/40\n",
      "Epoch 0: Total Loss=0.0776\n",
      "Epoch 1: Total Loss=0.0772\n",
      "Epoch 2: Total Loss=0.0769\n",
      "Epoch 3: Total Loss=0.0763\n",
      "Epoch 4: Total Loss=0.0761\n",
      "Epoch 5: Total Loss=0.0757\n",
      "Epoch 6: Total Loss=0.0757\n",
      "Epoch 7: Total Loss=0.0757\n",
      "Epoch 8: Total Loss=0.0757\n",
      "Epoch 9: Total Loss=0.0751\n",
      "Updated x: [0.0987752228975296, -0.2962072193622589], Function Value: 0.09749525785446167, Gradient: [0.005361518356949091, -0.04620051011443138]\n",
      "\n",
      "Step 33/40\n",
      "Epoch 0: Total Loss=0.0825\n",
      "Epoch 1: Total Loss=0.0826\n",
      "Epoch 2: Total Loss=0.0822\n",
      "Epoch 3: Total Loss=0.0822\n",
      "Epoch 4: Total Loss=0.0819\n",
      "Epoch 5: Total Loss=0.0819\n",
      "Epoch 6: Total Loss=0.0820\n",
      "Epoch 7: Total Loss=0.0819\n",
      "Epoch 8: Total Loss=0.0816\n",
      "Epoch 9: Total Loss=0.0811\n",
      "Updated x: [0.1284184753894806, -0.27316102385520935], Function Value: 0.09110824763774872, Gradient: [0.020382266491651535, -0.06639103591442108]\n",
      "\n",
      "Step 34/40\n",
      "Epoch 0: Total Loss=0.0795\n",
      "Epoch 1: Total Loss=0.0804\n",
      "Epoch 2: Total Loss=0.0716\n",
      "Epoch 3: Total Loss=0.0791\n",
      "Epoch 4: Total Loss=0.0800\n",
      "Epoch 5: Total Loss=0.0709\n",
      "Epoch 6: Total Loss=0.0795\n",
      "Epoch 7: Total Loss=0.0805\n",
      "Epoch 8: Total Loss=0.0712\n",
      "Epoch 9: Total Loss=0.0792\n",
      "Updated x: [0.09561935067176819, -0.09723764657974243], Function Value: 0.018598221242427826, Gradient: [0.02224271558225155, -0.06382475793361664]\n",
      "\n",
      "Step 35/40\n",
      "Epoch 0: Total Loss=0.0798\n",
      "Epoch 1: Total Loss=0.0669\n",
      "Epoch 2: Total Loss=0.0799\n",
      "Epoch 3: Total Loss=0.0663\n",
      "Epoch 4: Total Loss=0.0798\n",
      "Epoch 5: Total Loss=0.0666\n",
      "Epoch 6: Total Loss=0.0791\n",
      "Epoch 7: Total Loss=0.0665\n",
      "Epoch 8: Total Loss=0.0793\n",
      "Epoch 9: Total Loss=0.0665\n",
      "Updated x: [0.06236693263053894, 0.029013395309448242], Function Value: 0.004731411579996347, Gradient: [0.017994796857237816, -0.04520693048834801]\n",
      "\n",
      "Step 36/40\n",
      "Epoch 0: Total Loss=0.0726\n",
      "Epoch 1: Total Loss=0.0682\n",
      "Epoch 2: Total Loss=0.0689\n",
      "Epoch 3: Total Loss=0.0725\n",
      "Epoch 4: Total Loss=0.0679\n",
      "Epoch 5: Total Loss=0.0723\n",
      "Epoch 6: Total Loss=0.0676\n",
      "Epoch 7: Total Loss=0.0685\n",
      "Epoch 8: Total Loss=0.0724\n",
      "Epoch 9: Total Loss=0.0674\n",
      "Updated x: [0.03311162441968918, 0.03339523822069168], Function Value: 0.0022116214968264103, Gradient: [0.006483728066086769, -0.04424881562590599]\n",
      "\n",
      "Step 37/40\n",
      "Epoch 0: Total Loss=0.0666\n",
      "Epoch 1: Total Loss=0.0657\n",
      "Epoch 2: Total Loss=0.0725\n",
      "Epoch 3: Total Loss=0.0663\n",
      "Epoch 4: Total Loss=0.0644\n",
      "Epoch 5: Total Loss=0.0724\n",
      "Epoch 6: Total Loss=0.0659\n",
      "Epoch 7: Total Loss=0.0641\n",
      "Epoch 8: Total Loss=0.0726\n",
      "Epoch 9: Total Loss=0.0657\n",
      "Updated x: [0.07664797455072403, 0.07457028329372406], Function Value: 0.01143563911318779, Gradient: [0.002266098279505968, -0.02632855996489525]\n",
      "\n",
      "Step 38/40\n",
      "Epoch 0: Total Loss=0.0622\n",
      "Epoch 1: Total Loss=0.0631\n",
      "Epoch 2: Total Loss=0.0727\n",
      "Epoch 3: Total Loss=0.0621\n",
      "Epoch 4: Total Loss=0.0636\n",
      "Epoch 5: Total Loss=0.0634\n",
      "Epoch 6: Total Loss=0.0699\n",
      "Epoch 7: Total Loss=0.0621\n",
      "Epoch 8: Total Loss=0.0638\n",
      "Epoch 9: Total Loss=0.0724\n",
      "Updated x: [-0.0073503777384757996, -0.009232208132743835], Function Value: 0.00013926171232014894, Gradient: [-0.0017250311793759465, -0.03866574168205261]\n",
      "\n",
      "Step 39/40\n",
      "Epoch 0: Total Loss=0.0628\n",
      "Epoch 1: Total Loss=0.0625\n",
      "Epoch 2: Total Loss=0.0707\n",
      "Epoch 3: Total Loss=0.0619\n",
      "Epoch 4: Total Loss=0.0620\n",
      "Epoch 5: Total Loss=0.0617\n",
      "Epoch 6: Total Loss=0.0706\n",
      "Epoch 7: Total Loss=0.0619\n",
      "Epoch 8: Total Loss=0.0621\n",
      "Epoch 9: Total Loss=0.0625\n",
      "Updated x: [0.03165778890252113, 0.04867645353078842], Function Value: 0.003371612634509802, Gradient: [-0.002383648417890072, -0.019749997183680534]\n",
      "\n",
      "Step 40/40\n",
      "Epoch 0: Total Loss=0.0636\n",
      "Epoch 1: Total Loss=0.0591\n",
      "Epoch 2: Total Loss=0.0645\n",
      "Epoch 3: Total Loss=0.0676\n",
      "Epoch 4: Total Loss=0.0646\n",
      "Epoch 5: Total Loss=0.0614\n",
      "Epoch 6: Total Loss=0.0599\n",
      "Epoch 7: Total Loss=0.0721\n",
      "Epoch 8: Total Loss=0.0628\n",
      "Epoch 9: Total Loss=0.0644\n",
      "Updated x: [0.08111211657524109, 0.10501021146774292], Function Value: 0.01760631985962391, Gradient: [0.000722197990398854, -0.018980050459504128]\n",
      "\n",
      "Step 1/40\n",
      "Epoch 0: Total Loss=69.5132\n",
      "Epoch 1: Total Loss=48.8497\n",
      "Epoch 2: Total Loss=26.1730\n",
      "Epoch 3: Total Loss=14.4491\n",
      "Epoch 4: Total Loss=11.4553\n",
      "Epoch 5: Total Loss=10.3832\n",
      "Epoch 6: Total Loss=9.9505\n",
      "Epoch 7: Total Loss=9.2616\n",
      "Epoch 8: Total Loss=8.9546\n",
      "Epoch 9: Total Loss=8.7015\n",
      "Updated x: [0.8399245142936707, -0.8368268013000488], Function Value: 1.4057523012161255, Gradient: [0.915778636932373, -1.4006394147872925]\n",
      "\n",
      "Step 2/40\n",
      "Epoch 0: Total Loss=7.4518\n",
      "Epoch 1: Total Loss=7.1006\n",
      "Epoch 2: Total Loss=6.7779\n",
      "Epoch 3: Total Loss=6.5562\n",
      "Epoch 4: Total Loss=6.5332\n",
      "Epoch 5: Total Loss=6.4176\n",
      "Epoch 6: Total Loss=6.2705\n",
      "Epoch 7: Total Loss=6.3959\n",
      "Epoch 8: Total Loss=6.2488\n",
      "Epoch 9: Total Loss=6.1753\n",
      "Updated x: [0.7797883749008179, -0.8077681660652161], Function Value: 1.260559320449829, Gradient: [1.176617980003357, -1.5754625797271729]\n",
      "\n",
      "Step 3/40\n",
      "Epoch 0: Total Loss=5.7259\n",
      "Epoch 1: Total Loss=5.8502\n",
      "Epoch 2: Total Loss=5.5119\n",
      "Epoch 3: Total Loss=5.5504\n",
      "Epoch 4: Total Loss=5.5685\n",
      "Epoch 5: Total Loss=5.2764\n",
      "Epoch 6: Total Loss=5.1853\n",
      "Epoch 7: Total Loss=5.1378\n",
      "Epoch 8: Total Loss=5.0258\n",
      "Epoch 9: Total Loss=5.1073\n",
      "Updated x: [0.8150700330734253, -0.7860315442085266], Function Value: 1.2821848392486572, Gradient: [0.8563186526298523, -1.5035043954849243]\n",
      "\n",
      "Step 4/40\n",
      "Epoch 0: Total Loss=5.8780\n",
      "Epoch 1: Total Loss=5.6723\n",
      "Epoch 2: Total Loss=5.6558\n",
      "Epoch 3: Total Loss=5.6133\n",
      "Epoch 4: Total Loss=5.5360\n",
      "Epoch 5: Total Loss=5.6550\n",
      "Epoch 6: Total Loss=5.3267\n",
      "Epoch 7: Total Loss=5.3901\n",
      "Epoch 8: Total Loss=5.2533\n",
      "Epoch 9: Total Loss=5.1747\n",
      "Updated x: [0.8649023771286011, -0.771126389503479], Function Value: 1.3426920175552368, Gradient: [0.5683269500732422, -1.5447142124176025]\n",
      "\n",
      "Step 5/40\n",
      "Epoch 0: Total Loss=5.1479\n",
      "Epoch 1: Total Loss=5.0312\n",
      "Epoch 2: Total Loss=5.0081\n",
      "Epoch 3: Total Loss=4.9653\n",
      "Epoch 4: Total Loss=4.8978\n",
      "Epoch 5: Total Loss=4.8464\n",
      "Epoch 6: Total Loss=4.7894\n",
      "Epoch 7: Total Loss=4.6917\n",
      "Epoch 8: Total Loss=4.6628\n",
      "Epoch 9: Total Loss=4.6700\n",
      "Updated x: [0.898703932762146, -0.6821262836456299], Function Value: 1.2729649543762207, Gradient: [0.11963050067424774, -1.7650271654129028]\n",
      "\n",
      "Step 6/40\n",
      "Epoch 0: Total Loss=4.7808\n",
      "Epoch 1: Total Loss=3.7957\n",
      "Epoch 2: Total Loss=3.4372\n",
      "Epoch 3: Total Loss=3.1948\n",
      "Epoch 4: Total Loss=3.0128\n",
      "Epoch 5: Total Loss=2.8623\n",
      "Epoch 6: Total Loss=2.6979\n",
      "Epoch 7: Total Loss=2.5590\n",
      "Epoch 8: Total Loss=2.4354\n",
      "Epoch 9: Total Loss=2.3337\n",
      "Updated x: [0.7158292531967163, -0.645289957523346], Function Value: 0.9288106560707092, Gradient: [0.8568829894065857, -0.5333095192909241]\n",
      "\n",
      "Step 7/40\n",
      "Epoch 0: Total Loss=2.4459\n",
      "Epoch 1: Total Loss=2.3371\n",
      "Epoch 2: Total Loss=2.2617\n",
      "Epoch 3: Total Loss=2.3444\n",
      "Epoch 4: Total Loss=2.2574\n",
      "Epoch 5: Total Loss=2.2081\n",
      "Epoch 6: Total Loss=2.2765\n",
      "Epoch 7: Total Loss=2.2178\n",
      "Epoch 8: Total Loss=2.1724\n",
      "Epoch 9: Total Loss=2.2486\n",
      "Updated x: [0.7746599912643433, -0.6921836137771606], Function Value: 1.0792162418365479, Gradient: [0.6854066848754883, -0.7061693668365479]\n",
      "\n",
      "Step 8/40\n",
      "Epoch 0: Total Loss=2.1732\n",
      "Epoch 1: Total Loss=2.0674\n",
      "Epoch 2: Total Loss=2.0312\n",
      "Epoch 3: Total Loss=2.0479\n",
      "Epoch 4: Total Loss=2.1044\n",
      "Epoch 5: Total Loss=2.0166\n",
      "Epoch 6: Total Loss=2.0017\n",
      "Epoch 7: Total Loss=2.0352\n",
      "Epoch 8: Total Loss=2.0173\n",
      "Epoch 9: Total Loss=1.9967\n",
      "Updated x: [0.7508770823478699, -0.7681546807289124], Function Value: 1.1538779735565186, Gradient: [0.6092097163200378, -0.2331332564353943]\n",
      "\n",
      "Step 9/40\n",
      "Epoch 0: Total Loss=1.6120\n",
      "Epoch 1: Total Loss=1.6022\n",
      "Epoch 2: Total Loss=1.6008\n",
      "Epoch 3: Total Loss=1.5995\n",
      "Epoch 4: Total Loss=1.5963\n",
      "Epoch 5: Total Loss=1.5951\n",
      "Epoch 6: Total Loss=1.5970\n",
      "Epoch 7: Total Loss=1.5927\n",
      "Epoch 8: Total Loss=1.5942\n",
      "Epoch 9: Total Loss=1.5905\n",
      "Updated x: [0.7309116721153259, -0.7555899024009705], Function Value: 1.1051480770111084, Gradient: [0.539760410785675, -0.37412771582603455]\n",
      "\n",
      "Step 10/40\n",
      "Epoch 0: Total Loss=1.1710\n",
      "Epoch 1: Total Loss=1.1219\n",
      "Epoch 2: Total Loss=1.0609\n",
      "Epoch 3: Total Loss=1.1096\n",
      "Epoch 4: Total Loss=1.0411\n",
      "Epoch 5: Total Loss=1.0551\n",
      "Epoch 6: Total Loss=1.0866\n",
      "Epoch 7: Total Loss=1.0524\n",
      "Epoch 8: Total Loss=1.0711\n",
      "Epoch 9: Total Loss=1.0512\n",
      "Updated x: [0.7661470770835876, -0.6421484351158142], Function Value: 0.9993360042572021, Gradient: [0.43266749382019043, -0.4549688696861267]\n",
      "\n",
      "Step 11/40\n",
      "Epoch 0: Total Loss=1.1589\n",
      "Epoch 1: Total Loss=1.1515\n",
      "Epoch 2: Total Loss=1.1486\n",
      "Epoch 3: Total Loss=1.1570\n",
      "Epoch 4: Total Loss=1.1450\n",
      "Epoch 5: Total Loss=1.1635\n",
      "Epoch 6: Total Loss=1.1469\n",
      "Epoch 7: Total Loss=1.1432\n",
      "Epoch 8: Total Loss=1.1432\n",
      "Epoch 9: Total Loss=1.1435\n",
      "Updated x: [0.7357953190803528, -0.5732976198196411], Function Value: 0.8700649738311768, Gradient: [0.32623612880706787, 0.09826301783323288]\n",
      "\n",
      "Step 12/40\n",
      "Epoch 0: Total Loss=26.0946\n",
      "Epoch 1: Total Loss=9.1097\n",
      "Epoch 2: Total Loss=8.3058\n",
      "Epoch 3: Total Loss=7.7069\n",
      "Epoch 4: Total Loss=7.2443\n",
      "Epoch 5: Total Loss=6.6734\n",
      "Epoch 6: Total Loss=6.2403\n",
      "Epoch 7: Total Loss=5.6960\n",
      "Epoch 8: Total Loss=5.3275\n",
      "Epoch 9: Total Loss=4.7751\n",
      "Updated x: [0.6527565121650696, -0.6046581268310547], Function Value: 0.7917025089263916, Gradient: [0.9123566150665283, -0.9145727157592773]\n",
      "\n",
      "Step 13/40\n",
      "Epoch 0: Total Loss=3.5196\n",
      "Epoch 1: Total Loss=3.0500\n",
      "Epoch 2: Total Loss=2.7305\n",
      "Epoch 3: Total Loss=2.5471\n",
      "Epoch 4: Total Loss=2.4130\n",
      "Epoch 5: Total Loss=2.3185\n",
      "Epoch 6: Total Loss=2.2457\n",
      "Epoch 7: Total Loss=2.1991\n",
      "Epoch 8: Total Loss=2.1591\n",
      "Epoch 9: Total Loss=2.1376\n",
      "Updated x: [0.5878837704658508, -0.6185224652290344], Function Value: 0.7281773686408997, Gradient: [0.37394243478775024, -0.028451023623347282]\n",
      "\n",
      "Step 14/40\n",
      "Epoch 0: Total Loss=2.0924\n",
      "Epoch 1: Total Loss=2.0320\n",
      "Epoch 2: Total Loss=2.0116\n",
      "Epoch 3: Total Loss=2.0146\n",
      "Epoch 4: Total Loss=1.9730\n",
      "Epoch 5: Total Loss=1.9706\n",
      "Epoch 6: Total Loss=1.9930\n",
      "Epoch 7: Total Loss=1.9550\n",
      "Epoch 8: Total Loss=1.9463\n",
      "Epoch 9: Total Loss=1.9642\n",
      "Updated x: [0.567822277545929, -0.63275545835495], Function Value: 0.7228016257286072, Gradient: [0.36502009630203247, -0.07460831850767136]\n",
      "\n",
      "Step 15/40\n",
      "Epoch 0: Total Loss=1.9889\n",
      "Epoch 1: Total Loss=1.9712\n",
      "Epoch 2: Total Loss=1.9556\n",
      "Epoch 3: Total Loss=1.9653\n",
      "Epoch 4: Total Loss=1.9378\n",
      "Epoch 5: Total Loss=1.9420\n",
      "Epoch 6: Total Loss=1.9244\n",
      "Epoch 7: Total Loss=1.9291\n",
      "Epoch 8: Total Loss=1.9133\n",
      "Epoch 9: Total Loss=1.9083\n",
      "Updated x: [0.5396016836166382, -0.4917147755622864], Function Value: 0.5329533815383911, Gradient: [0.32625913619995117, -0.7669594883918762]\n",
      "\n",
      "Step 16/40\n",
      "Epoch 0: Total Loss=2.1922\n",
      "Epoch 1: Total Loss=1.6628\n",
      "Epoch 2: Total Loss=1.4192\n",
      "Epoch 3: Total Loss=1.2768\n",
      "Epoch 4: Total Loss=1.1915\n",
      "Epoch 5: Total Loss=1.1320\n",
      "Epoch 6: Total Loss=1.0807\n",
      "Epoch 7: Total Loss=1.0418\n",
      "Epoch 8: Total Loss=1.0163\n",
      "Epoch 9: Total Loss=0.9820\n",
      "Updated x: [0.5285192728042603, -0.5343161225318909], Function Value: 0.5648263692855835, Gradient: [0.6107630133628845, -0.6509723663330078]\n",
      "\n",
      "Step 17/40\n",
      "Epoch 0: Total Loss=1.7171\n",
      "Epoch 1: Total Loss=1.7904\n",
      "Epoch 2: Total Loss=1.7282\n",
      "Epoch 3: Total Loss=1.6533\n",
      "Epoch 4: Total Loss=1.7415\n",
      "Epoch 5: Total Loss=1.6836\n",
      "Epoch 6: Total Loss=1.6230\n",
      "Epoch 7: Total Loss=1.7098\n",
      "Epoch 8: Total Loss=1.6552\n",
      "Epoch 9: Total Loss=1.5991\n",
      "Updated x: [0.1536206603050232, -0.4698609709739685], Function Value: 0.24436864256858826, Gradient: [-0.8605250716209412, -0.5501270890235901]\n",
      "\n",
      "Step 18/40\n",
      "Epoch 0: Total Loss=2.3302\n",
      "Epoch 1: Total Loss=2.1744\n",
      "Epoch 2: Total Loss=2.3212\n",
      "Epoch 3: Total Loss=2.3118\n",
      "Epoch 4: Total Loss=2.1178\n",
      "Epoch 5: Total Loss=2.2484\n",
      "Epoch 6: Total Loss=2.2924\n",
      "Epoch 7: Total Loss=2.2222\n",
      "Epoch 8: Total Loss=2.1224\n",
      "Epoch 9: Total Loss=2.2867\n",
      "Updated x: [0.3589284420013428, -0.3512552082538605], Function Value: 0.2522098422050476, Gradient: [0.17315414547920227, 0.09317632764577866]\n",
      "\n",
      "Step 19/40\n",
      "Epoch 0: Total Loss=2.0540\n",
      "Epoch 1: Total Loss=2.0492\n",
      "Epoch 2: Total Loss=2.0492\n",
      "Epoch 3: Total Loss=2.0485\n",
      "Epoch 4: Total Loss=2.0467\n",
      "Epoch 5: Total Loss=2.0472\n",
      "Epoch 6: Total Loss=2.0445\n",
      "Epoch 7: Total Loss=2.0441\n",
      "Epoch 8: Total Loss=2.0436\n",
      "Epoch 9: Total Loss=2.0430\n",
      "Updated x: [0.19387374818325043, -0.36788347363471985], Function Value: 0.17292527854442596, Gradient: [-0.5060152411460876, -0.1810617297887802]\n",
      "\n",
      "Step 20/40\n",
      "Epoch 0: Total Loss=1.6300\n",
      "Epoch 1: Total Loss=1.4752\n",
      "Epoch 2: Total Loss=1.5358\n",
      "Epoch 3: Total Loss=1.5221\n",
      "Epoch 4: Total Loss=1.4567\n",
      "Epoch 5: Total Loss=1.5827\n",
      "Epoch 6: Total Loss=1.4268\n",
      "Epoch 7: Total Loss=1.5923\n",
      "Epoch 8: Total Loss=1.4243\n",
      "Epoch 9: Total Loss=1.5773\n",
      "Updated x: [0.1846439391374588, -0.3351486325263977], Function Value: 0.1464179903268814, Gradient: [-0.4755406975746155, -0.1371466964483261]\n",
      "\n",
      "Step 21/40\n",
      "Epoch 0: Total Loss=1.1490\n",
      "Epoch 1: Total Loss=1.1142\n",
      "Epoch 2: Total Loss=1.1013\n",
      "Epoch 3: Total Loss=1.0945\n",
      "Epoch 4: Total Loss=1.0898\n",
      "Epoch 5: Total Loss=1.0899\n",
      "Epoch 6: Total Loss=1.0879\n",
      "Epoch 7: Total Loss=1.0828\n",
      "Epoch 8: Total Loss=1.0797\n",
      "Epoch 9: Total Loss=1.0789\n",
      "Updated x: [0.10680540651082993, -0.3438646197319031], Function Value: 0.1296502649784088, Gradient: [-0.4395158886909485, -0.1552637815475464]\n",
      "\n",
      "Step 22/40\n",
      "Epoch 0: Total Loss=3.9121\n",
      "Epoch 1: Total Loss=2.7874\n",
      "Epoch 2: Total Loss=2.0602\n",
      "Epoch 3: Total Loss=1.6070\n",
      "Epoch 4: Total Loss=1.4155\n",
      "Epoch 5: Total Loss=1.3074\n",
      "Epoch 6: Total Loss=1.2425\n",
      "Epoch 7: Total Loss=1.1904\n",
      "Epoch 8: Total Loss=1.1508\n",
      "Epoch 9: Total Loss=1.1129\n",
      "Updated x: [0.16834808886051178, -0.29853540658950806], Function Value: 0.11746446788311005, Gradient: [-0.012924106791615486, -0.556344211101532]\n",
      "\n",
      "Step 23/40\n",
      "Epoch 0: Total Loss=0.7417\n",
      "Epoch 1: Total Loss=0.7113\n",
      "Epoch 2: Total Loss=0.6981\n",
      "Epoch 3: Total Loss=0.6891\n",
      "Epoch 4: Total Loss=0.6818\n",
      "Epoch 5: Total Loss=0.6757\n",
      "Epoch 6: Total Loss=0.6697\n",
      "Epoch 7: Total Loss=0.6642\n",
      "Epoch 8: Total Loss=0.6582\n",
      "Epoch 9: Total Loss=0.6532\n",
      "Updated x: [0.1514628678560257, -0.30430981516838074], Function Value: 0.11554546654224396, Gradient: [0.01617339998483658, -0.47453659772872925]\n",
      "\n",
      "Step 24/40\n",
      "Epoch 0: Total Loss=0.5809\n",
      "Epoch 1: Total Loss=0.5975\n",
      "Epoch 2: Total Loss=0.5597\n",
      "Epoch 3: Total Loss=0.5545\n",
      "Epoch 4: Total Loss=0.5796\n",
      "Epoch 5: Total Loss=0.5456\n",
      "Epoch 6: Total Loss=0.5425\n",
      "Epoch 7: Total Loss=0.5684\n",
      "Epoch 8: Total Loss=0.5352\n",
      "Epoch 9: Total Loss=0.5315\n",
      "Updated x: [0.1380552351474762, -0.2373884618282318], Function Value: 0.07541252672672272, Gradient: [0.0002114909002557397, -0.3171643614768982]\n",
      "\n",
      "Step 25/40\n",
      "Epoch 0: Total Loss=0.4202\n",
      "Epoch 1: Total Loss=0.4114\n",
      "Epoch 2: Total Loss=0.4086\n",
      "Epoch 3: Total Loss=0.4053\n",
      "Epoch 4: Total Loss=0.4041\n",
      "Epoch 5: Total Loss=0.4030\n",
      "Epoch 6: Total Loss=0.4019\n",
      "Epoch 7: Total Loss=0.4008\n",
      "Epoch 8: Total Loss=0.4001\n",
      "Epoch 9: Total Loss=0.3994\n",
      "Updated x: [0.22521302103996277, -0.19730451703071594], Function Value: 0.0896499752998352, Gradient: [0.03416445478796959, -0.5118811726570129]\n",
      "\n",
      "Step 26/40\n",
      "Epoch 0: Total Loss=0.5624\n",
      "Epoch 1: Total Loss=0.5228\n",
      "Epoch 2: Total Loss=0.5067\n",
      "Epoch 3: Total Loss=0.4974\n",
      "Epoch 4: Total Loss=0.4904\n",
      "Epoch 5: Total Loss=0.4852\n",
      "Epoch 6: Total Loss=0.4817\n",
      "Epoch 7: Total Loss=0.4784\n",
      "Epoch 8: Total Loss=0.4759\n",
      "Epoch 9: Total Loss=0.4729\n",
      "Updated x: [0.22519145905971527, -0.14833369851112366], Function Value: 0.07271407544612885, Gradient: [0.13409850001335144, 0.06535885483026505]\n",
      "\n",
      "Step 27/40\n",
      "Epoch 0: Total Loss=0.4029\n",
      "Epoch 1: Total Loss=0.3822\n",
      "Epoch 2: Total Loss=0.3512\n",
      "Epoch 3: Total Loss=0.3739\n",
      "Epoch 4: Total Loss=0.3681\n",
      "Epoch 5: Total Loss=0.3410\n",
      "Epoch 6: Total Loss=0.3641\n",
      "Epoch 7: Total Loss=0.3613\n",
      "Epoch 8: Total Loss=0.3344\n",
      "Epoch 9: Total Loss=0.3581\n",
      "Updated x: [0.10082442313432693, -0.11813727766275406], Function Value: 0.024121981114149094, Gradient: [-0.01659403368830681, 0.14561910927295685]\n",
      "\n",
      "Step 28/40\n",
      "Epoch 0: Total Loss=0.3430\n",
      "Epoch 1: Total Loss=0.3750\n",
      "Epoch 2: Total Loss=0.3710\n",
      "Epoch 3: Total Loss=0.3656\n",
      "Epoch 4: Total Loss=0.3378\n",
      "Epoch 5: Total Loss=0.3687\n",
      "Epoch 6: Total Loss=0.3649\n",
      "Epoch 7: Total Loss=0.3291\n",
      "Epoch 8: Total Loss=0.3664\n",
      "Epoch 9: Total Loss=0.3642\n",
      "Updated x: [0.2713856101036072, -0.04798811674118042], Function Value: 0.07595301419496536, Gradient: [0.18498383462429047, 0.1163327544927597]\n",
      "\n",
      "Step 29/40\n",
      "Epoch 0: Total Loss=0.2988\n",
      "Epoch 1: Total Loss=0.2922\n",
      "Epoch 2: Total Loss=0.2880\n",
      "Epoch 3: Total Loss=0.2853\n",
      "Epoch 4: Total Loss=0.2829\n",
      "Epoch 5: Total Loss=0.2816\n",
      "Epoch 6: Total Loss=0.2806\n",
      "Epoch 7: Total Loss=0.2789\n",
      "Epoch 8: Total Loss=0.2778\n",
      "Epoch 9: Total Loss=0.2771\n",
      "Updated x: [0.24764394760131836, 0.1614706665277481], Function Value: 0.08740030229091644, Gradient: [0.07008650153875351, 0.1557854264974594]\n",
      "\n",
      "Step 30/40\n",
      "Epoch 0: Total Loss=0.2671\n",
      "Epoch 1: Total Loss=0.2831\n",
      "Epoch 2: Total Loss=0.2527\n",
      "Epoch 3: Total Loss=0.2753\n",
      "Epoch 4: Total Loss=0.2491\n",
      "Epoch 5: Total Loss=0.2529\n",
      "Epoch 6: Total Loss=0.2691\n",
      "Epoch 7: Total Loss=0.2500\n",
      "Epoch 8: Total Loss=0.2719\n",
      "Epoch 9: Total Loss=0.2475\n",
      "Updated x: [0.14001205563545227, 0.007158845663070679], Function Value: 0.01965462416410446, Gradient: [0.07833632081747055, 0.41147878766059875]\n",
      "\n",
      "Step 31/40\n",
      "Epoch 0: Total Loss=0.2647\n",
      "Epoch 1: Total Loss=0.2602\n",
      "Epoch 2: Total Loss=0.2584\n",
      "Epoch 3: Total Loss=0.2580\n",
      "Epoch 4: Total Loss=0.2575\n",
      "Epoch 5: Total Loss=0.2567\n",
      "Epoch 6: Total Loss=0.2566\n",
      "Epoch 7: Total Loss=0.2560\n",
      "Epoch 8: Total Loss=0.2561\n",
      "Epoch 9: Total Loss=0.2551\n",
      "Updated x: [0.23649290204048157, -0.08562877029180527], Function Value: 0.06326118111610413, Gradient: [0.2772412598133087, 0.1548374891281128]\n",
      "\n",
      "Step 32/40\n",
      "Epoch 0: Total Loss=0.4591\n",
      "Epoch 1: Total Loss=0.2055\n",
      "Epoch 2: Total Loss=0.1302\n",
      "Epoch 3: Total Loss=0.1174\n",
      "Epoch 4: Total Loss=0.1095\n",
      "Epoch 5: Total Loss=0.1030\n",
      "Epoch 6: Total Loss=0.0994\n",
      "Epoch 7: Total Loss=0.0952\n",
      "Epoch 8: Total Loss=0.0927\n",
      "Epoch 9: Total Loss=0.0897\n",
      "Updated x: [0.28460654616355896, -0.19133618474006653], Function Value: 0.11761042475700378, Gradient: [0.20396925508975983, 0.018178585916757584]\n",
      "\n",
      "Step 33/40\n",
      "Epoch 0: Total Loss=0.2622\n",
      "Epoch 1: Total Loss=0.2518\n",
      "Epoch 2: Total Loss=0.2486\n",
      "Epoch 3: Total Loss=0.2469\n",
      "Epoch 4: Total Loss=0.2456\n",
      "Epoch 5: Total Loss=0.2447\n",
      "Epoch 6: Total Loss=0.2439\n",
      "Epoch 7: Total Loss=0.2433\n",
      "Epoch 8: Total Loss=0.2430\n",
      "Epoch 9: Total Loss=0.2425\n",
      "Updated x: [0.19139084219932556, -0.14537975192070007], Function Value: 0.05776572972536087, Gradient: [0.1592935472726822, -0.15188105404376984]\n",
      "\n",
      "Step 34/40\n",
      "Epoch 0: Total Loss=0.3092\n",
      "Epoch 1: Total Loss=0.3096\n",
      "Epoch 2: Total Loss=0.2964\n",
      "Epoch 3: Total Loss=0.2978\n",
      "Epoch 4: Total Loss=0.3054\n",
      "Epoch 5: Total Loss=0.2932\n",
      "Epoch 6: Total Loss=0.2954\n",
      "Epoch 7: Total Loss=0.3034\n",
      "Epoch 8: Total Loss=0.2915\n",
      "Epoch 9: Total Loss=0.2938\n",
      "Updated x: [0.14298203587532043, -0.08427925407886505], Function Value: 0.027546854689717293, Gradient: [0.2231885939836502, -0.44847217202186584]\n",
      "\n",
      "Step 35/40\n",
      "Epoch 0: Total Loss=0.3212\n",
      "Epoch 1: Total Loss=0.3143\n",
      "Epoch 2: Total Loss=0.3124\n",
      "Epoch 3: Total Loss=0.3112\n",
      "Epoch 4: Total Loss=0.3100\n",
      "Epoch 5: Total Loss=0.3090\n",
      "Epoch 6: Total Loss=0.3080\n",
      "Epoch 7: Total Loss=0.3074\n",
      "Epoch 8: Total Loss=0.3066\n",
      "Epoch 9: Total Loss=0.3058\n",
      "Updated x: [0.014637857675552368, -0.0956096351146698], Function Value: 0.009355468675494194, Gradient: [0.331152081489563, -0.5296198129653931]\n",
      "\n",
      "Step 36/40\n",
      "Epoch 0: Total Loss=0.4138\n",
      "Epoch 1: Total Loss=0.3747\n",
      "Epoch 2: Total Loss=0.3643\n",
      "Epoch 3: Total Loss=0.3595\n",
      "Epoch 4: Total Loss=0.3563\n",
      "Epoch 5: Total Loss=0.3546\n",
      "Epoch 6: Total Loss=0.3532\n",
      "Epoch 7: Total Loss=0.3524\n",
      "Epoch 8: Total Loss=0.3519\n",
      "Epoch 9: Total Loss=0.3511\n",
      "Updated x: [0.007362425327301025, -0.03860930725932121], Function Value: 0.0015448839403688908, Gradient: [-0.34883981943130493, 0.10161429643630981]\n",
      "\n",
      "Step 37/40\n",
      "Epoch 0: Total Loss=0.2849\n",
      "Epoch 1: Total Loss=0.2746\n",
      "Epoch 2: Total Loss=0.2602\n",
      "Epoch 3: Total Loss=0.2776\n",
      "Epoch 4: Total Loss=0.2716\n",
      "Epoch 5: Total Loss=0.2583\n",
      "Epoch 6: Total Loss=0.2762\n",
      "Epoch 7: Total Loss=0.2704\n",
      "Epoch 8: Total Loss=0.2576\n",
      "Epoch 9: Total Loss=0.2755\n",
      "Updated x: [0.012826058082282543, -0.041623130440711975], Function Value: 0.0018969927914440632, Gradient: [-0.114083431661129, 0.08541643619537354]\n",
      "\n",
      "Step 38/40\n",
      "Epoch 0: Total Loss=0.1383\n",
      "Epoch 1: Total Loss=0.1448\n",
      "Epoch 2: Total Loss=0.1422\n",
      "Epoch 3: Total Loss=0.1303\n",
      "Epoch 4: Total Loss=0.1388\n",
      "Epoch 5: Total Loss=0.1398\n",
      "Epoch 6: Total Loss=0.1391\n",
      "Epoch 7: Total Loss=0.1266\n",
      "Epoch 8: Total Loss=0.1383\n",
      "Epoch 9: Total Loss=0.1381\n",
      "Updated x: [0.035946980118751526, -0.07120366394519806], Function Value: 0.0063621471635997295, Gradient: [-0.056232746690511703, -0.0985398218035698]\n",
      "\n",
      "Step 39/40\n",
      "Epoch 0: Total Loss=0.1714\n",
      "Epoch 1: Total Loss=0.1661\n",
      "Epoch 2: Total Loss=0.1652\n",
      "Epoch 3: Total Loss=0.1648\n",
      "Epoch 4: Total Loss=0.1644\n",
      "Epoch 5: Total Loss=0.1639\n",
      "Epoch 6: Total Loss=0.1640\n",
      "Epoch 7: Total Loss=0.1632\n",
      "Epoch 8: Total Loss=0.1633\n",
      "Epoch 9: Total Loss=0.1632\n",
      "Updated x: [-0.05003537982702255, -0.009390756487846375], Function Value: 0.0025917254388332367, Gradient: [-0.4017498195171356, 0.09466466307640076]\n",
      "\n",
      "Step 40/40\n",
      "Epoch 0: Total Loss=0.1841\n",
      "Epoch 1: Total Loss=0.1650\n",
      "Epoch 2: Total Loss=0.1774\n",
      "Epoch 3: Total Loss=0.1654\n",
      "Epoch 4: Total Loss=0.1587\n",
      "Epoch 5: Total Loss=0.1830\n",
      "Epoch 6: Total Loss=0.1582\n",
      "Epoch 7: Total Loss=0.1830\n",
      "Epoch 8: Total Loss=0.1580\n",
      "Epoch 9: Total Loss=0.1779\n",
      "Updated x: [-0.10206848382949829, -0.07557515799999237], Function Value: 0.01612957939505577, Gradient: [-0.1724904477596283, 0.028211012482643127]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define the number of optimization steps\n",
    "optim_steps = 40\n",
    "N_s = 2  # Keep N_s constant\n",
    "\n",
    "# Define dataset sizes\n",
    "datasets = {\n",
    "    \"Small Dataset\": data_small,\n",
    "    \"Medium Dataset\": data,  # Default dataset\n",
    "    \"Large Dataset\": data_big\n",
    "}\n",
    "\n",
    "# Dictionary to store results\n",
    "results = {}\n",
    "\n",
    "# Loop over dataset sizes\n",
    "for dataset_name, dataset in datasets.items():\n",
    "    old_dataset = OldDataSet(dataset, k=10)\n",
    "    new_dataset = NewDataSet(k=10)\n",
    "    model = MLP(2, [5, 5, 5], 1)  # Standard network size\n",
    "\n",
    "    # Run optimization\n",
    "    _, y_path = optimize_surrogate_model(\n",
    "        model, old_dataset, new_dataset, assSim, \n",
    "        optim_steps=optim_steps, N_s=N_s, lr=0.001, merge_interval=10\n",
    "    )\n",
    "\n",
    "    # Store results\n",
    "    results[dataset_name] = y_path\n",
    "\n",
    "# Plot the results\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "for dataset_name in datasets.keys():\n",
    "    plt.plot(range(optim_steps), results[dataset_name], label=f\"{dataset_name}\")\n",
    "\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.ylabel(\"Objective y\")\n",
    "plt.title(\"Comparison of Different Dataset Sizes with Standard Network\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 1/200\n",
      "Epoch 0: Total Loss=84272.9766\n",
      "Epoch 1: Total Loss=84218.4180\n",
      "Epoch 2: Total Loss=84164.5352\n",
      "Epoch 3: Total Loss=84111.2227\n",
      "Epoch 4: Total Loss=84058.3984\n",
      "Epoch 5: Total Loss=84005.9570\n",
      "Epoch 6: Total Loss=83953.9062\n",
      "Epoch 7: Total Loss=83902.1953\n",
      "Epoch 8: Total Loss=83850.8633\n",
      "Epoch 9: Total Loss=83799.9336\n",
      "Updated x: [10.074095726013184, -10.089149475097656], Function Value: 203.27835083007812, Gradient: [-0.14141641557216644, -0.0008042083354666829]\n",
      "\n",
      "Step 2/200\n",
      "Epoch 0: Total Loss=83448.0664\n",
      "Epoch 1: Total Loss=83397.4883\n",
      "Epoch 2: Total Loss=83347.2578\n",
      "Epoch 3: Total Loss=83418.9805\n",
      "Epoch 4: Total Loss=83247.7266\n",
      "Epoch 5: Total Loss=83198.3477\n",
      "Epoch 6: Total Loss=83149.1953\n",
      "Epoch 7: Total Loss=83221.8164\n",
      "Epoch 8: Total Loss=83051.1680\n",
      "Epoch 9: Total Loss=83002.1172\n",
      "Updated x: [10.02176284790039, -10.113715171813965], Function Value: 202.72296142578125, Gradient: [-0.12135874480009079, -0.030062247067689896]\n",
      "\n",
      "Step 3/200\n",
      "Epoch 0: Total Loss=81861.8555\n",
      "Epoch 1: Total Loss=81812.8086\n",
      "Epoch 2: Total Loss=81641.9180\n",
      "Epoch 3: Total Loss=81592.5352\n",
      "Epoch 4: Total Loss=81664.7500\n",
      "Epoch 5: Total Loss=81493.6328\n",
      "Epoch 6: Total Loss=81444.4570\n",
      "Epoch 7: Total Loss=81517.5195\n",
      "Epoch 8: Total Loss=81348.2461\n",
      "Epoch 9: Total Loss=81423.8008\n",
      "Updated x: [9.870981216430664, -10.114486694335938], Function Value: 199.73910522460938, Gradient: [-0.0926588699221611, -0.05477273091673851]\n",
      "\n",
      "Step 4/200\n",
      "Epoch 0: Total Loss=80313.9297\n",
      "Epoch 1: Total Loss=80272.2500\n",
      "Epoch 2: Total Loss=80355.3281\n",
      "Epoch 3: Total Loss=80320.3320\n",
      "Epoch 4: Total Loss=80167.7070\n",
      "Epoch 5: Total Loss=80262.7266\n",
      "Epoch 6: Total Loss=80118.6953\n",
      "Epoch 7: Total Loss=80100.4258\n",
      "Epoch 8: Total Loss=80207.5391\n",
      "Epoch 9: Total Loss=80074.3633\n",
      "Updated x: [9.737008094787598, -10.007850646972656], Function Value: 194.96640014648438, Gradient: [-0.011698547750711441, -0.01185403112322092]\n",
      "\n",
      "Step 5/200\n",
      "Epoch 0: Total Loss=78324.4883\n",
      "Epoch 1: Total Loss=78438.0312\n",
      "Epoch 2: Total Loss=78310.6836\n",
      "Epoch 3: Total Loss=78306.4492\n",
      "Epoch 4: Total Loss=78424.0977\n",
      "Epoch 5: Total Loss=78419.6133\n",
      "Epoch 6: Total Loss=78414.5977\n",
      "Epoch 7: Total Loss=78287.5898\n",
      "Epoch 8: Total Loss=78282.1914\n",
      "Epoch 9: Total Loss=78276.9375\n",
      "Updated x: [9.657363891601562, -10.033878326416016], Function Value: 193.94338989257812, Gradient: [0.0003259870281908661, 0.0011194207472726703]\n",
      "\n",
      "Step 6/200\n",
      "Epoch 0: Total Loss=77139.2812\n",
      "Epoch 1: Total Loss=79152.4453\n",
      "Epoch 2: Total Loss=80121.4570\n",
      "Epoch 3: Total Loss=77001.3828\n",
      "Epoch 4: Total Loss=79257.3711\n",
      "Epoch 5: Total Loss=80104.5625\n",
      "Epoch 6: Total Loss=76984.5195\n",
      "Epoch 7: Total Loss=79118.5859\n",
      "Epoch 8: Total Loss=80087.2109\n",
      "Epoch 9: Total Loss=76967.6562\n",
      "Updated x: [9.712644577026367, -10.104260444641113], Function Value: 196.43154907226562, Gradient: [0.0015845549060031772, 0.001783824758604169]\n",
      "\n",
      "Step 7/200\n",
      "Epoch 0: Total Loss=76626.6641\n",
      "Epoch 1: Total Loss=76384.7656\n",
      "Epoch 2: Total Loss=78490.7305\n",
      "Epoch 3: Total Loss=76488.3203\n",
      "Epoch 4: Total Loss=76368.0664\n",
      "Epoch 5: Total Loss=78473.5977\n",
      "Epoch 6: Total Loss=76471.1133\n",
      "Epoch 7: Total Loss=76350.6562\n",
      "Epoch 8: Total Loss=78577.3945\n",
      "Epoch 9: Total Loss=76453.2148\n",
      "Updated x: [9.562694549560547, -9.976093292236328], Function Value: 190.96755981445312, Gradient: [0.000927901070099324, 0.0007789582596160471]\n",
      "\n",
      "Step 8/200\n",
      "Epoch 0: Total Loss=77872.0469\n",
      "Epoch 1: Total Loss=75062.6016\n",
      "Epoch 2: Total Loss=77981.3281\n",
      "Epoch 3: Total Loss=75050.3438\n",
      "Epoch 4: Total Loss=77968.8672\n",
      "Epoch 5: Total Loss=74916.0781\n",
      "Epoch 6: Total Loss=77955.9727\n",
      "Epoch 7: Total Loss=75025.0859\n",
      "Epoch 8: Total Loss=77820.9648\n",
      "Epoch 9: Total Loss=75011.9883\n",
      "Updated x: [9.520108222961426, -10.121537208557129], Function Value: 193.07797241210938, Gradient: [0.002769787795841694, 0.003068930236622691]\n",
      "\n",
      "Step 9/200\n",
      "Epoch 0: Total Loss=77600.5156\n",
      "Epoch 1: Total Loss=76011.0898\n",
      "Epoch 2: Total Loss=77708.4219\n",
      "Epoch 3: Total Loss=75997.2188\n",
      "Epoch 4: Total Loss=77572.5117\n",
      "Epoch 5: Total Loss=76104.8203\n",
      "Epoch 6: Total Loss=77557.9805\n",
      "Epoch 7: Total Loss=76090.2383\n",
      "Epoch 8: Total Loss=77664.8242\n",
      "Epoch 9: Total Loss=75953.4492\n",
      "Updated x: [9.652960777282715, -10.230123519897461], Function Value: 197.8350830078125, Gradient: [0.0024690956342965364, 0.0027662450447678566]\n",
      "\n",
      "Step 10/200\n",
      "Epoch 0: Total Loss=74969.6016\n",
      "Epoch 1: Total Loss=78548.1094\n",
      "Epoch 2: Total Loss=76591.1953\n",
      "Epoch 3: Total Loss=77358.2969\n",
      "Epoch 4: Total Loss=79125.6484\n",
      "Epoch 5: Total Loss=74931.0625\n",
      "Epoch 6: Total Loss=78508.2930\n",
      "Epoch 7: Total Loss=76551.3320\n",
      "Epoch 8: Total Loss=77317.3555\n",
      "Epoch 9: Total Loss=79084.0938\n",
      "Updated x: [9.735939979553223, -10.25721549987793], Function Value: 199.99899291992188, Gradient: [0.003012958914041519, 0.0035259639844298363]\n",
      "\n",
      "Step 11/200\n",
      "Epoch 0: Total Loss=330.6573\n",
      "Epoch 1: Total Loss=213.8194\n",
      "Epoch 2: Total Loss=323.4834\n",
      "Epoch 3: Total Loss=351.7152\n",
      "Epoch 4: Total Loss=196.5749\n",
      "Epoch 5: Total Loss=330.4847\n",
      "Epoch 6: Total Loss=335.4322\n",
      "Epoch 7: Total Loss=323.3726\n",
      "Epoch 8: Total Loss=229.8835\n",
      "Epoch 9: Total Loss=318.1720\n",
      "Updated x: [9.660021781921387, -10.127801895141602], Function Value: 195.88839721679688, Gradient: [0.012991441413760185, 0.021195363253355026]\n",
      "\n",
      "Step 12/200\n",
      "Epoch 0: Total Loss=77291.8711\n",
      "Epoch 1: Total Loss=77276.6641\n",
      "Epoch 2: Total Loss=77261.8242\n",
      "Epoch 3: Total Loss=77247.8984\n",
      "Epoch 4: Total Loss=77235.0703\n",
      "Epoch 5: Total Loss=77224.4023\n",
      "Epoch 6: Total Loss=77215.6445\n",
      "Epoch 7: Total Loss=77207.9727\n",
      "Epoch 8: Total Loss=77200.3828\n",
      "Epoch 9: Total Loss=77191.7656\n",
      "Updated x: [9.675919532775879, -10.17629623413086], Function Value: 197.180419921875, Gradient: [-0.008718186058104038, -0.01024943869560957]\n",
      "\n",
      "Step 13/200\n",
      "Epoch 0: Total Loss=77068.0117\n",
      "Epoch 1: Total Loss=77057.8516\n",
      "Epoch 2: Total Loss=77048.9414\n",
      "Epoch 3: Total Loss=77039.9180\n",
      "Epoch 4: Total Loss=77030.5078\n",
      "Epoch 5: Total Loss=77020.7656\n",
      "Epoch 6: Total Loss=77011.1484\n",
      "Epoch 7: Total Loss=77002.1602\n",
      "Epoch 8: Total Loss=76991.9141\n",
      "Epoch 9: Total Loss=76982.2656\n",
      "Updated x: [9.654082298278809, -10.182792663574219], Function Value: 196.89056396484375, Gradient: [0.00037511036498472095, 0.000314430333673954]\n",
      "\n",
      "Step 14/200\n",
      "Epoch 0: Total Loss=76673.6992\n",
      "Epoch 1: Total Loss=76663.6289\n",
      "Epoch 2: Total Loss=76653.2422\n",
      "Epoch 3: Total Loss=76643.0156\n",
      "Epoch 4: Total Loss=76632.4727\n",
      "Epoch 5: Total Loss=76621.7227\n",
      "Epoch 6: Total Loss=76611.1758\n",
      "Epoch 7: Total Loss=76600.0898\n",
      "Epoch 8: Total Loss=76589.3047\n",
      "Epoch 9: Total Loss=76578.0195\n",
      "Updated x: [9.711421012878418, -10.05239200592041], Function Value: 195.36227416992188, Gradient: [-0.0016065605450421572, -0.002140502445399761]\n",
      "\n",
      "Step 15/200\n",
      "Epoch 0: Total Loss=76784.6719\n",
      "Epoch 1: Total Loss=76773.8203\n",
      "Epoch 2: Total Loss=76762.0703\n",
      "Epoch 3: Total Loss=76750.3555\n",
      "Epoch 4: Total Loss=76739.0117\n",
      "Epoch 5: Total Loss=76726.9805\n",
      "Epoch 6: Total Loss=76715.5430\n",
      "Epoch 7: Total Loss=76703.4023\n",
      "Epoch 8: Total Loss=76690.7773\n",
      "Epoch 9: Total Loss=76678.5234\n",
      "Updated x: [9.831844329833984, -10.08086109161377], Function Value: 198.28892517089844, Gradient: [-0.001664097304455936, -0.002236759988591075]\n",
      "\n",
      "Step 16/200\n",
      "Epoch 0: Total Loss=77146.9453\n",
      "Epoch 1: Total Loss=77226.5664\n",
      "Epoch 2: Total Loss=77614.9023\n",
      "Epoch 3: Total Loss=77109.5938\n",
      "Epoch 4: Total Loss=77188.9492\n",
      "Epoch 5: Total Loss=77576.2422\n",
      "Epoch 6: Total Loss=77070.8164\n",
      "Epoch 7: Total Loss=77149.6328\n",
      "Epoch 8: Total Loss=77536.1797\n",
      "Epoch 9: Total Loss=77030.4648\n",
      "Updated x: [9.887609481811523, -10.146306991577148], Function Value: 200.71237182617188, Gradient: [-0.0009594726725481451, -0.0012541236355900764]\n",
      "\n",
      "Step 17/200\n",
      "Epoch 0: Total Loss=77014.0156\n",
      "Epoch 1: Total Loss=78109.0977\n",
      "Epoch 2: Total Loss=76989.8047\n",
      "Epoch 3: Total Loss=76972.3281\n",
      "Epoch 4: Total Loss=78067.2695\n",
      "Epoch 5: Total Loss=76947.1602\n",
      "Epoch 6: Total Loss=76929.3398\n",
      "Epoch 7: Total Loss=78022.9961\n",
      "Epoch 8: Total Loss=76903.0391\n",
      "Epoch 9: Total Loss=76884.5625\n",
      "Updated x: [10.042620658874512, -9.93710708618164], Function Value: 199.60032653808594, Gradient: [-0.0044457209296524525, -0.005678910296410322]\n",
      "\n",
      "Step 18/200\n",
      "Epoch 0: Total Loss=77089.7617\n",
      "Epoch 1: Total Loss=76867.7383\n",
      "Epoch 2: Total Loss=77058.8281\n",
      "Epoch 3: Total Loss=76836.2930\n",
      "Epoch 4: Total Loss=77027.0547\n",
      "Epoch 5: Total Loss=76803.3633\n",
      "Epoch 6: Total Loss=76992.1758\n",
      "Epoch 7: Total Loss=76765.2031\n",
      "Epoch 8: Total Loss=76949.1055\n",
      "Epoch 9: Total Loss=76714.4102\n",
      "Updated x: [9.83278751373291, -9.978819847106934], Function Value: 196.26055908203125, Gradient: [-0.07216113805770874, -0.03464186564087868]\n",
      "\n",
      "Step 19/200\n",
      "Epoch 0: Total Loss=76109.1602\n",
      "Epoch 1: Total Loss=76897.0078\n",
      "Epoch 2: Total Loss=76019.4453\n",
      "Epoch 3: Total Loss=76805.1211\n",
      "Epoch 4: Total Loss=75943.1484\n",
      "Epoch 5: Total Loss=76773.7188\n",
      "Epoch 6: Total Loss=75923.4336\n",
      "Epoch 7: Total Loss=76736.0898\n",
      "Epoch 8: Total Loss=75878.4805\n",
      "Epoch 9: Total Loss=76687.4844\n",
      "Updated x: [9.685226440429688, -10.035774230957031], Function Value: 194.5203857421875, Gradient: [-0.007445465307682753, -0.004655466880649328]\n",
      "\n",
      "Step 20/200\n",
      "Epoch 0: Total Loss=76307.0469\n",
      "Epoch 1: Total Loss=76256.2305\n",
      "Epoch 2: Total Loss=75290.6289\n",
      "Epoch 3: Total Loss=76129.1680\n",
      "Epoch 4: Total Loss=75046.8320\n",
      "Epoch 5: Total Loss=76212.7031\n",
      "Epoch 6: Total Loss=76165.6211\n",
      "Epoch 7: Total Loss=75198.7227\n",
      "Epoch 8: Total Loss=76036.3633\n",
      "Epoch 9: Total Loss=74953.1992\n",
      "Updated x: [9.756621360778809, -9.983734130859375], Function Value: 194.86660766601562, Gradient: [-0.013937492854893208, -0.013391347602009773]\n",
      "\n",
      "Step 21/200\n",
      "Epoch 0: Total Loss=49.6944\n",
      "Epoch 1: Total Loss=41.9844\n",
      "Epoch 2: Total Loss=24.3774\n",
      "Epoch 3: Total Loss=61.8961\n",
      "Epoch 4: Total Loss=30.7366\n",
      "Epoch 5: Total Loss=49.2047\n",
      "Epoch 6: Total Loss=41.1113\n",
      "Epoch 7: Total Loss=23.8979\n",
      "Epoch 8: Total Loss=61.6438\n",
      "Epoch 9: Total Loss=30.4307\n",
      "Updated x: [9.643988609313965, -9.816256523132324], Function Value: 189.36541748046875, Gradient: [1.0519115924835205, 0.9845373630523682]\n",
      "\n",
      "Step 22/200\n",
      "Epoch 0: Total Loss=72104.4375\n",
      "Epoch 1: Total Loss=71788.2344\n",
      "Epoch 2: Total Loss=71482.9922\n",
      "Epoch 3: Total Loss=71203.7109\n",
      "Epoch 4: Total Loss=70968.2656\n",
      "Epoch 5: Total Loss=70789.4453\n",
      "Epoch 6: Total Loss=70670.4141\n",
      "Epoch 7: Total Loss=70601.7734\n",
      "Epoch 8: Total Loss=70567.0156\n",
      "Epoch 9: Total Loss=70549.9727\n",
      "Updated x: [9.66238021850586, -9.839771270751953], Function Value: 190.1826934814453, Gradient: [-0.07848063856363297, -0.06213078647851944]\n",
      "\n",
      "Step 23/200\n",
      "Epoch 0: Total Loss=70738.6523\n",
      "Epoch 1: Total Loss=70716.7617\n",
      "Epoch 2: Total Loss=70696.9492\n",
      "Epoch 3: Total Loss=70674.7578\n",
      "Epoch 4: Total Loss=70655.7734\n",
      "Epoch 5: Total Loss=70635.6172\n",
      "Epoch 6: Total Loss=70614.7461\n",
      "Epoch 7: Total Loss=70594.6328\n",
      "Epoch 8: Total Loss=70574.2109\n",
      "Epoch 9: Total Loss=70552.9492\n",
      "Updated x: [9.69178581237793, -9.838459968566895], Function Value: 190.72601318359375, Gradient: [-0.0007437942549586296, -0.0031566540710628033]\n",
      "\n",
      "Step 24/200\n",
      "Epoch 0: Total Loss=70364.4062\n",
      "Epoch 1: Total Loss=70343.1094\n",
      "Epoch 2: Total Loss=70320.5859\n",
      "Epoch 3: Total Loss=70298.5312\n",
      "Epoch 4: Total Loss=70276.7734\n",
      "Epoch 5: Total Loss=70253.8945\n",
      "Epoch 6: Total Loss=70231.6133\n",
      "Epoch 7: Total Loss=70208.1797\n",
      "Epoch 8: Total Loss=70185.1094\n",
      "Epoch 9: Total Loss=70161.7695\n",
      "Updated x: [9.650970458984375, -9.842079162597656], Function Value: 190.00775146484375, Gradient: [0.010645228438079357, 0.002280198037624359]\n",
      "\n",
      "Step 25/200\n",
      "Epoch 0: Total Loss=71064.4258\n",
      "Epoch 1: Total Loss=71038.7266\n",
      "Epoch 2: Total Loss=71016.7422\n",
      "Epoch 3: Total Loss=70992.1367\n",
      "Epoch 4: Total Loss=70968.1523\n",
      "Epoch 5: Total Loss=70943.8594\n",
      "Epoch 6: Total Loss=70918.6719\n",
      "Epoch 7: Total Loss=70893.5859\n",
      "Epoch 8: Total Loss=70868.9141\n",
      "Epoch 9: Total Loss=70842.7891\n",
      "Updated x: [9.769987106323242, -9.971556663513184], Function Value: 194.88458251953125, Gradient: [0.010504389181733131, 0.0018200025660917163]\n",
      "\n",
      "Step 26/200\n",
      "Epoch 0: Total Loss=70732.6484\n",
      "Epoch 1: Total Loss=70003.9805\n",
      "Epoch 2: Total Loss=70916.6367\n",
      "Epoch 3: Total Loss=70653.7461\n",
      "Epoch 4: Total Loss=69926.0156\n",
      "Epoch 5: Total Loss=70836.4492\n",
      "Epoch 6: Total Loss=70574.3203\n",
      "Epoch 7: Total Loss=69844.5898\n",
      "Epoch 8: Total Loss=70754.5312\n",
      "Epoch 9: Total Loss=70490.7812\n",
      "Updated x: [9.668068885803223, -9.83868408203125], Function Value: 190.27127075195312, Gradient: [-0.0001842869387473911, -0.006694165524095297]\n",
      "\n",
      "Step 27/200\n",
      "Epoch 0: Total Loss=70060.0625\n",
      "Epoch 1: Total Loss=70084.7852\n",
      "Epoch 2: Total Loss=69619.8047\n",
      "Epoch 3: Total Loss=69974.7812\n",
      "Epoch 4: Total Loss=69998.1641\n",
      "Epoch 5: Total Loss=69533.6797\n",
      "Epoch 6: Total Loss=69887.1523\n",
      "Epoch 7: Total Loss=69909.7891\n",
      "Epoch 8: Total Loss=69444.0625\n",
      "Epoch 9: Total Loss=69796.7930\n",
      "Updated x: [9.601364135742188, -9.779900550842285], Function Value: 187.8326416015625, Gradient: [0.014464999549090862, 0.001883812597952783]\n",
      "\n",
      "Step 28/200\n",
      "Epoch 0: Total Loss=69735.4102\n",
      "Epoch 1: Total Loss=68346.0195\n",
      "Epoch 2: Total Loss=69676.7852\n",
      "Epoch 3: Total Loss=68285.4180\n",
      "Epoch 4: Total Loss=69612.7344\n",
      "Epoch 5: Total Loss=68225.6953\n",
      "Epoch 6: Total Loss=69549.7109\n",
      "Epoch 7: Total Loss=68162.2031\n",
      "Epoch 8: Total Loss=69486.7891\n",
      "Epoch 9: Total Loss=68098.2109\n",
      "Updated x: [9.572932243347168, -9.612098693847656], Function Value: 184.03347778320312, Gradient: [-0.035121120512485504, -0.03216654062271118]\n",
      "\n",
      "Step 29/200\n",
      "Epoch 0: Total Loss=67811.8516\n",
      "Epoch 1: Total Loss=68638.4648\n",
      "Epoch 2: Total Loss=67746.8242\n",
      "Epoch 3: Total Loss=68572.6016\n",
      "Epoch 4: Total Loss=67680.6172\n",
      "Epoch 5: Total Loss=68505.9570\n",
      "Epoch 6: Total Loss=67612.6738\n",
      "Epoch 7: Total Loss=68438.5039\n",
      "Epoch 8: Total Loss=67544.7266\n",
      "Epoch 9: Total Loss=68368.3086\n",
      "Updated x: [9.526239395141602, -9.720473289489746], Function Value: 185.23684692382812, Gradient: [0.07661167532205582, 0.040409982204437256]\n",
      "\n",
      "Step 30/200\n",
      "Epoch 0: Total Loss=67996.2070\n",
      "Epoch 1: Total Loss=67124.5781\n",
      "Epoch 2: Total Loss=68164.6836\n",
      "Epoch 3: Total Loss=67751.6836\n",
      "Epoch 4: Total Loss=67572.7031\n",
      "Epoch 5: Total Loss=67819.1836\n",
      "Epoch 6: Total Loss=66947.8047\n",
      "Epoch 7: Total Loss=67984.5703\n",
      "Epoch 8: Total Loss=67570.7578\n",
      "Epoch 9: Total Loss=67391.6797\n",
      "Updated x: [9.658315658569336, -9.660245895385742], Function Value: 186.60340881347656, Gradient: [-0.07050172984600067, -0.05562707409262657]\n",
      "\n",
      "Step 31/200\n",
      "Epoch 0: Total Loss=76.9462\n",
      "Epoch 1: Total Loss=65.4475\n",
      "Epoch 2: Total Loss=68.3191\n",
      "Epoch 3: Total Loss=49.8830\n",
      "Epoch 4: Total Loss=67.3398\n",
      "Epoch 5: Total Loss=75.5088\n",
      "Epoch 6: Total Loss=63.3983\n",
      "Epoch 7: Total Loss=65.6610\n",
      "Epoch 8: Total Loss=47.8847\n",
      "Epoch 9: Total Loss=65.5462\n",
      "Updated x: [9.511946678161621, -9.552533149719238], Function Value: 181.72802734375, Gradient: [1.3920927047729492, 1.2468162775039673]\n",
      "\n",
      "Step 32/200\n",
      "Epoch 0: Total Loss=61491.9844\n",
      "Epoch 1: Total Loss=61118.6582\n",
      "Epoch 2: Total Loss=60737.6055\n",
      "Epoch 3: Total Loss=60359.5039\n",
      "Epoch 4: Total Loss=60006.9590\n",
      "Epoch 5: Total Loss=59709.0000\n",
      "Epoch 6: Total Loss=59484.7559\n",
      "Epoch 7: Total Loss=59340.1289\n",
      "Epoch 8: Total Loss=59257.7656\n",
      "Epoch 9: Total Loss=59214.5137\n",
      "Updated x: [9.447373390197754, -9.389021873474121], Function Value: 177.40658569335938, Gradient: [-0.07744691520929337, -0.06037025526165962]\n",
      "\n",
      "Step 33/200\n",
      "Epoch 0: Total Loss=59247.9082\n",
      "Epoch 1: Total Loss=59212.1289\n",
      "Epoch 2: Total Loss=59176.8887\n",
      "Epoch 3: Total Loss=59140.5723\n",
      "Epoch 4: Total Loss=59106.3145\n",
      "Epoch 5: Total Loss=59070.3926\n",
      "Epoch 6: Total Loss=59033.4180\n",
      "Epoch 7: Total Loss=58997.7266\n",
      "Epoch 8: Total Loss=58962.1211\n",
      "Epoch 9: Total Loss=58923.7324\n",
      "Updated x: [9.547097206115723, -9.296889305114746], Function Value: 177.5792236328125, Gradient: [-0.06037745252251625, -0.049953605979681015]\n",
      "\n",
      "Step 34/200\n",
      "Epoch 0: Total Loss=58335.8613\n",
      "Epoch 1: Total Loss=58294.0898\n",
      "Epoch 2: Total Loss=58257.5352\n",
      "Epoch 3: Total Loss=58222.6523\n",
      "Epoch 4: Total Loss=58185.1406\n",
      "Epoch 5: Total Loss=58146.6621\n",
      "Epoch 6: Total Loss=58109.7188\n",
      "Epoch 7: Total Loss=58071.6191\n",
      "Epoch 8: Total Loss=58032.6758\n",
      "Epoch 9: Total Loss=57994.0020\n",
      "Updated x: [9.470465660095215, -9.198238372802734], Function Value: 174.29730224609375, Gradient: [-0.06409405916929245, -0.053757913410663605]\n",
      "\n",
      "Step 35/200\n",
      "Epoch 0: Total Loss=57586.9336\n",
      "Epoch 1: Total Loss=57549.7559\n",
      "Epoch 2: Total Loss=57508.9922\n",
      "Epoch 3: Total Loss=57469.8809\n",
      "Epoch 4: Total Loss=57429.3125\n",
      "Epoch 5: Total Loss=57388.6719\n",
      "Epoch 6: Total Loss=57348.9902\n",
      "Epoch 7: Total Loss=57307.5508\n",
      "Epoch 8: Total Loss=57267.3047\n",
      "Epoch 9: Total Loss=57225.1641\n",
      "Updated x: [9.701879501342773, -9.00352954864502], Function Value: 175.19000244140625, Gradient: [-0.18850073218345642, -0.13501104712486267]\n",
      "\n",
      "Step 36/200\n",
      "Epoch 0: Total Loss=56313.0723\n",
      "Epoch 1: Total Loss=56698.2793\n",
      "Epoch 2: Total Loss=57655.6680\n",
      "Epoch 3: Total Loss=56189.2070\n",
      "Epoch 4: Total Loss=56571.5371\n",
      "Epoch 5: Total Loss=57530.2871\n",
      "Epoch 6: Total Loss=56062.0371\n",
      "Epoch 7: Total Loss=56444.3691\n",
      "Epoch 8: Total Loss=57400.7246\n",
      "Epoch 9: Total Loss=55933.8418\n",
      "Updated x: [9.623432159423828, -8.929474830627441], Function Value: 172.34596252441406, Gradient: [-0.17111757397651672, -0.1244102343916893]\n",
      "\n",
      "Step 37/200\n",
      "Epoch 0: Total Loss=56760.1367\n",
      "Epoch 1: Total Loss=55747.9277\n",
      "Epoch 2: Total Loss=55577.3730\n",
      "Epoch 3: Total Loss=56633.9336\n",
      "Epoch 4: Total Loss=55617.0703\n",
      "Epoch 5: Total Loss=55447.5078\n",
      "Epoch 6: Total Loss=56497.7969\n",
      "Epoch 7: Total Loss=55485.3984\n",
      "Epoch 8: Total Loss=55312.3711\n",
      "Epoch 9: Total Loss=56364.4863\n",
      "Updated x: [9.587679862976074, -9.04266357421875], Function Value: 173.69337463378906, Gradient: [-0.0728171169757843, -0.061583518981933594]\n",
      "\n",
      "Step 38/200\n",
      "Epoch 0: Total Loss=55357.0039\n",
      "Epoch 1: Total Loss=56031.4141\n",
      "Epoch 2: Total Loss=55260.8281\n",
      "Epoch 3: Total Loss=55941.0273\n",
      "Epoch 4: Total Loss=55169.7109\n",
      "Epoch 5: Total Loss=55847.8730\n",
      "Epoch 6: Total Loss=55078.7539\n",
      "Epoch 7: Total Loss=55752.9043\n",
      "Epoch 8: Total Loss=54984.0977\n",
      "Epoch 9: Total Loss=55658.3633\n",
      "Updated x: [9.553688049316406, -9.073953628540039], Function Value: 173.60958862304688, Gradient: [-0.04476310312747955, -0.043579038232564926]\n",
      "\n",
      "Step 39/200\n",
      "Epoch 0: Total Loss=54886.2109\n",
      "Epoch 1: Total Loss=54828.5352\n",
      "Epoch 2: Total Loss=54789.9316\n",
      "Epoch 3: Total Loss=54729.7734\n",
      "Epoch 4: Total Loss=54694.1367\n",
      "Epoch 5: Total Loss=54632.5371\n",
      "Epoch 6: Total Loss=54594.3242\n",
      "Epoch 7: Total Loss=54535.6309\n",
      "Epoch 8: Total Loss=54492.6660\n",
      "Epoch 9: Total Loss=54433.0410\n",
      "Updated x: [9.444389343261719, -9.161141395568848], Function Value: 173.1230010986328, Gradient: [0.14719566702842712, 0.07703433930873871]\n",
      "\n",
      "Step 40/200\n",
      "Epoch 0: Total Loss=54473.4863\n",
      "Epoch 1: Total Loss=54457.8027\n",
      "Epoch 2: Total Loss=53836.7383\n",
      "Epoch 3: Total Loss=53848.9141\n",
      "Epoch 4: Total Loss=53713.1133\n",
      "Epoch 5: Total Loss=54219.0859\n",
      "Epoch 6: Total Loss=54199.3613\n",
      "Epoch 7: Total Loss=53584.2988\n",
      "Epoch 8: Total Loss=53590.4902\n",
      "Epoch 9: Total Loss=53456.0488\n",
      "Updated x: [9.513218879699707, -9.115777969360352], Function Value: 173.59873962402344, Gradient: [0.04203334078192711, 0.009755520150065422]\n",
      "\n",
      "Step 41/200\n",
      "Epoch 0: Total Loss=44.9495\n",
      "Epoch 1: Total Loss=47.1009\n",
      "Epoch 2: Total Loss=37.9511\n",
      "Epoch 3: Total Loss=39.4236\n",
      "Epoch 4: Total Loss=38.9490\n",
      "Epoch 5: Total Loss=33.6226\n",
      "Epoch 6: Total Loss=33.8121\n",
      "Epoch 7: Total Loss=24.6530\n",
      "Epoch 8: Total Loss=27.7526\n",
      "Epoch 9: Total Loss=28.5009\n",
      "Updated x: [9.41553020477295, -9.150956153869629], Function Value: 172.3922119140625, Gradient: [1.7599602937698364, 1.6058275699615479]\n",
      "\n",
      "Step 42/200\n",
      "Epoch 0: Total Loss=51607.4746\n",
      "Epoch 1: Total Loss=51195.5391\n",
      "Epoch 2: Total Loss=50778.4805\n",
      "Epoch 3: Total Loss=50351.7793\n",
      "Epoch 4: Total Loss=49914.4727\n",
      "Epoch 5: Total Loss=49474.8340\n",
      "Epoch 6: Total Loss=49055.1230\n",
      "Epoch 7: Total Loss=48691.7402\n",
      "Epoch 8: Total Loss=48417.7168\n",
      "Epoch 9: Total Loss=48241.0000\n",
      "Updated x: [9.233598709106445, -8.968832015991211], Function Value: 165.6992950439453, Gradient: [0.29083746671676636, 0.1765337884426117]\n",
      "\n",
      "Step 43/200\n",
      "Epoch 0: Total Loss=46585.5527\n",
      "Epoch 1: Total Loss=46521.1445\n",
      "Epoch 2: Total Loss=46479.2168\n",
      "Epoch 3: Total Loss=46429.4336\n",
      "Epoch 4: Total Loss=46374.2734\n",
      "Epoch 5: Total Loss=46324.5059\n",
      "Epoch 6: Total Loss=46274.6406\n",
      "Epoch 7: Total Loss=46225.8906\n",
      "Epoch 8: Total Loss=46172.4258\n",
      "Epoch 9: Total Loss=46119.8594\n",
      "Updated x: [9.04102897644043, -8.877791404724121], Function Value: 160.55538940429688, Gradient: [0.05576946958899498, 0.020841890946030617]\n",
      "\n",
      "Step 44/200\n",
      "Epoch 0: Total Loss=45878.1914\n",
      "Epoch 1: Total Loss=45821.6211\n",
      "Epoch 2: Total Loss=45770.9766\n",
      "Epoch 3: Total Loss=45719.4805\n",
      "Epoch 4: Total Loss=45663.5508\n",
      "Epoch 5: Total Loss=45612.7090\n",
      "Epoch 6: Total Loss=45558.0547\n",
      "Epoch 7: Total Loss=45506.3848\n",
      "Epoch 8: Total Loss=45450.0664\n",
      "Epoch 9: Total Loss=45395.0000\n",
      "Updated x: [9.014573097229004, -8.831216812133789], Function Value: 159.25291442871094, Gradient: [0.1528070718050003, 0.07499773800373077]\n",
      "\n",
      "Step 45/200\n",
      "Epoch 0: Total Loss=44985.8398\n",
      "Epoch 1: Total Loss=44931.1035\n",
      "Epoch 2: Total Loss=44876.5957\n",
      "Epoch 3: Total Loss=44820.6621\n",
      "Epoch 4: Total Loss=44763.8379\n",
      "Epoch 5: Total Loss=44708.4160\n",
      "Epoch 6: Total Loss=44650.5684\n",
      "Epoch 7: Total Loss=44596.1602\n",
      "Epoch 8: Total Loss=44537.0449\n",
      "Epoch 9: Total Loss=44480.6367\n",
      "Updated x: [9.167616844177246, -8.90549373626709], Function Value: 163.35301208496094, Gradient: [-0.05232658237218857, -0.04822520539164543]\n",
      "\n",
      "Step 46/200\n",
      "Epoch 0: Total Loss=44359.1504\n",
      "Epoch 1: Total Loss=44076.4863\n",
      "Epoch 2: Total Loss=43541.4160\n",
      "Epoch 3: Total Loss=44189.0352\n",
      "Epoch 4: Total Loss=43904.1504\n",
      "Epoch 5: Total Loss=43371.7188\n",
      "Epoch 6: Total Loss=44010.3320\n",
      "Epoch 7: Total Loss=43731.4688\n",
      "Epoch 8: Total Loss=43199.7266\n",
      "Epoch 9: Total Loss=43835.6582\n",
      "Updated x: [9.144479751586914, -8.743919372558594], Function Value: 160.07763671875, Gradient: [-0.13386492431163788, -0.09703633189201355]\n",
      "\n",
      "Step 47/200\n",
      "Epoch 0: Total Loss=43850.0078\n",
      "Epoch 1: Total Loss=42555.3945\n",
      "Epoch 2: Total Loss=43857.1934\n",
      "Epoch 3: Total Loss=43672.1152\n",
      "Epoch 4: Total Loss=42377.2676\n",
      "Epoch 5: Total Loss=43676.9453\n",
      "Epoch 6: Total Loss=43485.8770\n",
      "Epoch 7: Total Loss=42196.0039\n",
      "Epoch 8: Total Loss=43491.9688\n",
      "Epoch 9: Total Loss=43299.7656\n",
      "Updated x: [9.09433650970459, -8.827588081359863], Function Value: 160.63327026367188, Gradient: [0.052797168493270874, 0.01043873280286789]\n",
      "\n",
      "Step 48/200\n",
      "Epoch 0: Total Loss=43370.2383\n",
      "Epoch 1: Total Loss=41648.1973\n",
      "Epoch 2: Total Loss=43248.0723\n",
      "Epoch 3: Total Loss=41522.1973\n",
      "Epoch 4: Total Loss=43127.0664\n",
      "Epoch 5: Total Loss=41400.7070\n",
      "Epoch 6: Total Loss=42991.6094\n",
      "Epoch 7: Total Loss=41281.5527\n",
      "Epoch 8: Total Loss=42862.6250\n",
      "Epoch 9: Total Loss=41153.5117\n",
      "Updated x: [9.042326927185059, -8.80876636505127], Function Value: 159.35804748535156, Gradient: [0.01270655170083046, -0.013080116361379623]\n",
      "\n",
      "Step 49/200\n",
      "Epoch 0: Total Loss=42156.4238\n",
      "Epoch 1: Total Loss=41810.0059\n",
      "Epoch 2: Total Loss=42027.7539\n",
      "Epoch 3: Total Loss=41680.2539\n",
      "Epoch 4: Total Loss=41893.3027\n",
      "Epoch 5: Total Loss=41550.5430\n",
      "Epoch 6: Total Loss=41759.9160\n",
      "Epoch 7: Total Loss=41417.3066\n",
      "Epoch 8: Total Loss=41629.3340\n",
      "Epoch 9: Total Loss=41281.2129\n",
      "Updated x: [9.106803894042969, -8.819253921508789], Function Value: 160.71311950683594, Gradient: [-0.06133200228214264, -0.05583560839295387]\n",
      "\n",
      "Step 50/200\n",
      "Epoch 0: Total Loss=40813.3184\n",
      "Epoch 1: Total Loss=41881.4355\n",
      "Epoch 2: Total Loss=40819.0586\n",
      "Epoch 3: Total Loss=41819.1406\n",
      "Epoch 4: Total Loss=40573.0430\n",
      "Epoch 5: Total Loss=40472.8379\n",
      "Epoch 6: Total Loss=41535.0176\n",
      "Epoch 7: Total Loss=40472.0156\n",
      "Epoch 8: Total Loss=41471.3281\n",
      "Epoch 9: Total Loss=40225.4551\n",
      "Updated x: [9.126688957214355, -8.81949520111084], Function Value: 161.07994079589844, Gradient: [-0.03422967717051506, -0.04088061675429344]\n",
      "\n",
      "Step 51/200\n",
      "Epoch 0: Total Loss=142.6136\n",
      "Epoch 1: Total Loss=153.4907\n",
      "Epoch 2: Total Loss=142.6992\n",
      "Epoch 3: Total Loss=140.3152\n",
      "Epoch 4: Total Loss=127.1644\n",
      "Epoch 5: Total Loss=117.4985\n",
      "Epoch 6: Total Loss=117.6527\n",
      "Epoch 7: Total Loss=102.2066\n",
      "Epoch 8: Total Loss=98.7487\n",
      "Epoch 9: Total Loss=81.4246\n",
      "Updated x: [8.949713706970215, -8.83254623413086], Function Value: 158.11123657226562, Gradient: [2.699401378631592, 2.113527297973633]\n",
      "\n",
      "Step 52/200\n",
      "Epoch 0: Total Loss=43239.5781\n",
      "Epoch 1: Total Loss=42714.6816\n",
      "Epoch 2: Total Loss=42194.9316\n",
      "Epoch 3: Total Loss=41672.8398\n",
      "Epoch 4: Total Loss=41147.5215\n",
      "Epoch 5: Total Loss=40640.1758\n",
      "Epoch 6: Total Loss=40182.2402\n",
      "Epoch 7: Total Loss=39816.1523\n",
      "Epoch 8: Total Loss=39567.9980\n",
      "Epoch 9: Total Loss=39425.7402\n",
      "Updated x: [8.902066230773926, -8.919183731079102], Function Value: 158.79861450195312, Gradient: [0.06194232031702995, 0.031299181282520294]\n",
      "\n",
      "Step 53/200\n",
      "Epoch 0: Total Loss=39073.5117\n",
      "Epoch 1: Total Loss=39003.2129\n",
      "Epoch 2: Total Loss=38937.0566\n",
      "Epoch 3: Total Loss=38866.3848\n",
      "Epoch 4: Total Loss=38794.1113\n",
      "Epoch 5: Total Loss=38723.5859\n",
      "Epoch 6: Total Loss=38652.2773\n",
      "Epoch 7: Total Loss=38574.8008\n",
      "Epoch 8: Total Loss=38504.7168\n",
      "Epoch 9: Total Loss=38435.5508\n",
      "Updated x: [8.87237548828125, -8.893881797790527], Function Value: 157.8201904296875, Gradient: [0.028068087995052338, 0.0071516926400363445]\n",
      "\n",
      "Step 54/200\n",
      "Epoch 0: Total Loss=38624.9883\n",
      "Epoch 1: Total Loss=38558.7539\n",
      "Epoch 2: Total Loss=38488.2266\n",
      "Epoch 3: Total Loss=38413.4805\n",
      "Epoch 4: Total Loss=38336.5605\n",
      "Epoch 5: Total Loss=38267.1660\n",
      "Epoch 6: Total Loss=38189.8184\n",
      "Epoch 7: Total Loss=38117.4688\n",
      "Epoch 8: Total Loss=38042.9082\n",
      "Epoch 9: Total Loss=37964.8555\n",
      "Updated x: [8.872794151306152, -8.974464416503906], Function Value: 159.26748657226562, Gradient: [0.017401505261659622, -0.0014525831211358309]\n",
      "\n",
      "Step 55/200\n",
      "Epoch 0: Total Loss=37907.7363\n",
      "Epoch 1: Total Loss=37826.8789\n",
      "Epoch 2: Total Loss=37756.0234\n",
      "Epoch 3: Total Loss=37679.0781\n",
      "Epoch 4: Total Loss=37603.5996\n",
      "Epoch 5: Total Loss=37519.1836\n",
      "Epoch 6: Total Loss=37454.5586\n",
      "Epoch 7: Total Loss=37371.5684\n",
      "Epoch 8: Total Loss=37289.7129\n",
      "Epoch 9: Total Loss=37211.3828\n",
      "Updated x: [8.885441780090332, -8.96611213684082], Function Value: 159.3422393798828, Gradient: [-0.010702386498451233, -0.0182980727404356]\n",
      "\n",
      "Step 56/200\n",
      "Epoch 0: Total Loss=37257.9453\n",
      "Epoch 1: Total Loss=37077.4805\n",
      "Epoch 2: Total Loss=37386.9629\n",
      "Epoch 3: Total Loss=37024.4805\n",
      "Epoch 4: Total Loss=36842.0156\n",
      "Epoch 5: Total Loss=37150.9238\n",
      "Epoch 6: Total Loss=36789.8262\n",
      "Epoch 7: Total Loss=36603.4941\n",
      "Epoch 8: Total Loss=36911.2891\n",
      "Epoch 9: Total Loss=36550.4902\n",
      "Updated x: [9.008054733276367, -8.89109992980957], Function Value: 160.19671630859375, Gradient: [-0.2246117889881134, -0.13245514035224915]\n",
      "\n",
      "Step 57/200\n",
      "Epoch 0: Total Loss=36314.9004\n",
      "Epoch 1: Total Loss=36505.7695\n",
      "Epoch 2: Total Loss=36196.3398\n",
      "Epoch 3: Total Loss=36078.6328\n",
      "Epoch 4: Total Loss=36262.9414\n",
      "Epoch 5: Total Loss=35947.5566\n",
      "Epoch 6: Total Loss=35831.3301\n",
      "Epoch 7: Total Loss=36017.3496\n",
      "Epoch 8: Total Loss=35707.6621\n",
      "Epoch 9: Total Loss=35580.0215\n",
      "Updated x: [8.942264556884766, -8.837752342224121], Function Value: 158.06996154785156, Gradient: [-0.17309176921844482, -0.10604941099882126]\n",
      "\n",
      "Step 58/200\n",
      "Epoch 0: Total Loss=35454.3066\n",
      "Epoch 1: Total Loss=35716.2617\n",
      "Epoch 2: Total Loss=35284.0430\n",
      "Epoch 3: Total Loss=35548.8535\n",
      "Epoch 4: Total Loss=35121.0059\n",
      "Epoch 5: Total Loss=35380.9688\n",
      "Epoch 6: Total Loss=34955.2012\n",
      "Epoch 7: Total Loss=35213.9414\n",
      "Epoch 8: Total Loss=34780.2969\n",
      "Epoch 9: Total Loss=35042.3457\n",
      "Updated x: [8.974238395690918, -8.87731647491455], Function Value: 159.3437042236328, Gradient: [-0.10949026048183441, -0.0721597671508789]\n",
      "\n",
      "Step 59/200\n",
      "Epoch 0: Total Loss=34934.0918\n",
      "Epoch 1: Total Loss=34566.0742\n",
      "Epoch 2: Total Loss=34752.9766\n",
      "Epoch 3: Total Loss=34392.0938\n",
      "Epoch 4: Total Loss=34580.2168\n",
      "Epoch 5: Total Loss=34214.7441\n",
      "Epoch 6: Total Loss=34406.0840\n",
      "Epoch 7: Total Loss=34047.0293\n",
      "Epoch 8: Total Loss=34228.4395\n",
      "Epoch 9: Total Loss=33874.7324\n",
      "Updated x: [9.096580505371094, -8.716919898986816], Function Value: 158.73248291015625, Gradient: [-0.42857056856155396, -0.23416496813297272]\n",
      "\n",
      "Step 60/200\n",
      "Epoch 0: Total Loss=33996.5273\n",
      "Epoch 1: Total Loss=33585.1211\n",
      "Epoch 2: Total Loss=33788.0312\n",
      "Epoch 3: Total Loss=33814.4336\n",
      "Epoch 4: Total Loss=33400.5273\n",
      "Epoch 5: Total Loss=33554.7344\n",
      "Epoch 6: Total Loss=33135.5928\n",
      "Epoch 7: Total Loss=33323.0391\n",
      "Epoch 8: Total Loss=33378.3477\n",
      "Epoch 9: Total Loss=32954.9834\n",
      "Updated x: [9.105640411376953, -8.662527084350586], Function Value: 157.95205688476562, Gradient: [-0.4182468056678772, -0.23120006918907166]\n",
      "\n",
      "Step 61/200\n",
      "Epoch 0: Total Loss=404.8150\n",
      "Epoch 1: Total Loss=422.7131\n",
      "Epoch 2: Total Loss=406.8316\n",
      "Epoch 3: Total Loss=395.6636\n",
      "Epoch 4: Total Loss=396.4239\n",
      "Epoch 5: Total Loss=385.1750\n",
      "Epoch 6: Total Loss=388.2319\n",
      "Epoch 7: Total Loss=368.3595\n",
      "Epoch 8: Total Loss=362.9383\n",
      "Epoch 9: Total Loss=365.7034\n",
      "Updated x: [9.004988670349121, -8.57259750366211], Function Value: 154.57925415039062, Gradient: [-0.09654402732849121, -0.020090237259864807]\n",
      "\n",
      "Step 62/200\n",
      "Epoch 0: Total Loss=29491.2939\n",
      "Epoch 1: Total Loss=29386.7256\n",
      "Epoch 2: Total Loss=29301.8506\n",
      "Epoch 3: Total Loss=29201.5049\n",
      "Epoch 4: Total Loss=29103.1162\n",
      "Epoch 5: Total Loss=28991.6914\n",
      "Epoch 6: Total Loss=28884.6484\n",
      "Epoch 7: Total Loss=28763.5752\n",
      "Epoch 8: Total Loss=28630.8477\n",
      "Epoch 9: Total Loss=28505.8320\n",
      "Updated x: [8.937726974487305, -8.346035957336426], Function Value: 149.53927612304688, Gradient: [0.4046664834022522, 0.20623187720775604]\n",
      "\n",
      "Step 63/200\n",
      "Epoch 0: Total Loss=28568.1230\n",
      "Epoch 1: Total Loss=28486.9521\n",
      "Epoch 2: Total Loss=28395.6123\n",
      "Epoch 3: Total Loss=28324.2607\n",
      "Epoch 4: Total Loss=28237.1484\n",
      "Epoch 5: Total Loss=28156.7441\n",
      "Epoch 6: Total Loss=28064.3711\n",
      "Epoch 7: Total Loss=27982.1514\n",
      "Epoch 8: Total Loss=27891.9053\n",
      "Epoch 9: Total Loss=27794.1377\n",
      "Updated x: [8.978164672851562, -8.340752601623535], Function Value: 150.17559814453125, Gradient: [0.020313823595643044, -0.0066826133988797665]\n",
      "\n",
      "Step 64/200\n",
      "Epoch 0: Total Loss=27949.3877\n",
      "Epoch 1: Total Loss=27872.6299\n",
      "Epoch 2: Total Loss=27786.5752\n",
      "Epoch 3: Total Loss=27699.3115\n",
      "Epoch 4: Total Loss=27595.8711\n",
      "Epoch 5: Total Loss=27522.3350\n",
      "Epoch 6: Total Loss=27442.6211\n",
      "Epoch 7: Total Loss=27349.2266\n",
      "Epoch 8: Total Loss=27264.6689\n",
      "Epoch 9: Total Loss=27173.3232\n",
      "Updated x: [9.032638549804688, -8.365056037902832], Function Value: 151.56271362304688, Gradient: [-0.06417626887559891, -0.04817376285791397]\n",
      "\n",
      "Step 65/200\n",
      "Epoch 0: Total Loss=27646.8545\n",
      "Epoch 1: Total Loss=27560.4307\n",
      "Epoch 2: Total Loss=27469.2324\n",
      "Epoch 3: Total Loss=27375.8896\n",
      "Epoch 4: Total Loss=27288.8301\n",
      "Epoch 5: Total Loss=27191.7881\n",
      "Epoch 6: Total Loss=27112.3037\n",
      "Epoch 7: Total Loss=26996.9600\n",
      "Epoch 8: Total Loss=26925.8008\n",
      "Epoch 9: Total Loss=26833.5332\n",
      "Updated x: [9.035964012145996, -8.565653800964355], Function Value: 155.01907348632812, Gradient: [0.28920331597328186, 0.15171977877616882]\n",
      "\n",
      "Step 66/200\n",
      "Epoch 0: Total Loss=27381.7500\n",
      "Epoch 1: Total Loss=26251.2246\n",
      "Epoch 2: Total Loss=27586.9336\n",
      "Epoch 3: Total Loss=27109.3516\n",
      "Epoch 4: Total Loss=25987.0078\n",
      "Epoch 5: Total Loss=27319.0088\n",
      "Epoch 6: Total Loss=26829.1729\n",
      "Epoch 7: Total Loss=25711.9844\n",
      "Epoch 8: Total Loss=27026.0586\n",
      "Epoch 9: Total Loss=26548.9277\n",
      "Updated x: [9.079547882080078, -8.638998031616211], Function Value: 157.07046508789062, Gradient: [0.2651253640651703, 0.1392042487859726]\n",
      "\n",
      "Step 67/200\n",
      "Epoch 0: Total Loss=26613.5244\n",
      "Epoch 1: Total Loss=26081.9102\n",
      "Epoch 2: Total Loss=26424.1211\n",
      "Epoch 3: Total Loss=26329.5771\n",
      "Epoch 4: Total Loss=25788.0186\n",
      "Epoch 5: Total Loss=26161.1826\n",
      "Epoch 6: Total Loss=26034.7451\n",
      "Epoch 7: Total Loss=25505.4932\n",
      "Epoch 8: Total Loss=25871.8818\n",
      "Epoch 9: Total Loss=25740.4053\n",
      "Updated x: [9.010146141052246, -8.568814277648926], Function Value: 154.6072998046875, Gradient: [0.22965115308761597, 0.11903411895036697]\n",
      "\n",
      "Step 68/200\n",
      "Epoch 0: Total Loss=25612.8652\n",
      "Epoch 1: Total Loss=25060.4326\n",
      "Epoch 2: Total Loss=25412.5645\n",
      "Epoch 3: Total Loss=24856.1152\n",
      "Epoch 4: Total Loss=25221.5527\n",
      "Epoch 5: Total Loss=24679.7471\n",
      "Epoch 6: Total Loss=25035.2852\n",
      "Epoch 7: Total Loss=24501.1729\n",
      "Epoch 8: Total Loss=24840.2549\n",
      "Epoch 9: Total Loss=24309.6865\n",
      "Updated x: [8.853009223937988, -8.647503852844238], Function Value: 153.15509033203125, Gradient: [1.4079400300979614, 0.7481338381767273]\n",
      "\n",
      "Step 69/200\n",
      "Epoch 0: Total Loss=24087.4092\n",
      "Epoch 1: Total Loss=25166.2275\n",
      "Epoch 2: Total Loss=23896.9082\n",
      "Epoch 3: Total Loss=24943.7041\n",
      "Epoch 4: Total Loss=23717.2891\n",
      "Epoch 5: Total Loss=24763.7969\n",
      "Epoch 6: Total Loss=23528.1357\n",
      "Epoch 7: Total Loss=24563.9365\n",
      "Epoch 8: Total Loss=23323.6758\n",
      "Epoch 9: Total Loss=24355.9941\n",
      "Updated x: [9.004419326782227, -8.574141502380371], Function Value: 154.595458984375, Gradient: [0.09129820764064789, 0.04265761002898216]\n",
      "\n",
      "Step 70/200\n",
      "Epoch 0: Total Loss=23544.5010\n",
      "Epoch 1: Total Loss=23757.4814\n",
      "Epoch 2: Total Loss=22688.7969\n",
      "Epoch 3: Total Loss=23234.8867\n",
      "Epoch 4: Total Loss=22975.0498\n",
      "Epoch 5: Total Loss=23052.5850\n",
      "Epoch 6: Total Loss=23274.3223\n",
      "Epoch 7: Total Loss=22160.7842\n",
      "Epoch 8: Total Loss=22751.0029\n",
      "Epoch 9: Total Loss=22493.1260\n",
      "Updated x: [8.781373023986816, -8.535009384155273], Function Value: 149.95889282226562, Gradient: [1.0991203784942627, 0.5630750060081482]\n",
      "\n",
      "Step 71/200\n",
      "Epoch 0: Total Loss=1139.0023\n",
      "Epoch 1: Total Loss=1129.8489\n",
      "Epoch 2: Total Loss=1127.7730\n",
      "Epoch 3: Total Loss=1089.6412\n",
      "Epoch 4: Total Loss=1055.8639\n",
      "Epoch 5: Total Loss=1023.5742\n",
      "Epoch 6: Total Loss=969.3755\n",
      "Epoch 7: Total Loss=914.0466\n",
      "Epoch 8: Total Loss=836.8609\n",
      "Epoch 9: Total Loss=752.4455\n",
      "Updated x: [8.86862564086914, -8.44235897064209], Function Value: 149.92593383789062, Gradient: [5.943656921386719, 3.9757909774780273]\n",
      "\n",
      "Step 72/200\n",
      "Epoch 0: Total Loss=24872.6230\n",
      "Epoch 1: Total Loss=24190.2168\n",
      "Epoch 2: Total Loss=23551.1201\n",
      "Epoch 3: Total Loss=22930.2070\n",
      "Epoch 4: Total Loss=22406.9736\n",
      "Epoch 5: Total Loss=21962.5996\n",
      "Epoch 6: Total Loss=21692.3828\n",
      "Epoch 7: Total Loss=21545.7373\n",
      "Epoch 8: Total Loss=21481.8721\n",
      "Epoch 9: Total Loss=21418.6611\n",
      "Updated x: [8.878552436828613, -8.389638900756836], Function Value: 149.2147216796875, Gradient: [-0.7149685621261597, -0.3472951054573059]\n",
      "\n",
      "Step 73/200\n",
      "Epoch 0: Total Loss=20771.7178\n",
      "Epoch 1: Total Loss=20672.0615\n",
      "Epoch 2: Total Loss=20572.3506\n",
      "Epoch 3: Total Loss=20478.2266\n",
      "Epoch 4: Total Loss=20379.0820\n",
      "Epoch 5: Total Loss=20288.1523\n",
      "Epoch 6: Total Loss=20195.6348\n",
      "Epoch 7: Total Loss=20117.1025\n",
      "Epoch 8: Total Loss=20018.5479\n",
      "Epoch 9: Total Loss=19929.7236\n",
      "Updated x: [8.792227745056152, -8.309633255004883], Function Value: 146.353271484375, Gradient: [0.36260634660720825, 0.18275874853134155]\n",
      "\n",
      "Step 74/200\n",
      "Epoch 0: Total Loss=19582.2266\n",
      "Epoch 1: Total Loss=19511.2471\n",
      "Epoch 2: Total Loss=19416.9463\n",
      "Epoch 3: Total Loss=19326.6631\n",
      "Epoch 4: Total Loss=19202.7051\n",
      "Epoch 5: Total Loss=19133.4160\n",
      "Epoch 6: Total Loss=19033.8682\n",
      "Epoch 7: Total Loss=18946.4766\n",
      "Epoch 8: Total Loss=18860.8926\n",
      "Epoch 9: Total Loss=18768.7373\n",
      "Updated x: [8.841083526611328, -8.270791053771973], Function Value: 146.57073974609375, Gradient: [-0.16054877638816833, -0.08237490057945251]\n",
      "\n",
      "Step 75/200\n",
      "Epoch 0: Total Loss=18444.6221\n",
      "Epoch 1: Total Loss=18361.7910\n",
      "Epoch 2: Total Loss=18263.1611\n",
      "Epoch 3: Total Loss=18157.8125\n",
      "Epoch 4: Total Loss=18078.8887\n",
      "Epoch 5: Total Loss=17978.2490\n",
      "Epoch 6: Total Loss=17904.8721\n",
      "Epoch 7: Total Loss=17751.3945\n",
      "Epoch 8: Total Loss=17709.7051\n",
      "Epoch 9: Total Loss=17617.5693\n",
      "Updated x: [8.719963073730469, -8.246432304382324], Function Value: 144.04141235351562, Gradient: [0.13356006145477295, 0.06357845664024353]\n",
      "\n",
      "Step 76/200\n",
      "Epoch 0: Total Loss=17508.6143\n",
      "Epoch 1: Total Loss=16739.3120\n",
      "Epoch 2: Total Loss=16218.7241\n",
      "Epoch 3: Total Loss=17273.3369\n",
      "Epoch 4: Total Loss=16468.6470\n",
      "Epoch 5: Total Loss=15918.0537\n",
      "Epoch 6: Total Loss=17001.6152\n",
      "Epoch 7: Total Loss=16212.3999\n",
      "Epoch 8: Total Loss=15710.7959\n",
      "Epoch 9: Total Loss=16722.9136\n",
      "Updated x: [8.612510681152344, -8.18510913848877], Function Value: 141.17135620117188, Gradient: [0.5076010227203369, 0.24349144101142883]\n",
      "\n",
      "Step 77/200\n",
      "Epoch 0: Total Loss=16630.6309\n",
      "Epoch 1: Total Loss=15715.3384\n",
      "Epoch 2: Total Loss=15661.0493\n",
      "Epoch 3: Total Loss=16355.1265\n",
      "Epoch 4: Total Loss=15430.8799\n",
      "Epoch 5: Total Loss=15412.5015\n",
      "Epoch 6: Total Loss=16105.7012\n",
      "Epoch 7: Total Loss=15171.4751\n",
      "Epoch 8: Total Loss=15154.3867\n",
      "Epoch 9: Total Loss=15817.8960\n",
      "Updated x: [8.733115196228027, -8.12266731262207], Function Value: 142.24502563476562, Gradient: [-0.38946452736854553, -0.1897232085466385]\n",
      "\n",
      "Step 78/200\n",
      "Epoch 0: Total Loss=15185.2090\n",
      "Epoch 1: Total Loss=14762.8672\n",
      "Epoch 2: Total Loss=14984.9316\n",
      "Epoch 3: Total Loss=14582.2563\n",
      "Epoch 4: Total Loss=14796.0122\n",
      "Epoch 5: Total Loss=14420.9150\n",
      "Epoch 6: Total Loss=14656.9858\n",
      "Epoch 7: Total Loss=14231.6938\n",
      "Epoch 8: Total Loss=14472.5215\n",
      "Epoch 9: Total Loss=14094.3643\n",
      "Updated x: [8.659717559814453, -8.20726490020752], Function Value: 142.34991455078125, Gradient: [0.025965379551053047, 0.010039403103291988]\n",
      "\n",
      "Step 79/200\n",
      "Epoch 0: Total Loss=14090.7236\n",
      "Epoch 1: Total Loss=14157.5571\n",
      "Epoch 2: Total Loss=13929.8931\n",
      "Epoch 3: Total Loss=13979.7290\n",
      "Epoch 4: Total Loss=13737.2959\n",
      "Epoch 5: Total Loss=13828.1641\n",
      "Epoch 6: Total Loss=13615.7959\n",
      "Epoch 7: Total Loss=13650.0923\n",
      "Epoch 8: Total Loss=13433.2451\n",
      "Epoch 9: Total Loss=13487.7798\n",
      "Updated x: [8.549113273620605, -8.321094512939453], Function Value: 142.3279571533203, Gradient: [1.2446438074111938, 0.5752881169319153]\n",
      "\n",
      "Step 80/200\n",
      "Epoch 0: Total Loss=13502.0781\n",
      "Epoch 1: Total Loss=13079.0859\n",
      "Epoch 2: Total Loss=13411.3916\n",
      "Epoch 3: Total Loss=13274.8086\n",
      "Epoch 4: Total Loss=12764.8335\n",
      "Epoch 5: Total Loss=13137.5234\n",
      "Epoch 6: Total Loss=12711.0063\n",
      "Epoch 7: Total Loss=13003.5713\n",
      "Epoch 8: Total Loss=12876.6011\n",
      "Epoch 9: Total Loss=12437.9790\n",
      "Updated x: [8.554584503173828, -8.460984230041504], Function Value: 144.7691650390625, Gradient: [1.525834083557129, 0.690828800201416]\n",
      "\n",
      "Step 81/200\n",
      "Epoch 0: Total Loss=2578.9803\n",
      "Epoch 1: Total Loss=2547.6490\n",
      "Epoch 2: Total Loss=2492.5051\n",
      "Epoch 3: Total Loss=2464.2239\n",
      "Epoch 4: Total Loss=2424.6266\n",
      "Epoch 5: Total Loss=2386.9579\n",
      "Epoch 6: Total Loss=2345.4857\n",
      "Epoch 7: Total Loss=2359.0682\n",
      "Epoch 8: Total Loss=2301.3418\n",
      "Epoch 9: Total Loss=2292.4456\n",
      "Updated x: [8.408256530761719, -8.354708671569824], Function Value: 140.49993896484375, Gradient: [-0.12186678498983383, -0.03107316978275776]\n",
      "\n",
      "Step 82/200\n",
      "Epoch 0: Total Loss=12759.7544\n",
      "Epoch 1: Total Loss=12652.2896\n",
      "Epoch 2: Total Loss=12594.1611\n",
      "Epoch 3: Total Loss=12504.3457\n",
      "Epoch 4: Total Loss=12376.8540\n",
      "Epoch 5: Total Loss=12303.7842\n",
      "Epoch 6: Total Loss=12197.8291\n",
      "Epoch 7: Total Loss=12090.6475\n",
      "Epoch 8: Total Loss=11975.5864\n",
      "Epoch 9: Total Loss=11926.4263\n",
      "Updated x: [8.49356460571289, -8.313779830932617], Function Value: 141.25958251953125, Gradient: [1.3429951667785645, 0.5813093185424805]\n",
      "\n",
      "Step 83/200\n",
      "Epoch 0: Total Loss=11987.6929\n",
      "Epoch 1: Total Loss=11923.7134\n",
      "Epoch 2: Total Loss=11828.8174\n",
      "Epoch 3: Total Loss=11760.5464\n",
      "Epoch 4: Total Loss=11711.1104\n",
      "Epoch 5: Total Loss=11624.4067\n",
      "Epoch 6: Total Loss=11529.5928\n",
      "Epoch 7: Total Loss=11489.4927\n",
      "Epoch 8: Total Loss=11441.2056\n",
      "Epoch 9: Total Loss=11356.3896\n",
      "Updated x: [8.470064163208008, -8.40584945678711], Function Value: 142.40029907226562, Gradient: [0.0972037985920906, 0.030739801004529]\n",
      "\n",
      "Step 84/200\n",
      "Epoch 0: Total Loss=11607.8696\n",
      "Epoch 1: Total Loss=11560.8599\n",
      "Epoch 2: Total Loss=11487.2559\n",
      "Epoch 3: Total Loss=11427.4326\n",
      "Epoch 4: Total Loss=11333.3115\n",
      "Epoch 5: Total Loss=11259.5537\n",
      "Epoch 6: Total Loss=11224.0488\n",
      "Epoch 7: Total Loss=11121.9082\n",
      "Epoch 8: Total Loss=11044.7285\n",
      "Epoch 9: Total Loss=11000.1279\n",
      "Updated x: [8.687297821044922, -8.4233980178833], Function Value: 146.42279052734375, Gradient: [-0.993409276008606, -0.41109511256217957]\n",
      "\n",
      "Step 85/200\n",
      "Epoch 0: Total Loss=11304.0801\n",
      "Epoch 1: Total Loss=11197.6572\n",
      "Epoch 2: Total Loss=11170.6909\n",
      "Epoch 3: Total Loss=11118.6348\n",
      "Epoch 4: Total Loss=11043.6660\n",
      "Epoch 5: Total Loss=10968.8862\n",
      "Epoch 6: Total Loss=10906.8765\n",
      "Epoch 7: Total Loss=10831.7681\n",
      "Epoch 8: Total Loss=10796.9424\n",
      "Epoch 9: Total Loss=10716.3623\n",
      "Updated x: [8.757719993591309, -8.439467430114746], Function Value: 147.92227172851562, Gradient: [-1.0247188806533813, -0.42236557602882385]\n",
      "\n",
      "Step 86/200\n",
      "Epoch 0: Total Loss=10738.5430\n",
      "Epoch 1: Total Loss=10971.2524\n",
      "Epoch 2: Total Loss=11062.3501\n",
      "Epoch 3: Total Loss=10576.9956\n",
      "Epoch 4: Total Loss=10795.0698\n",
      "Epoch 5: Total Loss=10855.5181\n",
      "Epoch 6: Total Loss=10369.6211\n",
      "Epoch 7: Total Loss=10524.4746\n",
      "Epoch 8: Total Loss=10619.7207\n",
      "Epoch 9: Total Loss=10193.3789\n",
      "Updated x: [8.828819274902344, -8.461169242858887], Function Value: 149.5394287109375, Gradient: [-1.0988476276397705, -0.4474339783191681]\n",
      "\n",
      "Step 87/200\n",
      "Epoch 0: Total Loss=10523.8975\n",
      "Epoch 1: Total Loss=10818.5864\n",
      "Epoch 2: Total Loss=10268.5908\n",
      "Epoch 3: Total Loss=10322.4839\n",
      "Epoch 4: Total Loss=10627.7710\n",
      "Epoch 5: Total Loss=10097.7163\n",
      "Epoch 6: Total Loss=10170.3638\n",
      "Epoch 7: Total Loss=10454.8306\n",
      "Epoch 8: Total Loss=9914.0776\n",
      "Epoch 9: Total Loss=10006.0000\n",
      "Updated x: [8.850822448730469, -8.657509803771973], Function Value: 153.28953552246094, Gradient: [-0.9541335701942444, -0.38563352823257446]\n",
      "\n",
      "Step 88/200\n",
      "Epoch 0: Total Loss=10755.7671\n",
      "Epoch 1: Total Loss=9340.5820\n",
      "Epoch 2: Total Loss=10598.1167\n",
      "Epoch 3: Total Loss=9166.7568\n",
      "Epoch 4: Total Loss=10550.7031\n",
      "Epoch 5: Total Loss=9066.6040\n",
      "Epoch 6: Total Loss=10439.9722\n",
      "Epoch 7: Total Loss=8993.5933\n",
      "Epoch 8: Total Loss=10335.2119\n",
      "Epoch 9: Total Loss=8845.4751\n",
      "Updated x: [8.845471382141113, -8.573661804199219], Function Value: 151.75003051757812, Gradient: [-1.157051682472229, -0.4541581869125366]\n",
      "\n",
      "Step 89/200\n",
      "Epoch 0: Total Loss=9934.2168\n",
      "Epoch 1: Total Loss=9638.8149\n",
      "Epoch 2: Total Loss=9850.8921\n",
      "Epoch 3: Total Loss=9544.1758\n",
      "Epoch 4: Total Loss=9759.3301\n",
      "Epoch 5: Total Loss=9382.5137\n",
      "Epoch 6: Total Loss=9629.5928\n",
      "Epoch 7: Total Loss=9364.2012\n",
      "Epoch 8: Total Loss=9486.0396\n",
      "Epoch 9: Total Loss=9249.0498\n",
      "Updated x: [8.931925773620605, -8.57271671295166], Function Value: 153.27076721191406, Gradient: [-1.2532087564468384, -0.4806039035320282]\n",
      "\n",
      "Step 90/200\n",
      "Epoch 0: Total Loss=9162.2529\n",
      "Epoch 1: Total Loss=9615.2739\n",
      "Epoch 2: Total Loss=9100.8130\n",
      "Epoch 3: Total Loss=9749.6982\n",
      "Epoch 4: Total Loss=9764.5225\n",
      "Epoch 5: Total Loss=8940.8604\n",
      "Epoch 6: Total Loss=9331.1768\n",
      "Epoch 7: Total Loss=8976.1453\n",
      "Epoch 8: Total Loss=9544.3486\n",
      "Epoch 9: Total Loss=9582.4854\n",
      "Updated x: [8.938752174377441, -8.662841796875], Function Value: 154.9461212158203, Gradient: [-1.2407780885696411, -0.47066786885261536]\n",
      "\n",
      "Step 91/200\n",
      "Epoch 0: Total Loss=5429.5654\n",
      "Epoch 1: Total Loss=5354.4895\n",
      "Epoch 2: Total Loss=5284.6614\n",
      "Epoch 3: Total Loss=5208.3865\n",
      "Epoch 4: Total Loss=5158.6555\n",
      "Epoch 5: Total Loss=5082.4915\n",
      "Epoch 6: Total Loss=5005.8115\n",
      "Epoch 7: Total Loss=4988.3245\n",
      "Epoch 8: Total Loss=4917.3733\n",
      "Epoch 9: Total Loss=4822.0813\n",
      "Updated x: [8.944302558898926, -8.765250205993652], Function Value: 156.83016967773438, Gradient: [-0.012245958670973778, -0.0026098741218447685]\n",
      "\n",
      "Step 92/200\n",
      "Epoch 0: Total Loss=11577.3647\n",
      "Epoch 1: Total Loss=11507.2676\n",
      "Epoch 2: Total Loss=11427.8286\n",
      "Epoch 3: Total Loss=11378.1660\n",
      "Epoch 4: Total Loss=11312.0938\n",
      "Epoch 5: Total Loss=11241.2275\n",
      "Epoch 6: Total Loss=11204.0020\n",
      "Epoch 7: Total Loss=11099.5630\n",
      "Epoch 8: Total Loss=11045.3594\n",
      "Epoch 9: Total Loss=11027.9600\n",
      "Updated x: [8.9771089553833, -8.751944541931152], Function Value: 157.18502807617188, Gradient: [-4.1533341573085636e-05, -5.7918969105230644e-06]\n",
      "\n",
      "Step 93/200\n",
      "Epoch 0: Total Loss=11423.7949\n",
      "Epoch 1: Total Loss=11367.6401\n",
      "Epoch 2: Total Loss=11279.8633\n",
      "Epoch 3: Total Loss=11252.9263\n",
      "Epoch 4: Total Loss=11194.8818\n",
      "Epoch 5: Total Loss=11132.4634\n",
      "Epoch 6: Total Loss=11090.3164\n",
      "Epoch 7: Total Loss=11024.5557\n",
      "Epoch 8: Total Loss=10963.1777\n",
      "Epoch 9: Total Loss=10922.8237\n",
      "Updated x: [9.14172077178955, -8.820151329040527], Function Value: 161.36611938476562, Gradient: [1.2087318701503591e-08, -2.7688098480638246e-09]\n",
      "\n",
      "Step 94/200\n",
      "Epoch 0: Total Loss=11055.2637\n",
      "Epoch 1: Total Loss=10962.6855\n",
      "Epoch 2: Total Loss=10955.0249\n",
      "Epoch 3: Total Loss=10880.8784\n",
      "Epoch 4: Total Loss=10858.2842\n",
      "Epoch 5: Total Loss=10753.5063\n",
      "Epoch 6: Total Loss=10773.7612\n",
      "Epoch 7: Total Loss=10716.2012\n",
      "Epoch 8: Total Loss=10677.2061\n",
      "Epoch 9: Total Loss=10641.2202\n",
      "Updated x: [9.193387031555176, -8.73055362701416], Function Value: 160.74093627929688, Gradient: [4.2126169219613985e-09, -8.385298566615518e-10]\n",
      "\n",
      "Step 95/200\n",
      "Epoch 0: Total Loss=10633.3828\n",
      "Epoch 1: Total Loss=10588.5439\n",
      "Epoch 2: Total Loss=10557.6260\n",
      "Epoch 3: Total Loss=10509.3091\n",
      "Epoch 4: Total Loss=10478.2954\n",
      "Epoch 5: Total Loss=10439.2446\n",
      "Epoch 6: Total Loss=10406.3223\n",
      "Epoch 7: Total Loss=10385.7603\n",
      "Epoch 8: Total Loss=10342.3994\n",
      "Epoch 9: Total Loss=10291.5000\n",
      "Updated x: [9.272330284118652, -8.737810134887695], Function Value: 162.325439453125, Gradient: [2.6729245483636532e-09, -5.15356479713347e-10]\n",
      "\n",
      "Step 96/200\n",
      "Epoch 0: Total Loss=10234.7993\n",
      "Epoch 1: Total Loss=10283.4316\n",
      "Epoch 2: Total Loss=10361.3135\n",
      "Epoch 3: Total Loss=10135.5791\n",
      "Epoch 4: Total Loss=10217.2129\n",
      "Epoch 5: Total Loss=10303.5542\n",
      "Epoch 6: Total Loss=10040.1152\n",
      "Epoch 7: Total Loss=10111.3652\n",
      "Epoch 8: Total Loss=10231.0830\n",
      "Epoch 9: Total Loss=9961.0303\n",
      "Updated x: [9.173879623413086, -8.789641380310059], Function Value: 161.41786193847656, Gradient: [5.1309827497902916e-09, -9.455967120430842e-10]\n",
      "\n",
      "Step 97/200\n",
      "Epoch 0: Total Loss=10000.9033\n",
      "Epoch 1: Total Loss=10021.4116\n",
      "Epoch 2: Total Loss=10063.0728\n",
      "Epoch 3: Total Loss=9930.5640\n",
      "Epoch 4: Total Loss=9966.0244\n",
      "Epoch 5: Total Loss=9983.1709\n",
      "Epoch 6: Total Loss=9866.6777\n",
      "Epoch 7: Total Loss=9894.9316\n",
      "Epoch 8: Total Loss=9969.9165\n",
      "Epoch 9: Total Loss=9793.7603\n",
      "Updated x: [9.06368637084961, -8.938729286193848], Function Value: 162.05130004882812, Gradient: [1.0287013019194546e-08, -1.8331768325552389e-09]\n",
      "\n",
      "Step 98/200\n",
      "Epoch 0: Total Loss=9914.0210\n",
      "Epoch 1: Total Loss=9846.7168\n",
      "Epoch 2: Total Loss=9888.1108\n",
      "Epoch 3: Total Loss=9805.7734\n",
      "Epoch 4: Total Loss=9920.9297\n",
      "Epoch 5: Total Loss=9767.4136\n",
      "Epoch 6: Total Loss=9874.8242\n",
      "Epoch 7: Total Loss=9777.0020\n",
      "Epoch 8: Total Loss=9819.8335\n",
      "Epoch 9: Total Loss=9738.4546\n",
      "Updated x: [8.990877151489258, -9.088193893432617], Function Value: 163.43113708496094, Gradient: [1.7014878395116284e-08, -2.9779958499176473e-09]\n",
      "\n",
      "Step 99/200\n",
      "Epoch 0: Total Loss=9756.9043\n",
      "Epoch 1: Total Loss=9920.8936\n",
      "Epoch 2: Total Loss=9679.6270\n",
      "Epoch 3: Total Loss=9861.4517\n",
      "Epoch 4: Total Loss=9551.9414\n",
      "Epoch 5: Total Loss=9859.8105\n",
      "Epoch 6: Total Loss=9673.0093\n",
      "Epoch 7: Total Loss=9710.1562\n",
      "Epoch 8: Total Loss=9619.4985\n",
      "Epoch 9: Total Loss=9801.4180\n",
      "Updated x: [9.150484085083008, -9.148138046264648], Function Value: 167.4197998046875, Gradient: [9.775054543581518e-09, -1.7321100109768395e-09]\n",
      "\n",
      "Step 100/200\n",
      "Epoch 0: Total Loss=9890.9482\n",
      "Epoch 1: Total Loss=9697.1289\n",
      "Epoch 2: Total Loss=9696.8989\n",
      "Epoch 3: Total Loss=10015.6113\n",
      "Epoch 4: Total Loss=9565.7285\n",
      "Epoch 5: Total Loss=9792.3374\n",
      "Epoch 6: Total Loss=9584.4014\n",
      "Epoch 7: Total Loss=9561.8457\n",
      "Epoch 8: Total Loss=9942.5454\n",
      "Epoch 9: Total Loss=9483.3042\n",
      "Updated x: [9.189202308654785, -9.230894088745117], Function Value: 169.65084838867188, Gradient: [9.239967901919499e-09, -1.6845269623644299e-09]\n",
      "\n",
      "Step 101/200\n",
      "Epoch 0: Total Loss=7634.6995\n",
      "Epoch 1: Total Loss=7561.4597\n",
      "Epoch 2: Total Loss=7489.0657\n",
      "Epoch 3: Total Loss=7347.2849\n",
      "Epoch 4: Total Loss=7270.5598\n",
      "Epoch 5: Total Loss=7165.6487\n",
      "Epoch 6: Total Loss=7058.8455\n",
      "Epoch 7: Total Loss=6988.1738\n",
      "Epoch 8: Total Loss=6863.1006\n",
      "Epoch 9: Total Loss=6776.3057\n",
      "Updated x: [9.238724708557129, -9.178582191467285], Function Value: 169.60040283203125, Gradient: [1.344322129170905e-07, -2.202467896950111e-08]\n",
      "\n",
      "Step 102/200\n",
      "Epoch 0: Total Loss=11136.9844\n",
      "Epoch 1: Total Loss=11089.3330\n",
      "Epoch 2: Total Loss=11048.9346\n",
      "Epoch 3: Total Loss=10997.0508\n",
      "Epoch 4: Total Loss=10957.5674\n",
      "Epoch 5: Total Loss=10912.7432\n",
      "Epoch 6: Total Loss=10849.9512\n",
      "Epoch 7: Total Loss=10821.4639\n",
      "Epoch 8: Total Loss=10765.0112\n",
      "Epoch 9: Total Loss=10762.0161\n",
      "Updated x: [9.15257453918457, -9.255414962768555], Function Value: 169.4323272705078, Gradient: [3.641341379534424e-07, -6.634057569954166e-08]\n",
      "\n",
      "Step 103/200\n",
      "Epoch 0: Total Loss=10408.3657\n",
      "Epoch 1: Total Loss=10401.8018\n",
      "Epoch 2: Total Loss=10213.6997\n",
      "Epoch 3: Total Loss=10327.9292\n",
      "Epoch 4: Total Loss=10335.9404\n",
      "Epoch 5: Total Loss=10257.5752\n",
      "Epoch 6: Total Loss=10284.7246\n",
      "Epoch 7: Total Loss=10266.4590\n",
      "Epoch 8: Total Loss=10189.9824\n",
      "Epoch 9: Total Loss=10232.3833\n",
      "Updated x: [9.139835357666016, -9.028217315673828], Function Value: 165.0452880859375, Gradient: [7.927408773866773e-07, -1.5259215047080943e-07]\n",
      "\n",
      "Step 104/200\n",
      "Epoch 0: Total Loss=10172.2778\n",
      "Epoch 1: Total Loss=10146.8809\n",
      "Epoch 2: Total Loss=10084.6904\n",
      "Epoch 3: Total Loss=10078.2690\n",
      "Epoch 4: Total Loss=10111.2124\n",
      "Epoch 5: Total Loss=10079.7007\n",
      "Epoch 6: Total Loss=10059.0454\n",
      "Epoch 7: Total Loss=10035.9028\n",
      "Epoch 8: Total Loss=10023.5791\n",
      "Epoch 9: Total Loss=10011.1382\n",
      "Updated x: [9.19430923461914, -8.89760684967041], Function Value: 163.70272827148438, Gradient: [2.173419261453091e-06, -4.1109953485829465e-07]\n",
      "\n",
      "Step 105/200\n",
      "Epoch 0: Total Loss=9645.1479\n",
      "Epoch 1: Total Loss=9633.3223\n",
      "Epoch 2: Total Loss=9657.1567\n",
      "Epoch 3: Total Loss=9615.5190\n",
      "Epoch 4: Total Loss=9609.5571\n",
      "Epoch 5: Total Loss=9564.8706\n",
      "Epoch 6: Total Loss=9578.6465\n",
      "Epoch 7: Total Loss=9549.8545\n",
      "Epoch 8: Total Loss=9545.6089\n",
      "Epoch 9: Total Loss=9534.4312\n",
      "Updated x: [9.109655380249023, -8.738687515258789], Function Value: 159.35049438476562, Gradient: [7.776716302032582e-06, -1.4316869965114165e-06]\n",
      "\n",
      "Step 106/200\n",
      "Epoch 0: Total Loss=9494.7065\n",
      "Epoch 1: Total Loss=9127.0986\n",
      "Epoch 2: Total Loss=9141.3130\n",
      "Epoch 3: Total Loss=9470.9390\n",
      "Epoch 4: Total Loss=9086.1616\n",
      "Epoch 5: Total Loss=9041.9756\n",
      "Epoch 6: Total Loss=9412.7793\n",
      "Epoch 7: Total Loss=9010.3799\n",
      "Epoch 8: Total Loss=9036.5176\n",
      "Epoch 9: Total Loss=9340.9287\n",
      "Updated x: [9.001211166381836, -8.805170059204102], Function Value: 158.55282592773438, Gradient: [3.064911288674921e-05, -5.3834060054214206e-06]\n",
      "\n",
      "Step 107/200\n",
      "Epoch 0: Total Loss=9142.2163\n",
      "Epoch 1: Total Loss=9418.8726\n",
      "Epoch 2: Total Loss=8962.5010\n",
      "Epoch 3: Total Loss=9123.9219\n",
      "Epoch 4: Total Loss=9383.6055\n",
      "Epoch 5: Total Loss=8903.5049\n",
      "Epoch 6: Total Loss=9052.7793\n",
      "Epoch 7: Total Loss=9332.7939\n",
      "Epoch 8: Total Loss=8865.8716\n",
      "Epoch 9: Total Loss=8972.5625\n",
      "Updated x: [9.1131010055542, -8.92273998260498], Function Value: 162.6638946533203, Gradient: [7.668587932130322e-05, -1.2620411325769965e-05]\n",
      "\n",
      "Step 108/200\n",
      "Epoch 0: Total Loss=9099.5039\n",
      "Epoch 1: Total Loss=9148.0884\n",
      "Epoch 2: Total Loss=9067.0215\n",
      "Epoch 3: Total Loss=9123.4814\n",
      "Epoch 4: Total Loss=9034.9058\n",
      "Epoch 5: Total Loss=9073.4370\n",
      "Epoch 6: Total Loss=9015.4536\n",
      "Epoch 7: Total Loss=9022.5791\n",
      "Epoch 8: Total Loss=8955.3989\n",
      "Epoch 9: Total Loss=9023.0454\n",
      "Updated x: [9.353964805603027, -8.970011711120605], Function Value: 167.957763671875, Gradient: [0.0001853043504524976, -2.5921999622369185e-05]\n",
      "\n",
      "Step 109/200\n",
      "Epoch 0: Total Loss=9137.2173\n",
      "Epoch 1: Total Loss=8907.7500\n",
      "Epoch 2: Total Loss=9096.2129\n",
      "Epoch 3: Total Loss=8862.6846\n",
      "Epoch 4: Total Loss=9094.4990\n",
      "Epoch 5: Total Loss=8779.0098\n",
      "Epoch 6: Total Loss=9075.8618\n",
      "Epoch 7: Total Loss=8815.7568\n",
      "Epoch 8: Total Loss=9036.6777\n",
      "Epoch 9: Total Loss=8797.2334\n",
      "Updated x: [9.314336776733398, -8.932433128356934], Function Value: 166.54522705078125, Gradient: [0.0009989248355850577, -0.00011036706564482301]\n",
      "\n",
      "Step 110/200\n",
      "Epoch 0: Total Loss=8750.8657\n",
      "Epoch 1: Total Loss=9052.3022\n",
      "Epoch 2: Total Loss=8430.7837\n",
      "Epoch 3: Total Loss=8982.2944\n",
      "Epoch 4: Total Loss=8627.6860\n",
      "Epoch 5: Total Loss=8742.3455\n",
      "Epoch 6: Total Loss=8965.3633\n",
      "Epoch 7: Total Loss=8369.3091\n",
      "Epoch 8: Total Loss=8987.6826\n",
      "Epoch 9: Total Loss=8567.8557\n",
      "Updated x: [9.178450584411621, -8.847986221313477], Function Value: 162.53082275390625, Gradient: [0.005129935685545206, -0.0004086255794391036]\n",
      "\n",
      "Step 111/200\n",
      "Epoch 0: Total Loss=7135.7791\n",
      "Epoch 1: Total Loss=6991.0613\n",
      "Epoch 2: Total Loss=6904.9287\n",
      "Epoch 3: Total Loss=6802.1714\n",
      "Epoch 4: Total Loss=6683.5530\n",
      "Epoch 5: Total Loss=6627.9531\n",
      "Epoch 6: Total Loss=6490.7314\n",
      "Epoch 7: Total Loss=6410.7061\n",
      "Epoch 8: Total Loss=6325.9817\n",
      "Epoch 9: Total Loss=6205.1062\n",
      "Updated x: [9.187925338745117, -8.82985782623291], Function Value: 162.38436889648438, Gradient: [0.0638669952750206, 0.0011978289112448692]\n",
      "\n",
      "Step 112/200\n",
      "Epoch 0: Total Loss=9129.3955\n",
      "Epoch 1: Total Loss=9082.2656\n",
      "Epoch 2: Total Loss=9053.8506\n",
      "Epoch 3: Total Loss=9008.7935\n",
      "Epoch 4: Total Loss=8976.7124\n",
      "Epoch 5: Total Loss=8950.6416\n",
      "Epoch 6: Total Loss=8914.2842\n",
      "Epoch 7: Total Loss=8882.0581\n",
      "Epoch 8: Total Loss=8871.2935\n",
      "Epoch 9: Total Loss=8867.5703\n",
      "Updated x: [9.32007122039795, -8.812769889831543], Function Value: 164.52862548828125, Gradient: [0.0205229464918375, -0.0006532180705107749]\n",
      "\n",
      "Step 113/200\n",
      "Epoch 0: Total Loss=8727.1904\n",
      "Epoch 1: Total Loss=8752.1177\n",
      "Epoch 2: Total Loss=8746.8057\n",
      "Epoch 3: Total Loss=8587.4409\n",
      "Epoch 4: Total Loss=8721.2432\n",
      "Epoch 5: Total Loss=8708.1323\n",
      "Epoch 6: Total Loss=8686.6572\n",
      "Epoch 7: Total Loss=8677.7778\n",
      "Epoch 8: Total Loss=8657.1738\n",
      "Epoch 9: Total Loss=8642.9780\n",
      "Updated x: [9.331350326538086, -8.734200477600098], Function Value: 163.3603515625, Gradient: [0.06032898649573326, 0.001190018025226891]\n",
      "\n",
      "Step 114/200\n",
      "Epoch 0: Total Loss=8558.6953\n",
      "Epoch 1: Total Loss=8546.8408\n",
      "Epoch 2: Total Loss=8498.9082\n",
      "Epoch 3: Total Loss=8519.2637\n",
      "Epoch 4: Total Loss=8500.7573\n",
      "Epoch 5: Total Loss=8493.0166\n",
      "Epoch 6: Total Loss=8479.5930\n",
      "Epoch 7: Total Loss=8457.1963\n",
      "Epoch 8: Total Loss=8455.4485\n",
      "Epoch 9: Total Loss=8441.4399\n",
      "Updated x: [9.243638038635254, -8.785989761352539], Function Value: 162.63845825195312, Gradient: [0.12945103645324707, 0.0130568016320467]\n",
      "\n",
      "Step 115/200\n",
      "Epoch 0: Total Loss=8585.7446\n",
      "Epoch 1: Total Loss=8572.2632\n",
      "Epoch 2: Total Loss=8500.6577\n",
      "Epoch 3: Total Loss=8540.7700\n",
      "Epoch 4: Total Loss=8449.9639\n",
      "Epoch 5: Total Loss=8518.9243\n",
      "Epoch 6: Total Loss=8510.9927\n",
      "Epoch 7: Total Loss=8499.1616\n",
      "Epoch 8: Total Loss=8477.5381\n",
      "Epoch 9: Total Loss=8471.5312\n",
      "Updated x: [9.408400535583496, -8.903261184692383], Function Value: 167.7860565185547, Gradient: [0.13127261400222778, 0.01671692542731762]\n",
      "\n",
      "Step 116/200\n",
      "Epoch 0: Total Loss=8764.6333\n",
      "Epoch 1: Total Loss=8698.2896\n",
      "Epoch 2: Total Loss=8267.0276\n",
      "Epoch 3: Total Loss=8730.7378\n",
      "Epoch 4: Total Loss=8670.2410\n",
      "Epoch 5: Total Loss=8263.4424\n",
      "Epoch 6: Total Loss=8697.1997\n",
      "Epoch 7: Total Loss=8632.9844\n",
      "Epoch 8: Total Loss=8232.4985\n",
      "Epoch 9: Total Loss=8670.0186\n",
      "Updated x: [9.58401107788086, -9.025070190429688], Function Value: 173.30516052246094, Gradient: [0.13264647126197815, 0.020005375146865845]\n",
      "\n",
      "Step 117/200\n",
      "Epoch 0: Total Loss=8348.1636\n",
      "Epoch 1: Total Loss=9125.1123\n",
      "Epoch 2: Total Loss=8886.1924\n",
      "Epoch 3: Total Loss=8320.1118\n",
      "Epoch 4: Total Loss=9074.9106\n",
      "Epoch 5: Total Loss=8895.6443\n",
      "Epoch 6: Total Loss=8277.2795\n",
      "Epoch 7: Total Loss=8994.2363\n",
      "Epoch 8: Total Loss=8854.1501\n",
      "Epoch 9: Total Loss=8273.3589\n",
      "Updated x: [9.802997589111328, -9.062545776367188], Function Value: 178.22850036621094, Gradient: [0.11854685097932816, 0.017377885058522224]\n",
      "\n",
      "Step 118/200\n",
      "Epoch 0: Total Loss=9404.6733\n",
      "Epoch 1: Total Loss=8300.1748\n",
      "Epoch 2: Total Loss=9399.5947\n",
      "Epoch 3: Total Loss=8293.9175\n",
      "Epoch 4: Total Loss=9360.5298\n",
      "Epoch 5: Total Loss=8272.6631\n",
      "Epoch 6: Total Loss=9346.2773\n",
      "Epoch 7: Total Loss=8241.1155\n",
      "Epoch 8: Total Loss=9319.0127\n",
      "Epoch 9: Total Loss=8179.5142\n",
      "Updated x: [10.002490997314453, -9.05129337310791], Function Value: 181.97573852539062, Gradient: [0.1251300424337387, 0.022226860746741295]\n",
      "\n",
      "Step 119/200\n",
      "Epoch 0: Total Loss=9708.0933\n",
      "Epoch 1: Total Loss=8337.1587\n",
      "Epoch 2: Total Loss=9660.5488\n",
      "Epoch 3: Total Loss=8332.7683\n",
      "Epoch 4: Total Loss=9624.0737\n",
      "Epoch 5: Total Loss=8239.6594\n",
      "Epoch 6: Total Loss=9528.3301\n",
      "Epoch 7: Total Loss=8280.5017\n",
      "Epoch 8: Total Loss=9571.6890\n",
      "Epoch 9: Total Loss=8277.4885\n",
      "Updated x: [9.99245548248291, -9.047186851501465], Function Value: 181.7007598876953, Gradient: [0.12230049818754196, 0.021907322108745575]\n",
      "\n",
      "Step 120/200\n",
      "Epoch 0: Total Loss=9547.6108\n",
      "Epoch 1: Total Loss=8281.8833\n",
      "Epoch 2: Total Loss=9516.3501\n",
      "Epoch 3: Total Loss=9277.0303\n",
      "Epoch 4: Total Loss=9012.9424\n",
      "Epoch 5: Total Loss=9416.8726\n",
      "Epoch 6: Total Loss=8228.8369\n",
      "Epoch 7: Total Loss=9438.0635\n",
      "Epoch 8: Total Loss=9222.9541\n",
      "Epoch 9: Total Loss=8960.7793\n",
      "Updated x: [10.065168380737305, -8.991518020629883], Function Value: 182.15501403808594, Gradient: [0.1253424882888794, 0.025247957557439804]\n",
      "\n",
      "Step 121/200\n",
      "Epoch 0: Total Loss=7653.7732\n",
      "Epoch 1: Total Loss=7495.8613\n",
      "Epoch 2: Total Loss=7336.0508\n",
      "Epoch 3: Total Loss=7287.8452\n",
      "Epoch 4: Total Loss=7084.6992\n",
      "Epoch 5: Total Loss=7116.7693\n",
      "Epoch 6: Total Loss=6972.9336\n",
      "Epoch 7: Total Loss=6831.1887\n",
      "Epoch 8: Total Loss=6808.4229\n",
      "Epoch 9: Total Loss=6564.2405\n",
      "Updated x: [10.056628227233887, -9.008463859558105], Function Value: 182.28819274902344, Gradient: [0.08829593658447266, 0.026434486731886864]\n",
      "\n",
      "Step 122/200\n",
      "Epoch 0: Total Loss=15193.8452\n",
      "Epoch 1: Total Loss=14783.3218\n",
      "Epoch 2: Total Loss=14964.0474\n",
      "Epoch 3: Total Loss=15655.3096\n",
      "Epoch 4: Total Loss=16078.1787\n",
      "Epoch 5: Total Loss=14030.5464\n",
      "Epoch 6: Total Loss=14538.0947\n",
      "Epoch 7: Total Loss=14719.8232\n",
      "Epoch 8: Total Loss=15084.1821\n",
      "Epoch 9: Total Loss=13813.4150\n",
      "Updated x: [10.095442771911621, -9.083564758300781], Function Value: 184.42910766601562, Gradient: [0.0658312514424324, 0.009778455831110477]\n",
      "\n",
      "Step 123/200\n",
      "Epoch 0: Total Loss=15167.6133\n",
      "Epoch 1: Total Loss=14268.6401\n",
      "Epoch 2: Total Loss=16640.7241\n",
      "Epoch 3: Total Loss=15461.8340\n",
      "Epoch 4: Total Loss=16001.7397\n",
      "Epoch 5: Total Loss=15226.3447\n",
      "Epoch 6: Total Loss=15642.2627\n",
      "Epoch 7: Total Loss=14393.6172\n",
      "Epoch 8: Total Loss=15600.6104\n",
      "Epoch 9: Total Loss=14418.1001\n",
      "Updated x: [10.09864330291748, -9.080679893493652], Function Value: 184.44134521484375, Gradient: [0.13895921409130096, 0.032589856535196304]\n",
      "\n",
      "Step 124/200\n",
      "Epoch 0: Total Loss=15484.7056\n",
      "Epoch 1: Total Loss=13424.5864\n",
      "Epoch 2: Total Loss=14107.7437\n",
      "Epoch 3: Total Loss=13350.0200\n",
      "Epoch 4: Total Loss=16560.5742\n",
      "Epoch 5: Total Loss=11971.0867\n",
      "Epoch 6: Total Loss=14368.6494\n",
      "Epoch 7: Total Loss=15221.8057\n",
      "Epoch 8: Total Loss=15189.0522\n",
      "Epoch 9: Total Loss=12750.1260\n",
      "Updated x: [10.156749725341797, -9.070210456848145], Function Value: 185.42828369140625, Gradient: [0.13159698247909546, 0.031027644872665405]\n",
      "\n",
      "Step 125/200\n",
      "Epoch 0: Total Loss=13006.8391\n",
      "Epoch 1: Total Loss=13255.5801\n",
      "Epoch 2: Total Loss=14133.6821\n",
      "Epoch 3: Total Loss=12030.7065\n",
      "Epoch 4: Total Loss=13214.2798\n",
      "Epoch 5: Total Loss=12027.5898\n",
      "Epoch 6: Total Loss=13866.6538\n",
      "Epoch 7: Total Loss=13279.6108\n",
      "Epoch 8: Total Loss=12308.2720\n",
      "Epoch 9: Total Loss=14191.8433\n",
      "Updated x: [10.148921012878418, -9.078843116760254], Function Value: 185.42599487304688, Gradient: [0.13450676202774048, 0.031714893877506256]\n",
      "\n",
      "Step 126/200\n",
      "Epoch 0: Total Loss=15233.6328\n",
      "Epoch 1: Total Loss=11861.9238\n",
      "Epoch 2: Total Loss=12853.9971\n",
      "Epoch 3: Total Loss=12482.0505\n",
      "Epoch 4: Total Loss=15645.9863\n",
      "Epoch 5: Total Loss=14395.4473\n",
      "Epoch 6: Total Loss=11168.3954\n",
      "Epoch 7: Total Loss=15484.2119\n",
      "Epoch 8: Total Loss=12886.1274\n",
      "Epoch 9: Total Loss=14601.1357\n",
      "Updated x: [10.072423934936523, -9.060006141662598], Function Value: 183.53744506835938, Gradient: [0.1378244012594223, 0.03277850151062012]\n",
      "\n",
      "Step 127/200\n",
      "Epoch 0: Total Loss=11542.0288\n",
      "Epoch 1: Total Loss=12627.2927\n",
      "Epoch 2: Total Loss=12498.2048\n",
      "Epoch 3: Total Loss=13576.5698\n",
      "Epoch 4: Total Loss=14026.8130\n",
      "Epoch 5: Total Loss=14627.2158\n",
      "Epoch 6: Total Loss=14574.6338\n",
      "Epoch 7: Total Loss=12857.9526\n",
      "Epoch 8: Total Loss=13149.6565\n",
      "Epoch 9: Total Loss=11984.7136\n",
      "Updated x: [9.970684051513672, -8.940685272216797], Function Value: 179.35040283203125, Gradient: [0.15368926525115967, 0.0408305898308754]\n",
      "\n",
      "Step 128/200\n",
      "Epoch 0: Total Loss=13846.9688\n",
      "Epoch 1: Total Loss=12436.2734\n",
      "Epoch 2: Total Loss=12949.0249\n",
      "Epoch 3: Total Loss=10500.4041\n",
      "Epoch 4: Total Loss=12138.5405\n",
      "Epoch 5: Total Loss=12956.4902\n",
      "Epoch 6: Total Loss=12782.9075\n",
      "Epoch 7: Total Loss=13582.1367\n",
      "Epoch 8: Total Loss=11161.0627\n",
      "Epoch 9: Total Loss=13710.3179\n",
      "Updated x: [9.992395401000977, -9.005274772644043], Function Value: 180.94293212890625, Gradient: [0.1461978703737259, 0.03811483085155487]\n",
      "\n",
      "Step 129/200\n",
      "Epoch 0: Total Loss=14102.7842\n",
      "Epoch 1: Total Loss=13382.9482\n",
      "Epoch 2: Total Loss=14205.0996\n",
      "Epoch 3: Total Loss=13323.1729\n",
      "Epoch 4: Total Loss=14362.1934\n",
      "Epoch 5: Total Loss=14080.9868\n",
      "Epoch 6: Total Loss=10734.5616\n",
      "Epoch 7: Total Loss=12596.0933\n",
      "Epoch 8: Total Loss=11580.4141\n",
      "Epoch 9: Total Loss=10793.4961\n",
      "Updated x: [10.031072616577148, -9.231846809387207], Function Value: 185.84942626953125, Gradient: [0.13677401840686798, 0.029093673452734947]\n",
      "\n",
      "Step 130/200\n",
      "Epoch 0: Total Loss=13461.4644\n",
      "Epoch 1: Total Loss=11755.8799\n",
      "Epoch 2: Total Loss=12898.2603\n",
      "Epoch 3: Total Loss=11101.1489\n",
      "Epoch 4: Total Loss=10608.4268\n",
      "Epoch 5: Total Loss=13434.6211\n",
      "Epoch 6: Total Loss=15130.7905\n",
      "Epoch 7: Total Loss=12063.7827\n",
      "Epoch 8: Total Loss=12653.2646\n",
      "Epoch 9: Total Loss=10745.1230\n",
      "Updated x: [10.075353622436523, -9.22897720336914], Function Value: 186.686767578125, Gradient: [0.15258654952049255, 0.035952914506196976]\n",
      "\n",
      "Step 131/200\n",
      "Epoch 0: Total Loss=11209.0557\n",
      "Epoch 1: Total Loss=10774.5012\n",
      "Epoch 2: Total Loss=8384.5558\n",
      "Epoch 3: Total Loss=10636.0061\n",
      "Epoch 4: Total Loss=8680.8655\n",
      "Epoch 5: Total Loss=10904.4534\n",
      "Epoch 6: Total Loss=8825.1873\n",
      "Epoch 7: Total Loss=7197.7013\n",
      "Epoch 8: Total Loss=8355.6726\n",
      "Epoch 9: Total Loss=8895.7290\n",
      "Updated x: [10.16239070892334, -9.40731430053711], Function Value: 191.77174377441406, Gradient: [0.14266493916511536, 0.03563163802027702]\n",
      "\n",
      "Step 132/200\n",
      "Epoch 0: Total Loss=13996.0674\n",
      "Epoch 1: Total Loss=13668.4268\n",
      "Epoch 2: Total Loss=14467.3174\n",
      "Epoch 3: Total Loss=13687.2231\n",
      "Epoch 4: Total Loss=12456.1821\n",
      "Epoch 5: Total Loss=13493.7231\n",
      "Epoch 6: Total Loss=14941.7720\n",
      "Epoch 7: Total Loss=11769.8364\n",
      "Epoch 8: Total Loss=14332.1704\n",
      "Epoch 9: Total Loss=11441.0837\n",
      "Updated x: [9.997760772705078, -9.38402271270752], Function Value: 188.01510620117188, Gradient: [0.07100613415241241, 0.00968471821397543]\n",
      "\n",
      "Step 133/200\n",
      "Epoch 0: Total Loss=12213.6155\n",
      "Epoch 1: Total Loss=11224.9495\n",
      "Epoch 2: Total Loss=12661.8545\n",
      "Epoch 3: Total Loss=14107.5200\n",
      "Epoch 4: Total Loss=14218.2402\n",
      "Epoch 5: Total Loss=11805.9238\n",
      "Epoch 6: Total Loss=10761.4883\n",
      "Epoch 7: Total Loss=12093.9287\n",
      "Epoch 8: Total Loss=12777.9448\n",
      "Epoch 9: Total Loss=13388.8018\n",
      "Updated x: [9.826292037963867, -9.309638023376465], Function Value: 183.22537231445312, Gradient: [0.1409887820482254, 0.022147860378026962]\n",
      "\n",
      "Step 134/200\n",
      "Epoch 0: Total Loss=11245.7329\n",
      "Epoch 1: Total Loss=12396.2676\n",
      "Epoch 2: Total Loss=12757.3259\n",
      "Epoch 3: Total Loss=11536.2319\n",
      "Epoch 4: Total Loss=12361.0088\n",
      "Epoch 5: Total Loss=11708.8142\n",
      "Epoch 6: Total Loss=11189.4531\n",
      "Epoch 7: Total Loss=11727.3499\n",
      "Epoch 8: Total Loss=11274.5056\n",
      "Epoch 9: Total Loss=10843.9722\n",
      "Updated x: [9.706453323364258, -9.319487571716309], Function Value: 181.06808471679688, Gradient: [0.1312171369791031, 0.01685188338160515]\n",
      "\n",
      "Step 135/200\n",
      "Epoch 0: Total Loss=10756.2659\n",
      "Epoch 1: Total Loss=10417.9167\n",
      "Epoch 2: Total Loss=11239.9890\n",
      "Epoch 3: Total Loss=9927.0452\n",
      "Epoch 4: Total Loss=10925.5281\n",
      "Epoch 5: Total Loss=9746.4058\n",
      "Epoch 6: Total Loss=10254.7336\n",
      "Epoch 7: Total Loss=11143.2549\n",
      "Epoch 8: Total Loss=11446.8535\n",
      "Epoch 9: Total Loss=10833.2534\n",
      "Updated x: [9.729361534118652, -9.244061470031738], Function Value: 180.1131591796875, Gradient: [0.13662374019622803, 0.010946055874228477]\n",
      "\n",
      "Step 136/200\n",
      "Epoch 0: Total Loss=11841.3210\n",
      "Epoch 1: Total Loss=11666.0603\n",
      "Epoch 2: Total Loss=10584.6416\n",
      "Epoch 3: Total Loss=9727.3098\n",
      "Epoch 4: Total Loss=9539.6396\n",
      "Epoch 5: Total Loss=10984.4595\n",
      "Epoch 6: Total Loss=10465.1423\n",
      "Epoch 7: Total Loss=10783.9243\n",
      "Epoch 8: Total Loss=9930.4829\n",
      "Epoch 9: Total Loss=9911.3467\n",
      "Updated x: [9.659428596496582, -9.34874153137207], Function Value: 180.70352172851562, Gradient: [0.12730027735233307, -5.072134081274271e-05]\n",
      "\n",
      "Step 137/200\n",
      "Epoch 0: Total Loss=10293.9229\n",
      "Epoch 1: Total Loss=9452.8384\n",
      "Epoch 2: Total Loss=10628.8396\n",
      "Epoch 3: Total Loss=10304.0854\n",
      "Epoch 4: Total Loss=11238.4944\n",
      "Epoch 5: Total Loss=9886.9783\n",
      "Epoch 6: Total Loss=13148.6868\n",
      "Epoch 7: Total Loss=10013.3127\n",
      "Epoch 8: Total Loss=10196.4614\n",
      "Epoch 9: Total Loss=10709.1384\n",
      "Updated x: [9.67851448059082, -9.415471076965332], Function Value: 182.32473754882812, Gradient: [0.12312648445367813, -0.013207930140197277]\n",
      "\n",
      "Step 138/200\n",
      "Epoch 0: Total Loss=9998.5010\n",
      "Epoch 1: Total Loss=9497.2043\n",
      "Epoch 2: Total Loss=9698.5393\n",
      "Epoch 3: Total Loss=10087.9399\n",
      "Epoch 4: Total Loss=9528.2085\n",
      "Epoch 5: Total Loss=10973.5969\n",
      "Epoch 6: Total Loss=10282.4487\n",
      "Epoch 7: Total Loss=9845.9312\n",
      "Epoch 8: Total Loss=10167.4607\n",
      "Epoch 9: Total Loss=9331.2903\n",
      "Updated x: [9.693185806274414, -9.529617309570312], Function Value: 184.77145385742188, Gradient: [0.11153416335582733, -0.02505442686378956]\n",
      "\n",
      "Step 139/200\n",
      "Epoch 0: Total Loss=9681.9175\n",
      "Epoch 1: Total Loss=10902.0254\n",
      "Epoch 2: Total Loss=10622.4016\n",
      "Epoch 3: Total Loss=9096.2625\n",
      "Epoch 4: Total Loss=10503.1282\n",
      "Epoch 5: Total Loss=9438.7832\n",
      "Epoch 6: Total Loss=9477.9463\n",
      "Epoch 7: Total Loss=8761.4146\n",
      "Epoch 8: Total Loss=8910.1462\n",
      "Epoch 9: Total Loss=10374.5591\n",
      "Updated x: [9.592855453491211, -9.570052146911621], Function Value: 183.6087646484375, Gradient: [0.09195709973573685, -0.03358599171042442]\n",
      "\n",
      "Step 140/200\n",
      "Epoch 0: Total Loss=8075.6973\n",
      "Epoch 1: Total Loss=10243.9883\n",
      "Epoch 2: Total Loss=9990.7168\n",
      "Epoch 3: Total Loss=9076.0142\n",
      "Epoch 4: Total Loss=10166.0957\n",
      "Epoch 5: Total Loss=10615.3760\n",
      "Epoch 6: Total Loss=8940.1309\n",
      "Epoch 7: Total Loss=9149.1174\n",
      "Epoch 8: Total Loss=8555.0909\n",
      "Epoch 9: Total Loss=8507.4661\n",
      "Updated x: [9.610307693481445, -9.615021705627441], Function Value: 184.80665588378906, Gradient: [0.08966083824634552, -0.04404957592487335]\n",
      "\n",
      "Step 141/200\n",
      "Epoch 0: Total Loss=10244.3086\n",
      "Epoch 1: Total Loss=9168.5808\n",
      "Epoch 2: Total Loss=6877.0530\n",
      "Epoch 3: Total Loss=6750.9810\n",
      "Epoch 4: Total Loss=7325.4343\n",
      "Epoch 5: Total Loss=7151.9775\n",
      "Epoch 6: Total Loss=6826.8071\n",
      "Epoch 7: Total Loss=7590.3364\n",
      "Epoch 8: Total Loss=5843.8387\n",
      "Epoch 9: Total Loss=8421.0007\n",
      "Updated x: [9.609962463378906, -9.583024024963379], Function Value: 184.18572998046875, Gradient: [0.039571478962898254, -0.03070932999253273]\n",
      "\n",
      "Step 142/200\n",
      "Epoch 0: Total Loss=9820.9604\n",
      "Epoch 1: Total Loss=10325.1904\n",
      "Epoch 2: Total Loss=10457.5032\n",
      "Epoch 3: Total Loss=9541.8708\n",
      "Epoch 4: Total Loss=8110.9941\n",
      "Epoch 5: Total Loss=8894.4446\n",
      "Epoch 6: Total Loss=10472.8940\n",
      "Epoch 7: Total Loss=9746.0327\n",
      "Epoch 8: Total Loss=9068.1414\n",
      "Epoch 9: Total Loss=9938.6201\n",
      "Updated x: [9.462668418884277, -9.567503929138184], Function Value: 181.0792236328125, Gradient: [0.030105406418442726, -0.02555907517671585]\n",
      "\n",
      "Step 143/200\n",
      "Epoch 0: Total Loss=9156.2524\n",
      "Epoch 1: Total Loss=7863.9983\n",
      "Epoch 2: Total Loss=8405.5996\n",
      "Epoch 3: Total Loss=8249.8403\n",
      "Epoch 4: Total Loss=9615.7158\n",
      "Epoch 5: Total Loss=9974.6184\n",
      "Epoch 6: Total Loss=8373.2300\n",
      "Epoch 7: Total Loss=9420.4790\n",
      "Epoch 8: Total Loss=8607.4487\n",
      "Epoch 9: Total Loss=8655.6572\n",
      "Updated x: [9.449795722961426, -9.345800399780273], Function Value: 176.6426239013672, Gradient: [0.06342216581106186, -0.08500300347805023]\n",
      "\n",
      "Step 144/200\n",
      "Epoch 0: Total Loss=7900.1731\n",
      "Epoch 1: Total Loss=7226.8462\n",
      "Epoch 2: Total Loss=8032.2854\n",
      "Epoch 3: Total Loss=8944.4250\n",
      "Epoch 4: Total Loss=7551.6526\n",
      "Epoch 5: Total Loss=7354.9562\n",
      "Epoch 6: Total Loss=8682.2102\n",
      "Epoch 7: Total Loss=8436.1472\n",
      "Epoch 8: Total Loss=7824.2161\n",
      "Epoch 9: Total Loss=7209.7793\n",
      "Updated x: [9.271758079528809, -9.350654602050781], Function Value: 173.40023803710938, Gradient: [0.050745755434036255, -0.10491546988487244]\n",
      "\n",
      "Step 145/200\n",
      "Epoch 0: Total Loss=8215.5247\n",
      "Epoch 1: Total Loss=7752.9434\n",
      "Epoch 2: Total Loss=8697.7151\n",
      "Epoch 3: Total Loss=9098.9888\n",
      "Epoch 4: Total Loss=7802.5803\n",
      "Epoch 5: Total Loss=7429.5526\n",
      "Epoch 6: Total Loss=6572.2166\n",
      "Epoch 7: Total Loss=9366.3457\n",
      "Epoch 8: Total Loss=6799.3646\n",
      "Epoch 9: Total Loss=8805.8877\n",
      "Updated x: [9.356219291687012, -9.507124900817871], Function Value: 177.92425537109375, Gradient: [0.03433948755264282, -0.11687953025102615]\n",
      "\n",
      "Step 146/200\n",
      "Epoch 0: Total Loss=6667.0536\n",
      "Epoch 1: Total Loss=8796.6201\n",
      "Epoch 2: Total Loss=7828.0173\n",
      "Epoch 3: Total Loss=7801.5652\n",
      "Epoch 4: Total Loss=8277.6072\n",
      "Epoch 5: Total Loss=7546.7483\n",
      "Epoch 6: Total Loss=8055.1077\n",
      "Epoch 7: Total Loss=7431.0776\n",
      "Epoch 8: Total Loss=8030.5447\n",
      "Epoch 9: Total Loss=8167.1912\n",
      "Updated x: [9.277470588684082, -9.408308029174805], Function Value: 174.58770751953125, Gradient: [0.017791640013456345, -0.14514505863189697]\n",
      "\n",
      "Step 147/200\n",
      "Epoch 0: Total Loss=7205.8506\n",
      "Epoch 1: Total Loss=7910.1531\n",
      "Epoch 2: Total Loss=8074.7568\n",
      "Epoch 3: Total Loss=7406.3442\n",
      "Epoch 4: Total Loss=7562.1833\n",
      "Epoch 5: Total Loss=7339.0293\n",
      "Epoch 6: Total Loss=7452.8374\n",
      "Epoch 7: Total Loss=6921.7251\n",
      "Epoch 8: Total Loss=6609.4991\n",
      "Epoch 9: Total Loss=6593.6428\n",
      "Updated x: [9.360550880432129, -9.445565223693848], Function Value: 176.838623046875, Gradient: [0.013613348826766014, -0.14328627288341522]\n",
      "\n",
      "Step 148/200\n",
      "Epoch 0: Total Loss=7903.9912\n",
      "Epoch 1: Total Loss=7312.9414\n",
      "Epoch 2: Total Loss=8743.4976\n",
      "Epoch 3: Total Loss=7043.3909\n",
      "Epoch 4: Total Loss=6471.3704\n",
      "Epoch 5: Total Loss=6813.6603\n",
      "Epoch 6: Total Loss=6656.1292\n",
      "Epoch 7: Total Loss=6112.9596\n",
      "Epoch 8: Total Loss=7550.0566\n",
      "Epoch 9: Total Loss=7805.4602\n",
      "Updated x: [9.395902633666992, -9.493668556213379], Function Value: 178.41273498535156, Gradient: [-0.0036860534455627203, -0.16251839697360992]\n",
      "\n",
      "Step 149/200\n",
      "Epoch 0: Total Loss=6873.7849\n",
      "Epoch 1: Total Loss=7231.5525\n",
      "Epoch 2: Total Loss=6976.8640\n",
      "Epoch 3: Total Loss=8541.9221\n",
      "Epoch 4: Total Loss=6966.4153\n",
      "Epoch 5: Total Loss=6999.2412\n",
      "Epoch 6: Total Loss=6513.2856\n",
      "Epoch 7: Total Loss=6608.9036\n",
      "Epoch 8: Total Loss=7435.1689\n",
      "Epoch 9: Total Loss=7460.3507\n",
      "Updated x: [9.346529960632324, -9.473369598388672], Function Value: 177.10235595703125, Gradient: [-0.008376626297831535, -0.1621422916650772]\n",
      "\n",
      "Step 150/200\n",
      "Epoch 0: Total Loss=6724.9559\n",
      "Epoch 1: Total Loss=7073.6753\n",
      "Epoch 2: Total Loss=8944.2092\n",
      "Epoch 3: Total Loss=7654.1084\n",
      "Epoch 4: Total Loss=6745.3416\n",
      "Epoch 5: Total Loss=7077.9119\n",
      "Epoch 6: Total Loss=6376.7844\n",
      "Epoch 7: Total Loss=7022.8037\n",
      "Epoch 8: Total Loss=6430.7390\n",
      "Epoch 9: Total Loss=6274.9812\n",
      "Updated x: [9.329729080200195, -9.595497131347656], Function Value: 179.11740112304688, Gradient: [-0.021518973633646965, -0.1676914393901825]\n",
      "\n",
      "Step 151/200\n",
      "Epoch 0: Total Loss=6943.5830\n",
      "Epoch 1: Total Loss=5733.8463\n",
      "Epoch 2: Total Loss=5650.5065\n",
      "Epoch 3: Total Loss=5517.6554\n",
      "Epoch 4: Total Loss=5670.1787\n",
      "Epoch 5: Total Loss=5531.2170\n",
      "Epoch 6: Total Loss=4634.8760\n",
      "Epoch 7: Total Loss=4146.5472\n",
      "Epoch 8: Total Loss=5420.7212\n",
      "Epoch 9: Total Loss=5350.2501\n",
      "Updated x: [9.40882682800293, -9.631977081298828], Function Value: 181.30101013183594, Gradient: [-0.05415710434317589, -0.19232143461704254]\n",
      "\n",
      "Step 152/200\n",
      "Epoch 0: Total Loss=9630.3105\n",
      "Epoch 1: Total Loss=8555.1118\n",
      "Epoch 2: Total Loss=7990.5957\n",
      "Epoch 3: Total Loss=8064.2910\n",
      "Epoch 4: Total Loss=7957.8452\n",
      "Epoch 5: Total Loss=8385.5847\n",
      "Epoch 6: Total Loss=6831.7068\n",
      "Epoch 7: Total Loss=7041.5264\n",
      "Epoch 8: Total Loss=7246.4458\n",
      "Epoch 9: Total Loss=7144.7124\n",
      "Updated x: [9.55189323425293, -9.58222770690918], Function Value: 183.0577392578125, Gradient: [-0.0016485227970406413, -0.03930243104696274]\n",
      "\n",
      "Step 153/200\n",
      "Epoch 0: Total Loss=6802.1467\n",
      "Epoch 1: Total Loss=7616.1802\n",
      "Epoch 2: Total Loss=7528.8340\n",
      "Epoch 3: Total Loss=6736.8678\n",
      "Epoch 4: Total Loss=7621.1299\n",
      "Epoch 5: Total Loss=7045.2993\n",
      "Epoch 6: Total Loss=7506.8271\n",
      "Epoch 7: Total Loss=7404.0217\n",
      "Epoch 8: Total Loss=7208.4661\n",
      "Epoch 9: Total Loss=6608.8108\n",
      "Updated x: [9.560704231262207, -9.503392219543457], Function Value: 181.72152709960938, Gradient: [-0.03277059644460678, -0.197229266166687]\n",
      "\n",
      "Step 154/200\n",
      "Epoch 0: Total Loss=6738.3975\n",
      "Epoch 1: Total Loss=7397.2019\n",
      "Epoch 2: Total Loss=6574.5735\n",
      "Epoch 3: Total Loss=7235.0126\n",
      "Epoch 4: Total Loss=6270.4952\n",
      "Epoch 5: Total Loss=7612.4121\n",
      "Epoch 6: Total Loss=6416.5341\n",
      "Epoch 7: Total Loss=7629.7319\n",
      "Epoch 8: Total Loss=7908.0012\n",
      "Epoch 9: Total Loss=6377.1278\n",
      "Updated x: [9.590899467468262, -9.496461868286133], Function Value: 182.1681365966797, Gradient: [-0.050456371158361435, -0.22128760814666748]\n",
      "\n",
      "Step 155/200\n",
      "Epoch 0: Total Loss=6218.8322\n",
      "Epoch 1: Total Loss=6850.6580\n",
      "Epoch 2: Total Loss=6643.5806\n",
      "Epoch 3: Total Loss=7256.6499\n",
      "Epoch 4: Total Loss=6449.6655\n",
      "Epoch 5: Total Loss=6324.3853\n",
      "Epoch 6: Total Loss=7509.1890\n",
      "Epoch 7: Total Loss=6238.4921\n",
      "Epoch 8: Total Loss=5914.2554\n",
      "Epoch 9: Total Loss=6016.8687\n",
      "Updated x: [9.61164665222168, -9.421010971069336], Function Value: 181.13919067382812, Gradient: [-0.06300875544548035, -0.23911798000335693]\n",
      "\n",
      "Step 156/200\n",
      "Epoch 0: Total Loss=6998.7662\n",
      "Epoch 1: Total Loss=6126.9471\n",
      "Epoch 2: Total Loss=6281.8920\n",
      "Epoch 3: Total Loss=6711.4165\n",
      "Epoch 4: Total Loss=6526.7842\n",
      "Epoch 5: Total Loss=6637.4973\n",
      "Epoch 6: Total Loss=6288.8429\n",
      "Epoch 7: Total Loss=7634.1360\n",
      "Epoch 8: Total Loss=6494.0618\n",
      "Epoch 9: Total Loss=6235.6294\n",
      "Updated x: [9.687034606933594, -9.631671905517578], Function Value: 186.6077423095703, Gradient: [-0.06974086165428162, -0.23458270728588104]\n",
      "\n",
      "Step 157/200\n",
      "Epoch 0: Total Loss=8029.1465\n",
      "Epoch 1: Total Loss=6769.8892\n",
      "Epoch 2: Total Loss=5936.6133\n",
      "Epoch 3: Total Loss=7119.6598\n",
      "Epoch 4: Total Loss=6160.9688\n",
      "Epoch 5: Total Loss=6807.1498\n",
      "Epoch 6: Total Loss=6231.6519\n",
      "Epoch 7: Total Loss=5838.2461\n",
      "Epoch 8: Total Loss=6652.5889\n",
      "Epoch 9: Total Loss=6058.7465\n",
      "Updated x: [9.74780559539795, -9.51307487487793], Function Value: 185.518310546875, Gradient: [-0.07667450606822968, -0.24796396493911743]\n",
      "\n",
      "Step 158/200\n",
      "Epoch 0: Total Loss=5559.7231\n",
      "Epoch 1: Total Loss=6337.4274\n",
      "Epoch 2: Total Loss=6427.1072\n",
      "Epoch 3: Total Loss=5922.9429\n",
      "Epoch 4: Total Loss=8069.9714\n",
      "Epoch 5: Total Loss=6556.3613\n",
      "Epoch 6: Total Loss=6789.6477\n",
      "Epoch 7: Total Loss=6415.7451\n",
      "Epoch 8: Total Loss=5695.5706\n",
      "Epoch 9: Total Loss=6157.3199\n",
      "Updated x: [9.712719917297363, -9.506967544555664], Function Value: 184.7193603515625, Gradient: [-0.08896013349294662, -0.265352338552475]\n",
      "\n",
      "Step 159/200\n",
      "Epoch 0: Total Loss=6516.1532\n",
      "Epoch 1: Total Loss=6788.0636\n",
      "Epoch 2: Total Loss=6690.4023\n",
      "Epoch 3: Total Loss=6087.5527\n",
      "Epoch 4: Total Loss=7329.9916\n",
      "Epoch 5: Total Loss=6010.2549\n",
      "Epoch 6: Total Loss=5667.0914\n",
      "Epoch 7: Total Loss=5812.1348\n",
      "Epoch 8: Total Loss=6275.8948\n",
      "Epoch 9: Total Loss=6229.8990\n",
      "Updated x: [9.888890266418457, -9.47938346862793], Function Value: 187.64886474609375, Gradient: [-0.12123619019985199, -0.3207869231700897]\n",
      "\n",
      "Step 160/200\n",
      "Epoch 0: Total Loss=5681.4537\n",
      "Epoch 1: Total Loss=5758.6116\n",
      "Epoch 2: Total Loss=6445.2676\n",
      "Epoch 3: Total Loss=6758.6536\n",
      "Epoch 4: Total Loss=5583.9871\n",
      "Epoch 5: Total Loss=6261.6927\n",
      "Epoch 6: Total Loss=6477.3257\n",
      "Epoch 7: Total Loss=6193.5592\n",
      "Epoch 8: Total Loss=5510.4023\n",
      "Epoch 9: Total Loss=6712.9126\n",
      "Updated x: [9.76940631866455, -9.521666526794434], Function Value: 186.10342407226562, Gradient: [-0.13064512610435486, -0.3282182812690735]\n",
      "\n",
      "Step 161/200\n",
      "Epoch 0: Total Loss=4867.3206\n",
      "Epoch 1: Total Loss=4792.3314\n",
      "Epoch 2: Total Loss=4643.4474\n",
      "Epoch 3: Total Loss=5784.0140\n",
      "Epoch 4: Total Loss=5785.4642\n",
      "Epoch 5: Total Loss=4346.8438\n",
      "Epoch 6: Total Loss=5132.7521\n",
      "Epoch 7: Total Loss=4124.1073\n",
      "Epoch 8: Total Loss=4446.0802\n",
      "Epoch 9: Total Loss=4101.2543\n",
      "Updated x: [9.713505744934082, -9.576419830322266], Function Value: 186.0600128173828, Gradient: [-0.14327169954776764, -0.2875974774360657]\n",
      "\n",
      "Step 162/200\n",
      "Epoch 0: Total Loss=7729.9678\n",
      "Epoch 1: Total Loss=6910.6050\n",
      "Epoch 2: Total Loss=7065.7109\n",
      "Epoch 3: Total Loss=7037.4038\n",
      "Epoch 4: Total Loss=6736.8240\n",
      "Epoch 5: Total Loss=7316.1549\n",
      "Epoch 6: Total Loss=6894.9016\n",
      "Epoch 7: Total Loss=7008.8403\n",
      "Epoch 8: Total Loss=5375.7004\n",
      "Epoch 9: Total Loss=6367.9684\n",
      "Updated x: [9.908027648925781, -9.516290664672852], Function Value: 188.7288055419922, Gradient: [-0.01114488672465086, -0.03601398319005966]\n",
      "\n",
      "Step 163/200\n",
      "Epoch 0: Total Loss=5911.9524\n",
      "Epoch 1: Total Loss=6250.3787\n",
      "Epoch 2: Total Loss=7490.5367\n",
      "Epoch 3: Total Loss=5955.8070\n",
      "Epoch 4: Total Loss=6524.7633\n",
      "Epoch 5: Total Loss=5549.1780\n",
      "Epoch 6: Total Loss=6413.8928\n",
      "Epoch 7: Total Loss=6480.0499\n",
      "Epoch 8: Total Loss=5584.4987\n",
      "Epoch 9: Total Loss=5512.3951\n",
      "Updated x: [9.828812599182129, -9.469446182250977], Function Value: 186.27597045898438, Gradient: [-0.12410564720630646, -0.3129570782184601]\n",
      "\n",
      "Step 164/200\n",
      "Epoch 0: Total Loss=6327.1514\n",
      "Epoch 1: Total Loss=5567.5342\n",
      "Epoch 2: Total Loss=6569.7001\n",
      "Epoch 3: Total Loss=5774.0208\n",
      "Epoch 4: Total Loss=5418.0499\n",
      "Epoch 5: Total Loss=6084.6713\n",
      "Epoch 6: Total Loss=5776.6189\n",
      "Epoch 7: Total Loss=6784.2709\n",
      "Epoch 8: Total Loss=6065.8807\n",
      "Epoch 9: Total Loss=5906.9330\n",
      "Updated x: [9.791791915893555, -9.533173561096191], Function Value: 186.76058959960938, Gradient: [-0.1543169766664505, -0.3539727032184601]\n",
      "\n",
      "Step 165/200\n",
      "Epoch 0: Total Loss=5790.7170\n",
      "Epoch 1: Total Loss=6523.9495\n",
      "Epoch 2: Total Loss=6152.1071\n",
      "Epoch 3: Total Loss=5451.4895\n",
      "Epoch 4: Total Loss=5776.2094\n",
      "Epoch 5: Total Loss=7435.6277\n",
      "Epoch 6: Total Loss=5966.1329\n",
      "Epoch 7: Total Loss=5873.7213\n",
      "Epoch 8: Total Loss=5945.0078\n",
      "Epoch 9: Total Loss=5626.0116\n",
      "Updated x: [9.996601104736328, -9.505034446716309], Function Value: 190.2777099609375, Gradient: [-0.13069359958171844, -0.3094737231731415]\n",
      "\n",
      "Step 166/200\n",
      "Epoch 0: Total Loss=5193.7698\n",
      "Epoch 1: Total Loss=6322.7065\n",
      "Epoch 2: Total Loss=5490.0469\n",
      "Epoch 3: Total Loss=5595.8475\n",
      "Epoch 4: Total Loss=5678.3516\n",
      "Epoch 5: Total Loss=5652.9783\n",
      "Epoch 6: Total Loss=5729.2040\n",
      "Epoch 7: Total Loss=5049.8389\n",
      "Epoch 8: Total Loss=5579.4398\n",
      "Epoch 9: Total Loss=5593.7889\n",
      "Updated x: [10.122564315795898, -9.54940128326416], Function Value: 193.65737915039062, Gradient: [-0.1442980021238327, -0.33212947845458984]\n",
      "\n",
      "Step 167/200\n",
      "Epoch 0: Total Loss=6154.1003\n",
      "Epoch 1: Total Loss=5384.1576\n",
      "Epoch 2: Total Loss=5826.0560\n",
      "Epoch 3: Total Loss=5787.9543\n",
      "Epoch 4: Total Loss=5739.5964\n",
      "Epoch 5: Total Loss=5308.9279\n",
      "Epoch 6: Total Loss=4805.9081\n",
      "Epoch 7: Total Loss=5496.9857\n",
      "Epoch 8: Total Loss=5997.4457\n",
      "Epoch 9: Total Loss=6144.1498\n",
      "Updated x: [10.215609550476074, -9.508508682250977], Function Value: 194.77041625976562, Gradient: [-0.15962345898151398, -0.3599274456501007]\n",
      "\n",
      "Step 168/200\n",
      "Epoch 0: Total Loss=6415.5151\n",
      "Epoch 1: Total Loss=4959.8392\n",
      "Epoch 2: Total Loss=6154.3010\n",
      "Epoch 3: Total Loss=5855.0139\n",
      "Epoch 4: Total Loss=5078.6010\n",
      "Epoch 5: Total Loss=5703.6506\n",
      "Epoch 6: Total Loss=5348.0891\n",
      "Epoch 7: Total Loss=5469.9294\n",
      "Epoch 8: Total Loss=5276.7914\n",
      "Epoch 9: Total Loss=5738.2417\n",
      "Updated x: [10.17482852935791, -9.461708068847656], Function Value: 193.05105590820312, Gradient: [-0.15948344767093658, -0.35437917709350586]\n",
      "\n",
      "Step 169/200\n",
      "Epoch 0: Total Loss=5064.4601\n",
      "Epoch 1: Total Loss=5809.1061\n",
      "Epoch 2: Total Loss=6426.7594\n",
      "Epoch 3: Total Loss=5860.2170\n",
      "Epoch 4: Total Loss=5868.7233\n",
      "Epoch 5: Total Loss=4968.7479\n",
      "Epoch 6: Total Loss=6148.4059\n",
      "Epoch 7: Total Loss=5149.8545\n",
      "Epoch 8: Total Loss=5819.9713\n",
      "Epoch 9: Total Loss=6571.2391\n",
      "Updated x: [10.201151847839355, -9.526873588562012], Function Value: 194.8248291015625, Gradient: [-0.11934434622526169, -0.2656322121620178]\n",
      "\n",
      "Step 170/200\n",
      "Epoch 0: Total Loss=5600.2743\n",
      "Epoch 1: Total Loss=5307.6357\n",
      "Epoch 2: Total Loss=5859.5345\n",
      "Epoch 3: Total Loss=5562.1455\n",
      "Epoch 4: Total Loss=5597.2874\n",
      "Epoch 5: Total Loss=5306.9009\n",
      "Epoch 6: Total Loss=4928.6936\n",
      "Epoch 7: Total Loss=6082.5265\n",
      "Epoch 8: Total Loss=4610.7865\n",
      "Epoch 9: Total Loss=6604.4797\n",
      "Updated x: [10.167266845703125, -9.506954193115234], Function Value: 193.7554931640625, Gradient: [-0.15429091453552246, -0.3286876082420349]\n",
      "\n",
      "Step 171/200\n",
      "Epoch 0: Total Loss=4670.5868\n",
      "Epoch 1: Total Loss=4400.8619\n",
      "Epoch 2: Total Loss=4310.2083\n",
      "Epoch 3: Total Loss=4393.2469\n",
      "Epoch 4: Total Loss=4066.1007\n",
      "Epoch 5: Total Loss=4411.8015\n",
      "Epoch 6: Total Loss=4895.4636\n",
      "Epoch 7: Total Loss=3885.9741\n",
      "Epoch 8: Total Loss=3841.8483\n",
      "Epoch 9: Total Loss=3624.8696\n",
      "Updated x: [10.115684509277344, -9.547303199768066], Function Value: 193.4780731201172, Gradient: [-0.20895758271217346, -0.360652357339859]\n",
      "\n",
      "Step 172/200\n",
      "Epoch 0: Total Loss=7170.2002\n",
      "Epoch 1: Total Loss=6928.2095\n",
      "Epoch 2: Total Loss=6410.9702\n",
      "Epoch 3: Total Loss=6695.9460\n",
      "Epoch 4: Total Loss=5426.9045\n",
      "Epoch 5: Total Loss=6036.2815\n",
      "Epoch 6: Total Loss=6152.9138\n",
      "Epoch 7: Total Loss=5543.7874\n",
      "Epoch 8: Total Loss=5574.0709\n",
      "Epoch 9: Total Loss=5271.7842\n",
      "Updated x: [10.097371101379395, -9.638348579406738], Function Value: 194.85467529296875, Gradient: [-0.005600247066468, -0.01334930770099163]\n",
      "\n",
      "Step 173/200\n",
      "Epoch 0: Total Loss=5253.1818\n",
      "Epoch 1: Total Loss=5495.0969\n",
      "Epoch 2: Total Loss=5286.0520\n",
      "Epoch 3: Total Loss=5401.2500\n",
      "Epoch 4: Total Loss=5117.8359\n",
      "Epoch 5: Total Loss=4788.3060\n",
      "Epoch 6: Total Loss=5453.4675\n",
      "Epoch 7: Total Loss=5040.8529\n",
      "Epoch 8: Total Loss=5940.8242\n",
      "Epoch 9: Total Loss=5149.5995\n",
      "Updated x: [10.1002779006958, -9.465398788452148], Function Value: 191.60939025878906, Gradient: [-0.17330262064933777, -0.35910865664482117]\n",
      "\n",
      "Step 174/200\n",
      "Epoch 0: Total Loss=5752.3801\n",
      "Epoch 1: Total Loss=4898.9280\n",
      "Epoch 2: Total Loss=5037.4706\n",
      "Epoch 3: Total Loss=4314.4089\n",
      "Epoch 4: Total Loss=5094.1722\n",
      "Epoch 5: Total Loss=4979.7156\n",
      "Epoch 6: Total Loss=4376.4233\n",
      "Epoch 7: Total Loss=5755.1599\n",
      "Epoch 8: Total Loss=4710.6438\n",
      "Epoch 9: Total Loss=4961.2789\n",
      "Updated x: [10.114383697509766, -9.342864036560059], Function Value: 189.58987426757812, Gradient: [-0.05944732204079628, -0.1298263818025589]\n",
      "\n",
      "Step 175/200\n",
      "Epoch 0: Total Loss=4759.6918\n",
      "Epoch 1: Total Loss=4301.8214\n",
      "Epoch 2: Total Loss=4336.5695\n",
      "Epoch 3: Total Loss=5144.9231\n",
      "Epoch 4: Total Loss=5201.2996\n",
      "Epoch 5: Total Loss=4988.0852\n",
      "Epoch 6: Total Loss=4360.5786\n",
      "Epoch 7: Total Loss=5882.9839\n",
      "Epoch 8: Total Loss=4799.2832\n",
      "Epoch 9: Total Loss=4615.2362\n",
      "Updated x: [10.024296760559082, -9.317764282226562], Function Value: 187.3072509765625, Gradient: [-0.0001707258925307542, -0.00045138614950701594]\n",
      "\n",
      "Step 176/200\n",
      "Epoch 0: Total Loss=6033.3164\n",
      "Epoch 1: Total Loss=4974.6624\n",
      "Epoch 2: Total Loss=3831.1760\n",
      "Epoch 3: Total Loss=4136.4548\n",
      "Epoch 4: Total Loss=4594.0616\n",
      "Epoch 5: Total Loss=5026.6700\n",
      "Epoch 6: Total Loss=3993.8282\n",
      "Epoch 7: Total Loss=5800.5015\n",
      "Epoch 8: Total Loss=4669.3650\n",
      "Epoch 9: Total Loss=4498.0970\n",
      "Updated x: [10.0756254196167, -9.204154968261719], Function Value: 186.2346954345703, Gradient: [-2.7227584770139757e-11, -1.0377670944805573e-10]\n",
      "\n",
      "Step 177/200\n",
      "Epoch 0: Total Loss=4448.1030\n",
      "Epoch 1: Total Loss=4262.8593\n",
      "Epoch 2: Total Loss=5147.3110\n",
      "Epoch 3: Total Loss=4271.1843\n",
      "Epoch 4: Total Loss=4381.4446\n",
      "Epoch 5: Total Loss=4399.8385\n",
      "Epoch 6: Total Loss=4192.2742\n",
      "Epoch 7: Total Loss=4554.0746\n",
      "Epoch 8: Total Loss=4548.7687\n",
      "Epoch 9: Total Loss=4934.9609\n",
      "Updated x: [10.163724899291992, -9.255159378051758], Function Value: 188.9592742919922, Gradient: [-5.0785318910754507e-23, -2.9925750197388826e-22]\n",
      "\n",
      "Step 178/200\n",
      "Epoch 0: Total Loss=5048.5442\n",
      "Epoch 1: Total Loss=4560.5903\n",
      "Epoch 2: Total Loss=3920.8929\n",
      "Epoch 3: Total Loss=4030.4601\n",
      "Epoch 4: Total Loss=3994.2794\n",
      "Epoch 5: Total Loss=4728.7439\n",
      "Epoch 6: Total Loss=4088.1655\n",
      "Epoch 7: Total Loss=4515.8787\n",
      "Epoch 8: Total Loss=4581.9943\n",
      "Epoch 9: Total Loss=3866.3699\n",
      "Updated x: [10.14557933807373, -9.280485153198242], Function Value: 189.0601806640625, Gradient: [-1.3710646091779305e-38, -1.528956866528685e-37]\n",
      "\n",
      "Step 179/200\n",
      "Epoch 0: Total Loss=3842.5681\n",
      "Epoch 1: Total Loss=3764.9365\n",
      "Epoch 2: Total Loss=4181.7125\n",
      "Epoch 3: Total Loss=4010.4436\n",
      "Epoch 4: Total Loss=4943.8998\n",
      "Epoch 5: Total Loss=4332.1476\n",
      "Epoch 6: Total Loss=3925.6974\n",
      "Epoch 7: Total Loss=4342.6255\n",
      "Epoch 8: Total Loss=3934.0950\n",
      "Epoch 9: Total Loss=4520.9225\n",
      "Updated x: [10.190816879272461, -9.380904197692871], Function Value: 191.85411071777344, Gradient: [0.0, 0.0]\n",
      "\n",
      "Step 180/200\n",
      "Epoch 0: Total Loss=3699.9008\n",
      "Epoch 1: Total Loss=3832.7244\n",
      "Epoch 2: Total Loss=3804.6609\n",
      "Epoch 3: Total Loss=3578.1889\n",
      "Epoch 4: Total Loss=3882.6237\n",
      "Epoch 5: Total Loss=4098.4340\n",
      "Epoch 6: Total Loss=3974.9332\n",
      "Epoch 7: Total Loss=3911.2854\n",
      "Epoch 8: Total Loss=4242.2250\n",
      "Epoch 9: Total Loss=4209.3787\n",
      "Updated x: [10.184314727783203, -9.355325698852539], Function Value: 191.2423858642578, Gradient: [0.0, 0.0]\n",
      "\n",
      "Step 181/200\n",
      "Epoch 0: Total Loss=4049.1450\n",
      "Epoch 1: Total Loss=3615.3721\n",
      "Epoch 2: Total Loss=3817.8767\n",
      "Epoch 3: Total Loss=3976.7202\n",
      "Epoch 4: Total Loss=3546.9316\n",
      "Epoch 5: Total Loss=3196.8845\n",
      "Epoch 6: Total Loss=3785.7020\n",
      "Epoch 7: Total Loss=2950.0573\n",
      "Epoch 8: Total Loss=2620.9499\n",
      "Epoch 9: Total Loss=3468.3015\n",
      "Updated x: [10.156901359558105, -9.518264770507812], Function Value: 193.760009765625, Gradient: [0.0, 0.0]\n",
      "\n",
      "Step 182/200\n",
      "Epoch 0: Total Loss=5259.0066\n",
      "Epoch 1: Total Loss=5159.8798\n",
      "Epoch 2: Total Loss=4714.9048\n",
      "Epoch 3: Total Loss=4836.5562\n",
      "Epoch 4: Total Loss=4246.3616\n",
      "Epoch 5: Total Loss=4664.1625\n",
      "Epoch 6: Total Loss=4592.8949\n",
      "Epoch 7: Total Loss=3838.6323\n",
      "Epoch 8: Total Loss=3863.7765\n",
      "Epoch 9: Total Loss=4515.6898\n",
      "Updated x: [10.024805068969727, -9.626072883605957], Function Value: 193.15798950195312, Gradient: [0.0, 0.0]\n",
      "\n",
      "Step 183/200\n",
      "Epoch 0: Total Loss=3918.6726\n",
      "Epoch 1: Total Loss=3635.4202\n",
      "Epoch 2: Total Loss=3689.6194\n",
      "Epoch 3: Total Loss=3557.1393\n",
      "Epoch 4: Total Loss=4055.4491\n",
      "Epoch 5: Total Loss=3995.5327\n",
      "Epoch 6: Total Loss=3553.1880\n",
      "Epoch 7: Total Loss=4075.8243\n",
      "Epoch 8: Total Loss=4234.9285\n",
      "Epoch 9: Total Loss=4272.0696\n",
      "Updated x: [9.97542667388916, -9.73763370513916], Function Value: 194.33065795898438, Gradient: [0.0, 0.0]\n",
      "\n",
      "Step 184/200\n",
      "Epoch 0: Total Loss=3611.4437\n",
      "Epoch 1: Total Loss=4191.0045\n",
      "Epoch 2: Total Loss=4013.9883\n",
      "Epoch 3: Total Loss=3891.2889\n",
      "Epoch 4: Total Loss=3335.6716\n",
      "Epoch 5: Total Loss=4144.3933\n",
      "Epoch 6: Total Loss=3866.6609\n",
      "Epoch 7: Total Loss=3476.0032\n",
      "Epoch 8: Total Loss=3909.5486\n",
      "Epoch 9: Total Loss=4288.8701\n",
      "Updated x: [9.742131233215332, -9.746833801269531], Function Value: 189.90988159179688, Gradient: [0.0, 0.0]\n",
      "\n",
      "Step 185/200\n",
      "Epoch 0: Total Loss=3652.1865\n",
      "Epoch 1: Total Loss=4147.7218\n",
      "Epoch 2: Total Loss=4753.2709\n",
      "Epoch 3: Total Loss=4110.3971\n",
      "Epoch 4: Total Loss=3404.5538\n",
      "Epoch 5: Total Loss=4230.9532\n",
      "Epoch 6: Total Loss=3821.3209\n",
      "Epoch 7: Total Loss=3522.8658\n",
      "Epoch 8: Total Loss=4235.6051\n",
      "Epoch 9: Total Loss=3987.2488\n",
      "Updated x: [9.759395599365234, -9.893653869628906], Function Value: 193.13018798828125, Gradient: [0.0, 0.0]\n",
      "\n",
      "Step 186/200\n",
      "Epoch 0: Total Loss=4013.6853\n",
      "Epoch 1: Total Loss=3839.9307\n",
      "Epoch 2: Total Loss=3145.4340\n",
      "Epoch 3: Total Loss=3388.8778\n",
      "Epoch 4: Total Loss=3545.4249\n",
      "Epoch 5: Total Loss=3202.2890\n",
      "Epoch 6: Total Loss=3642.4982\n",
      "Epoch 7: Total Loss=3638.3174\n",
      "Epoch 8: Total Loss=3860.3280\n",
      "Epoch 9: Total Loss=3588.8026\n",
      "Updated x: [9.717890739440918, -9.843133926391602], Function Value: 191.32467651367188, Gradient: [0.0, 0.0]\n",
      "\n",
      "Step 187/200\n",
      "Epoch 0: Total Loss=3702.4275\n",
      "Epoch 1: Total Loss=3540.8829\n",
      "Epoch 2: Total Loss=3251.9035\n",
      "Epoch 3: Total Loss=3731.4082\n",
      "Epoch 4: Total Loss=3017.7600\n",
      "Epoch 5: Total Loss=3603.9146\n",
      "Epoch 6: Total Loss=3282.1960\n",
      "Epoch 7: Total Loss=3334.1606\n",
      "Epoch 8: Total Loss=3288.6398\n",
      "Epoch 9: Total Loss=3670.2648\n",
      "Updated x: [9.859768867492676, -9.84640884399414], Function Value: 194.16680908203125, Gradient: [0.0, 0.0]\n",
      "\n",
      "Step 188/200\n",
      "Epoch 0: Total Loss=3262.1854\n",
      "Epoch 1: Total Loss=3744.1145\n",
      "Epoch 2: Total Loss=3284.2018\n",
      "Epoch 3: Total Loss=3711.7820\n",
      "Epoch 4: Total Loss=3272.5236\n",
      "Epoch 5: Total Loss=3495.4159\n",
      "Epoch 6: Total Loss=3586.9854\n",
      "Epoch 7: Total Loss=3195.3007\n",
      "Epoch 8: Total Loss=3163.4938\n",
      "Epoch 9: Total Loss=3553.5447\n",
      "Updated x: [9.729238510131836, -9.919896125793457], Function Value: 193.0624237060547, Gradient: [0.0, 0.0]\n",
      "\n",
      "Step 189/200\n",
      "Epoch 0: Total Loss=3265.7647\n",
      "Epoch 1: Total Loss=3110.5006\n",
      "Epoch 2: Total Loss=3321.8314\n",
      "Epoch 3: Total Loss=3562.5549\n",
      "Epoch 4: Total Loss=2929.9225\n",
      "Epoch 5: Total Loss=3464.4387\n",
      "Epoch 6: Total Loss=3335.1458\n",
      "Epoch 7: Total Loss=3166.0756\n",
      "Epoch 8: Total Loss=3300.4836\n",
      "Epoch 9: Total Loss=2849.3275\n",
      "Updated x: [9.706186294555664, -10.008941650390625], Function Value: 194.3889617919922, Gradient: [0.0, 0.0]\n",
      "\n",
      "Step 190/200\n",
      "Epoch 0: Total Loss=2939.5505\n",
      "Epoch 1: Total Loss=3602.5914\n",
      "Epoch 2: Total Loss=3117.5938\n",
      "Epoch 3: Total Loss=3029.8813\n",
      "Epoch 4: Total Loss=3165.0385\n",
      "Epoch 5: Total Loss=3183.7499\n",
      "Epoch 6: Total Loss=3273.9414\n",
      "Epoch 7: Total Loss=4556.6592\n",
      "Epoch 8: Total Loss=3784.7665\n",
      "Epoch 9: Total Loss=3094.4183\n",
      "Updated x: [9.797511100769043, -10.210186004638672], Function Value: 200.2391357421875, Gradient: [0.0, 0.0]\n",
      "\n",
      "Step 191/200\n",
      "Epoch 0: Total Loss=3326.5787\n",
      "Epoch 1: Total Loss=2591.7013\n",
      "Epoch 2: Total Loss=2821.2355\n",
      "Epoch 3: Total Loss=2857.6310\n",
      "Epoch 4: Total Loss=2884.4692\n",
      "Epoch 5: Total Loss=2612.7892\n",
      "Epoch 6: Total Loss=3256.7200\n",
      "Epoch 7: Total Loss=2742.4320\n",
      "Epoch 8: Total Loss=2382.6932\n",
      "Epoch 9: Total Loss=2151.9157\n",
      "Updated x: [9.610016822814941, -10.17760181427002], Function Value: 195.93600463867188, Gradient: [0.0, 0.0]\n",
      "\n",
      "Step 192/200\n",
      "Epoch 0: Total Loss=4794.4229\n",
      "Epoch 1: Total Loss=4732.6458\n",
      "Epoch 2: Total Loss=4034.1053\n",
      "Epoch 3: Total Loss=3893.9811\n",
      "Epoch 4: Total Loss=3969.0156\n",
      "Epoch 5: Total Loss=3853.7789\n",
      "Epoch 6: Total Loss=3447.1411\n",
      "Epoch 7: Total Loss=3498.2528\n",
      "Epoch 8: Total Loss=3137.5591\n",
      "Epoch 9: Total Loss=3122.3596\n",
      "Updated x: [9.641538619995117, -10.262666702270508], Function Value: 198.28158569335938, Gradient: [0.0, 0.0]\n",
      "\n",
      "Step 193/200\n",
      "Epoch 0: Total Loss=3311.4620\n",
      "Epoch 1: Total Loss=3113.3952\n",
      "Epoch 2: Total Loss=3218.7766\n",
      "Epoch 3: Total Loss=3196.7341\n",
      "Epoch 4: Total Loss=3278.9011\n",
      "Epoch 5: Total Loss=3141.1909\n",
      "Epoch 6: Total Loss=3046.0592\n",
      "Epoch 7: Total Loss=3194.9651\n",
      "Epoch 8: Total Loss=2996.5148\n",
      "Epoch 9: Total Loss=3743.6559\n",
      "Updated x: [9.530895233154297, -10.135788917541504], Function Value: 193.57217407226562, Gradient: [0.0, 0.0]\n",
      "\n",
      "Step 194/200\n",
      "Epoch 0: Total Loss=2865.6505\n",
      "Epoch 1: Total Loss=2836.7346\n",
      "Epoch 2: Total Loss=2840.8557\n",
      "Epoch 3: Total Loss=2955.7591\n",
      "Epoch 4: Total Loss=3116.8734\n",
      "Epoch 5: Total Loss=2960.6242\n",
      "Epoch 6: Total Loss=3086.2911\n",
      "Epoch 7: Total Loss=3311.5691\n",
      "Epoch 8: Total Loss=3303.6265\n",
      "Epoch 9: Total Loss=3526.6954\n",
      "Updated x: [9.514240264892578, -10.032163619995117], Function Value: 191.16506958007812, Gradient: [0.0, 0.0]\n",
      "\n",
      "Step 195/200\n",
      "Epoch 0: Total Loss=3370.6369\n",
      "Epoch 1: Total Loss=3087.7597\n",
      "Epoch 2: Total Loss=2625.9988\n",
      "Epoch 3: Total Loss=2978.8377\n",
      "Epoch 4: Total Loss=2910.7173\n",
      "Epoch 5: Total Loss=2999.9823\n",
      "Epoch 6: Total Loss=2917.0759\n",
      "Epoch 7: Total Loss=3083.7104\n",
      "Epoch 8: Total Loss=2859.2641\n",
      "Epoch 9: Total Loss=2808.9990\n",
      "Updated x: [9.543949127197266, -10.165162086486816], Function Value: 194.41748046875, Gradient: [0.0, 0.0]\n",
      "\n",
      "Step 196/200\n",
      "Epoch 0: Total Loss=3106.4951\n",
      "Epoch 1: Total Loss=3098.1288\n",
      "Epoch 2: Total Loss=2603.7685\n",
      "Epoch 3: Total Loss=3165.1351\n",
      "Epoch 4: Total Loss=3148.7375\n",
      "Epoch 5: Total Loss=2758.0601\n",
      "Epoch 6: Total Loss=2769.9861\n",
      "Epoch 7: Total Loss=3347.9794\n",
      "Epoch 8: Total Loss=2477.5034\n",
      "Epoch 9: Total Loss=2900.1895\n",
      "Updated x: [9.434013366699219, -10.048237800598145], Function Value: 189.96768188476562, Gradient: [0.0, 0.0]\n",
      "\n",
      "Step 197/200\n",
      "Epoch 0: Total Loss=2590.0490\n",
      "Epoch 1: Total Loss=2309.8706\n",
      "Epoch 2: Total Loss=2638.9197\n",
      "Epoch 3: Total Loss=2813.4954\n",
      "Epoch 4: Total Loss=2801.5959\n",
      "Epoch 5: Total Loss=2544.6259\n",
      "Epoch 6: Total Loss=2267.0138\n",
      "Epoch 7: Total Loss=2441.5685\n",
      "Epoch 8: Total Loss=2777.0500\n",
      "Epoch 9: Total Loss=2459.5825\n",
      "Updated x: [9.406633377075195, -10.052742004394531], Function Value: 189.54237365722656, Gradient: [0.0, 0.0]\n",
      "\n",
      "Step 198/200\n",
      "Epoch 0: Total Loss=2774.3122\n",
      "Epoch 1: Total Loss=2344.2589\n",
      "Epoch 2: Total Loss=2222.0248\n",
      "Epoch 3: Total Loss=2453.1706\n",
      "Epoch 4: Total Loss=2958.4723\n",
      "Epoch 5: Total Loss=2752.2306\n",
      "Epoch 6: Total Loss=2497.3060\n",
      "Epoch 7: Total Loss=2245.4373\n",
      "Epoch 8: Total Loss=2279.1106\n",
      "Epoch 9: Total Loss=2685.1687\n",
      "Updated x: [9.334613800048828, -10.129693984985352], Function Value: 189.7457275390625, Gradient: [0.0, 0.0]\n",
      "\n",
      "Step 199/200\n",
      "Epoch 0: Total Loss=2595.7311\n",
      "Epoch 1: Total Loss=2805.2517\n",
      "Epoch 2: Total Loss=2965.6343\n",
      "Epoch 3: Total Loss=2410.9802\n",
      "Epoch 4: Total Loss=2359.8809\n",
      "Epoch 5: Total Loss=2295.7219\n",
      "Epoch 6: Total Loss=2390.8550\n",
      "Epoch 7: Total Loss=2599.7079\n",
      "Epoch 8: Total Loss=2442.8049\n",
      "Epoch 9: Total Loss=2495.0770\n",
      "Updated x: [9.327133178710938, -10.047112464904785], Function Value: 187.93988037109375, Gradient: [0.0, 0.0]\n",
      "\n",
      "Step 200/200\n",
      "Epoch 0: Total Loss=2507.6867\n",
      "Epoch 1: Total Loss=2692.5850\n",
      "Epoch 2: Total Loss=2803.7579\n",
      "Epoch 3: Total Loss=2690.8193\n",
      "Epoch 4: Total Loss=2139.4615\n",
      "Epoch 5: Total Loss=2601.3294\n",
      "Epoch 6: Total Loss=2915.7412\n",
      "Epoch 7: Total Loss=2806.8079\n",
      "Epoch 8: Total Loss=2287.5687\n",
      "Epoch 9: Total Loss=2410.3940\n",
      "Updated x: [9.412214279174805, -10.129133224487305], Function Value: 191.18911743164062, Gradient: [0.0, 0.0]\n",
      "\n",
      "Step 1/200\n",
      "Epoch 0: Total Loss=76186.5234\n",
      "Epoch 1: Total Loss=76104.9648\n",
      "Epoch 2: Total Loss=76022.3750\n",
      "Epoch 3: Total Loss=75938.6875\n",
      "Epoch 4: Total Loss=75853.7930\n",
      "Epoch 5: Total Loss=75767.6289\n",
      "Epoch 6: Total Loss=75680.0234\n",
      "Epoch 7: Total Loss=75590.9023\n",
      "Epoch 8: Total Loss=75500.1445\n",
      "Epoch 9: Total Loss=75407.6250\n",
      "Updated x: [9.89365291595459, -9.845974922180176], Function Value: 194.8275909423828, Gradient: [-0.07808776199817657, -0.653588056564331]\n",
      "\n",
      "Step 2/200\n",
      "Epoch 0: Total Loss=71500.2695\n",
      "Epoch 1: Total Loss=71490.5586\n",
      "Epoch 2: Total Loss=71477.7031\n",
      "Epoch 3: Total Loss=71308.0664\n",
      "Epoch 4: Total Loss=71209.6914\n",
      "Epoch 5: Total Loss=71197.0898\n",
      "Epoch 6: Total Loss=71030.7383\n",
      "Epoch 7: Total Loss=70924.0234\n",
      "Epoch 8: Total Loss=70667.7031\n",
      "Epoch 9: Total Loss=70641.8672\n",
      "Updated x: [9.927689552307129, -9.622699737548828], Function Value: 191.15536499023438, Gradient: [-0.07444899529218674, -0.7722580432891846]\n",
      "\n",
      "Step 3/200\n",
      "Epoch 0: Total Loss=69799.5234\n",
      "Epoch 1: Total Loss=70121.8945\n",
      "Epoch 2: Total Loss=69442.0820\n",
      "Epoch 3: Total Loss=69986.2852\n",
      "Epoch 4: Total Loss=69304.3633\n",
      "Epoch 5: Total Loss=69770.5391\n",
      "Epoch 6: Total Loss=69092.8594\n",
      "Epoch 7: Total Loss=69469.5000\n",
      "Epoch 8: Total Loss=69016.3633\n",
      "Epoch 9: Total Loss=69318.0703\n",
      "Updated x: [9.863460540771484, -9.693770408630371], Function Value: 191.25704956054688, Gradient: [-0.02709628827869892, -0.8721771240234375]\n",
      "\n",
      "Step 4/200\n",
      "Epoch 0: Total Loss=604.6072\n",
      "Epoch 1: Total Loss=533.3183\n",
      "Epoch 2: Total Loss=536.4125\n",
      "Epoch 3: Total Loss=605.7044\n",
      "Epoch 4: Total Loss=531.4574\n",
      "Epoch 5: Total Loss=454.6132\n",
      "Epoch 6: Total Loss=446.1221\n",
      "Epoch 7: Total Loss=449.7036\n",
      "Epoch 8: Total Loss=529.2704\n",
      "Epoch 9: Total Loss=528.8479\n",
      "Updated x: [9.927316665649414, -9.646695137023926], Function Value: 191.61033630371094, Gradient: [-0.07641665637493134, -0.8122654557228088]\n",
      "\n",
      "Step 5/200\n",
      "Epoch 0: Total Loss=532.0479\n",
      "Epoch 1: Total Loss=510.3131\n",
      "Epoch 2: Total Loss=681.0750\n",
      "Epoch 3: Total Loss=597.6876\n",
      "Epoch 4: Total Loss=612.8200\n",
      "Epoch 5: Total Loss=516.3596\n",
      "Epoch 6: Total Loss=599.9319\n",
      "Epoch 7: Total Loss=522.7829\n",
      "Epoch 8: Total Loss=605.8311\n",
      "Epoch 9: Total Loss=590.7211\n",
      "Updated x: [9.934099197387695, -9.51190185546875], Function Value: 189.16259765625, Gradient: [-0.13715286552906036, -0.761195182800293]\n",
      "\n",
      "Step 6/200\n",
      "Epoch 0: Total Loss=520.8134\n",
      "Epoch 1: Total Loss=594.6266\n",
      "Epoch 2: Total Loss=527.6049\n",
      "Epoch 3: Total Loss=524.3795\n",
      "Epoch 4: Total Loss=680.3837\n",
      "Epoch 5: Total Loss=599.8143\n",
      "Epoch 6: Total Loss=435.4846\n",
      "Epoch 7: Total Loss=595.3549\n",
      "Epoch 8: Total Loss=606.5742\n",
      "Epoch 9: Total Loss=521.6445\n",
      "Updated x: [9.814349174499512, -9.520394325256348], Function Value: 186.9593505859375, Gradient: [-0.185651957988739, -0.6815920472145081]\n",
      "\n",
      "Step 7/200\n",
      "Epoch 0: Total Loss=462.2288\n",
      "Epoch 1: Total Loss=671.4342\n",
      "Epoch 2: Total Loss=521.1503\n",
      "Epoch 3: Total Loss=591.0824\n",
      "Epoch 4: Total Loss=527.8301\n",
      "Epoch 5: Total Loss=518.9664\n",
      "Epoch 6: Total Loss=619.1554\n",
      "Epoch 7: Total Loss=514.3101\n",
      "Epoch 8: Total Loss=446.4071\n",
      "Epoch 9: Total Loss=514.7489\n",
      "Updated x: [9.58183765411377, -9.579832077026367], Function Value: 183.58480834960938, Gradient: [-0.22401109337806702, -0.6139870285987854]\n",
      "\n",
      "Step 8/200\n",
      "Epoch 0: Total Loss=609.3323\n",
      "Epoch 1: Total Loss=603.2396\n",
      "Epoch 2: Total Loss=434.1619\n",
      "Epoch 3: Total Loss=461.0805\n",
      "Epoch 4: Total Loss=538.1132\n",
      "Epoch 5: Total Loss=691.4391\n",
      "Epoch 6: Total Loss=523.7150\n",
      "Epoch 7: Total Loss=526.6334\n",
      "Epoch 8: Total Loss=601.3794\n",
      "Epoch 9: Total Loss=747.4216\n",
      "Updated x: [9.590560913085938, -9.468873023986816], Function Value: 181.63841247558594, Gradient: [-0.20241381227970123, -0.4775707423686981]\n",
      "\n",
      "Step 9/200\n",
      "Epoch 0: Total Loss=597.0892\n",
      "Epoch 1: Total Loss=623.6768\n",
      "Epoch 2: Total Loss=519.6184\n",
      "Epoch 3: Total Loss=613.9863\n",
      "Epoch 4: Total Loss=601.2030\n",
      "Epoch 5: Total Loss=678.9887\n",
      "Epoch 6: Total Loss=523.9554\n",
      "Epoch 7: Total Loss=677.9717\n",
      "Epoch 8: Total Loss=514.5165\n",
      "Epoch 9: Total Loss=617.0519\n",
      "Updated x: [9.487540245056152, -9.453754425048828], Function Value: 179.38690185546875, Gradient: [-0.21704117953777313, -0.4277355670928955]\n",
      "\n",
      "Step 10/200\n",
      "Epoch 0: Total Loss=530.0098\n",
      "Epoch 1: Total Loss=546.0209\n",
      "Epoch 2: Total Loss=515.0604\n",
      "Epoch 3: Total Loss=522.3612\n",
      "Epoch 4: Total Loss=598.5257\n",
      "Epoch 5: Total Loss=603.5155\n",
      "Epoch 6: Total Loss=518.2124\n",
      "Epoch 7: Total Loss=449.2079\n",
      "Epoch 8: Total Loss=518.7995\n",
      "Epoch 9: Total Loss=528.3389\n",
      "Updated x: [9.34085464477539, -9.494873046875], Function Value: 177.4041748046875, Gradient: [-0.32624393701553345, -0.5338739156723022]\n",
      "\n",
      "Step 11/200\n",
      "Epoch 0: Total Loss=526.8016\n",
      "Epoch 1: Total Loss=450.9386\n",
      "Epoch 2: Total Loss=606.4949\n",
      "Epoch 3: Total Loss=598.5740\n",
      "Epoch 4: Total Loss=526.4784\n",
      "Epoch 5: Total Loss=443.5250\n",
      "Epoch 6: Total Loss=513.7487\n",
      "Epoch 7: Total Loss=600.9366\n",
      "Epoch 8: Total Loss=604.4715\n",
      "Epoch 9: Total Loss=611.4625\n",
      "Updated x: [9.261279106140137, -9.490236282348633], Function Value: 175.83587646484375, Gradient: [-0.3426097333431244, -0.5387172698974609]\n",
      "\n",
      "Step 12/200\n",
      "Epoch 0: Total Loss=61090.3535\n",
      "Epoch 1: Total Loss=61001.8496\n",
      "Epoch 2: Total Loss=60909.8379\n",
      "Epoch 3: Total Loss=60815.1289\n",
      "Epoch 4: Total Loss=60717.4668\n",
      "Epoch 5: Total Loss=60616.2168\n",
      "Epoch 6: Total Loss=60511.8516\n",
      "Epoch 7: Total Loss=60404.1289\n",
      "Epoch 8: Total Loss=60294.0977\n",
      "Epoch 9: Total Loss=60180.4473\n",
      "Updated x: [9.247828483581543, -9.358349800109863], Function Value: 173.10104370117188, Gradient: [-0.5121765732765198, -0.8821794390678406]\n",
      "\n",
      "Step 13/200\n",
      "Epoch 0: Total Loss=59311.4688\n",
      "Epoch 1: Total Loss=56840.2598\n",
      "Epoch 2: Total Loss=59085.7051\n",
      "Epoch 3: Total Loss=56619.2266\n",
      "Epoch 4: Total Loss=58855.5742\n",
      "Epoch 5: Total Loss=56394.8535\n",
      "Epoch 6: Total Loss=58622.3398\n",
      "Epoch 7: Total Loss=56168.4961\n",
      "Epoch 8: Total Loss=58388.3242\n",
      "Epoch 9: Total Loss=55942.3594\n",
      "Updated x: [9.138047218322754, -9.13014030456543], Function Value: 166.86337280273438, Gradient: [-0.528830885887146, -1.0918368101119995]\n",
      "\n",
      "Step 14/200\n",
      "Epoch 0: Total Loss=63.7342\n",
      "Epoch 1: Total Loss=62.8540\n",
      "Epoch 2: Total Loss=50.7085\n",
      "Epoch 3: Total Loss=62.7682\n",
      "Epoch 4: Total Loss=61.5687\n",
      "Epoch 5: Total Loss=49.6697\n",
      "Epoch 6: Total Loss=61.5825\n",
      "Epoch 7: Total Loss=60.6401\n",
      "Epoch 8: Total Loss=48.4900\n",
      "Epoch 9: Total Loss=60.2366\n",
      "Updated x: [9.144851684570312, -9.159558296203613], Function Value: 167.52581787109375, Gradient: [-0.5513107776641846, -0.9308801889419556]\n",
      "\n",
      "Step 15/200\n",
      "Epoch 0: Total Loss=29.1790\n",
      "Epoch 1: Total Loss=36.4268\n",
      "Epoch 2: Total Loss=68.2564\n",
      "Epoch 3: Total Loss=50.6360\n",
      "Epoch 4: Total Loss=27.7133\n",
      "Epoch 5: Total Loss=35.3735\n",
      "Epoch 6: Total Loss=67.0684\n",
      "Epoch 7: Total Loss=49.9279\n",
      "Epoch 8: Total Loss=27.1181\n",
      "Epoch 9: Total Loss=34.8331\n",
      "Updated x: [9.000536918640137, -9.071815490722656], Function Value: 163.3074951171875, Gradient: [-0.3851611018180847, -0.5962271094322205]\n",
      "\n",
      "Step 16/200\n",
      "Epoch 0: Total Loss=23.4566\n",
      "Epoch 1: Total Loss=55.8452\n",
      "Epoch 2: Total Loss=43.1447\n",
      "Epoch 3: Total Loss=36.2534\n",
      "Epoch 4: Total Loss=19.6852\n",
      "Epoch 5: Total Loss=22.8671\n",
      "Epoch 6: Total Loss=55.1129\n",
      "Epoch 7: Total Loss=42.5425\n",
      "Epoch 8: Total Loss=36.0563\n",
      "Epoch 9: Total Loss=19.2471\n",
      "Updated x: [8.882766723632812, -9.057280540466309], Function Value: 160.9378662109375, Gradient: [-0.2604743540287018, -0.36216801404953003]\n",
      "\n",
      "Step 17/200\n",
      "Epoch 0: Total Loss=19.1918\n",
      "Epoch 1: Total Loss=23.8580\n",
      "Epoch 2: Total Loss=19.0535\n",
      "Epoch 3: Total Loss=24.3234\n",
      "Epoch 4: Total Loss=64.3277\n",
      "Epoch 5: Total Loss=18.1770\n",
      "Epoch 6: Total Loss=18.9254\n",
      "Epoch 7: Total Loss=23.6136\n",
      "Epoch 8: Total Loss=18.9657\n",
      "Epoch 9: Total Loss=24.2710\n",
      "Updated x: [8.936485290527344, -8.993085861206055], Function Value: 160.73635864257812, Gradient: [-0.18788880109786987, -0.22724995017051697]\n",
      "\n",
      "Step 18/200\n",
      "Epoch 0: Total Loss=15.5571\n",
      "Epoch 1: Total Loss=38.3954\n",
      "Epoch 2: Total Loss=26.0674\n",
      "Epoch 3: Total Loss=30.1224\n",
      "Epoch 4: Total Loss=11.9771\n",
      "Epoch 5: Total Loss=18.0641\n",
      "Epoch 6: Total Loss=18.4030\n",
      "Epoch 7: Total Loss=15.4139\n",
      "Epoch 8: Total Loss=38.4150\n",
      "Epoch 9: Total Loss=26.2172\n",
      "Updated x: [8.88938045501709, -9.016626358032227], Function Value: 160.32064819335938, Gradient: [-0.3355378806591034, -0.3651004433631897]\n",
      "\n",
      "Step 19/200\n",
      "Epoch 0: Total Loss=22.9145\n",
      "Epoch 1: Total Loss=51.9187\n",
      "Epoch 2: Total Loss=17.8742\n",
      "Epoch 3: Total Loss=22.4486\n",
      "Epoch 4: Total Loss=25.8737\n",
      "Epoch 5: Total Loss=21.0188\n",
      "Epoch 6: Total Loss=10.4613\n",
      "Epoch 7: Total Loss=16.4503\n",
      "Epoch 8: Total Loss=22.5920\n",
      "Epoch 9: Total Loss=51.7165\n",
      "Updated x: [8.726546287536621, -8.928956985473633], Function Value: 155.87887573242188, Gradient: [-0.4865838885307312, -0.533623993396759]\n",
      "\n",
      "Step 20/200\n",
      "Epoch 0: Total Loss=11.1927\n",
      "Epoch 1: Total Loss=18.0887\n",
      "Epoch 2: Total Loss=15.1893\n",
      "Epoch 3: Total Loss=30.8507\n",
      "Epoch 4: Total Loss=33.0974\n",
      "Epoch 5: Total Loss=19.4201\n",
      "Epoch 6: Total Loss=23.4697\n",
      "Epoch 7: Total Loss=32.7249\n",
      "Epoch 8: Total Loss=17.1602\n",
      "Epoch 9: Total Loss=11.3225\n",
      "Updated x: [8.560705184936523, -8.968522071838379], Function Value: 153.72006225585938, Gradient: [-0.5596798062324524, -0.5966110825538635]\n",
      "\n",
      "Step 21/200\n",
      "Epoch 0: Total Loss=9.6734\n",
      "Epoch 1: Total Loss=18.2414\n",
      "Epoch 2: Total Loss=26.7905\n",
      "Epoch 3: Total Loss=13.5414\n",
      "Epoch 4: Total Loss=37.4424\n",
      "Epoch 5: Total Loss=33.9869\n",
      "Epoch 6: Total Loss=23.3655\n",
      "Epoch 7: Total Loss=19.2135\n",
      "Epoch 8: Total Loss=36.2439\n",
      "Epoch 9: Total Loss=19.5336\n",
      "Updated x: [8.52125358581543, -8.79974365234375], Function Value: 150.0472412109375, Gradient: [-0.5147097706794739, -0.5462988615036011]\n",
      "\n",
      "Step 22/200\n",
      "Epoch 0: Total Loss=44050.3379\n",
      "Epoch 1: Total Loss=43989.9277\n",
      "Epoch 2: Total Loss=43928.3574\n",
      "Epoch 3: Total Loss=43865.4980\n",
      "Epoch 4: Total Loss=43801.4102\n",
      "Epoch 5: Total Loss=43735.9609\n",
      "Epoch 6: Total Loss=43669.2402\n",
      "Epoch 7: Total Loss=43601.3027\n",
      "Epoch 8: Total Loss=43532.2422\n",
      "Epoch 9: Total Loss=43461.8242\n",
      "Updated x: [8.373064041137695, -8.745536804199219], Function Value: 146.59262084960938, Gradient: [-0.682425856590271, -0.8465839624404907]\n",
      "\n",
      "Step 23/200\n",
      "Epoch 0: Total Loss=41702.4590\n",
      "Epoch 1: Total Loss=42773.6367\n",
      "Epoch 2: Total Loss=41564.8730\n",
      "Epoch 3: Total Loss=42632.1758\n",
      "Epoch 4: Total Loss=41425.7207\n",
      "Epoch 5: Total Loss=42489.3535\n",
      "Epoch 6: Total Loss=41285.2910\n",
      "Epoch 7: Total Loss=42345.6855\n",
      "Epoch 8: Total Loss=41144.2305\n",
      "Epoch 9: Total Loss=42201.6270\n",
      "Updated x: [8.172090530395508, -8.735620498657227], Function Value: 143.09413146972656, Gradient: [-0.6001696586608887, -0.9104180335998535]\n",
      "\n",
      "Step 24/200\n",
      "Epoch 0: Total Loss=30.4071\n",
      "Epoch 1: Total Loss=32.4327\n",
      "Epoch 2: Total Loss=33.9588\n",
      "Epoch 3: Total Loss=29.5528\n",
      "Epoch 4: Total Loss=31.6317\n",
      "Epoch 5: Total Loss=33.2183\n",
      "Epoch 6: Total Loss=28.8155\n",
      "Epoch 7: Total Loss=30.9152\n",
      "Epoch 8: Total Loss=32.5896\n",
      "Epoch 9: Total Loss=28.3451\n",
      "Updated x: [8.084494590759277, -8.719290733337402], Function Value: 141.3850860595703, Gradient: [-0.6796813607215881, -0.852999746799469]\n",
      "\n",
      "Step 25/200\n",
      "Epoch 0: Total Loss=37.8113\n",
      "Epoch 1: Total Loss=20.8448\n",
      "Epoch 2: Total Loss=23.7208\n",
      "Epoch 3: Total Loss=25.3555\n",
      "Epoch 4: Total Loss=37.3422\n",
      "Epoch 5: Total Loss=20.5103\n",
      "Epoch 6: Total Loss=23.4293\n",
      "Epoch 7: Total Loss=25.0901\n",
      "Epoch 8: Total Loss=37.0139\n",
      "Epoch 9: Total Loss=20.2854\n",
      "Updated x: [8.032857894897461, -8.543441772460938], Function Value: 137.5172119140625, Gradient: [-0.6198865175247192, -0.6775643229484558]\n",
      "\n",
      "Step 26/200\n",
      "Epoch 0: Total Loss=26.3905\n",
      "Epoch 1: Total Loss=16.7523\n",
      "Epoch 2: Total Loss=38.0497\n",
      "Epoch 3: Total Loss=33.2490\n",
      "Epoch 4: Total Loss=33.1426\n",
      "Epoch 5: Total Loss=26.4359\n",
      "Epoch 6: Total Loss=16.6887\n",
      "Epoch 7: Total Loss=38.0140\n",
      "Epoch 8: Total Loss=33.2619\n",
      "Epoch 9: Total Loss=33.1015\n",
      "Updated x: [8.03900146484375, -8.397727012634277], Function Value: 135.14736938476562, Gradient: [-0.4975621700286865, -0.5380258560180664]\n",
      "\n",
      "Step 27/200\n",
      "Epoch 0: Total Loss=28.4173\n",
      "Epoch 1: Total Loss=20.8243\n",
      "Epoch 2: Total Loss=17.9571\n",
      "Epoch 3: Total Loss=41.9207\n",
      "Epoch 4: Total Loss=29.3523\n",
      "Epoch 5: Total Loss=18.6136\n",
      "Epoch 6: Total Loss=28.4113\n",
      "Epoch 7: Total Loss=20.8627\n",
      "Epoch 8: Total Loss=17.9418\n",
      "Epoch 9: Total Loss=41.9672\n",
      "Updated x: [7.936325550079346, -8.302593231201172], Function Value: 131.91831970214844, Gradient: [-0.5714917182922363, -0.6161556839942932]\n",
      "\n",
      "Step 28/200\n",
      "Epoch 0: Total Loss=25.2619\n",
      "Epoch 1: Total Loss=32.1752\n",
      "Epoch 2: Total Loss=16.0623\n",
      "Epoch 3: Total Loss=20.2169\n",
      "Epoch 4: Total Loss=35.1985\n",
      "Epoch 5: Total Loss=18.8896\n",
      "Epoch 6: Total Loss=23.0176\n",
      "Epoch 7: Total Loss=25.2935\n",
      "Epoch 8: Total Loss=32.1622\n",
      "Epoch 9: Total Loss=16.1376\n",
      "Updated x: [7.727361679077148, -8.295120239257812], Function Value: 128.52114868164062, Gradient: [-0.6556758284568787, -0.7131509780883789]\n",
      "\n",
      "Step 29/200\n",
      "Epoch 0: Total Loss=22.4681\n",
      "Epoch 1: Total Loss=17.5159\n",
      "Epoch 2: Total Loss=30.4856\n",
      "Epoch 3: Total Loss=23.9834\n",
      "Epoch 4: Total Loss=17.9668\n",
      "Epoch 5: Total Loss=24.4770\n",
      "Epoch 6: Total Loss=41.7354\n",
      "Epoch 7: Total Loss=24.2158\n",
      "Epoch 8: Total Loss=22.4732\n",
      "Epoch 9: Total Loss=17.5167\n",
      "Updated x: [7.5896100997924805, -8.173564910888672], Function Value: 124.40934753417969, Gradient: [-0.5914362668991089, -0.6430742740631104]\n",
      "\n",
      "Step 30/200\n",
      "Epoch 0: Total Loss=25.6084\n",
      "Epoch 1: Total Loss=28.3324\n",
      "Epoch 2: Total Loss=21.3903\n",
      "Epoch 3: Total Loss=60.9928\n",
      "Epoch 4: Total Loss=29.9448\n",
      "Epoch 5: Total Loss=17.4353\n",
      "Epoch 6: Total Loss=28.4563\n",
      "Epoch 7: Total Loss=60.4231\n",
      "Epoch 8: Total Loss=22.3362\n",
      "Epoch 9: Total Loss=25.5876\n",
      "Updated x: [7.436761856079102, -8.002416610717773], Function Value: 119.34410095214844, Gradient: [-0.5361001491546631, -0.5799516439437866]\n",
      "\n",
      "Step 31/200\n",
      "Epoch 0: Total Loss=36.6203\n",
      "Epoch 1: Total Loss=31.5100\n",
      "Epoch 2: Total Loss=25.8362\n",
      "Epoch 3: Total Loss=20.0712\n",
      "Epoch 4: Total Loss=26.1667\n",
      "Epoch 5: Total Loss=14.3435\n",
      "Epoch 6: Total Loss=39.2090\n",
      "Epoch 7: Total Loss=27.0223\n",
      "Epoch 8: Total Loss=24.3727\n",
      "Epoch 9: Total Loss=23.6368\n",
      "Updated x: [7.404102325439453, -8.007184028625488], Function Value: 118.93572998046875, Gradient: [-0.47262775897979736, -0.5262019634246826]\n",
      "\n",
      "Step 32/200\n",
      "Epoch 0: Total Loss=42638.6035\n",
      "Epoch 1: Total Loss=42951.0518\n",
      "Epoch 2: Total Loss=42419.9600\n",
      "Epoch 3: Total Loss=42725.2432\n",
      "Epoch 4: Total Loss=42196.4785\n",
      "Epoch 5: Total Loss=42493.3682\n",
      "Epoch 6: Total Loss=41960.0420\n",
      "Epoch 7: Total Loss=42250.9717\n",
      "Epoch 8: Total Loss=41717.7646\n",
      "Epoch 9: Total Loss=42003.5205\n",
      "Updated x: [7.472604751586914, -7.926215648651123], Function Value: 118.66471862792969, Gradient: [-0.5747910737991333, -0.8323033452033997]\n",
      "\n",
      "Step 33/200\n",
      "Epoch 0: Total Loss=41852.6797\n",
      "Epoch 1: Total Loss=41257.3018\n",
      "Epoch 2: Total Loss=40760.8662\n",
      "Epoch 3: Total Loss=40605.4580\n",
      "Epoch 4: Total Loss=41356.9609\n",
      "Epoch 5: Total Loss=40767.7832\n",
      "Epoch 6: Total Loss=40273.5742\n",
      "Epoch 7: Total Loss=40121.0137\n",
      "Epoch 8: Total Loss=40863.0557\n",
      "Epoch 9: Total Loss=40277.1494\n",
      "Updated x: [7.403808116912842, -7.7410054206848145], Function Value: 114.73954010009766, Gradient: [-0.4745006263256073, -0.9645259976387024]\n",
      "\n",
      "Step 34/200\n",
      "Epoch 0: Total Loss=74.0863\n",
      "Epoch 1: Total Loss=61.3630\n",
      "Epoch 2: Total Loss=62.0582\n",
      "Epoch 3: Total Loss=57.0673\n",
      "Epoch 4: Total Loss=58.9541\n",
      "Epoch 5: Total Loss=58.6350\n",
      "Epoch 6: Total Loss=57.5970\n",
      "Epoch 7: Total Loss=55.3633\n",
      "Epoch 8: Total Loss=55.3178\n",
      "Epoch 9: Total Loss=60.9073\n",
      "Updated x: [7.329657077789307, -7.705867767333984], Function Value: 113.1042709350586, Gradient: [-0.6163188219070435, -0.8843421339988708]\n",
      "\n",
      "Step 35/200\n",
      "Epoch 0: Total Loss=42.6743\n",
      "Epoch 1: Total Loss=45.8692\n",
      "Epoch 2: Total Loss=38.6043\n",
      "Epoch 3: Total Loss=48.5293\n",
      "Epoch 4: Total Loss=46.4236\n",
      "Epoch 5: Total Loss=46.1403\n",
      "Epoch 6: Total Loss=37.9802\n",
      "Epoch 7: Total Loss=43.1297\n",
      "Epoch 8: Total Loss=41.3609\n",
      "Epoch 9: Total Loss=43.1236\n",
      "Updated x: [7.250766754150391, -7.61831521987915], Function Value: 110.61235046386719, Gradient: [-0.5277113318443298, -0.6184903979301453]\n",
      "\n",
      "Step 36/200\n",
      "Epoch 0: Total Loss=26.1580\n",
      "Epoch 1: Total Loss=34.2162\n",
      "Epoch 2: Total Loss=37.7895\n",
      "Epoch 3: Total Loss=38.2279\n",
      "Epoch 4: Total Loss=30.0900\n",
      "Epoch 5: Total Loss=42.8979\n",
      "Epoch 6: Total Loss=25.5159\n",
      "Epoch 7: Total Loss=30.7847\n",
      "Epoch 8: Total Loss=33.3809\n",
      "Epoch 9: Total Loss=38.4093\n",
      "Updated x: [7.3466291427612305, -7.534339904785156], Function Value: 110.73924255371094, Gradient: [-0.39894795417785645, -0.42941156029701233]\n",
      "\n",
      "Step 37/200\n",
      "Epoch 0: Total Loss=31.1466\n",
      "Epoch 1: Total Loss=20.9650\n",
      "Epoch 2: Total Loss=32.1786\n",
      "Epoch 3: Total Loss=36.1098\n",
      "Epoch 4: Total Loss=31.3842\n",
      "Epoch 5: Total Loss=22.8411\n",
      "Epoch 6: Total Loss=33.6753\n",
      "Epoch 7: Total Loss=36.3977\n",
      "Epoch 8: Total Loss=30.6997\n",
      "Epoch 9: Total Loss=21.3262\n",
      "Updated x: [7.205931186676025, -7.365350723266602], Function Value: 106.17383575439453, Gradient: [-0.4222497344017029, -0.4574882388114929]\n",
      "\n",
      "Step 38/200\n",
      "Epoch 0: Total Loss=56.4197\n",
      "Epoch 1: Total Loss=49.7465\n",
      "Epoch 2: Total Loss=38.3914\n",
      "Epoch 3: Total Loss=25.1436\n",
      "Epoch 4: Total Loss=27.5442\n",
      "Epoch 5: Total Loss=54.1198\n",
      "Epoch 6: Total Loss=54.9301\n",
      "Epoch 7: Total Loss=28.1223\n",
      "Epoch 8: Total Loss=24.1701\n",
      "Epoch 9: Total Loss=29.4372\n",
      "Updated x: [7.079215049743652, -7.1900410652160645], Function Value: 101.81197357177734, Gradient: [-0.5275458693504333, -0.5727471113204956]\n",
      "\n",
      "Step 39/200\n",
      "Epoch 0: Total Loss=47.2036\n",
      "Epoch 1: Total Loss=49.9017\n",
      "Epoch 2: Total Loss=25.2910\n",
      "Epoch 3: Total Loss=30.7344\n",
      "Epoch 4: Total Loss=63.6734\n",
      "Epoch 5: Total Loss=38.7876\n",
      "Epoch 6: Total Loss=49.0832\n",
      "Epoch 7: Total Loss=36.9514\n",
      "Epoch 8: Total Loss=22.3109\n",
      "Epoch 9: Total Loss=55.3940\n",
      "Updated x: [7.021535396575928, -7.022036075592041], Function Value: 98.61094665527344, Gradient: [-0.5380780100822449, -0.5842034220695496]\n",
      "\n",
      "Step 40/200\n",
      "Epoch 0: Total Loss=33.7572\n",
      "Epoch 1: Total Loss=28.4422\n",
      "Epoch 2: Total Loss=36.0942\n",
      "Epoch 3: Total Loss=29.7353\n",
      "Epoch 4: Total Loss=31.4518\n",
      "Epoch 5: Total Loss=38.4282\n",
      "Epoch 6: Total Loss=31.8467\n",
      "Epoch 7: Total Loss=26.3284\n",
      "Epoch 8: Total Loss=38.3092\n",
      "Epoch 9: Total Loss=30.5331\n",
      "Updated x: [6.926610946655273, -7.04953670501709], Function Value: 97.67390441894531, Gradient: [-0.7138170003890991, -0.7859868407249451]\n",
      "\n",
      "Step 41/200\n",
      "Epoch 0: Total Loss=25.1390\n",
      "Epoch 1: Total Loss=22.9348\n",
      "Epoch 2: Total Loss=29.0872\n",
      "Epoch 3: Total Loss=26.5495\n",
      "Epoch 4: Total Loss=29.7639\n",
      "Epoch 5: Total Loss=40.4694\n",
      "Epoch 6: Total Loss=25.7732\n",
      "Epoch 7: Total Loss=27.3502\n",
      "Epoch 8: Total Loss=21.3138\n",
      "Epoch 9: Total Loss=33.7795\n",
      "Updated x: [6.77931547164917, -6.915764331817627], Function Value: 93.78691101074219, Gradient: [-0.6993761658668518, -0.749414324760437]\n",
      "\n",
      "Step 42/200\n",
      "Epoch 0: Total Loss=25834.8779\n",
      "Epoch 1: Total Loss=25826.9795\n",
      "Epoch 2: Total Loss=25648.1416\n",
      "Epoch 3: Total Loss=25642.8145\n",
      "Epoch 4: Total Loss=25461.8496\n",
      "Epoch 5: Total Loss=25457.6123\n",
      "Epoch 6: Total Loss=25271.6855\n",
      "Epoch 7: Total Loss=25265.0322\n",
      "Epoch 8: Total Loss=25078.2139\n",
      "Epoch 9: Total Loss=25068.1621\n",
      "Updated x: [6.578081130981445, -6.869356155395508], Function Value: 90.4592056274414, Gradient: [-0.8069813847541809, -1.1231331825256348]\n",
      "\n",
      "Step 43/200\n",
      "Epoch 0: Total Loss=23882.1133\n",
      "Epoch 1: Total Loss=23671.9595\n",
      "Epoch 2: Total Loss=23538.7104\n",
      "Epoch 3: Total Loss=23989.0850\n",
      "Epoch 4: Total Loss=23517.8208\n",
      "Epoch 5: Total Loss=23311.2178\n",
      "Epoch 6: Total Loss=23185.9937\n",
      "Epoch 7: Total Loss=23628.9067\n",
      "Epoch 8: Total Loss=23173.8989\n",
      "Epoch 9: Total Loss=22969.7881\n",
      "Updated x: [6.519623279571533, -6.7434539794921875], Function Value: 87.97966003417969, Gradient: [-0.5490741729736328, -1.1209321022033691]\n",
      "\n",
      "Step 44/200\n",
      "Epoch 0: Total Loss=66.5797\n",
      "Epoch 1: Total Loss=44.3384\n",
      "Epoch 2: Total Loss=61.1265\n",
      "Epoch 3: Total Loss=39.5327\n",
      "Epoch 4: Total Loss=60.3506\n",
      "Epoch 5: Total Loss=35.9289\n",
      "Epoch 6: Total Loss=55.4745\n",
      "Epoch 7: Total Loss=33.0217\n",
      "Epoch 8: Total Loss=52.3082\n",
      "Epoch 9: Total Loss=28.9582\n",
      "Updated x: [6.421849250793457, -6.798641681671143], Function Value: 87.461669921875, Gradient: [-0.7926913499832153, -1.1135622262954712]\n",
      "\n",
      "Step 45/200\n",
      "Epoch 0: Total Loss=36.9966\n",
      "Epoch 1: Total Loss=34.2212\n",
      "Epoch 2: Total Loss=26.5861\n",
      "Epoch 3: Total Loss=39.0476\n",
      "Epoch 4: Total Loss=20.6722\n",
      "Epoch 5: Total Loss=28.6870\n",
      "Epoch 6: Total Loss=35.8646\n",
      "Epoch 7: Total Loss=14.9402\n",
      "Epoch 8: Total Loss=33.3697\n",
      "Epoch 9: Total Loss=30.5989\n",
      "Updated x: [6.250241756439209, -6.803062915802002], Function Value: 85.34718322753906, Gradient: [-0.8171912431716919, -0.9136368036270142]\n",
      "\n",
      "Step 46/200\n",
      "Epoch 0: Total Loss=46.3890\n",
      "Epoch 1: Total Loss=27.1656\n",
      "Epoch 2: Total Loss=19.4660\n",
      "Epoch 3: Total Loss=43.3889\n",
      "Epoch 4: Total Loss=17.7559\n",
      "Epoch 5: Total Loss=27.3371\n",
      "Epoch 6: Total Loss=37.1067\n",
      "Epoch 7: Total Loss=26.4662\n",
      "Epoch 8: Total Loss=25.5709\n",
      "Epoch 9: Total Loss=15.3474\n",
      "Updated x: [6.116247177124023, -6.761738300323486], Function Value: 83.12957763671875, Gradient: [-0.7793659567832947, -0.8567288517951965]\n",
      "\n",
      "Step 47/200\n",
      "Epoch 0: Total Loss=24.6166\n",
      "Epoch 1: Total Loss=43.8890\n",
      "Epoch 2: Total Loss=19.7044\n",
      "Epoch 3: Total Loss=22.0783\n",
      "Epoch 4: Total Loss=25.5011\n",
      "Epoch 5: Total Loss=43.2459\n",
      "Epoch 6: Total Loss=19.5637\n",
      "Epoch 7: Total Loss=21.9860\n",
      "Epoch 8: Total Loss=24.6692\n",
      "Epoch 9: Total Loss=43.3079\n",
      "Updated x: [6.032624244689941, -6.705460071563721], Function Value: 81.35575103759766, Gradient: [-0.6782161593437195, -0.7444578409194946]\n",
      "\n",
      "Step 48/200\n",
      "Epoch 0: Total Loss=20.8477\n",
      "Epoch 1: Total Loss=22.3717\n",
      "Epoch 2: Total Loss=35.1358\n",
      "Epoch 3: Total Loss=19.5779\n",
      "Epoch 4: Total Loss=20.8491\n",
      "Epoch 5: Total Loss=24.7004\n",
      "Epoch 6: Total Loss=18.9919\n",
      "Epoch 7: Total Loss=33.2437\n",
      "Epoch 8: Total Loss=19.2661\n",
      "Epoch 9: Total Loss=19.9142\n",
      "Updated x: [5.917052745819092, -6.67795991897583], Function Value: 79.60665893554688, Gradient: [-0.5937992334365845, -0.6586589217185974]\n",
      "\n",
      "Step 49/200\n",
      "Epoch 0: Total Loss=24.2915\n",
      "Epoch 1: Total Loss=33.3487\n",
      "Epoch 2: Total Loss=22.2609\n",
      "Epoch 3: Total Loss=24.5685\n",
      "Epoch 4: Total Loss=17.4486\n",
      "Epoch 5: Total Loss=22.9645\n",
      "Epoch 6: Total Loss=31.8370\n",
      "Epoch 7: Total Loss=21.8264\n",
      "Epoch 8: Total Loss=24.4582\n",
      "Epoch 9: Total Loss=17.7835\n",
      "Updated x: [5.670952796936035, -6.689689636230469], Function Value: 76.91165161132812, Gradient: [-0.5725945830345154, -0.6297266483306885]\n",
      "\n",
      "Step 50/200\n",
      "Epoch 0: Total Loss=15.8767\n",
      "Epoch 1: Total Loss=38.0777\n",
      "Epoch 2: Total Loss=18.0583\n",
      "Epoch 3: Total Loss=18.7718\n",
      "Epoch 4: Total Loss=23.3901\n",
      "Epoch 5: Total Loss=22.5646\n",
      "Epoch 6: Total Loss=15.8986\n",
      "Epoch 7: Total Loss=36.2007\n",
      "Epoch 8: Total Loss=19.9297\n",
      "Epoch 9: Total Loss=17.9710\n",
      "Updated x: [5.562826633453369, -6.6733503341674805], Function Value: 75.47864532470703, Gradient: [-0.47164714336395264, -0.5210617780685425]\n",
      "\n",
      "Step 51/200\n",
      "Epoch 0: Total Loss=18.2412\n",
      "Epoch 1: Total Loss=36.3647\n",
      "Epoch 2: Total Loss=22.9336\n",
      "Epoch 3: Total Loss=19.9987\n",
      "Epoch 4: Total Loss=21.6288\n",
      "Epoch 5: Total Loss=22.9485\n",
      "Epoch 6: Total Loss=17.3207\n",
      "Epoch 7: Total Loss=17.8225\n",
      "Epoch 8: Total Loss=36.6270\n",
      "Epoch 9: Total Loss=24.5322\n",
      "Updated x: [5.609935760498047, -6.474600791931152], Function Value: 73.39183044433594, Gradient: [-0.441280335187912, -0.503566563129425]\n",
      "\n",
      "Step 52/200\n",
      "Epoch 0: Total Loss=15678.0083\n",
      "Epoch 1: Total Loss=15817.2051\n",
      "Epoch 2: Total Loss=15551.6514\n",
      "Epoch 3: Total Loss=15690.0698\n",
      "Epoch 4: Total Loss=15422.9683\n",
      "Epoch 5: Total Loss=15560.2524\n",
      "Epoch 6: Total Loss=15292.6494\n",
      "Epoch 7: Total Loss=15427.9297\n",
      "Epoch 8: Total Loss=15159.0776\n",
      "Epoch 9: Total Loss=15292.9800\n",
      "Updated x: [5.4285149574279785, -6.502343654632568], Function Value: 71.7492446899414, Gradient: [-0.46297839283943176, -0.7475250363349915]\n",
      "\n",
      "Step 53/200\n",
      "Epoch 0: Total Loss=14751.1860\n",
      "Epoch 1: Total Loss=14964.2646\n",
      "Epoch 2: Total Loss=14716.1978\n",
      "Epoch 3: Total Loss=14538.3760\n",
      "Epoch 4: Total Loss=14486.7124\n",
      "Epoch 5: Total Loss=14696.1519\n",
      "Epoch 6: Total Loss=14450.1191\n",
      "Epoch 7: Total Loss=14276.1201\n",
      "Epoch 8: Total Loss=14223.3818\n",
      "Epoch 9: Total Loss=14430.5093\n",
      "Updated x: [5.476175785064697, -6.366521835327148], Function Value: 70.52110290527344, Gradient: [-0.3884652554988861, -0.9483504295349121]\n",
      "\n",
      "Step 54/200\n",
      "Epoch 0: Total Loss=39.1095\n",
      "Epoch 1: Total Loss=35.8028\n",
      "Epoch 2: Total Loss=35.0870\n",
      "Epoch 3: Total Loss=29.9434\n",
      "Epoch 4: Total Loss=30.5877\n",
      "Epoch 5: Total Loss=27.3632\n",
      "Epoch 6: Total Loss=28.3274\n",
      "Epoch 7: Total Loss=24.8934\n",
      "Epoch 8: Total Loss=24.7499\n",
      "Epoch 9: Total Loss=21.3160\n",
      "Updated x: [5.330136299133301, -6.396366119384766], Function Value: 69.3238525390625, Gradient: [-0.4800771474838257, -0.7755869030952454]\n",
      "\n",
      "Step 55/200\n",
      "Epoch 0: Total Loss=21.6164\n",
      "Epoch 1: Total Loss=19.2764\n",
      "Epoch 2: Total Loss=18.8587\n",
      "Epoch 3: Total Loss=17.6818\n",
      "Epoch 4: Total Loss=15.7936\n",
      "Epoch 5: Total Loss=18.7723\n",
      "Epoch 6: Total Loss=14.4343\n",
      "Epoch 7: Total Loss=15.7685\n",
      "Epoch 8: Total Loss=17.1581\n",
      "Epoch 9: Total Loss=15.6440\n",
      "Updated x: [5.340862274169922, -6.332394123077393], Function Value: 68.6240234375, Gradient: [-0.47545939683914185, -0.5652347207069397]\n",
      "\n",
      "Step 56/200\n",
      "Epoch 0: Total Loss=13.4294\n",
      "Epoch 1: Total Loss=12.9338\n",
      "Epoch 2: Total Loss=18.0933\n",
      "Epoch 3: Total Loss=12.4568\n",
      "Epoch 4: Total Loss=13.6068\n",
      "Epoch 5: Total Loss=17.9382\n",
      "Epoch 6: Total Loss=12.9932\n",
      "Epoch 7: Total Loss=12.3330\n",
      "Epoch 8: Total Loss=14.8180\n",
      "Epoch 9: Total Loss=15.1914\n",
      "Updated x: [5.3080949783325195, -6.255155563354492], Function Value: 67.30284118652344, Gradient: [-0.4565654993057251, -0.5205696821212769]\n",
      "\n",
      "Step 57/200\n",
      "Epoch 0: Total Loss=12.0779\n",
      "Epoch 1: Total Loss=15.2713\n",
      "Epoch 2: Total Loss=12.8592\n",
      "Epoch 3: Total Loss=11.2626\n",
      "Epoch 4: Total Loss=12.3463\n",
      "Epoch 5: Total Loss=14.0515\n",
      "Epoch 6: Total Loss=13.6075\n",
      "Epoch 7: Total Loss=12.0715\n",
      "Epoch 8: Total Loss=12.3496\n",
      "Epoch 9: Total Loss=14.8844\n",
      "Updated x: [5.324372291564941, -6.21035623550415], Function Value: 66.91746520996094, Gradient: [-0.46491146087646484, -0.5160326361656189]\n",
      "\n",
      "Step 58/200\n",
      "Epoch 0: Total Loss=12.8645\n",
      "Epoch 1: Total Loss=11.3570\n",
      "Epoch 2: Total Loss=18.5971\n",
      "Epoch 3: Total Loss=12.5063\n",
      "Epoch 4: Total Loss=12.1944\n",
      "Epoch 5: Total Loss=11.6619\n",
      "Epoch 6: Total Loss=17.7852\n",
      "Epoch 7: Total Loss=11.9520\n",
      "Epoch 8: Total Loss=11.7710\n",
      "Epoch 9: Total Loss=12.7400\n",
      "Updated x: [5.135900020599365, -6.104759693145752], Function Value: 63.64555740356445, Gradient: [-0.42796581983566284, -0.47791334986686707]\n",
      "\n",
      "Step 59/200\n",
      "Epoch 0: Total Loss=23.3255\n",
      "Epoch 1: Total Loss=11.6352\n",
      "Epoch 2: Total Loss=14.8233\n",
      "Epoch 3: Total Loss=18.0032\n",
      "Epoch 4: Total Loss=13.0263\n",
      "Epoch 5: Total Loss=23.5718\n",
      "Epoch 6: Total Loss=11.2297\n",
      "Epoch 7: Total Loss=12.2076\n",
      "Epoch 8: Total Loss=21.7742\n",
      "Epoch 9: Total Loss=12.4283\n",
      "Updated x: [5.145463943481445, -5.904791355133057], Function Value: 61.34236145019531, Gradient: [-0.4630250930786133, -0.5119583606719971]\n",
      "\n",
      "Step 60/200\n",
      "Epoch 0: Total Loss=13.1763\n",
      "Epoch 1: Total Loss=19.9442\n",
      "Epoch 2: Total Loss=13.8676\n",
      "Epoch 3: Total Loss=15.8769\n",
      "Epoch 4: Total Loss=17.7934\n",
      "Epoch 5: Total Loss=22.5184\n",
      "Epoch 6: Total Loss=13.6435\n",
      "Epoch 7: Total Loss=19.4664\n",
      "Epoch 8: Total Loss=12.6845\n",
      "Epoch 9: Total Loss=15.8380\n",
      "Updated x: [5.122681140899658, -5.74653959274292], Function Value: 59.26457977294922, Gradient: [-0.47349339723587036, -0.5385465025901794]\n",
      "\n",
      "Step 61/200\n",
      "Epoch 0: Total Loss=13.2194\n",
      "Epoch 1: Total Loss=15.7253\n",
      "Epoch 2: Total Loss=12.8259\n",
      "Epoch 3: Total Loss=16.3119\n",
      "Epoch 4: Total Loss=13.9870\n",
      "Epoch 5: Total Loss=13.2618\n",
      "Epoch 6: Total Loss=13.1515\n",
      "Epoch 7: Total Loss=17.2309\n",
      "Epoch 8: Total Loss=10.9591\n",
      "Epoch 9: Total Loss=14.6440\n",
      "Updated x: [5.231808662414551, -5.695678234100342], Function Value: 59.81257247924805, Gradient: [-0.5063852667808533, -0.5843724012374878]\n",
      "\n",
      "Step 62/200\n",
      "Epoch 0: Total Loss=11115.3757\n",
      "Epoch 1: Total Loss=10950.6951\n",
      "Epoch 2: Total Loss=11019.0178\n",
      "Epoch 3: Total Loss=10854.3167\n",
      "Epoch 4: Total Loss=10921.2446\n",
      "Epoch 5: Total Loss=10755.9146\n",
      "Epoch 6: Total Loss=10821.2085\n",
      "Epoch 7: Total Loss=10656.2156\n",
      "Epoch 8: Total Loss=10719.5205\n",
      "Epoch 9: Total Loss=10554.1177\n",
      "Updated x: [5.155431747436523, -5.752516746520996], Function Value: 59.669925689697266, Gradient: [-0.5551820993423462, -0.8666306138038635]\n",
      "\n",
      "Step 63/200\n",
      "Epoch 0: Total Loss=10150.4370\n",
      "Epoch 1: Total Loss=10142.6738\n",
      "Epoch 2: Total Loss=10303.9644\n",
      "Epoch 3: Total Loss=10182.4739\n",
      "Epoch 4: Total Loss=9956.5010\n",
      "Epoch 5: Total Loss=9950.0283\n",
      "Epoch 6: Total Loss=10108.4253\n",
      "Epoch 7: Total Loss=9989.9807\n",
      "Epoch 8: Total Loss=9768.4089\n",
      "Epoch 9: Total Loss=9761.1902\n",
      "Updated x: [4.889639377593994, -5.665767192840576], Function Value: 56.009490966796875, Gradient: [-0.41151031851768494, -0.995574414730072]\n",
      "\n",
      "Step 64/200\n",
      "Epoch 0: Total Loss=72.3055\n",
      "Epoch 1: Total Loss=78.1972\n",
      "Epoch 2: Total Loss=67.5766\n",
      "Epoch 3: Total Loss=74.2511\n",
      "Epoch 4: Total Loss=63.7904\n",
      "Epoch 5: Total Loss=70.6464\n",
      "Epoch 6: Total Loss=60.0797\n",
      "Epoch 7: Total Loss=67.8236\n",
      "Epoch 8: Total Loss=58.8946\n",
      "Epoch 9: Total Loss=65.5399\n",
      "Updated x: [4.673409461975098, -5.648332118988037], Function Value: 53.74441146850586, Gradient: [-0.524081826210022, -0.8468340635299683]\n",
      "\n",
      "Step 65/200\n",
      "Epoch 0: Total Loss=43.8348\n",
      "Epoch 1: Total Loss=37.3784\n",
      "Epoch 2: Total Loss=39.0629\n",
      "Epoch 3: Total Loss=35.5991\n",
      "Epoch 4: Total Loss=36.8371\n",
      "Epoch 5: Total Loss=38.1255\n",
      "Epoch 6: Total Loss=29.3697\n",
      "Epoch 7: Total Loss=34.2085\n",
      "Epoch 8: Total Loss=38.4754\n",
      "Epoch 9: Total Loss=34.2801\n",
      "Updated x: [4.539187908172607, -5.715660095214844], Function Value: 53.27299499511719, Gradient: [-0.53440922498703, -0.6321048140525818]\n",
      "\n",
      "Step 66/200\n",
      "Epoch 0: Total Loss=19.4188\n",
      "Epoch 1: Total Loss=23.9187\n",
      "Epoch 2: Total Loss=29.7842\n",
      "Epoch 3: Total Loss=25.6490\n",
      "Epoch 4: Total Loss=20.1973\n",
      "Epoch 5: Total Loss=29.1313\n",
      "Epoch 6: Total Loss=29.9518\n",
      "Epoch 7: Total Loss=16.0305\n",
      "Epoch 8: Total Loss=28.2801\n",
      "Epoch 9: Total Loss=28.9308\n",
      "Updated x: [4.481935977935791, -5.646062850952148], Function Value: 51.96577453613281, Gradient: [-0.43713265657424927, -0.4960009455680847]\n",
      "\n",
      "Step 67/200\n",
      "Epoch 0: Total Loss=27.0672\n",
      "Epoch 1: Total Loss=23.5454\n",
      "Epoch 2: Total Loss=22.3095\n",
      "Epoch 3: Total Loss=24.7661\n",
      "Epoch 4: Total Loss=27.1539\n",
      "Epoch 5: Total Loss=23.8341\n",
      "Epoch 6: Total Loss=22.8404\n",
      "Epoch 7: Total Loss=25.4868\n",
      "Epoch 8: Total Loss=26.9710\n",
      "Epoch 9: Total Loss=23.5983\n",
      "Updated x: [4.480978965759277, -5.49987268447876], Function Value: 50.32777404785156, Gradient: [-0.3867611289024353, -0.44290879368782043]\n",
      "\n",
      "Step 68/200\n",
      "Epoch 0: Total Loss=17.8846\n",
      "Epoch 1: Total Loss=23.4275\n",
      "Epoch 2: Total Loss=23.9371\n",
      "Epoch 3: Total Loss=21.7949\n",
      "Epoch 4: Total Loss=23.8873\n",
      "Epoch 5: Total Loss=20.4130\n",
      "Epoch 6: Total Loss=21.9740\n",
      "Epoch 7: Total Loss=23.5266\n",
      "Epoch 8: Total Loss=24.4343\n",
      "Epoch 9: Total Loss=24.3069\n",
      "Updated x: [4.400007247924805, -5.4006667137146], Function Value: 48.52726364135742, Gradient: [-0.35068896412849426, -0.418416827917099]\n",
      "\n",
      "Step 69/200\n",
      "Epoch 0: Total Loss=21.4159\n",
      "Epoch 1: Total Loss=18.0875\n",
      "Epoch 2: Total Loss=26.6563\n",
      "Epoch 3: Total Loss=33.3425\n",
      "Epoch 4: Total Loss=16.7325\n",
      "Epoch 5: Total Loss=18.6301\n",
      "Epoch 6: Total Loss=19.4403\n",
      "Epoch 7: Total Loss=22.5921\n",
      "Epoch 8: Total Loss=32.2032\n",
      "Epoch 9: Total Loss=21.3396\n",
      "Updated x: [4.38725471496582, -5.232561111450195], Function Value: 46.62770080566406, Gradient: [-0.29076290130615234, -0.37287628650665283]\n",
      "\n",
      "Step 70/200\n",
      "Epoch 0: Total Loss=20.8631\n",
      "Epoch 1: Total Loss=18.4052\n",
      "Epoch 2: Total Loss=20.2172\n",
      "Epoch 3: Total Loss=21.7701\n",
      "Epoch 4: Total Loss=20.2211\n",
      "Epoch 5: Total Loss=23.1627\n",
      "Epoch 6: Total Loss=20.8435\n",
      "Epoch 7: Total Loss=18.2333\n",
      "Epoch 8: Total Loss=20.6964\n",
      "Epoch 9: Total Loss=22.0336\n",
      "Updated x: [4.4117751121521, -5.094273090362549], Function Value: 45.41537857055664, Gradient: [-0.28785544633865356, -0.3778958022594452]\n",
      "\n",
      "Step 71/200\n",
      "Epoch 0: Total Loss=17.7859\n",
      "Epoch 1: Total Loss=19.6613\n",
      "Epoch 2: Total Loss=18.6389\n",
      "Epoch 3: Total Loss=24.1361\n",
      "Epoch 4: Total Loss=13.8769\n",
      "Epoch 5: Total Loss=24.2176\n",
      "Epoch 6: Total Loss=20.9098\n",
      "Epoch 7: Total Loss=17.7432\n",
      "Epoch 8: Total Loss=19.8574\n",
      "Epoch 9: Total Loss=20.5361\n",
      "Updated x: [4.293177127838135, -5.0870819091796875], Function Value: 44.30977249145508, Gradient: [-0.24626247584819794, -0.33899417519569397]\n",
      "\n",
      "Step 72/200\n",
      "Epoch 0: Total Loss=6167.8569\n",
      "Epoch 1: Total Loss=6018.0630\n",
      "Epoch 2: Total Loss=6112.1373\n",
      "Epoch 3: Total Loss=5962.5756\n",
      "Epoch 4: Total Loss=6055.3634\n",
      "Epoch 5: Total Loss=5905.9133\n",
      "Epoch 6: Total Loss=5996.6169\n",
      "Epoch 7: Total Loss=5848.2141\n",
      "Epoch 8: Total Loss=5936.8638\n",
      "Epoch 9: Total Loss=5788.7465\n",
      "Updated x: [4.4253058433532715, -4.939702033996582], Function Value: 43.983985900878906, Gradient: [-0.30943745374679565, -0.5919315218925476]\n",
      "\n",
      "Step 73/200\n",
      "Epoch 0: Total Loss=5596.5792\n",
      "Epoch 1: Total Loss=5677.3964\n",
      "Epoch 2: Total Loss=5610.2572\n",
      "Epoch 3: Total Loss=5404.7123\n",
      "Epoch 4: Total Loss=5481.2561\n",
      "Epoch 5: Total Loss=5559.5142\n",
      "Epoch 6: Total Loss=5493.8077\n",
      "Epoch 7: Total Loss=5291.1255\n",
      "Epoch 8: Total Loss=5364.0020\n",
      "Epoch 9: Total Loss=5439.3225\n",
      "Updated x: [4.458037853240967, -4.6871819496154785], Function Value: 41.84377670288086, Gradient: [-0.3205779194831848, -0.8502507209777832]\n",
      "\n",
      "Step 74/200\n",
      "Epoch 0: Total Loss=42.5923\n",
      "Epoch 1: Total Loss=32.0232\n",
      "Epoch 2: Total Loss=39.1176\n",
      "Epoch 3: Total Loss=28.3907\n",
      "Epoch 4: Total Loss=35.7142\n",
      "Epoch 5: Total Loss=25.7801\n",
      "Epoch 6: Total Loss=33.3306\n",
      "Epoch 7: Total Loss=23.5331\n",
      "Epoch 8: Total Loss=31.5441\n",
      "Epoch 9: Total Loss=21.9244\n",
      "Updated x: [4.303077697753906, -4.658912658691406], Function Value: 40.221946716308594, Gradient: [-0.30865544080734253, -0.6087797284126282]\n",
      "\n",
      "Step 75/200\n",
      "Epoch 0: Total Loss=35.9804\n",
      "Epoch 1: Total Loss=29.6934\n",
      "Epoch 2: Total Loss=30.6355\n",
      "Epoch 3: Total Loss=25.5840\n",
      "Epoch 4: Total Loss=28.6070\n",
      "Epoch 5: Total Loss=35.5715\n",
      "Epoch 6: Total Loss=26.7733\n",
      "Epoch 7: Total Loss=21.1638\n",
      "Epoch 8: Total Loss=32.8507\n",
      "Epoch 9: Total Loss=26.7756\n",
      "Updated x: [4.18532657623291, -4.397071838378906], Function Value: 36.8511962890625, Gradient: [-0.17795376479625702, -0.3067443370819092]\n",
      "\n",
      "Step 76/200\n",
      "Epoch 0: Total Loss=29.7600\n",
      "Epoch 1: Total Loss=21.5842\n",
      "Epoch 2: Total Loss=27.7135\n",
      "Epoch 3: Total Loss=30.0242\n",
      "Epoch 4: Total Loss=19.9958\n",
      "Epoch 5: Total Loss=19.0867\n",
      "Epoch 6: Total Loss=30.3238\n",
      "Epoch 7: Total Loss=28.3253\n",
      "Epoch 8: Total Loss=20.4409\n",
      "Epoch 9: Total Loss=27.4661\n",
      "Updated x: [4.063257217407227, -4.290246486663818], Function Value: 34.91627502441406, Gradient: [-0.2511075437068939, -0.3550977110862732]\n",
      "\n",
      "Step 77/200\n",
      "Epoch 0: Total Loss=25.1403\n",
      "Epoch 1: Total Loss=19.1127\n",
      "Epoch 2: Total Loss=20.8677\n",
      "Epoch 3: Total Loss=26.5824\n",
      "Epoch 4: Total Loss=25.0936\n",
      "Epoch 5: Total Loss=19.1003\n",
      "Epoch 6: Total Loss=21.0083\n",
      "Epoch 7: Total Loss=26.4867\n",
      "Epoch 8: Total Loss=25.1444\n",
      "Epoch 9: Total Loss=19.0383\n",
      "Updated x: [3.8258910179138184, -4.34251594543457], Function Value: 33.49488830566406, Gradient: [-0.34401458501815796, -0.4618588387966156]\n",
      "\n",
      "Step 78/200\n",
      "Epoch 0: Total Loss=26.4311\n",
      "Epoch 1: Total Loss=25.4779\n",
      "Epoch 2: Total Loss=19.7011\n",
      "Epoch 3: Total Loss=18.0280\n",
      "Epoch 4: Total Loss=19.2303\n",
      "Epoch 5: Total Loss=26.7663\n",
      "Epoch 6: Total Loss=24.9570\n",
      "Epoch 7: Total Loss=19.2833\n",
      "Epoch 8: Total Loss=18.3315\n",
      "Epoch 9: Total Loss=22.8338\n",
      "Updated x: [3.807262659072876, -4.193348407745361], Function Value: 32.07942199707031, Gradient: [-0.28134384751319885, -0.38852301239967346]\n",
      "\n",
      "Step 79/200\n",
      "Epoch 0: Total Loss=25.3629\n",
      "Epoch 1: Total Loss=17.6946\n",
      "Epoch 2: Total Loss=19.9881\n",
      "Epoch 3: Total Loss=16.0961\n",
      "Epoch 4: Total Loss=17.2024\n",
      "Epoch 5: Total Loss=27.1940\n",
      "Epoch 6: Total Loss=16.5251\n",
      "Epoch 7: Total Loss=16.7995\n",
      "Epoch 8: Total Loss=20.2414\n",
      "Epoch 9: Total Loss=16.4135\n",
      "Updated x: [3.647141456604004, -4.127715587615967], Function Value: 30.339675903320312, Gradient: [-0.32164549827575684, -0.425881952047348]\n",
      "\n",
      "Step 80/200\n",
      "Epoch 0: Total Loss=27.1520\n",
      "Epoch 1: Total Loss=15.8211\n",
      "Epoch 2: Total Loss=17.5463\n",
      "Epoch 3: Total Loss=15.6031\n",
      "Epoch 4: Total Loss=15.6390\n",
      "Epoch 5: Total Loss=21.2615\n",
      "Epoch 6: Total Loss=27.4518\n",
      "Epoch 7: Total Loss=16.0658\n",
      "Epoch 8: Total Loss=17.4440\n",
      "Epoch 9: Total Loss=15.3300\n",
      "Updated x: [3.5775458812713623, -4.0185770988464355], Function Value: 28.947795867919922, Gradient: [-0.3711584508419037, -0.47711122035980225]\n",
      "\n",
      "Step 81/200\n",
      "Epoch 0: Total Loss=17.6723\n",
      "Epoch 1: Total Loss=16.6896\n",
      "Epoch 2: Total Loss=15.3182\n",
      "Epoch 3: Total Loss=17.1446\n",
      "Epoch 4: Total Loss=20.0330\n",
      "Epoch 5: Total Loss=18.1228\n",
      "Epoch 6: Total Loss=25.4582\n",
      "Epoch 7: Total Loss=18.3473\n",
      "Epoch 8: Total Loss=15.0607\n",
      "Epoch 9: Total Loss=16.5603\n",
      "Updated x: [3.539232015609741, -3.8776512145996094], Function Value: 27.562341690063477, Gradient: [-0.3862697184085846, -0.49787312746047974]\n",
      "\n",
      "Step 82/200\n",
      "Epoch 0: Total Loss=2418.7903\n",
      "Epoch 1: Total Loss=2455.4070\n",
      "Epoch 2: Total Loss=2388.0291\n",
      "Epoch 3: Total Loss=2424.6363\n",
      "Epoch 4: Total Loss=2356.7702\n",
      "Epoch 5: Total Loss=2393.0724\n",
      "Epoch 6: Total Loss=2324.8150\n",
      "Epoch 7: Total Loss=2360.9702\n",
      "Epoch 8: Total Loss=2292.5206\n",
      "Epoch 9: Total Loss=2328.3812\n",
      "Updated x: [3.446042060852051, -3.9009103775024414], Function Value: 27.092308044433594, Gradient: [-0.5150824189186096, -0.9094938635826111]\n",
      "\n",
      "Step 83/200\n",
      "Epoch 0: Total Loss=2155.2543\n",
      "Epoch 1: Total Loss=2150.0588\n",
      "Epoch 2: Total Loss=2118.7083\n",
      "Epoch 3: Total Loss=2139.2112\n",
      "Epoch 4: Total Loss=2095.8212\n",
      "Epoch 5: Total Loss=2090.5457\n",
      "Epoch 6: Total Loss=2060.4575\n",
      "Epoch 7: Total Loss=2080.6810\n",
      "Epoch 8: Total Loss=2038.2212\n",
      "Epoch 9: Total Loss=2033.3794\n",
      "Updated x: [3.30484676361084, -3.7668371200561523], Function Value: 25.111074447631836, Gradient: [-0.45421260595321655, -1.0932575464248657]\n",
      "\n",
      "Step 84/200\n",
      "Epoch 0: Total Loss=35.2936\n",
      "Epoch 1: Total Loss=36.0940\n",
      "Epoch 2: Total Loss=31.2430\n",
      "Epoch 3: Total Loss=32.0923\n",
      "Epoch 4: Total Loss=27.3308\n",
      "Epoch 5: Total Loss=28.6104\n",
      "Epoch 6: Total Loss=24.3027\n",
      "Epoch 7: Total Loss=25.7692\n",
      "Epoch 8: Total Loss=21.6641\n",
      "Epoch 9: Total Loss=23.5268\n",
      "Updated x: [3.3696765899658203, -3.6571764945983887], Function Value: 24.729660034179688, Gradient: [-0.5132810473442078, -0.9220180511474609]\n",
      "\n",
      "Step 85/200\n",
      "Epoch 0: Total Loss=18.0519\n",
      "Epoch 1: Total Loss=19.1713\n",
      "Epoch 2: Total Loss=15.9570\n",
      "Epoch 3: Total Loss=13.8575\n",
      "Epoch 4: Total Loss=16.6524\n",
      "Epoch 5: Total Loss=14.2360\n",
      "Epoch 6: Total Loss=15.0042\n",
      "Epoch 7: Total Loss=12.3534\n",
      "Epoch 8: Total Loss=13.2634\n",
      "Epoch 9: Total Loss=15.3212\n",
      "Updated x: [3.322377920150757, -3.5645182132720947], Function Value: 23.74398422241211, Gradient: [-0.39016062021255493, -0.5292754173278809]\n",
      "\n",
      "Step 86/200\n",
      "Epoch 0: Total Loss=13.2897\n",
      "Epoch 1: Total Loss=13.0797\n",
      "Epoch 2: Total Loss=13.8768\n",
      "Epoch 3: Total Loss=13.1580\n",
      "Epoch 4: Total Loss=13.1437\n",
      "Epoch 5: Total Loss=12.7317\n",
      "Epoch 6: Total Loss=13.4600\n",
      "Epoch 7: Total Loss=13.7474\n",
      "Epoch 8: Total Loss=11.5191\n",
      "Epoch 9: Total Loss=13.0798\n",
      "Updated x: [3.2425711154937744, -3.4536449909210205], Function Value: 22.441930770874023, Gradient: [-0.3145081102848053, -0.3888261616230011]\n",
      "\n",
      "Step 87/200\n",
      "Epoch 0: Total Loss=13.1926\n",
      "Epoch 1: Total Loss=10.6527\n",
      "Epoch 2: Total Loss=14.9632\n",
      "Epoch 3: Total Loss=11.2628\n",
      "Epoch 4: Total Loss=13.3236\n",
      "Epoch 5: Total Loss=10.5993\n",
      "Epoch 6: Total Loss=15.0105\n",
      "Epoch 7: Total Loss=11.1262\n",
      "Epoch 8: Total Loss=13.2927\n",
      "Epoch 9: Total Loss=10.7672\n",
      "Updated x: [3.3428568840026855, -3.228423833847046], Function Value: 21.597412109375, Gradient: [-0.16346068680286407, -0.17544925212860107]\n",
      "\n",
      "Step 88/200\n",
      "Epoch 0: Total Loss=10.6205\n",
      "Epoch 1: Total Loss=10.2954\n",
      "Epoch 2: Total Loss=13.0817\n",
      "Epoch 3: Total Loss=11.5788\n",
      "Epoch 4: Total Loss=9.7304\n",
      "Epoch 5: Total Loss=10.9315\n",
      "Epoch 6: Total Loss=10.5092\n",
      "Epoch 7: Total Loss=13.8019\n",
      "Epoch 8: Total Loss=10.6487\n",
      "Epoch 9: Total Loss=9.7298\n",
      "Updated x: [3.3447976112365723, -3.2689573764801025], Function Value: 21.87375259399414, Gradient: [-0.13676805794239044, -0.1560812145471573]\n",
      "\n",
      "Step 89/200\n",
      "Epoch 0: Total Loss=15.4073\n",
      "Epoch 1: Total Loss=9.6732\n",
      "Epoch 2: Total Loss=10.2464\n",
      "Epoch 3: Total Loss=9.8868\n",
      "Epoch 4: Total Loss=10.6654\n",
      "Epoch 5: Total Loss=12.5320\n",
      "Epoch 6: Total Loss=12.8224\n",
      "Epoch 7: Total Loss=9.3498\n",
      "Epoch 8: Total Loss=10.5957\n",
      "Epoch 9: Total Loss=9.6431\n",
      "Updated x: [3.229008436203003, -3.094088315963745], Function Value: 19.9998779296875, Gradient: [-0.07942137867212296, -0.0976312905550003]\n",
      "\n",
      "Step 90/200\n",
      "Epoch 0: Total Loss=14.8648\n",
      "Epoch 1: Total Loss=10.7845\n",
      "Epoch 2: Total Loss=10.3903\n",
      "Epoch 3: Total Loss=9.9610\n",
      "Epoch 4: Total Loss=14.6519\n",
      "Epoch 5: Total Loss=12.8789\n",
      "Epoch 6: Total Loss=14.9469\n",
      "Epoch 7: Total Loss=10.7614\n",
      "Epoch 8: Total Loss=10.4054\n",
      "Epoch 9: Total Loss=10.0245\n",
      "Updated x: [3.009911298751831, -3.0095670223236084], Function Value: 18.1170597076416, Gradient: [-0.1159299984574318, -0.15696533024311066]\n",
      "\n",
      "Step 91/200\n",
      "Epoch 0: Total Loss=11.5272\n",
      "Epoch 1: Total Loss=11.5302\n",
      "Epoch 2: Total Loss=12.6847\n",
      "Epoch 3: Total Loss=10.6560\n",
      "Epoch 4: Total Loss=11.7585\n",
      "Epoch 5: Total Loss=14.7159\n",
      "Epoch 6: Total Loss=12.4304\n",
      "Epoch 7: Total Loss=11.1964\n",
      "Epoch 8: Total Loss=10.8588\n",
      "Epoch 9: Total Loss=12.1255\n",
      "Updated x: [2.8371527194976807, -3.1082494258880615], Function Value: 17.710651397705078, Gradient: [-0.1520899087190628, -0.20901958644390106]\n",
      "\n",
      "Step 92/200\n",
      "Epoch 0: Total Loss=1029.1912\n",
      "Epoch 1: Total Loss=1037.3520\n",
      "Epoch 2: Total Loss=1015.2318\n",
      "Epoch 3: Total Loss=1023.0194\n",
      "Epoch 4: Total Loss=1000.8962\n",
      "Epoch 5: Total Loss=1008.3679\n",
      "Epoch 6: Total Loss=986.3008\n",
      "Epoch 7: Total Loss=993.4473\n",
      "Epoch 8: Total Loss=971.4702\n",
      "Epoch 9: Total Loss=978.3890\n",
      "Updated x: [2.788539409637451, -3.098449230194092], Function Value: 17.376338958740234, Gradient: [-0.26099199056625366, -0.5861645936965942]\n",
      "\n",
      "Step 93/200\n",
      "Epoch 0: Total Loss=943.9005\n",
      "Epoch 1: Total Loss=898.9044\n",
      "Epoch 2: Total Loss=922.3166\n",
      "Epoch 3: Total Loss=903.0345\n",
      "Epoch 4: Total Loss=916.0109\n",
      "Epoch 5: Total Loss=872.1902\n",
      "Epoch 6: Total Loss=894.6882\n",
      "Epoch 7: Total Loss=876.3407\n",
      "Epoch 8: Total Loss=889.5565\n",
      "Epoch 9: Total Loss=847.1174\n",
      "Updated x: [2.8821914196014404, -2.9059205055236816], Function Value: 16.751401901245117, Gradient: [-0.25314247608184814, -0.8163388967514038]\n",
      "\n",
      "Step 94/200\n",
      "Epoch 0: Total Loss=27.5947\n",
      "Epoch 1: Total Loss=24.5028\n",
      "Epoch 2: Total Loss=24.0260\n",
      "Epoch 3: Total Loss=21.1368\n",
      "Epoch 4: Total Loss=20.9353\n",
      "Epoch 5: Total Loss=18.3777\n",
      "Epoch 6: Total Loss=18.4617\n",
      "Epoch 7: Total Loss=16.1293\n",
      "Epoch 8: Total Loss=16.4856\n",
      "Epoch 9: Total Loss=14.3625\n",
      "Updated x: [2.866579532623291, -2.844768524169922], Function Value: 16.309986114501953, Gradient: [-0.1925012469291687, -0.5081813931465149]\n",
      "\n",
      "Step 95/200\n",
      "Epoch 0: Total Loss=13.2788\n",
      "Epoch 1: Total Loss=14.2647\n",
      "Epoch 2: Total Loss=12.5531\n",
      "Epoch 3: Total Loss=12.3887\n",
      "Epoch 4: Total Loss=12.2330\n",
      "Epoch 5: Total Loss=10.2923\n",
      "Epoch 6: Total Loss=11.5057\n",
      "Epoch 7: Total Loss=11.0736\n",
      "Epoch 8: Total Loss=9.7230\n",
      "Epoch 9: Total Loss=11.4693\n",
      "Updated x: [2.914006471633911, -2.717650890350342], Function Value: 15.877059936523438, Gradient: [-0.0630430206656456, -0.11323503404855728]\n",
      "\n",
      "Step 96/200\n",
      "Epoch 0: Total Loss=10.4300\n",
      "Epoch 1: Total Loss=10.0023\n",
      "Epoch 2: Total Loss=8.9897\n",
      "Epoch 3: Total Loss=9.2963\n",
      "Epoch 4: Total Loss=10.6131\n",
      "Epoch 5: Total Loss=9.5438\n",
      "Epoch 6: Total Loss=9.4033\n",
      "Epoch 7: Total Loss=10.3306\n",
      "Epoch 8: Total Loss=9.8333\n",
      "Epoch 9: Total Loss=9.2761\n",
      "Updated x: [2.832223653793335, -2.6249918937683105], Function Value: 14.912073135375977, Gradient: [-0.03789743408560753, -0.0424315482378006]\n",
      "\n",
      "Step 97/200\n",
      "Epoch 0: Total Loss=9.0818\n",
      "Epoch 1: Total Loss=9.3720\n",
      "Epoch 2: Total Loss=9.9552\n",
      "Epoch 3: Total Loss=9.6443\n",
      "Epoch 4: Total Loss=9.0718\n",
      "Epoch 5: Total Loss=9.3705\n",
      "Epoch 6: Total Loss=9.9464\n",
      "Epoch 7: Total Loss=9.6295\n",
      "Epoch 8: Total Loss=9.0689\n",
      "Epoch 9: Total Loss=9.3534\n",
      "Updated x: [2.7602381706237793, -2.615339517593384], Function Value: 14.458915710449219, Gradient: [-0.022570304572582245, -0.04002291336655617]\n",
      "\n",
      "Step 98/200\n",
      "Epoch 0: Total Loss=8.8005\n",
      "Epoch 1: Total Loss=9.4718\n",
      "Epoch 2: Total Loss=9.1271\n",
      "Epoch 3: Total Loss=10.5861\n",
      "Epoch 4: Total Loss=8.9592\n",
      "Epoch 5: Total Loss=8.9021\n",
      "Epoch 6: Total Loss=9.3950\n",
      "Epoch 7: Total Loss=8.8147\n",
      "Epoch 8: Total Loss=10.6901\n",
      "Epoch 9: Total Loss=8.8905\n",
      "Updated x: [2.6670188903808594, -2.642702579498291], Function Value: 14.096866607666016, Gradient: [-0.027744822204113007, -0.06344743072986603]\n",
      "\n",
      "Step 99/200\n",
      "Epoch 0: Total Loss=9.7030\n",
      "Epoch 1: Total Loss=9.7309\n",
      "Epoch 2: Total Loss=8.9228\n",
      "Epoch 3: Total Loss=8.5058\n",
      "Epoch 4: Total Loss=9.7719\n",
      "Epoch 5: Total Loss=9.3868\n",
      "Epoch 6: Total Loss=8.6539\n",
      "Epoch 7: Total Loss=10.0172\n",
      "Epoch 8: Total Loss=8.6751\n",
      "Epoch 9: Total Loss=8.9037\n",
      "Updated x: [2.6443238258361816, -2.5088837146759033], Function Value: 13.286945343017578, Gradient: [-0.000550768687389791, -0.03185918927192688]\n",
      "\n",
      "Step 100/200\n",
      "Epoch 0: Total Loss=9.1909\n",
      "Epoch 1: Total Loss=12.4554\n",
      "Epoch 2: Total Loss=8.7658\n",
      "Epoch 3: Total Loss=8.5726\n",
      "Epoch 4: Total Loss=9.4735\n",
      "Epoch 5: Total Loss=8.5353\n",
      "Epoch 6: Total Loss=9.1740\n",
      "Epoch 7: Total Loss=12.4496\n",
      "Epoch 8: Total Loss=8.7535\n",
      "Epoch 9: Total Loss=8.5621\n",
      "Updated x: [2.5208868980407715, -2.346315622329712], Function Value: 11.860067367553711, Gradient: [0.0054350122809410095, -0.03903830423951149]\n",
      "\n",
      "Step 101/200\n",
      "Epoch 0: Total Loss=9.9489\n",
      "Epoch 1: Total Loss=8.9161\n",
      "Epoch 2: Total Loss=13.8622\n",
      "Epoch 3: Total Loss=8.9354\n",
      "Epoch 4: Total Loss=9.7715\n",
      "Epoch 5: Total Loss=8.4530\n",
      "Epoch 6: Total Loss=9.1268\n",
      "Epoch 7: Total Loss=10.1759\n",
      "Epoch 8: Total Loss=12.2687\n",
      "Epoch 9: Total Loss=10.3937\n",
      "Updated x: [2.2966411113739014, -2.2950477600097656], Function Value: 10.541805267333984, Gradient: [-0.0013467733515426517, -0.056413423269987106]\n",
      "\n",
      "Step 102/200\n",
      "Epoch 0: Total Loss=427.1008\n",
      "Epoch 1: Total Loss=423.1784\n",
      "Epoch 2: Total Loss=419.1847\n",
      "Epoch 3: Total Loss=414.8643\n",
      "Epoch 4: Total Loss=411.7377\n",
      "Epoch 5: Total Loss=408.0700\n",
      "Epoch 6: Total Loss=403.5229\n",
      "Epoch 7: Total Loss=399.7233\n",
      "Epoch 8: Total Loss=396.5827\n",
      "Epoch 9: Total Loss=392.6802\n",
      "Updated x: [2.1992244720458984, -2.135639190673828], Function Value: 9.397542953491211, Gradient: [-0.0005368919228203595, -0.41374051570892334]\n",
      "\n",
      "Step 103/200\n",
      "Epoch 0: Total Loss=359.9798\n",
      "Epoch 1: Total Loss=356.9473\n",
      "Epoch 2: Total Loss=354.4398\n",
      "Epoch 3: Total Loss=351.4772\n",
      "Epoch 4: Total Loss=348.9304\n",
      "Epoch 5: Total Loss=345.1976\n",
      "Epoch 6: Total Loss=344.7923\n",
      "Epoch 7: Total Loss=341.0096\n",
      "Epoch 8: Total Loss=340.0957\n",
      "Epoch 9: Total Loss=338.6083\n",
      "Updated x: [2.0789597034454346, -1.973082184791565], Function Value: 8.215126991271973, Gradient: [0.051698267459869385, -0.6542413830757141]\n",
      "\n",
      "Step 104/200\n",
      "Epoch 0: Total Loss=40.7826\n",
      "Epoch 1: Total Loss=37.6503\n",
      "Epoch 2: Total Loss=34.0731\n",
      "Epoch 3: Total Loss=31.3003\n",
      "Epoch 4: Total Loss=28.8365\n",
      "Epoch 5: Total Loss=27.4145\n",
      "Epoch 6: Total Loss=24.3738\n",
      "Epoch 7: Total Loss=23.5921\n",
      "Epoch 8: Total Loss=23.1352\n",
      "Epoch 9: Total Loss=22.1821\n",
      "Updated x: [1.994065523147583, -1.8829374313354492], Function Value: 7.521750450134277, Gradient: [0.007953737862408161, -0.4088916480541229]\n",
      "\n",
      "Step 105/200\n",
      "Epoch 0: Total Loss=19.7013\n",
      "Epoch 1: Total Loss=17.2398\n",
      "Epoch 2: Total Loss=18.8104\n",
      "Epoch 3: Total Loss=15.6082\n",
      "Epoch 4: Total Loss=20.4244\n",
      "Epoch 5: Total Loss=14.4914\n",
      "Epoch 6: Total Loss=15.0961\n",
      "Epoch 7: Total Loss=14.1005\n",
      "Epoch 8: Total Loss=14.6838\n",
      "Epoch 9: Total Loss=14.3675\n",
      "Updated x: [1.842368245124817, -1.7488200664520264], Function Value: 6.452692031860352, Gradient: [-0.014112438075244427, -0.08184122294187546]\n",
      "\n",
      "Step 106/200\n",
      "Epoch 0: Total Loss=11.7226\n",
      "Epoch 1: Total Loss=16.4203\n",
      "Epoch 2: Total Loss=12.0161\n",
      "Epoch 3: Total Loss=17.2463\n",
      "Epoch 4: Total Loss=14.9363\n",
      "Epoch 5: Total Loss=11.0715\n",
      "Epoch 6: Total Loss=15.9270\n",
      "Epoch 7: Total Loss=12.2008\n",
      "Epoch 8: Total Loss=15.4656\n",
      "Epoch 9: Total Loss=15.1326\n",
      "Updated x: [1.8638662099838257, -1.6830917596817017], Function Value: 6.306795120239258, Gradient: [-0.021587606519460678, -0.08159273862838745]\n",
      "\n",
      "Step 107/200\n",
      "Epoch 0: Total Loss=15.5070\n",
      "Epoch 1: Total Loss=12.2621\n",
      "Epoch 2: Total Loss=11.3112\n",
      "Epoch 3: Total Loss=15.3028\n",
      "Epoch 4: Total Loss=11.4043\n",
      "Epoch 5: Total Loss=10.6364\n",
      "Epoch 6: Total Loss=15.1598\n",
      "Epoch 7: Total Loss=12.4132\n",
      "Epoch 8: Total Loss=12.0351\n",
      "Epoch 9: Total Loss=15.0181\n",
      "Updated x: [1.622246265411377, -1.644948124885559], Function Value: 5.3375372886657715, Gradient: [-0.014641497284173965, -0.07764281332492828]\n",
      "\n",
      "Step 108/200\n",
      "Epoch 0: Total Loss=10.4291\n",
      "Epoch 1: Total Loss=14.1341\n",
      "Epoch 2: Total Loss=15.5192\n",
      "Epoch 3: Total Loss=10.9106\n",
      "Epoch 4: Total Loss=10.3803\n",
      "Epoch 5: Total Loss=15.8957\n",
      "Epoch 6: Total Loss=13.8800\n",
      "Epoch 7: Total Loss=12.1005\n",
      "Epoch 8: Total Loss=10.9753\n",
      "Epoch 9: Total Loss=16.0885\n",
      "Updated x: [1.5420259237289429, -1.622104525566101], Function Value: 5.009067058563232, Gradient: [-0.0036355634219944477, -0.043988682329654694]\n",
      "\n",
      "Step 109/200\n",
      "Epoch 0: Total Loss=12.2389\n",
      "Epoch 1: Total Loss=10.7541\n",
      "Epoch 2: Total Loss=12.7256\n",
      "Epoch 3: Total Loss=11.0863\n",
      "Epoch 4: Total Loss=14.3571\n",
      "Epoch 5: Total Loss=11.7024\n",
      "Epoch 6: Total Loss=11.4538\n",
      "Epoch 7: Total Loss=10.8553\n",
      "Epoch 8: Total Loss=12.3350\n",
      "Epoch 9: Total Loss=11.3070\n",
      "Updated x: [1.589721441268921, -1.5544109344482422], Function Value: 4.9434075355529785, Gradient: [-0.0004694561648648232, -0.039140548557043076]\n",
      "\n",
      "Step 110/200\n",
      "Epoch 0: Total Loss=10.9574\n",
      "Epoch 1: Total Loss=15.2648\n",
      "Epoch 2: Total Loss=9.8112\n",
      "Epoch 3: Total Loss=12.6997\n",
      "Epoch 4: Total Loss=12.7993\n",
      "Epoch 5: Total Loss=9.1862\n",
      "Epoch 6: Total Loss=13.8650\n",
      "Epoch 7: Total Loss=10.1033\n",
      "Epoch 8: Total Loss=12.9468\n",
      "Epoch 9: Total Loss=10.5489\n",
      "Updated x: [1.572693109512329, -1.538445234298706], Function Value: 4.840177536010742, Gradient: [-0.005263926461338997, -0.028767529875040054]\n",
      "\n",
      "Step 111/200\n",
      "Epoch 0: Total Loss=11.8238\n",
      "Epoch 1: Total Loss=12.2679\n",
      "Epoch 2: Total Loss=11.1859\n",
      "Epoch 3: Total Loss=9.5590\n",
      "Epoch 4: Total Loss=9.1360\n",
      "Epoch 5: Total Loss=12.2487\n",
      "Epoch 6: Total Loss=13.4023\n",
      "Epoch 7: Total Loss=10.5584\n",
      "Epoch 8: Total Loss=10.5349\n",
      "Epoch 9: Total Loss=9.8729\n",
      "Updated x: [1.5603265762329102, -1.5364357233047485], Function Value: 4.795253753662109, Gradient: [-0.00827456172555685, -0.020294317975640297]\n",
      "\n",
      "Step 112/200\n",
      "Epoch 0: Total Loss=117.0360\n",
      "Epoch 1: Total Loss=116.0478\n",
      "Epoch 2: Total Loss=114.9088\n",
      "Epoch 3: Total Loss=113.8433\n",
      "Epoch 4: Total Loss=113.2931\n",
      "Epoch 5: Total Loss=112.9615\n",
      "Epoch 6: Total Loss=112.1787\n",
      "Epoch 7: Total Loss=111.6895\n",
      "Epoch 8: Total Loss=110.4921\n",
      "Epoch 9: Total Loss=109.9852\n",
      "Updated x: [1.6610394716262817, -1.4915765523910522], Function Value: 4.983852386474609, Gradient: [0.015275844372808933, -0.34078294038772583]\n",
      "\n",
      "Step 113/200\n",
      "Epoch 0: Total Loss=109.2805\n",
      "Epoch 1: Total Loss=109.0285\n",
      "Epoch 2: Total Loss=108.7739\n",
      "Epoch 3: Total Loss=107.7792\n",
      "Epoch 4: Total Loss=107.1996\n",
      "Epoch 5: Total Loss=106.1774\n",
      "Epoch 6: Total Loss=105.0589\n",
      "Epoch 7: Total Loss=104.8839\n",
      "Epoch 8: Total Loss=104.1144\n",
      "Epoch 9: Total Loss=102.8714\n",
      "Updated x: [1.6210931539535522, -1.4003232717514038], Function Value: 4.588848114013672, Gradient: [0.0424034483730793, -0.45830127596855164]\n",
      "\n",
      "Step 114/200\n",
      "Epoch 0: Total Loss=14.0391\n",
      "Epoch 1: Total Loss=11.2704\n",
      "Epoch 2: Total Loss=10.3530\n",
      "Epoch 3: Total Loss=10.3986\n",
      "Epoch 4: Total Loss=10.0896\n",
      "Epoch 5: Total Loss=9.1032\n",
      "Epoch 6: Total Loss=9.9230\n",
      "Epoch 7: Total Loss=10.0569\n",
      "Epoch 8: Total Loss=8.9794\n",
      "Epoch 9: Total Loss=10.3987\n",
      "Updated x: [1.6418757438659668, -1.2653571367263794], Function Value: 4.296884536743164, Gradient: [-0.006586546078324318, -0.1900307983160019]\n",
      "\n",
      "Step 115/200\n",
      "Epoch 0: Total Loss=9.2099\n",
      "Epoch 1: Total Loss=9.8699\n",
      "Epoch 2: Total Loss=8.9953\n",
      "Epoch 3: Total Loss=10.3207\n",
      "Epoch 4: Total Loss=8.9262\n",
      "Epoch 5: Total Loss=9.7392\n",
      "Epoch 6: Total Loss=9.5819\n",
      "Epoch 7: Total Loss=9.8139\n",
      "Epoch 8: Total Loss=9.0231\n",
      "Epoch 9: Total Loss=10.1225\n",
      "Updated x: [1.601239800453186, -1.2758821249008179], Function Value: 4.1918439865112305, Gradient: [0.0021853374782949686, -0.2021777331829071]\n",
      "\n",
      "Step 116/200\n",
      "Epoch 0: Total Loss=8.8391\n",
      "Epoch 1: Total Loss=10.0359\n",
      "Epoch 2: Total Loss=9.0560\n",
      "Epoch 3: Total Loss=9.5723\n",
      "Epoch 4: Total Loss=9.1040\n",
      "Epoch 5: Total Loss=8.7733\n",
      "Epoch 6: Total Loss=10.7317\n",
      "Epoch 7: Total Loss=8.4117\n",
      "Epoch 8: Total Loss=9.9222\n",
      "Epoch 9: Total Loss=9.1930\n",
      "Updated x: [1.483873724937439, -1.2790859937667847], Function Value: 3.837942123413086, Gradient: [0.007215922698378563, -0.17901311814785004]\n",
      "\n",
      "Step 117/200\n",
      "Epoch 0: Total Loss=8.8626\n",
      "Epoch 1: Total Loss=9.8812\n",
      "Epoch 2: Total Loss=9.6105\n",
      "Epoch 3: Total Loss=9.0546\n",
      "Epoch 4: Total Loss=9.5669\n",
      "Epoch 5: Total Loss=8.8261\n",
      "Epoch 6: Total Loss=9.1909\n",
      "Epoch 7: Total Loss=10.6387\n",
      "Epoch 8: Total Loss=9.2823\n",
      "Epoch 9: Total Loss=8.5447\n",
      "Updated x: [1.355887770652771, -1.3202717304229736], Function Value: 3.5815491676330566, Gradient: [0.017820321023464203, -0.23666687309741974]\n",
      "\n",
      "Step 118/200\n",
      "Epoch 0: Total Loss=9.0814\n",
      "Epoch 1: Total Loss=9.0235\n",
      "Epoch 2: Total Loss=9.1107\n",
      "Epoch 3: Total Loss=9.4056\n",
      "Epoch 4: Total Loss=9.1931\n",
      "Epoch 5: Total Loss=9.4236\n",
      "Epoch 6: Total Loss=9.8018\n",
      "Epoch 7: Total Loss=9.2031\n",
      "Epoch 8: Total Loss=9.4070\n",
      "Epoch 9: Total Loss=8.9131\n",
      "Updated x: [1.2713286876678467, -1.3787202835083008], Function Value: 3.517146110534668, Gradient: [0.018659982830286026, -0.2623882293701172]\n",
      "\n",
      "Step 119/200\n",
      "Epoch 0: Total Loss=8.7957\n",
      "Epoch 1: Total Loss=9.6957\n",
      "Epoch 2: Total Loss=9.2285\n",
      "Epoch 3: Total Loss=9.6467\n",
      "Epoch 4: Total Loss=9.4690\n",
      "Epoch 5: Total Loss=10.5868\n",
      "Epoch 6: Total Loss=8.7714\n",
      "Epoch 7: Total Loss=8.5970\n",
      "Epoch 8: Total Loss=8.8268\n",
      "Epoch 9: Total Loss=10.6954\n",
      "Updated x: [1.259914755821228, -1.3391145467758179], Function Value: 3.380612850189209, Gradient: [0.019469909369945526, -0.2808511555194855]\n",
      "\n",
      "Step 120/200\n",
      "Epoch 0: Total Loss=9.8646\n",
      "Epoch 1: Total Loss=9.3605\n",
      "Epoch 2: Total Loss=9.4504\n",
      "Epoch 3: Total Loss=8.3728\n",
      "Epoch 4: Total Loss=9.3897\n",
      "Epoch 5: Total Loss=9.9215\n",
      "Epoch 6: Total Loss=9.0308\n",
      "Epoch 7: Total Loss=9.1112\n",
      "Epoch 8: Total Loss=8.9163\n",
      "Epoch 9: Total Loss=9.5112\n",
      "Updated x: [1.308812141418457, -1.2500731945037842], Function Value: 3.275672197341919, Gradient: [0.015525382943451405, -0.21357887983322144]\n",
      "\n",
      "Step 121/200\n",
      "Epoch 0: Total Loss=9.7301\n",
      "Epoch 1: Total Loss=8.8208\n",
      "Epoch 2: Total Loss=9.2356\n",
      "Epoch 3: Total Loss=8.8397\n",
      "Epoch 4: Total Loss=10.1055\n",
      "Epoch 5: Total Loss=9.2822\n",
      "Epoch 6: Total Loss=8.3600\n",
      "Epoch 7: Total Loss=8.8782\n",
      "Epoch 8: Total Loss=8.6180\n",
      "Epoch 9: Total Loss=9.5796\n",
      "Updated x: [1.209754228591919, -1.1563116312026978], Function Value: 2.8005619049072266, Gradient: [0.002932598115876317, -0.13272656500339508]\n",
      "\n",
      "Step 122/200\n",
      "Epoch 0: Total Loss=41.4787\n",
      "Epoch 1: Total Loss=41.2283\n",
      "Epoch 2: Total Loss=40.8934\n",
      "Epoch 3: Total Loss=40.7166\n",
      "Epoch 4: Total Loss=40.2229\n",
      "Epoch 5: Total Loss=39.8022\n",
      "Epoch 6: Total Loss=39.9362\n",
      "Epoch 7: Total Loss=39.1901\n",
      "Epoch 8: Total Loss=38.8782\n",
      "Epoch 9: Total Loss=38.5343\n",
      "Updated x: [1.1101868152618408, -1.0917420387268066], Function Value: 2.4244155883789062, Gradient: [0.06185239925980568, -0.33012691140174866]\n",
      "\n",
      "Step 123/200\n",
      "Epoch 0: Total Loss=34.3968\n",
      "Epoch 1: Total Loss=33.5281\n",
      "Epoch 2: Total Loss=33.2915\n",
      "Epoch 3: Total Loss=33.2069\n",
      "Epoch 4: Total Loss=32.2073\n",
      "Epoch 5: Total Loss=32.5436\n",
      "Epoch 6: Total Loss=31.7737\n",
      "Epoch 7: Total Loss=31.1115\n",
      "Epoch 8: Total Loss=31.0863\n",
      "Epoch 9: Total Loss=30.9598\n",
      "Updated x: [1.0246431827545166, -1.082701325416565], Function Value: 2.2221357822418213, Gradient: [0.1178906112909317, -0.5072317123413086]\n",
      "\n",
      "Step 124/200\n",
      "Epoch 0: Total Loss=9.0128\n",
      "Epoch 1: Total Loss=8.4634\n",
      "Epoch 2: Total Loss=9.2012\n",
      "Epoch 3: Total Loss=9.1468\n",
      "Epoch 4: Total Loss=8.5816\n",
      "Epoch 5: Total Loss=9.0325\n",
      "Epoch 6: Total Loss=9.0531\n",
      "Epoch 7: Total Loss=8.4490\n",
      "Epoch 8: Total Loss=9.0836\n",
      "Epoch 9: Total Loss=9.2335\n",
      "Updated x: [0.9554405808448792, -1.0967321395874023], Function Value: 2.1156880855560303, Gradient: [0.07548987120389938, -0.41261419653892517]\n",
      "\n",
      "Step 125/200\n",
      "Epoch 0: Total Loss=8.9244\n",
      "Epoch 1: Total Loss=8.3518\n",
      "Epoch 2: Total Loss=9.0146\n",
      "Epoch 3: Total Loss=8.4669\n",
      "Epoch 4: Total Loss=8.5195\n",
      "Epoch 5: Total Loss=8.5730\n",
      "Epoch 6: Total Loss=8.6607\n",
      "Epoch 7: Total Loss=8.4887\n",
      "Epoch 8: Total Loss=9.3631\n",
      "Epoch 9: Total Loss=8.8070\n",
      "Updated x: [0.9216403961181641, -1.088565707206726], Function Value: 2.034396171569824, Gradient: [0.04044684022665024, -0.4067802429199219]\n",
      "\n",
      "Step 126/200\n",
      "Epoch 0: Total Loss=8.1687\n",
      "Epoch 1: Total Loss=8.8451\n",
      "Epoch 2: Total Loss=8.3555\n",
      "Epoch 3: Total Loss=8.5856\n",
      "Epoch 4: Total Loss=8.5978\n",
      "Epoch 5: Total Loss=8.3961\n",
      "Epoch 6: Total Loss=8.8807\n",
      "Epoch 7: Total Loss=8.2122\n",
      "Epoch 8: Total Loss=8.4599\n",
      "Epoch 9: Total Loss=8.3126\n",
      "Updated x: [0.8799035549163818, -1.0969420671463013], Function Value: 1.9775121212005615, Gradient: [0.03889840841293335, -0.42768341302871704]\n",
      "\n",
      "Step 127/200\n",
      "Epoch 0: Total Loss=8.4696\n",
      "Epoch 1: Total Loss=8.8289\n",
      "Epoch 2: Total Loss=8.9628\n",
      "Epoch 3: Total Loss=8.6795\n",
      "Epoch 4: Total Loss=8.1237\n",
      "Epoch 5: Total Loss=8.8101\n",
      "Epoch 6: Total Loss=8.7793\n",
      "Epoch 7: Total Loss=8.5061\n",
      "Epoch 8: Total Loss=9.0435\n",
      "Epoch 9: Total Loss=8.5641\n",
      "Updated x: [0.7316511869430542, -1.1383939981460571], Function Value: 1.8312543630599976, Gradient: [-0.028836948797106743, -0.4880041182041168]\n",
      "\n",
      "Step 128/200\n",
      "Epoch 0: Total Loss=8.6042\n",
      "Epoch 1: Total Loss=8.8811\n",
      "Epoch 2: Total Loss=8.2329\n",
      "Epoch 3: Total Loss=8.2928\n",
      "Epoch 4: Total Loss=8.5485\n",
      "Epoch 5: Total Loss=8.2116\n",
      "Epoch 6: Total Loss=8.3306\n",
      "Epoch 7: Total Loss=8.2641\n",
      "Epoch 8: Total Loss=8.4808\n",
      "Epoch 9: Total Loss=8.3399\n",
      "Updated x: [0.8037807941436768, -1.002760887145996], Function Value: 1.6515929698944092, Gradient: [0.004902869928628206, -0.36667323112487793]\n",
      "\n",
      "Step 129/200\n",
      "Epoch 0: Total Loss=8.7115\n",
      "Epoch 1: Total Loss=8.5152\n",
      "Epoch 2: Total Loss=9.2256\n",
      "Epoch 3: Total Loss=8.4185\n",
      "Epoch 4: Total Loss=8.4690\n",
      "Epoch 5: Total Loss=8.3572\n",
      "Epoch 6: Total Loss=8.5016\n",
      "Epoch 7: Total Loss=8.3756\n",
      "Epoch 8: Total Loss=8.3808\n",
      "Epoch 9: Total Loss=8.6579\n",
      "Updated x: [0.7708432674407959, -0.9817101955413818], Function Value: 1.5579543113708496, Gradient: [-0.021594615653157234, -0.32967570424079895]\n",
      "\n",
      "Step 130/200\n",
      "Epoch 0: Total Loss=8.3860\n",
      "Epoch 1: Total Loss=8.5268\n",
      "Epoch 2: Total Loss=8.9986\n",
      "Epoch 3: Total Loss=8.3548\n",
      "Epoch 4: Total Loss=8.6370\n",
      "Epoch 5: Total Loss=8.7023\n",
      "Epoch 6: Total Loss=8.9604\n",
      "Epoch 7: Total Loss=8.6569\n",
      "Epoch 8: Total Loss=8.4539\n",
      "Epoch 9: Total Loss=8.4692\n",
      "Updated x: [0.8119081258773804, -0.9360811114311218], Function Value: 1.535442590713501, Gradient: [-0.016347920522093773, -0.23643337190151215]\n",
      "\n",
      "Step 131/200\n",
      "Epoch 0: Total Loss=8.4453\n",
      "Epoch 1: Total Loss=8.4495\n",
      "Epoch 2: Total Loss=8.9690\n",
      "Epoch 3: Total Loss=8.2483\n",
      "Epoch 4: Total Loss=8.0670\n",
      "Epoch 5: Total Loss=8.7432\n",
      "Epoch 6: Total Loss=8.4217\n",
      "Epoch 7: Total Loss=8.6724\n",
      "Epoch 8: Total Loss=9.1136\n",
      "Epoch 9: Total Loss=8.1717\n",
      "Updated x: [0.6476039886474609, -0.8253202438354492], Function Value: 1.1005444526672363, Gradient: [-0.045620404183864594, -0.09155051410198212]\n",
      "\n",
      "Step 132/200\n",
      "Epoch 0: Total Loss=12.3114\n",
      "Epoch 1: Total Loss=12.2501\n",
      "Epoch 2: Total Loss=12.3829\n",
      "Epoch 3: Total Loss=12.3027\n",
      "Epoch 4: Total Loss=12.1963\n",
      "Epoch 5: Total Loss=11.9959\n",
      "Epoch 6: Total Loss=11.9522\n",
      "Epoch 7: Total Loss=11.9050\n",
      "Epoch 8: Total Loss=11.8312\n",
      "Epoch 9: Total Loss=11.6276\n",
      "Updated x: [0.5012423992156982, -0.6728817820549011], Function Value: 0.7040138244628906, Gradient: [-0.031195644289255142, -0.12010076642036438]\n",
      "\n",
      "Step 133/200\n",
      "Epoch 0: Total Loss=10.8169\n",
      "Epoch 1: Total Loss=11.1091\n",
      "Epoch 2: Total Loss=10.6647\n",
      "Epoch 3: Total Loss=10.7695\n",
      "Epoch 4: Total Loss=10.7621\n",
      "Epoch 5: Total Loss=10.7602\n",
      "Epoch 6: Total Loss=10.6685\n",
      "Epoch 7: Total Loss=10.3005\n",
      "Epoch 8: Total Loss=10.4391\n",
      "Epoch 9: Total Loss=10.4360\n",
      "Updated x: [0.28804346919059753, -0.583340048789978], Function Value: 0.4232546389102936, Gradient: [-0.014026745222508907, -0.3025307357311249]\n",
      "\n",
      "Step 134/200\n",
      "Epoch 0: Total Loss=8.2914\n",
      "Epoch 1: Total Loss=8.4850\n",
      "Epoch 2: Total Loss=8.5630\n",
      "Epoch 3: Total Loss=8.4119\n",
      "Epoch 4: Total Loss=8.3065\n",
      "Epoch 5: Total Loss=8.2582\n",
      "Epoch 6: Total Loss=8.1955\n",
      "Epoch 7: Total Loss=8.4279\n",
      "Epoch 8: Total Loss=8.6820\n",
      "Epoch 9: Total Loss=8.1777\n",
      "Updated x: [0.3464915156364441, -0.44103190302848816], Function Value: 0.314565509557724, Gradient: [0.04522409290075302, -0.14065338671207428]\n",
      "\n",
      "Step 135/200\n",
      "Epoch 0: Total Loss=8.2496\n",
      "Epoch 1: Total Loss=8.6512\n",
      "Epoch 2: Total Loss=8.1846\n",
      "Epoch 3: Total Loss=8.3697\n",
      "Epoch 4: Total Loss=8.2805\n",
      "Epoch 5: Total Loss=8.1562\n",
      "Epoch 6: Total Loss=8.3938\n",
      "Epoch 7: Total Loss=8.1698\n",
      "Epoch 8: Total Loss=8.0159\n",
      "Epoch 9: Total Loss=8.2208\n",
      "Updated x: [0.2540624737739563, -0.3281979262828827], Function Value: 0.17226162552833557, Gradient: [0.04577214643359184, 0.030426619574427605]\n",
      "\n",
      "Step 136/200\n",
      "Epoch 0: Total Loss=8.0774\n",
      "Epoch 1: Total Loss=8.4949\n",
      "Epoch 2: Total Loss=8.1120\n",
      "Epoch 3: Total Loss=8.3633\n",
      "Epoch 4: Total Loss=8.1537\n",
      "Epoch 5: Total Loss=8.3784\n",
      "Epoch 6: Total Loss=8.4611\n",
      "Epoch 7: Total Loss=8.2377\n",
      "Epoch 8: Total Loss=8.1719\n",
      "Epoch 9: Total Loss=8.0667\n",
      "Updated x: [0.23304229974746704, -0.27080509066581726], Function Value: 0.1276441067457199, Gradient: [0.03538549691438675, 0.05756063386797905]\n",
      "\n",
      "Step 137/200\n",
      "Epoch 0: Total Loss=8.0031\n",
      "Epoch 1: Total Loss=8.2596\n",
      "Epoch 2: Total Loss=8.1135\n",
      "Epoch 3: Total Loss=7.9355\n",
      "Epoch 4: Total Loss=8.0990\n",
      "Epoch 5: Total Loss=8.3961\n",
      "Epoch 6: Total Loss=7.9411\n",
      "Epoch 7: Total Loss=7.9650\n",
      "Epoch 8: Total Loss=7.9307\n",
      "Epoch 9: Total Loss=8.1897\n",
      "Updated x: [0.1364688277244568, -0.31787413358688354], Function Value: 0.11966770142316818, Gradient: [0.003433570731431246, 0.06326959282159805]\n",
      "\n",
      "Step 138/200\n",
      "Epoch 0: Total Loss=8.2383\n",
      "Epoch 1: Total Loss=8.4401\n",
      "Epoch 2: Total Loss=7.8754\n",
      "Epoch 3: Total Loss=8.1304\n",
      "Epoch 4: Total Loss=7.9178\n",
      "Epoch 5: Total Loss=7.9448\n",
      "Epoch 6: Total Loss=8.0888\n",
      "Epoch 7: Total Loss=8.1674\n",
      "Epoch 8: Total Loss=8.0397\n",
      "Epoch 9: Total Loss=7.8138\n",
      "Updated x: [0.08984266221523285, -0.03374737501144409], Function Value: 0.009210589341819286, Gradient: [0.03123866207897663, 0.05864884331822395]\n",
      "\n",
      "Step 139/200\n",
      "Epoch 0: Total Loss=7.8977\n",
      "Epoch 1: Total Loss=7.9728\n",
      "Epoch 2: Total Loss=8.4374\n",
      "Epoch 3: Total Loss=7.9281\n",
      "Epoch 4: Total Loss=7.9288\n",
      "Epoch 5: Total Loss=8.0741\n",
      "Epoch 6: Total Loss=7.9207\n",
      "Epoch 7: Total Loss=7.7957\n",
      "Epoch 8: Total Loss=8.3076\n",
      "Epoch 9: Total Loss=8.1823\n",
      "Updated x: [0.08478796482086182, -0.036658238619565964], Function Value: 0.008532825857400894, Gradient: [0.02179226465523243, 0.055477265268564224]\n",
      "\n",
      "Step 140/200\n",
      "Epoch 0: Total Loss=8.3682\n",
      "Epoch 1: Total Loss=7.8494\n",
      "Epoch 2: Total Loss=7.9578\n",
      "Epoch 3: Total Loss=7.9447\n",
      "Epoch 4: Total Loss=7.9280\n",
      "Epoch 5: Total Loss=8.0879\n",
      "Epoch 6: Total Loss=8.1887\n",
      "Epoch 7: Total Loss=7.8410\n",
      "Epoch 8: Total Loss=7.7755\n",
      "Epoch 9: Total Loss=7.9407\n",
      "Updated x: [0.007084742188453674, -0.022516781464219093], Function Value: 0.0005571990041062236, Gradient: [0.006215672940015793, 0.05395173281431198]\n",
      "\n",
      "Step 141/200\n",
      "Epoch 0: Total Loss=8.1206\n",
      "Epoch 1: Total Loss=7.9927\n",
      "Epoch 2: Total Loss=7.9256\n",
      "Epoch 3: Total Loss=7.9571\n",
      "Epoch 4: Total Loss=8.2628\n",
      "Epoch 5: Total Loss=8.1581\n",
      "Epoch 6: Total Loss=7.9101\n",
      "Epoch 7: Total Loss=8.3188\n",
      "Epoch 8: Total Loss=7.8871\n",
      "Epoch 9: Total Loss=8.3527\n",
      "Updated x: [-0.032780811190605164, -0.013874099589884281], Function Value: 0.0012670722790062428, Gradient: [0.0021995343267917633, 0.05388908088207245]\n",
      "\n",
      "Step 142/200\n",
      "Epoch 0: Total Loss=7.6439\n",
      "Epoch 1: Total Loss=7.7968\n",
      "Epoch 2: Total Loss=7.5454\n",
      "Epoch 3: Total Loss=7.6422\n",
      "Epoch 4: Total Loss=7.6173\n",
      "Epoch 5: Total Loss=7.5672\n",
      "Epoch 6: Total Loss=7.5365\n",
      "Epoch 7: Total Loss=7.5646\n",
      "Epoch 8: Total Loss=7.7160\n",
      "Epoch 9: Total Loss=7.6811\n",
      "Updated x: [-0.014131434261798859, 0.06597548723220825], Function Value: 0.004552462138235569, Gradient: [-0.0029303142800927162, 0.01602507196366787]\n",
      "\n",
      "Step 143/200\n",
      "Epoch 0: Total Loss=7.5411\n",
      "Epoch 1: Total Loss=7.6269\n",
      "Epoch 2: Total Loss=7.6598\n",
      "Epoch 3: Total Loss=7.4966\n",
      "Epoch 4: Total Loss=7.6297\n",
      "Epoch 5: Total Loss=7.6434\n",
      "Epoch 6: Total Loss=7.7231\n",
      "Epoch 7: Total Loss=7.6122\n",
      "Epoch 8: Total Loss=7.6439\n",
      "Epoch 9: Total Loss=7.5206\n",
      "Updated x: [0.03755304217338562, 0.08043711632490158], Function Value: 0.007880360819399357, Gradient: [0.017359010875225067, -0.0012070148950442672]\n",
      "\n",
      "Step 144/200\n",
      "Epoch 0: Total Loss=7.7093\n",
      "Epoch 1: Total Loss=7.5291\n",
      "Epoch 2: Total Loss=7.5633\n",
      "Epoch 3: Total Loss=7.5381\n",
      "Epoch 4: Total Loss=7.7456\n",
      "Epoch 5: Total Loss=7.5957\n",
      "Epoch 6: Total Loss=7.5795\n",
      "Epoch 7: Total Loss=7.5078\n",
      "Epoch 8: Total Loss=7.6771\n",
      "Epoch 9: Total Loss=7.5152\n",
      "Updated x: [0.04985063523054123, 0.04916791245341301], Function Value: 0.004902569577097893, Gradient: [0.03521973267197609, 0.005018729716539383]\n",
      "\n",
      "Step 145/200\n",
      "Epoch 0: Total Loss=7.6569\n",
      "Epoch 1: Total Loss=7.5384\n",
      "Epoch 2: Total Loss=7.5974\n",
      "Epoch 3: Total Loss=7.6513\n",
      "Epoch 4: Total Loss=7.5899\n",
      "Epoch 5: Total Loss=7.6983\n",
      "Epoch 6: Total Loss=7.5901\n",
      "Epoch 7: Total Loss=7.7523\n",
      "Epoch 8: Total Loss=7.5886\n",
      "Epoch 9: Total Loss=7.5784\n",
      "Updated x: [-0.0017250031232833862, -0.10580456256866455], Function Value: 0.011197580955922604, Gradient: [0.009638854302465916, 0.012772838585078716]\n",
      "\n",
      "Step 146/200\n",
      "Epoch 0: Total Loss=7.5669\n",
      "Epoch 1: Total Loss=7.5526\n",
      "Epoch 2: Total Loss=7.6393\n",
      "Epoch 3: Total Loss=7.6017\n",
      "Epoch 4: Total Loss=7.4903\n",
      "Epoch 5: Total Loss=7.5702\n",
      "Epoch 6: Total Loss=7.5464\n",
      "Epoch 7: Total Loss=7.5817\n",
      "Epoch 8: Total Loss=7.5454\n",
      "Epoch 9: Total Loss=7.5106\n",
      "Updated x: [0.05222376435995102, 0.07238326966762543], Function Value: 0.007966659031808376, Gradient: [0.01927826553583145, -0.0007998980581760406]\n",
      "\n",
      "Step 147/200\n",
      "Epoch 0: Total Loss=7.5256\n",
      "Epoch 1: Total Loss=7.5888\n",
      "Epoch 2: Total Loss=7.6645\n",
      "Epoch 3: Total Loss=7.5284\n",
      "Epoch 4: Total Loss=7.6497\n",
      "Epoch 5: Total Loss=7.5910\n",
      "Epoch 6: Total Loss=7.7108\n",
      "Epoch 7: Total Loss=7.5768\n",
      "Epoch 8: Total Loss=7.5919\n",
      "Epoch 9: Total Loss=7.7999\n",
      "Updated x: [0.09195376932621002, -0.025561727583408356], Function Value: 0.009108897298574448, Gradient: [0.03251093998551369, 0.009256629273295403]\n",
      "\n",
      "Step 148/200\n",
      "Epoch 0: Total Loss=7.7324\n",
      "Epoch 1: Total Loss=7.7297\n",
      "Epoch 2: Total Loss=7.5519\n",
      "Epoch 3: Total Loss=7.7256\n",
      "Epoch 4: Total Loss=7.5422\n",
      "Epoch 5: Total Loss=7.5530\n",
      "Epoch 6: Total Loss=7.6125\n",
      "Epoch 7: Total Loss=7.5476\n",
      "Epoch 8: Total Loss=7.7721\n",
      "Epoch 9: Total Loss=7.5822\n",
      "Updated x: [-0.062117382884025574, -0.00532357394695282], Function Value: 0.0038869096897542477, Gradient: [-0.009090008214116096, -0.008327700197696686]\n",
      "\n",
      "Step 149/200\n",
      "Epoch 0: Total Loss=7.5351\n",
      "Epoch 1: Total Loss=7.5967\n",
      "Epoch 2: Total Loss=7.6365\n",
      "Epoch 3: Total Loss=7.6119\n",
      "Epoch 4: Total Loss=7.5248\n",
      "Epoch 5: Total Loss=7.5995\n",
      "Epoch 6: Total Loss=7.5455\n",
      "Epoch 7: Total Loss=7.6215\n",
      "Epoch 8: Total Loss=7.5203\n",
      "Epoch 9: Total Loss=7.4947\n",
      "Updated x: [0.05023643374443054, -0.06461828202009201], Function Value: 0.006699221674352884, Gradient: [0.013627811335027218, -0.0022796180564910173]\n",
      "\n",
      "Step 150/200\n",
      "Epoch 0: Total Loss=7.5464\n",
      "Epoch 1: Total Loss=7.5229\n",
      "Epoch 2: Total Loss=7.6817\n",
      "Epoch 3: Total Loss=7.6262\n",
      "Epoch 4: Total Loss=7.5422\n",
      "Epoch 5: Total Loss=7.5422\n",
      "Epoch 6: Total Loss=7.7080\n",
      "Epoch 7: Total Loss=7.6477\n",
      "Epoch 8: Total Loss=7.6502\n",
      "Epoch 9: Total Loss=7.6220\n",
      "Updated x: [-0.02168455719947815, -0.03587561100721359], Function Value: 0.0017572795040905476, Gradient: [-0.002712496556341648, -0.005428202450275421]\n",
      "\n",
      "Step 151/200\n",
      "Epoch 0: Total Loss=7.5783\n",
      "Epoch 1: Total Loss=7.5291\n",
      "Epoch 2: Total Loss=7.6964\n",
      "Epoch 3: Total Loss=7.5705\n",
      "Epoch 4: Total Loss=7.5502\n",
      "Epoch 5: Total Loss=7.5939\n",
      "Epoch 6: Total Loss=7.5415\n",
      "Epoch 7: Total Loss=7.4860\n",
      "Epoch 8: Total Loss=7.5578\n",
      "Epoch 9: Total Loss=7.6363\n",
      "Updated x: [-0.024958349764347076, 0.009995315223932266], Function Value: 0.000722825585398823, Gradient: [0.0026832628063857555, -0.006138958968222141]\n",
      "\n",
      "Step 152/200\n",
      "Epoch 0: Total Loss=7.3073\n",
      "Epoch 1: Total Loss=7.3231\n",
      "Epoch 2: Total Loss=7.3171\n",
      "Epoch 3: Total Loss=7.2927\n",
      "Epoch 4: Total Loss=7.2923\n",
      "Epoch 5: Total Loss=7.2560\n",
      "Epoch 6: Total Loss=7.3191\n",
      "Epoch 7: Total Loss=7.2939\n",
      "Epoch 8: Total Loss=7.3123\n",
      "Epoch 9: Total Loss=7.2572\n",
      "Updated x: [0.06805028021335602, -0.05195667967200279], Function Value: 0.007330337539315224, Gradient: [0.019641166552901268, 0.004436223767697811]\n",
      "\n",
      "Step 153/200\n",
      "Epoch 0: Total Loss=7.2786\n",
      "Epoch 1: Total Loss=7.2739\n",
      "Epoch 2: Total Loss=7.2705\n",
      "Epoch 3: Total Loss=7.2789\n",
      "Epoch 4: Total Loss=7.2938\n",
      "Epoch 5: Total Loss=7.2900\n",
      "Epoch 6: Total Loss=7.2631\n",
      "Epoch 7: Total Loss=7.2772\n",
      "Epoch 8: Total Loss=7.2865\n",
      "Epoch 9: Total Loss=7.2768\n",
      "Updated x: [0.07012447714805603, 0.11668024957180023], Function Value: 0.01853172294795513, Gradient: [0.03261122480034828, 0.0029101178515702486]\n",
      "\n",
      "Step 154/200\n",
      "Epoch 0: Total Loss=7.3230\n",
      "Epoch 1: Total Loss=7.2988\n",
      "Epoch 2: Total Loss=7.2377\n",
      "Epoch 3: Total Loss=7.2698\n",
      "Epoch 4: Total Loss=7.2656\n",
      "Epoch 5: Total Loss=7.2864\n",
      "Epoch 6: Total Loss=7.2898\n",
      "Epoch 7: Total Loss=7.2840\n",
      "Epoch 8: Total Loss=7.3367\n",
      "Epoch 9: Total Loss=7.2756\n",
      "Updated x: [0.09536721557378769, -0.054923295974731445], Function Value: 0.012111474759876728, Gradient: [0.024837611243128777, -0.009464768692851067]\n",
      "\n",
      "Step 155/200\n",
      "Epoch 0: Total Loss=7.2873\n",
      "Epoch 1: Total Loss=7.2956\n",
      "Epoch 2: Total Loss=7.2472\n",
      "Epoch 3: Total Loss=7.2885\n",
      "Epoch 4: Total Loss=7.2561\n",
      "Epoch 5: Total Loss=7.3190\n",
      "Epoch 6: Total Loss=7.3116\n",
      "Epoch 7: Total Loss=7.2550\n",
      "Epoch 8: Total Loss=7.2450\n",
      "Epoch 9: Total Loss=7.2999\n",
      "Updated x: [0.1345919519662857, -0.03169503062963486], Function Value: 0.019119568169116974, Gradient: [0.020454833284020424, -0.01550996582955122]\n",
      "\n",
      "Step 156/200\n",
      "Epoch 0: Total Loss=7.3053\n",
      "Epoch 1: Total Loss=7.3013\n",
      "Epoch 2: Total Loss=7.2878\n",
      "Epoch 3: Total Loss=7.2857\n",
      "Epoch 4: Total Loss=7.2504\n",
      "Epoch 5: Total Loss=7.2743\n",
      "Epoch 6: Total Loss=7.2644\n",
      "Epoch 7: Total Loss=7.2525\n",
      "Epoch 8: Total Loss=7.2683\n",
      "Epoch 9: Total Loss=7.3318\n",
      "Updated x: [0.10851668566465378, 0.01545572280883789], Function Value: 0.012014750391244888, Gradient: [0.018889453262090683, -0.012046951800584793]\n",
      "\n",
      "Step 157/200\n",
      "Epoch 0: Total Loss=7.3041\n",
      "Epoch 1: Total Loss=7.2928\n",
      "Epoch 2: Total Loss=7.2794\n",
      "Epoch 3: Total Loss=7.2703\n",
      "Epoch 4: Total Loss=7.2521\n",
      "Epoch 5: Total Loss=7.2960\n",
      "Epoch 6: Total Loss=7.2669\n",
      "Epoch 7: Total Loss=7.2889\n",
      "Epoch 8: Total Loss=7.3154\n",
      "Epoch 9: Total Loss=7.2824\n",
      "Updated x: [0.044650785624980927, -0.047763191163539886], Function Value: 0.004275015089660883, Gradient: [0.011899339966475964, -0.013019442558288574]\n",
      "\n",
      "Step 158/200\n",
      "Epoch 0: Total Loss=7.2680\n",
      "Epoch 1: Total Loss=7.2868\n",
      "Epoch 2: Total Loss=7.2922\n",
      "Epoch 3: Total Loss=7.2798\n",
      "Epoch 4: Total Loss=7.2844\n",
      "Epoch 5: Total Loss=7.2774\n",
      "Epoch 6: Total Loss=7.2706\n",
      "Epoch 7: Total Loss=7.2641\n",
      "Epoch 8: Total Loss=7.2754\n",
      "Epoch 9: Total Loss=7.2685\n",
      "Updated x: [0.06799943000078201, 0.0038320496678352356], Function Value: 0.004638607148081064, Gradient: [0.012759651988744736, -0.010109266266226768]\n",
      "\n",
      "Step 159/200\n",
      "Epoch 0: Total Loss=7.2966\n",
      "Epoch 1: Total Loss=7.2647\n",
      "Epoch 2: Total Loss=7.2954\n",
      "Epoch 3: Total Loss=7.2820\n",
      "Epoch 4: Total Loss=7.2466\n",
      "Epoch 5: Total Loss=7.2927\n",
      "Epoch 6: Total Loss=7.3001\n",
      "Epoch 7: Total Loss=7.2827\n",
      "Epoch 8: Total Loss=7.2430\n",
      "Epoch 9: Total Loss=7.3041\n",
      "Updated x: [0.028134386986494064, 0.019933363422751427], Function Value: 0.0011888827430084348, Gradient: [0.00919407606124878, -0.006912273820489645]\n",
      "\n",
      "Step 160/200\n",
      "Epoch 0: Total Loss=7.2925\n",
      "Epoch 1: Total Loss=7.2738\n",
      "Epoch 2: Total Loss=7.2604\n",
      "Epoch 3: Total Loss=7.2958\n",
      "Epoch 4: Total Loss=7.3015\n",
      "Epoch 5: Total Loss=7.3130\n",
      "Epoch 6: Total Loss=7.2812\n",
      "Epoch 7: Total Loss=7.2735\n",
      "Epoch 8: Total Loss=7.2712\n",
      "Epoch 9: Total Loss=7.2740\n",
      "Updated x: [-0.0018349364399909973, -0.005829349160194397], Function Value: 3.7348305340856314e-05, Gradient: [0.0013360785087570548, -0.008568004705011845]\n",
      "\n",
      "Step 161/200\n",
      "Epoch 0: Total Loss=7.2851\n",
      "Epoch 1: Total Loss=7.2862\n",
      "Epoch 2: Total Loss=7.2755\n",
      "Epoch 3: Total Loss=7.3159\n",
      "Epoch 4: Total Loss=7.2749\n",
      "Epoch 5: Total Loss=7.2680\n",
      "Epoch 6: Total Loss=7.2954\n",
      "Epoch 7: Total Loss=7.2717\n",
      "Epoch 8: Total Loss=7.2679\n",
      "Epoch 9: Total Loss=7.2628\n",
      "Updated x: [0.020072942599654198, -0.02360888570547104], Function Value: 0.0009603025391697884, Gradient: [0.0015237231273204088, -0.012338819913566113]\n",
      "\n",
      "Step 162/200\n",
      "Epoch 0: Total Loss=8.3200\n",
      "Epoch 1: Total Loss=9.3321\n",
      "Epoch 2: Total Loss=9.2179\n",
      "Epoch 3: Total Loss=8.2233\n",
      "Epoch 4: Total Loss=8.0292\n",
      "Epoch 5: Total Loss=8.6415\n",
      "Epoch 6: Total Loss=8.2154\n",
      "Epoch 7: Total Loss=8.7173\n",
      "Epoch 8: Total Loss=9.0544\n",
      "Epoch 9: Total Loss=9.5111\n",
      "Updated x: [0.09263110160827637, -0.008942105807363987], Function Value: 0.008660482242703438, Gradient: [0.013124766759574413, -0.0284521896392107]\n",
      "\n",
      "Step 163/200\n",
      "Epoch 0: Total Loss=8.9618\n",
      "Epoch 1: Total Loss=7.9408\n",
      "Epoch 2: Total Loss=9.6298\n",
      "Epoch 3: Total Loss=8.4107\n",
      "Epoch 4: Total Loss=8.6600\n",
      "Epoch 5: Total Loss=7.9371\n",
      "Epoch 6: Total Loss=9.2340\n",
      "Epoch 7: Total Loss=9.0576\n",
      "Epoch 8: Total Loss=9.2295\n",
      "Epoch 9: Total Loss=8.4550\n",
      "Updated x: [0.1992851197719574, 0.031516287475824356], Function Value: 0.04070783779025078, Gradient: [0.04276392236351967, -0.028701558709144592]\n",
      "\n",
      "Step 164/200\n",
      "Epoch 0: Total Loss=8.7909\n",
      "Epoch 1: Total Loss=9.7843\n",
      "Epoch 2: Total Loss=8.3382\n",
      "Epoch 3: Total Loss=8.7182\n",
      "Epoch 4: Total Loss=8.4437\n",
      "Epoch 5: Total Loss=7.6073\n",
      "Epoch 6: Total Loss=7.5902\n",
      "Epoch 7: Total Loss=8.0161\n",
      "Epoch 8: Total Loss=8.7944\n",
      "Epoch 9: Total Loss=8.5098\n",
      "Updated x: [-0.013806089758872986, 0.046738822013139725], Function Value: 0.002375125652179122, Gradient: [0.0012289477745071054, -0.029534006491303444]\n",
      "\n",
      "Step 165/200\n",
      "Epoch 0: Total Loss=9.1289\n",
      "Epoch 1: Total Loss=10.7416\n",
      "Epoch 2: Total Loss=8.5037\n",
      "Epoch 3: Total Loss=8.8440\n",
      "Epoch 4: Total Loss=9.9619\n",
      "Epoch 5: Total Loss=8.0114\n",
      "Epoch 6: Total Loss=8.5158\n",
      "Epoch 7: Total Loss=9.9258\n",
      "Epoch 8: Total Loss=8.9873\n",
      "Epoch 9: Total Loss=8.1063\n",
      "Updated x: [0.06438528746366501, 0.00909467414021492], Function Value: 0.004228178411722183, Gradient: [0.009940487332642078, -0.03154611960053444]\n",
      "\n",
      "Step 166/200\n",
      "Epoch 0: Total Loss=8.3083\n",
      "Epoch 1: Total Loss=9.4016\n",
      "Epoch 2: Total Loss=8.6585\n",
      "Epoch 3: Total Loss=8.2892\n",
      "Epoch 4: Total Loss=7.7783\n",
      "Epoch 5: Total Loss=8.3961\n",
      "Epoch 6: Total Loss=8.5952\n",
      "Epoch 7: Total Loss=8.3561\n",
      "Epoch 8: Total Loss=9.1080\n",
      "Epoch 9: Total Loss=8.3175\n",
      "Updated x: [-0.012700796127319336, -0.027554206550121307], Function Value: 0.0009205444948747754, Gradient: [-0.0021822964772582054, -0.02678767777979374]\n",
      "\n",
      "Step 167/200\n",
      "Epoch 0: Total Loss=8.4637\n",
      "Epoch 1: Total Loss=13.0202\n",
      "Epoch 2: Total Loss=8.7479\n",
      "Epoch 3: Total Loss=8.0115\n",
      "Epoch 4: Total Loss=7.9576\n",
      "Epoch 5: Total Loss=8.6435\n",
      "Epoch 6: Total Loss=8.1481\n",
      "Epoch 7: Total Loss=8.6729\n",
      "Epoch 8: Total Loss=9.0515\n",
      "Epoch 9: Total Loss=8.5623\n",
      "Updated x: [0.011115999892354012, 0.06306097656488419], Function Value: 0.004100252408534288, Gradient: [0.006391536444425583, -0.016774902120232582]\n",
      "\n",
      "Step 168/200\n",
      "Epoch 0: Total Loss=8.6317\n",
      "Epoch 1: Total Loss=8.4975\n",
      "Epoch 2: Total Loss=8.2323\n",
      "Epoch 3: Total Loss=8.9972\n",
      "Epoch 4: Total Loss=8.5575\n",
      "Epoch 5: Total Loss=8.5010\n",
      "Epoch 6: Total Loss=8.6356\n",
      "Epoch 7: Total Loss=8.4927\n",
      "Epoch 8: Total Loss=8.3568\n",
      "Epoch 9: Total Loss=9.7491\n",
      "Updated x: [-0.007677601650357246, -0.014612823724746704], Function Value: 0.0002724801888689399, Gradient: [0.0027269271668046713, -0.024149490520358086]\n",
      "\n",
      "Step 169/200\n",
      "Epoch 0: Total Loss=8.5300\n",
      "Epoch 1: Total Loss=8.4909\n",
      "Epoch 2: Total Loss=8.7039\n",
      "Epoch 3: Total Loss=10.9953\n",
      "Epoch 4: Total Loss=8.2035\n",
      "Epoch 5: Total Loss=8.9807\n",
      "Epoch 6: Total Loss=9.5142\n",
      "Epoch 7: Total Loss=8.2884\n",
      "Epoch 8: Total Loss=8.1046\n",
      "Epoch 9: Total Loss=9.0387\n",
      "Updated x: [0.05590029060840607, -0.03831329196691513], Function Value: 0.004592750687152147, Gradient: [0.012470747344195843, -0.024643857032060623]\n",
      "\n",
      "Step 170/200\n",
      "Epoch 0: Total Loss=7.5215\n",
      "Epoch 1: Total Loss=7.7673\n",
      "Epoch 2: Total Loss=8.3258\n",
      "Epoch 3: Total Loss=8.0096\n",
      "Epoch 4: Total Loss=8.1639\n",
      "Epoch 5: Total Loss=7.4876\n",
      "Epoch 6: Total Loss=8.8751\n",
      "Epoch 7: Total Loss=8.8170\n",
      "Epoch 8: Total Loss=9.1255\n",
      "Epoch 9: Total Loss=9.0659\n",
      "Updated x: [0.05948364734649658, -0.11483502388000488], Function Value: 0.016725387424230576, Gradient: [0.008635861799120903, -0.02964750863611698]\n",
      "\n",
      "Step 171/200\n",
      "Epoch 0: Total Loss=8.0882\n",
      "Epoch 1: Total Loss=9.6786\n",
      "Epoch 2: Total Loss=8.6367\n",
      "Epoch 3: Total Loss=8.8686\n",
      "Epoch 4: Total Loss=8.0578\n",
      "Epoch 5: Total Loss=7.8754\n",
      "Epoch 6: Total Loss=10.0554\n",
      "Epoch 7: Total Loss=8.8389\n",
      "Epoch 8: Total Loss=9.0939\n",
      "Epoch 9: Total Loss=12.3368\n",
      "Updated x: [-0.0035353899002075195, -0.018654480576515198], Function Value: 0.0003604886296670884, Gradient: [0.008674131706357002, -0.015468486584722996]\n",
      "\n",
      "Step 172/200\n",
      "Epoch 0: Total Loss=8.1923\n",
      "Epoch 1: Total Loss=8.6906\n",
      "Epoch 2: Total Loss=9.5075\n",
      "Epoch 3: Total Loss=8.4141\n",
      "Epoch 4: Total Loss=7.9669\n",
      "Epoch 5: Total Loss=8.2364\n",
      "Epoch 6: Total Loss=9.2495\n",
      "Epoch 7: Total Loss=8.0582\n",
      "Epoch 8: Total Loss=8.4423\n",
      "Epoch 9: Total Loss=7.9986\n",
      "Updated x: [-0.011225247755646706, 0.01291251927614212], Function Value: 0.00029273933614604175, Gradient: [-0.01421454455703497, -0.027485864236950874]\n",
      "\n",
      "Step 173/200\n",
      "Epoch 0: Total Loss=8.9782\n",
      "Epoch 1: Total Loss=9.5068\n",
      "Epoch 2: Total Loss=8.2998\n",
      "Epoch 3: Total Loss=8.3076\n",
      "Epoch 4: Total Loss=8.1394\n",
      "Epoch 5: Total Loss=8.2540\n",
      "Epoch 6: Total Loss=7.9604\n",
      "Epoch 7: Total Loss=8.2523\n",
      "Epoch 8: Total Loss=8.3763\n",
      "Epoch 9: Total Loss=8.0259\n",
      "Updated x: [-0.04634973406791687, 0.13020527362823486], Function Value: 0.019101710990071297, Gradient: [-0.03159555792808533, -0.005080670118331909]\n",
      "\n",
      "Step 174/200\n",
      "Epoch 0: Total Loss=8.3171\n",
      "Epoch 1: Total Loss=8.0415\n",
      "Epoch 2: Total Loss=9.4178\n",
      "Epoch 3: Total Loss=9.3381\n",
      "Epoch 4: Total Loss=8.1310\n",
      "Epoch 5: Total Loss=8.4957\n",
      "Epoch 6: Total Loss=7.8480\n",
      "Epoch 7: Total Loss=8.0425\n",
      "Epoch 8: Total Loss=9.2459\n",
      "Epoch 9: Total Loss=8.4556\n",
      "Updated x: [0.0642920583486557, 0.009615667164325714], Function Value: 0.0042259301990270615, Gradient: [-0.016025861725211143, -0.02334265410900116]\n",
      "\n",
      "Step 175/200\n",
      "Epoch 0: Total Loss=8.4045\n",
      "Epoch 1: Total Loss=8.0299\n",
      "Epoch 2: Total Loss=8.5652\n",
      "Epoch 3: Total Loss=8.3718\n",
      "Epoch 4: Total Loss=8.3182\n",
      "Epoch 5: Total Loss=8.9104\n",
      "Epoch 6: Total Loss=8.8985\n",
      "Epoch 7: Total Loss=8.2136\n",
      "Epoch 8: Total Loss=8.5502\n",
      "Epoch 9: Total Loss=8.4075\n",
      "Updated x: [-0.004828028380870819, 0.0005478337407112122], Function Value: 2.360998041694984e-05, Gradient: [-0.026135513558983803, -0.024024726822972298]\n",
      "\n",
      "Step 176/200\n",
      "Epoch 0: Total Loss=8.0528\n",
      "Epoch 1: Total Loss=7.8506\n",
      "Epoch 2: Total Loss=9.3580\n",
      "Epoch 3: Total Loss=8.1525\n",
      "Epoch 4: Total Loss=9.5585\n",
      "Epoch 5: Total Loss=7.9974\n",
      "Epoch 6: Total Loss=7.8440\n",
      "Epoch 7: Total Loss=8.1600\n",
      "Epoch 8: Total Loss=8.4605\n",
      "Epoch 9: Total Loss=8.1859\n",
      "Updated x: [-0.04264092072844505, 0.019804706797003746], Function Value: 0.0022104745730757713, Gradient: [-0.015924964100122452, -0.014989796094596386]\n",
      "\n",
      "Step 177/200\n",
      "Epoch 0: Total Loss=8.3138\n",
      "Epoch 1: Total Loss=8.1450\n",
      "Epoch 2: Total Loss=8.3417\n",
      "Epoch 3: Total Loss=8.5380\n",
      "Epoch 4: Total Loss=8.4957\n",
      "Epoch 5: Total Loss=8.1996\n",
      "Epoch 6: Total Loss=8.5885\n",
      "Epoch 7: Total Loss=8.2751\n",
      "Epoch 8: Total Loss=8.5295\n",
      "Epoch 9: Total Loss=9.2227\n",
      "Updated x: [-0.04917240887880325, -0.02851380966603756], Function Value: 0.003230963135138154, Gradient: [-0.020518086850643158, -0.022956285625696182]\n",
      "\n",
      "Step 178/200\n",
      "Epoch 0: Total Loss=8.1607\n",
      "Epoch 1: Total Loss=8.6581\n",
      "Epoch 2: Total Loss=8.4965\n",
      "Epoch 3: Total Loss=7.8832\n",
      "Epoch 4: Total Loss=8.6984\n",
      "Epoch 5: Total Loss=8.0528\n",
      "Epoch 6: Total Loss=8.1483\n",
      "Epoch 7: Total Loss=8.5577\n",
      "Epoch 8: Total Loss=9.0816\n",
      "Epoch 9: Total Loss=9.5363\n",
      "Updated x: [-0.046574242413043976, 0.06829233467578888], Function Value: 0.006833003368228674, Gradient: [-0.015116358175873756, -0.006791252642869949]\n",
      "\n",
      "Step 179/200\n",
      "Epoch 0: Total Loss=8.0562\n",
      "Epoch 1: Total Loss=7.9118\n",
      "Epoch 2: Total Loss=8.4231\n",
      "Epoch 3: Total Loss=8.0089\n",
      "Epoch 4: Total Loss=9.2029\n",
      "Epoch 5: Total Loss=7.8163\n",
      "Epoch 6: Total Loss=7.8323\n",
      "Epoch 7: Total Loss=9.2104\n",
      "Epoch 8: Total Loss=8.1500\n",
      "Epoch 9: Total Loss=8.6268\n",
      "Updated x: [-0.11806941032409668, 4.415959119796753e-05], Function Value: 0.013940387405455112, Gradient: [-0.016376808285713196, -0.009203393943607807]\n",
      "\n",
      "Step 180/200\n",
      "Epoch 0: Total Loss=8.9326\n",
      "Epoch 1: Total Loss=8.2188\n",
      "Epoch 2: Total Loss=9.1875\n",
      "Epoch 3: Total Loss=8.4261\n",
      "Epoch 4: Total Loss=8.3161\n",
      "Epoch 5: Total Loss=8.5908\n",
      "Epoch 6: Total Loss=7.9790\n",
      "Epoch 7: Total Loss=8.3154\n",
      "Epoch 8: Total Loss=8.4244\n",
      "Epoch 9: Total Loss=8.1103\n",
      "Updated x: [0.016795888543128967, -0.010134650394320488], Function Value: 0.0003848130290862173, Gradient: [-0.010402373969554901, -0.0159748662263155]\n",
      "\n",
      "Step 181/200\n",
      "Epoch 0: Total Loss=8.1020\n",
      "Epoch 1: Total Loss=8.4424\n",
      "Epoch 2: Total Loss=8.4639\n",
      "Epoch 3: Total Loss=7.9393\n",
      "Epoch 4: Total Loss=8.4489\n",
      "Epoch 5: Total Loss=8.4598\n",
      "Epoch 6: Total Loss=8.3986\n",
      "Epoch 7: Total Loss=7.7978\n",
      "Epoch 8: Total Loss=9.8252\n",
      "Epoch 9: Total Loss=8.2873\n",
      "Updated x: [0.022929586470127106, -0.03990881145000458], Function Value: 0.0021184789948165417, Gradient: [-0.009743815287947655, -0.015665270388126373]\n",
      "\n",
      "Step 182/200\n",
      "Epoch 0: Total Loss=8.0623\n",
      "Epoch 1: Total Loss=8.0033\n",
      "Epoch 2: Total Loss=8.1585\n",
      "Epoch 3: Total Loss=7.8380\n",
      "Epoch 4: Total Loss=8.0193\n",
      "Epoch 5: Total Loss=8.6276\n",
      "Epoch 6: Total Loss=9.1286\n",
      "Epoch 7: Total Loss=8.1967\n",
      "Epoch 8: Total Loss=8.6254\n",
      "Epoch 9: Total Loss=7.9888\n",
      "Updated x: [0.03426271304488182, 0.09211885929107666], Function Value: 0.009659817442297935, Gradient: [-0.0038794660940766335, -0.0025687715969979763]\n",
      "\n",
      "Step 183/200\n",
      "Epoch 0: Total Loss=8.1625\n",
      "Epoch 1: Total Loss=7.9048\n",
      "Epoch 2: Total Loss=8.2560\n",
      "Epoch 3: Total Loss=8.1493\n",
      "Epoch 4: Total Loss=8.1136\n",
      "Epoch 5: Total Loss=8.2004\n",
      "Epoch 6: Total Loss=8.4374\n",
      "Epoch 7: Total Loss=8.2606\n",
      "Epoch 8: Total Loss=7.9267\n",
      "Epoch 9: Total Loss=8.0256\n",
      "Updated x: [0.0340750589966774, -0.06065584719181061], Function Value: 0.0048402417451143265, Gradient: [-0.013643586076796055, -0.01842656545341015]\n",
      "\n",
      "Step 184/200\n",
      "Epoch 0: Total Loss=7.9095\n",
      "Epoch 1: Total Loss=7.7399\n",
      "Epoch 2: Total Loss=7.7793\n",
      "Epoch 3: Total Loss=7.9824\n",
      "Epoch 4: Total Loss=7.8840\n",
      "Epoch 5: Total Loss=7.7950\n",
      "Epoch 6: Total Loss=7.9053\n",
      "Epoch 7: Total Loss=8.2598\n",
      "Epoch 8: Total Loss=8.3949\n",
      "Epoch 9: Total Loss=9.1985\n",
      "Updated x: [0.019837789237499237, -0.06792987138032913], Function Value: 0.005008005071431398, Gradient: [-0.017783353105187416, -0.024280935525894165]\n",
      "\n",
      "Step 185/200\n",
      "Epoch 0: Total Loss=8.0951\n",
      "Epoch 1: Total Loss=8.3214\n",
      "Epoch 2: Total Loss=8.2582\n",
      "Epoch 3: Total Loss=8.3306\n",
      "Epoch 4: Total Loss=8.4496\n",
      "Epoch 5: Total Loss=8.1174\n",
      "Epoch 6: Total Loss=8.2668\n",
      "Epoch 7: Total Loss=7.8686\n",
      "Epoch 8: Total Loss=8.2728\n",
      "Epoch 9: Total Loss=8.6182\n",
      "Updated x: [0.013003083877265453, 0.02454577386379242], Function Value: 0.0007715752581134439, Gradient: [-0.019417613744735718, -0.011308997869491577]\n",
      "\n",
      "Step 186/200\n",
      "Epoch 0: Total Loss=8.1752\n",
      "Epoch 1: Total Loss=7.7745\n",
      "Epoch 2: Total Loss=8.2085\n",
      "Epoch 3: Total Loss=7.8285\n",
      "Epoch 4: Total Loss=8.1098\n",
      "Epoch 5: Total Loss=8.0592\n",
      "Epoch 6: Total Loss=8.2221\n",
      "Epoch 7: Total Loss=7.9097\n",
      "Epoch 8: Total Loss=8.0293\n",
      "Epoch 9: Total Loss=8.1892\n",
      "Updated x: [0.13509590923786163, -0.003276422619819641], Function Value: 0.018261639401316643, Gradient: [-0.013780594803392887, -0.019777290523052216]\n",
      "\n",
      "Step 187/200\n",
      "Epoch 0: Total Loss=7.9523\n",
      "Epoch 1: Total Loss=7.7411\n",
      "Epoch 2: Total Loss=7.9043\n",
      "Epoch 3: Total Loss=7.8768\n",
      "Epoch 4: Total Loss=7.9831\n",
      "Epoch 5: Total Loss=7.9786\n",
      "Epoch 6: Total Loss=7.9623\n",
      "Epoch 7: Total Loss=7.8480\n",
      "Epoch 8: Total Loss=8.1267\n",
      "Epoch 9: Total Loss=8.3536\n",
      "Updated x: [0.04604102671146393, -0.05376766622066498], Function Value: 0.0050107380375266075, Gradient: [-0.009059350937604904, -0.01719086430966854]\n",
      "\n",
      "Step 188/200\n",
      "Epoch 0: Total Loss=8.6800\n",
      "Epoch 1: Total Loss=7.9465\n",
      "Epoch 2: Total Loss=7.8963\n",
      "Epoch 3: Total Loss=8.2328\n",
      "Epoch 4: Total Loss=7.9494\n",
      "Epoch 5: Total Loss=8.3070\n",
      "Epoch 6: Total Loss=7.8802\n",
      "Epoch 7: Total Loss=7.9350\n",
      "Epoch 8: Total Loss=7.8587\n",
      "Epoch 9: Total Loss=8.0970\n",
      "Updated x: [0.10044197738170624, -0.008386973291635513], Function Value: 0.010158931836485863, Gradient: [-0.008526736870408058, -0.0171618964523077]\n",
      "\n",
      "Step 189/200\n",
      "Epoch 0: Total Loss=8.0908\n",
      "Epoch 1: Total Loss=8.1476\n",
      "Epoch 2: Total Loss=7.8322\n",
      "Epoch 3: Total Loss=7.9213\n",
      "Epoch 4: Total Loss=7.8279\n",
      "Epoch 5: Total Loss=7.8968\n",
      "Epoch 6: Total Loss=7.9280\n",
      "Epoch 7: Total Loss=7.8316\n",
      "Epoch 8: Total Loss=8.0421\n",
      "Epoch 9: Total Loss=7.6574\n",
      "Updated x: [-0.06320114433765411, 0.08512216806411743], Function Value: 0.01124016847461462, Gradient: [-0.012837909162044525, 0.001125419745221734]\n",
      "\n",
      "Step 190/200\n",
      "Epoch 0: Total Loss=8.4228\n",
      "Epoch 1: Total Loss=8.0718\n",
      "Epoch 2: Total Loss=8.1047\n",
      "Epoch 3: Total Loss=8.0175\n",
      "Epoch 4: Total Loss=7.8529\n",
      "Epoch 5: Total Loss=8.1943\n",
      "Epoch 6: Total Loss=8.1207\n",
      "Epoch 7: Total Loss=8.1636\n",
      "Epoch 8: Total Loss=8.0914\n",
      "Epoch 9: Total Loss=8.2380\n",
      "Updated x: [0.07823202013969421, 0.0671011358499527], Function Value: 0.010622811503708363, Gradient: [-0.012790901586413383, -0.006701572798192501]\n",
      "\n",
      "Step 191/200\n",
      "Epoch 0: Total Loss=7.8170\n",
      "Epoch 1: Total Loss=8.0027\n",
      "Epoch 2: Total Loss=8.3812\n",
      "Epoch 3: Total Loss=7.8493\n",
      "Epoch 4: Total Loss=8.5230\n",
      "Epoch 5: Total Loss=8.0598\n",
      "Epoch 6: Total Loss=8.2285\n",
      "Epoch 7: Total Loss=7.9116\n",
      "Epoch 8: Total Loss=8.0367\n",
      "Epoch 9: Total Loss=8.0666\n",
      "Updated x: [0.008559845387935638, -0.016016997396945953], Function Value: 0.0003298151714261621, Gradient: [-0.01079736277461052, -0.00973537191748619]\n",
      "\n",
      "Step 192/200\n",
      "Epoch 0: Total Loss=7.6373\n",
      "Epoch 1: Total Loss=7.7739\n",
      "Epoch 2: Total Loss=7.5996\n",
      "Epoch 3: Total Loss=7.7477\n",
      "Epoch 4: Total Loss=7.9165\n",
      "Epoch 5: Total Loss=7.7989\n",
      "Epoch 6: Total Loss=7.9670\n",
      "Epoch 7: Total Loss=7.7674\n",
      "Epoch 8: Total Loss=7.9826\n",
      "Epoch 9: Total Loss=7.7404\n",
      "Updated x: [0.011995956301689148, 0.06583262979984283], Function Value: 0.0044778380542993546, Gradient: [-0.009400663897395134, 0.008427844382822514]\n",
      "\n",
      "Step 193/200\n",
      "Epoch 0: Total Loss=7.8092\n",
      "Epoch 1: Total Loss=7.7114\n",
      "Epoch 2: Total Loss=7.7671\n",
      "Epoch 3: Total Loss=7.9138\n",
      "Epoch 4: Total Loss=7.8649\n",
      "Epoch 5: Total Loss=7.8785\n",
      "Epoch 6: Total Loss=7.8924\n",
      "Epoch 7: Total Loss=7.8418\n",
      "Epoch 8: Total Loss=8.0393\n",
      "Epoch 9: Total Loss=7.8955\n",
      "Updated x: [0.04584158957004547, 0.15959733724594116], Function Value: 0.027572760358452797, Gradient: [-0.030624674633145332, 0.035343822091817856]\n",
      "\n",
      "Step 194/200\n",
      "Epoch 0: Total Loss=7.9183\n",
      "Epoch 1: Total Loss=7.7469\n",
      "Epoch 2: Total Loss=7.6961\n",
      "Epoch 3: Total Loss=7.9353\n",
      "Epoch 4: Total Loss=7.7818\n",
      "Epoch 5: Total Loss=7.9249\n",
      "Epoch 6: Total Loss=7.7318\n",
      "Epoch 7: Total Loss=8.0067\n",
      "Epoch 8: Total Loss=7.6313\n",
      "Epoch 9: Total Loss=8.1436\n",
      "Updated x: [-0.13235872983932495, -0.06932036578655243], Function Value: 0.022324146702885628, Gradient: [-0.0012297331122681499, 0.024677084758877754]\n",
      "\n",
      "Step 195/200\n",
      "Epoch 0: Total Loss=8.0391\n",
      "Epoch 1: Total Loss=8.0567\n",
      "Epoch 2: Total Loss=8.2408\n",
      "Epoch 3: Total Loss=7.9335\n",
      "Epoch 4: Total Loss=7.8900\n",
      "Epoch 5: Total Loss=7.9351\n",
      "Epoch 6: Total Loss=7.7127\n",
      "Epoch 7: Total Loss=7.8174\n",
      "Epoch 8: Total Loss=7.5631\n",
      "Epoch 9: Total Loss=7.7470\n",
      "Updated x: [-0.041343413293361664, -0.005838923156261444], Function Value: 0.0017433708999305964, Gradient: [-0.006008173804730177, 0.02578483708202839]\n",
      "\n",
      "Step 196/200\n",
      "Epoch 0: Total Loss=7.9280\n",
      "Epoch 1: Total Loss=7.7154\n",
      "Epoch 2: Total Loss=7.6377\n",
      "Epoch 3: Total Loss=8.0123\n",
      "Epoch 4: Total Loss=7.8700\n",
      "Epoch 5: Total Loss=7.7341\n",
      "Epoch 6: Total Loss=8.0443\n",
      "Epoch 7: Total Loss=7.7714\n",
      "Epoch 8: Total Loss=7.9309\n",
      "Epoch 9: Total Loss=7.8084\n",
      "Updated x: [0.005635742098093033, -0.01713409274816513], Function Value: 0.00032533874036744237, Gradient: [-0.011513627134263515, 0.009266830049455166]\n",
      "\n",
      "Step 197/200\n",
      "Epoch 0: Total Loss=7.6749\n",
      "Epoch 1: Total Loss=7.9742\n",
      "Epoch 2: Total Loss=7.7669\n",
      "Epoch 3: Total Loss=7.7869\n",
      "Epoch 4: Total Loss=7.9437\n",
      "Epoch 5: Total Loss=7.8531\n",
      "Epoch 6: Total Loss=7.8931\n",
      "Epoch 7: Total Loss=7.7481\n",
      "Epoch 8: Total Loss=7.7870\n",
      "Epoch 9: Total Loss=7.7590\n",
      "Updated x: [-0.031684793531894684, -0.0384320504963398], Function Value: 0.0024809488095343113, Gradient: [-0.010300634428858757, 0.007814656011760235]\n",
      "\n",
      "Step 198/200\n",
      "Epoch 0: Total Loss=7.7768\n",
      "Epoch 1: Total Loss=7.5808\n",
      "Epoch 2: Total Loss=7.6166\n",
      "Epoch 3: Total Loss=7.7847\n",
      "Epoch 4: Total Loss=7.8539\n",
      "Epoch 5: Total Loss=7.7390\n",
      "Epoch 6: Total Loss=7.8076\n",
      "Epoch 7: Total Loss=7.7270\n",
      "Epoch 8: Total Loss=7.7799\n",
      "Epoch 9: Total Loss=7.8954\n",
      "Updated x: [-0.10444318503141403, -0.004310566931962967], Function Value: 0.010926960036158562, Gradient: [-0.011839949525892735, 0.010304749943315983]\n",
      "\n",
      "Step 199/200\n",
      "Epoch 0: Total Loss=7.8947\n",
      "Epoch 1: Total Loss=7.6436\n",
      "Epoch 2: Total Loss=7.8645\n",
      "Epoch 3: Total Loss=7.7547\n",
      "Epoch 4: Total Loss=7.7148\n",
      "Epoch 5: Total Loss=8.3296\n",
      "Epoch 6: Total Loss=7.8482\n",
      "Epoch 7: Total Loss=7.7639\n",
      "Epoch 8: Total Loss=7.8173\n",
      "Epoch 9: Total Loss=7.6937\n",
      "Updated x: [-0.08955571055412292, -0.0019594519399106503], Function Value: 0.0080240648239851, Gradient: [-0.011251742020249367, 0.010173732414841652]\n",
      "\n",
      "Step 200/200\n",
      "Epoch 0: Total Loss=8.0067\n",
      "Epoch 1: Total Loss=7.9802\n",
      "Epoch 2: Total Loss=7.8829\n",
      "Epoch 3: Total Loss=8.0092\n",
      "Epoch 4: Total Loss=7.8023\n",
      "Epoch 5: Total Loss=7.8501\n",
      "Epoch 6: Total Loss=7.7981\n",
      "Epoch 7: Total Loss=8.1856\n",
      "Epoch 8: Total Loss=7.8062\n",
      "Epoch 9: Total Loss=7.9126\n",
      "Updated x: [-0.06448338180780411, 0.01680837757885456], Function Value: 0.004440627992153168, Gradient: [-0.011020062491297722, 0.010129856877028942]\n",
      "\n",
      "Step 1/200\n",
      "Epoch 0: Total Loss=81783.5664\n",
      "Epoch 1: Total Loss=81042.9805\n",
      "Epoch 2: Total Loss=81748.1562\n",
      "Epoch 3: Total Loss=81008.5977\n",
      "Epoch 4: Total Loss=81714.3633\n",
      "Epoch 5: Total Loss=80975.9727\n",
      "Epoch 6: Total Loss=81682.4492\n",
      "Epoch 7: Total Loss=80945.4023\n",
      "Epoch 8: Total Loss=81652.8320\n",
      "Epoch 9: Total Loss=80917.3047\n",
      "Updated x: [9.913610458374023, -9.873135566711426], Function Value: 195.75848388671875, Gradient: [0.01712724007666111, 0.04173462465405464]\n",
      "\n",
      "Step 2/200\n",
      "Epoch 0: Total Loss=77505.5625\n",
      "Epoch 1: Total Loss=76575.0781\n",
      "Epoch 2: Total Loss=77437.0117\n",
      "Epoch 3: Total Loss=76677.7734\n",
      "Epoch 4: Total Loss=77456.5273\n",
      "Epoch 5: Total Loss=76614.8555\n",
      "Epoch 6: Total Loss=77393.7227\n",
      "Epoch 7: Total Loss=76595.1406\n",
      "Epoch 8: Total Loss=77416.4961\n",
      "Epoch 9: Total Loss=76490.5156\n",
      "Updated x: [9.6680269241333, -9.902178764343262], Function Value: 191.52389526367188, Gradient: [0.0124374283477664, 0.026807432994246483]\n",
      "\n",
      "Step 3/200\n",
      "Epoch 0: Total Loss=513.3992\n",
      "Epoch 1: Total Loss=573.7737\n",
      "Epoch 2: Total Loss=634.4893\n",
      "Epoch 3: Total Loss=607.3545\n",
      "Epoch 4: Total Loss=472.6382\n",
      "Epoch 5: Total Loss=643.5953\n",
      "Epoch 6: Total Loss=555.3291\n",
      "Epoch 7: Total Loss=557.7558\n",
      "Epoch 8: Total Loss=616.0000\n",
      "Epoch 9: Total Loss=506.9359\n",
      "Updated x: [9.664285659790039, -9.764530181884766], Function Value: 188.7444610595703, Gradient: [0.003302214201539755, 0.003672725521028042]\n",
      "\n",
      "Step 4/200\n",
      "Epoch 0: Total Loss=615.6472\n",
      "Epoch 1: Total Loss=585.8148\n",
      "Epoch 2: Total Loss=542.7877\n",
      "Epoch 3: Total Loss=444.4964\n",
      "Epoch 4: Total Loss=556.3140\n",
      "Epoch 5: Total Loss=616.1967\n",
      "Epoch 6: Total Loss=583.7554\n",
      "Epoch 7: Total Loss=539.1925\n",
      "Epoch 8: Total Loss=583.0546\n",
      "Epoch 9: Total Loss=461.9796\n",
      "Updated x: [9.562692642211914, -9.788376808166504], Function Value: 187.25741577148438, Gradient: [-0.01344794500619173, -0.016335364431142807]\n",
      "\n",
      "Step 5/200\n",
      "Epoch 0: Total Loss=448.0502\n",
      "Epoch 1: Total Loss=457.5254\n",
      "Epoch 2: Total Loss=502.2700\n",
      "Epoch 3: Total Loss=553.7770\n",
      "Epoch 4: Total Loss=482.6866\n",
      "Epoch 5: Total Loss=610.6683\n",
      "Epoch 6: Total Loss=580.7349\n",
      "Epoch 7: Total Loss=617.9595\n",
      "Epoch 8: Total Loss=588.9170\n",
      "Epoch 9: Total Loss=505.9512\n",
      "Updated x: [9.501423835754395, -9.653120040893555], Function Value: 183.45977783203125, Gradient: [-0.02650531381368637, -0.03874892368912697]\n",
      "\n",
      "Step 6/200\n",
      "Epoch 0: Total Loss=584.1427\n",
      "Epoch 1: Total Loss=506.3152\n",
      "Epoch 2: Total Loss=558.7859\n",
      "Epoch 3: Total Loss=490.1125\n",
      "Epoch 4: Total Loss=489.8309\n",
      "Epoch 5: Total Loss=489.9287\n",
      "Epoch 6: Total Loss=529.2762\n",
      "Epoch 7: Total Loss=621.4732\n",
      "Epoch 8: Total Loss=530.2881\n",
      "Epoch 9: Total Loss=497.4152\n",
      "Updated x: [9.327890396118164, -9.692155838012695], Function Value: 180.94741821289062, Gradient: [-0.046610135585069656, -0.055971577763557434]\n",
      "\n",
      "Step 7/200\n",
      "Epoch 0: Total Loss=583.5616\n",
      "Epoch 1: Total Loss=508.7781\n",
      "Epoch 2: Total Loss=495.9813\n",
      "Epoch 3: Total Loss=616.3614\n",
      "Epoch 4: Total Loss=620.8246\n",
      "Epoch 5: Total Loss=536.4875\n",
      "Epoch 6: Total Loss=540.2795\n",
      "Epoch 7: Total Loss=573.0023\n",
      "Epoch 8: Total Loss=526.4620\n",
      "Epoch 9: Total Loss=575.5700\n",
      "Updated x: [9.176674842834473, -9.693520545959473], Function Value: 178.1757049560547, Gradient: [-0.05813659727573395, -0.07191526889801025]\n",
      "\n",
      "Step 8/200\n",
      "Epoch 0: Total Loss=571.2787\n",
      "Epoch 1: Total Loss=612.3203\n",
      "Epoch 2: Total Loss=580.2413\n",
      "Epoch 3: Total Loss=570.1639\n",
      "Epoch 4: Total Loss=611.6781\n",
      "Epoch 5: Total Loss=632.1255\n",
      "Epoch 6: Total Loss=580.1666\n",
      "Epoch 7: Total Loss=546.6760\n",
      "Epoch 8: Total Loss=572.5575\n",
      "Epoch 9: Total Loss=632.9576\n",
      "Updated x: [9.173028945922852, -9.547354698181152], Function Value: 175.29644775390625, Gradient: [-0.08772840350866318, -0.10282056778669357]\n",
      "\n",
      "Step 9/200\n",
      "Epoch 0: Total Loss=530.1190\n",
      "Epoch 1: Total Loss=589.3729\n",
      "Epoch 2: Total Loss=575.0829\n",
      "Epoch 3: Total Loss=614.1644\n",
      "Epoch 4: Total Loss=453.1536\n",
      "Epoch 5: Total Loss=565.4972\n",
      "Epoch 6: Total Loss=484.2225\n",
      "Epoch 7: Total Loss=678.8344\n",
      "Epoch 8: Total Loss=535.1672\n",
      "Epoch 9: Total Loss=491.4152\n",
      "Updated x: [8.990199089050293, -9.591008186340332], Function Value: 172.8111114501953, Gradient: [-0.12606963515281677, -0.13674284517765045]\n",
      "\n",
      "Step 10/200\n",
      "Epoch 0: Total Loss=567.9336\n",
      "Epoch 1: Total Loss=527.5365\n",
      "Epoch 2: Total Loss=517.8385\n",
      "Epoch 3: Total Loss=576.3644\n",
      "Epoch 4: Total Loss=527.2509\n",
      "Epoch 5: Total Loss=624.3915\n",
      "Epoch 6: Total Loss=578.4334\n",
      "Epoch 7: Total Loss=481.8250\n",
      "Epoch 8: Total Loss=490.3651\n",
      "Epoch 9: Total Loss=547.6102\n",
      "Updated x: [8.865683555603027, -9.551898002624512], Function Value: 169.83909606933594, Gradient: [-0.15609700977802277, -0.17656011879444122]\n",
      "\n",
      "Step 11/200\n",
      "Epoch 0: Total Loss=575.2053\n",
      "Epoch 1: Total Loss=572.2204\n",
      "Epoch 2: Total Loss=505.4162\n",
      "Epoch 3: Total Loss=534.5152\n",
      "Epoch 4: Total Loss=531.5245\n",
      "Epoch 5: Total Loss=482.8962\n",
      "Epoch 6: Total Loss=488.6926\n",
      "Epoch 7: Total Loss=588.9274\n",
      "Epoch 8: Total Loss=482.7819\n",
      "Epoch 9: Total Loss=495.6549\n",
      "Updated x: [8.737234115600586, -9.514015197753906], Function Value: 166.85574340820312, Gradient: [-0.1935187131166458, -0.22824209928512573]\n",
      "\n",
      "Step 12/200\n",
      "Epoch 0: Total Loss=57326.5137\n",
      "Epoch 1: Total Loss=55540.1914\n",
      "Epoch 2: Total Loss=57198.7031\n",
      "Epoch 3: Total Loss=55423.2988\n",
      "Epoch 4: Total Loss=57086.3770\n",
      "Epoch 5: Total Loss=55320.9473\n",
      "Epoch 6: Total Loss=56988.0742\n",
      "Epoch 7: Total Loss=55231.0508\n",
      "Epoch 8: Total Loss=56901.2832\n",
      "Epoch 9: Total Loss=55150.7676\n",
      "Updated x: [8.640091896057129, -9.421890258789062], Function Value: 163.4232177734375, Gradient: [-0.11045653373003006, -0.20144373178482056]\n",
      "\n",
      "Step 13/200\n",
      "Epoch 0: Total Loss=37.8403\n",
      "Epoch 1: Total Loss=42.8130\n",
      "Epoch 2: Total Loss=44.4827\n",
      "Epoch 3: Total Loss=38.5495\n",
      "Epoch 4: Total Loss=19.6180\n",
      "Epoch 5: Total Loss=65.1729\n",
      "Epoch 6: Total Loss=23.9602\n",
      "Epoch 7: Total Loss=37.4940\n",
      "Epoch 8: Total Loss=42.5648\n",
      "Epoch 9: Total Loss=44.2773\n",
      "Updated x: [8.533912658691406, -9.215163230895996], Function Value: 157.7469024658203, Gradient: [-0.19087085127830505, -0.23203927278518677]\n",
      "\n",
      "Step 14/200\n",
      "Epoch 0: Total Loss=18.1309\n",
      "Epoch 1: Total Loss=30.4716\n",
      "Epoch 2: Total Loss=28.7324\n",
      "Epoch 3: Total Loss=27.3684\n",
      "Epoch 4: Total Loss=38.0256\n",
      "Epoch 5: Total Loss=21.4656\n",
      "Epoch 6: Total Loss=32.0198\n",
      "Epoch 7: Total Loss=21.1593\n",
      "Epoch 8: Total Loss=32.6764\n",
      "Epoch 9: Total Loss=21.7979\n",
      "Updated x: [8.393503189086914, -9.148323059082031], Function Value: 154.14271545410156, Gradient: [-0.22372636198997498, -0.2550998032093048]\n",
      "\n",
      "Step 15/200\n",
      "Epoch 0: Total Loss=16.3170\n",
      "Epoch 1: Total Loss=29.3052\n",
      "Epoch 2: Total Loss=45.6328\n",
      "Epoch 3: Total Loss=34.3968\n",
      "Epoch 4: Total Loss=16.5461\n",
      "Epoch 5: Total Loss=30.8960\n",
      "Epoch 6: Total Loss=25.8782\n",
      "Epoch 7: Total Loss=16.2792\n",
      "Epoch 8: Total Loss=29.2839\n",
      "Epoch 9: Total Loss=45.5777\n",
      "Updated x: [8.108699798583984, -9.134567260742188], Function Value: 149.1913299560547, Gradient: [-0.1976078748703003, -0.22341659665107727]\n",
      "\n",
      "Step 16/200\n",
      "Epoch 0: Total Loss=32.2502\n",
      "Epoch 1: Total Loss=12.8584\n",
      "Epoch 2: Total Loss=14.0634\n",
      "Epoch 3: Total Loss=33.4637\n",
      "Epoch 4: Total Loss=17.4658\n",
      "Epoch 5: Total Loss=21.6621\n",
      "Epoch 6: Total Loss=13.0822\n",
      "Epoch 7: Total Loss=17.7801\n",
      "Epoch 8: Total Loss=17.4583\n",
      "Epoch 9: Total Loss=32.1852\n",
      "Updated x: [7.909010410308838, -9.16337776184082], Function Value: 146.51992797851562, Gradient: [-0.16983449459075928, -0.18950428068637848]\n",
      "\n",
      "Step 17/200\n",
      "Epoch 0: Total Loss=21.2783\n",
      "Epoch 1: Total Loss=15.0230\n",
      "Epoch 2: Total Loss=25.2404\n",
      "Epoch 3: Total Loss=21.1163\n",
      "Epoch 4: Total Loss=16.1549\n",
      "Epoch 5: Total Loss=39.4335\n",
      "Epoch 6: Total Loss=23.9677\n",
      "Epoch 7: Total Loss=22.7642\n",
      "Epoch 8: Total Loss=23.0283\n",
      "Epoch 9: Total Loss=17.3124\n",
      "Updated x: [7.841327667236328, -9.044404029846191], Function Value: 143.28765869140625, Gradient: [-0.18143166601657867, -0.19115190207958221]\n",
      "\n",
      "Step 18/200\n",
      "Epoch 0: Total Loss=23.9635\n",
      "Epoch 1: Total Loss=37.2625\n",
      "Epoch 2: Total Loss=24.7874\n",
      "Epoch 3: Total Loss=18.0926\n",
      "Epoch 4: Total Loss=12.4270\n",
      "Epoch 5: Total Loss=29.7553\n",
      "Epoch 6: Total Loss=13.6151\n",
      "Epoch 7: Total Loss=20.6966\n",
      "Epoch 8: Total Loss=16.7060\n",
      "Epoch 9: Total Loss=35.5026\n",
      "Updated x: [7.736372947692871, -8.820716857910156], Function Value: 137.65650939941406, Gradient: [-0.17960284650325775, -0.19080880284309387]\n",
      "\n",
      "Step 19/200\n",
      "Epoch 0: Total Loss=14.1254\n",
      "Epoch 1: Total Loss=16.4869\n",
      "Epoch 2: Total Loss=22.3071\n",
      "Epoch 3: Total Loss=15.3553\n",
      "Epoch 4: Total Loss=13.5338\n",
      "Epoch 5: Total Loss=39.3350\n",
      "Epoch 6: Total Loss=13.3251\n",
      "Epoch 7: Total Loss=15.1736\n",
      "Epoch 8: Total Loss=13.8888\n",
      "Epoch 9: Total Loss=21.8464\n",
      "Updated x: [7.917786121368408, -8.638439178466797], Function Value: 137.31396484375, Gradient: [-0.20567674934864044, -0.21686527132987976]\n",
      "\n",
      "Step 20/200\n",
      "Epoch 0: Total Loss=16.4296\n",
      "Epoch 1: Total Loss=16.6262\n",
      "Epoch 2: Total Loss=19.1808\n",
      "Epoch 3: Total Loss=16.0191\n",
      "Epoch 4: Total Loss=13.9948\n",
      "Epoch 5: Total Loss=10.8582\n",
      "Epoch 6: Total Loss=17.7252\n",
      "Epoch 7: Total Loss=25.5572\n",
      "Epoch 8: Total Loss=16.2768\n",
      "Epoch 9: Total Loss=23.0524\n",
      "Updated x: [7.790400505065918, -8.503437042236328], Function Value: 132.998779296875, Gradient: [-0.20594441890716553, -0.20786114037036896]\n",
      "\n",
      "Step 21/200\n",
      "Epoch 0: Total Loss=15.8221\n",
      "Epoch 1: Total Loss=12.8474\n",
      "Epoch 2: Total Loss=15.9013\n",
      "Epoch 3: Total Loss=13.9744\n",
      "Epoch 4: Total Loss=24.1735\n",
      "Epoch 5: Total Loss=13.5380\n",
      "Epoch 6: Total Loss=17.8878\n",
      "Epoch 7: Total Loss=14.8572\n",
      "Epoch 8: Total Loss=21.0378\n",
      "Epoch 9: Total Loss=15.5573\n",
      "Updated x: [7.804856777191162, -8.402713775634766], Function Value: 131.52139282226562, Gradient: [-0.1992577612400055, -0.20197483897209167]\n",
      "\n",
      "Step 22/200\n",
      "Epoch 0: Total Loss=51584.6660\n",
      "Epoch 1: Total Loss=51823.1465\n",
      "Epoch 2: Total Loss=51997.4785\n",
      "Epoch 3: Total Loss=51067.4668\n",
      "Epoch 4: Total Loss=51261.9844\n",
      "Epoch 5: Total Loss=51522.5156\n",
      "Epoch 6: Total Loss=51720.5664\n",
      "Epoch 7: Total Loss=50815.9707\n",
      "Epoch 8: Total Loss=51028.4863\n",
      "Epoch 9: Total Loss=51303.8184\n",
      "Updated x: [7.560886383056641, -8.438054084777832], Function Value: 128.36776733398438, Gradient: [-0.09613971412181854, -0.18574130535125732]\n",
      "\n",
      "Step 23/200\n",
      "Epoch 0: Total Loss=40.9385\n",
      "Epoch 1: Total Loss=44.5074\n",
      "Epoch 2: Total Loss=47.7544\n",
      "Epoch 3: Total Loss=34.8769\n",
      "Epoch 4: Total Loss=54.7982\n",
      "Epoch 5: Total Loss=31.9653\n",
      "Epoch 6: Total Loss=54.1345\n",
      "Epoch 7: Total Loss=39.4186\n",
      "Epoch 8: Total Loss=45.1610\n",
      "Epoch 9: Total Loss=46.3988\n",
      "Updated x: [7.383870601654053, -8.373871803283691], Function Value: 124.64327239990234, Gradient: [-0.17480351030826569, -0.18946103751659393]\n",
      "\n",
      "Step 24/200\n",
      "Epoch 0: Total Loss=41.0856\n",
      "Epoch 1: Total Loss=33.4623\n",
      "Epoch 2: Total Loss=29.5584\n",
      "Epoch 3: Total Loss=60.5776\n",
      "Epoch 4: Total Loss=32.3118\n",
      "Epoch 5: Total Loss=31.1462\n",
      "Epoch 6: Total Loss=34.2052\n",
      "Epoch 7: Total Loss=64.4012\n",
      "Epoch 8: Total Loss=29.0020\n",
      "Epoch 9: Total Loss=28.0927\n",
      "Updated x: [7.231780529022217, -8.259092330932617], Function Value: 120.51126098632812, Gradient: [-0.11632392555475235, -0.1278940588235855]\n",
      "\n",
      "Step 25/200\n",
      "Epoch 0: Total Loss=58.1376\n",
      "Epoch 1: Total Loss=34.4936\n",
      "Epoch 2: Total Loss=24.0807\n",
      "Epoch 3: Total Loss=27.3541\n",
      "Epoch 4: Total Loss=50.1034\n",
      "Epoch 5: Total Loss=40.8409\n",
      "Epoch 6: Total Loss=24.9292\n",
      "Epoch 7: Total Loss=25.2799\n",
      "Epoch 8: Total Loss=27.7377\n",
      "Epoch 9: Total Loss=57.9616\n",
      "Updated x: [7.2458367347717285, -7.934140682220459], Function Value: 115.45274353027344, Gradient: [-0.1154422014951706, -0.12511326372623444]\n",
      "\n",
      "Step 26/200\n",
      "Epoch 0: Total Loss=26.3503\n",
      "Epoch 1: Total Loss=28.9135\n",
      "Epoch 2: Total Loss=45.3681\n",
      "Epoch 3: Total Loss=25.4989\n",
      "Epoch 4: Total Loss=26.1092\n",
      "Epoch 5: Total Loss=21.6304\n",
      "Epoch 6: Total Loss=26.8503\n",
      "Epoch 7: Total Loss=28.8630\n",
      "Epoch 8: Total Loss=45.0150\n",
      "Epoch 9: Total Loss=24.9700\n",
      "Updated x: [7.219354152679443, -7.93381929397583], Function Value: 115.06455993652344, Gradient: [-0.1002376601099968, -0.10980518162250519]\n",
      "\n",
      "Step 27/200\n",
      "Epoch 0: Total Loss=23.2988\n",
      "Epoch 1: Total Loss=23.6874\n",
      "Epoch 2: Total Loss=28.2220\n",
      "Epoch 3: Total Loss=26.7169\n",
      "Epoch 4: Total Loss=22.5629\n",
      "Epoch 5: Total Loss=25.9879\n",
      "Epoch 6: Total Loss=27.5851\n",
      "Epoch 7: Total Loss=23.9480\n",
      "Epoch 8: Total Loss=24.0367\n",
      "Epoch 9: Total Loss=27.8460\n",
      "Updated x: [7.112705230712891, -7.809928894042969], Function Value: 111.58556365966797, Gradient: [-0.08628089725971222, -0.09456689655780792]\n",
      "\n",
      "Step 28/200\n",
      "Epoch 0: Total Loss=21.3946\n",
      "Epoch 1: Total Loss=13.6483\n",
      "Epoch 2: Total Loss=25.6274\n",
      "Epoch 3: Total Loss=24.4244\n",
      "Epoch 4: Total Loss=24.5060\n",
      "Epoch 5: Total Loss=27.6940\n",
      "Epoch 6: Total Loss=20.1282\n",
      "Epoch 7: Total Loss=20.5760\n",
      "Epoch 8: Total Loss=12.4271\n",
      "Epoch 9: Total Loss=21.7514\n",
      "Updated x: [7.099099159240723, -7.743005275726318], Function Value: 110.3513412475586, Gradient: [-0.06623079627752304, -0.08078926056623459]\n",
      "\n",
      "Step 29/200\n",
      "Epoch 0: Total Loss=8.9651\n",
      "Epoch 1: Total Loss=19.6533\n",
      "Epoch 2: Total Loss=28.1313\n",
      "Epoch 3: Total Loss=21.2902\n",
      "Epoch 4: Total Loss=19.4501\n",
      "Epoch 5: Total Loss=22.3465\n",
      "Epoch 6: Total Loss=30.9647\n",
      "Epoch 7: Total Loss=34.3386\n",
      "Epoch 8: Total Loss=13.8291\n",
      "Epoch 9: Total Loss=11.6937\n",
      "Updated x: [6.941781044006348, -7.608015537261963], Function Value: 106.07022094726562, Gradient: [-0.066538967192173, -0.075249083340168]\n",
      "\n",
      "Step 30/200\n",
      "Epoch 0: Total Loss=23.7029\n",
      "Epoch 1: Total Loss=12.7276\n",
      "Epoch 2: Total Loss=27.7936\n",
      "Epoch 3: Total Loss=16.1668\n",
      "Epoch 4: Total Loss=18.8880\n",
      "Epoch 5: Total Loss=37.7020\n",
      "Epoch 6: Total Loss=18.6164\n",
      "Epoch 7: Total Loss=18.8284\n",
      "Epoch 8: Total Loss=21.3835\n",
      "Epoch 9: Total Loss=18.2696\n",
      "Updated x: [6.899352073669434, -7.53452730178833], Function Value: 104.37016296386719, Gradient: [-0.06473084539175034, -0.08213125914335251]\n",
      "\n",
      "Step 31/200\n",
      "Epoch 0: Total Loss=19.9466\n",
      "Epoch 1: Total Loss=12.6470\n",
      "Epoch 2: Total Loss=27.7175\n",
      "Epoch 3: Total Loss=21.4300\n",
      "Epoch 4: Total Loss=23.3007\n",
      "Epoch 5: Total Loss=12.9277\n",
      "Epoch 6: Total Loss=18.5716\n",
      "Epoch 7: Total Loss=26.3014\n",
      "Epoch 8: Total Loss=20.7465\n",
      "Epoch 9: Total Loss=19.2032\n",
      "Updated x: [6.865297794342041, -7.447854042053223], Function Value: 102.60284423828125, Gradient: [-0.07014317810535431, -0.08646617084741592]\n",
      "\n",
      "Step 32/200\n",
      "Epoch 0: Total Loss=31571.7188\n",
      "Epoch 1: Total Loss=31926.8633\n",
      "Epoch 2: Total Loss=31513.1934\n",
      "Epoch 3: Total Loss=32273.1055\n",
      "Epoch 4: Total Loss=31474.8525\n",
      "Epoch 5: Total Loss=31835.3193\n",
      "Epoch 6: Total Loss=31426.4209\n",
      "Epoch 7: Total Loss=32187.5918\n",
      "Epoch 8: Total Loss=31392.1768\n",
      "Epoch 9: Total Loss=31753.0029\n",
      "Updated x: [6.795223712921143, -7.324419021606445], Function Value: 99.82217407226562, Gradient: [-0.039541095495224, -0.08003383874893188]\n",
      "\n",
      "Step 33/200\n",
      "Epoch 0: Total Loss=20.3753\n",
      "Epoch 1: Total Loss=27.7236\n",
      "Epoch 2: Total Loss=18.7766\n",
      "Epoch 3: Total Loss=30.1876\n",
      "Epoch 4: Total Loss=17.2870\n",
      "Epoch 5: Total Loss=30.1569\n",
      "Epoch 6: Total Loss=13.6477\n",
      "Epoch 7: Total Loss=20.2803\n",
      "Epoch 8: Total Loss=27.7195\n",
      "Epoch 9: Total Loss=19.1066\n",
      "Updated x: [6.82820463180542, -7.253378391265869], Function Value: 99.23587799072266, Gradient: [-0.07498106360435486, -0.0914311334490776]\n",
      "\n",
      "Step 34/200\n",
      "Epoch 0: Total Loss=27.5513\n",
      "Epoch 1: Total Loss=11.6060\n",
      "Epoch 2: Total Loss=16.7017\n",
      "Epoch 3: Total Loss=13.4953\n",
      "Epoch 4: Total Loss=27.1072\n",
      "Epoch 5: Total Loss=12.3534\n",
      "Epoch 6: Total Loss=15.4437\n",
      "Epoch 7: Total Loss=27.7288\n",
      "Epoch 8: Total Loss=14.0338\n",
      "Epoch 9: Total Loss=15.0209\n",
      "Updated x: [6.839682102203369, -7.118542194366455], Function Value: 97.45489501953125, Gradient: [-0.08920923620462418, -0.10660769045352936]\n",
      "\n",
      "Step 35/200\n",
      "Epoch 0: Total Loss=11.9754\n",
      "Epoch 1: Total Loss=23.4290\n",
      "Epoch 2: Total Loss=14.9022\n",
      "Epoch 3: Total Loss=17.0860\n",
      "Epoch 4: Total Loss=11.8382\n",
      "Epoch 5: Total Loss=12.5156\n",
      "Epoch 6: Total Loss=25.7706\n",
      "Epoch 7: Total Loss=18.0603\n",
      "Epoch 8: Total Loss=11.5477\n",
      "Epoch 9: Total Loss=11.2619\n",
      "Updated x: [6.806126117706299, -6.94854211807251], Function Value: 94.6055908203125, Gradient: [-0.09602480381727219, -0.11096718907356262]\n",
      "\n",
      "Step 36/200\n",
      "Epoch 0: Total Loss=11.4243\n",
      "Epoch 1: Total Loss=23.4049\n",
      "Epoch 2: Total Loss=10.5085\n",
      "Epoch 3: Total Loss=11.5739\n",
      "Epoch 4: Total Loss=13.2674\n",
      "Epoch 5: Total Loss=16.1825\n",
      "Epoch 6: Total Loss=11.5672\n",
      "Epoch 7: Total Loss=23.1703\n",
      "Epoch 8: Total Loss=10.6307\n",
      "Epoch 9: Total Loss=11.2278\n",
      "Updated x: [6.839989185333252, -6.9012651443481445], Function Value: 94.41291809082031, Gradient: [-0.11369121819734573, -0.13039864599704742]\n",
      "\n",
      "Step 37/200\n",
      "Epoch 0: Total Loss=10.2816\n",
      "Epoch 1: Total Loss=12.2999\n",
      "Epoch 2: Total Loss=22.8289\n",
      "Epoch 3: Total Loss=13.1334\n",
      "Epoch 4: Total Loss=10.3404\n",
      "Epoch 5: Total Loss=19.0066\n",
      "Epoch 6: Total Loss=10.8770\n",
      "Epoch 7: Total Loss=10.0266\n",
      "Epoch 8: Total Loss=12.4279\n",
      "Epoch 9: Total Loss=23.2609\n",
      "Updated x: [6.62202262878418, -6.815154075622559], Function Value: 90.2975082397461, Gradient: [-0.10723838210105896, -0.12556567788124084]\n",
      "\n",
      "Step 38/200\n",
      "Epoch 0: Total Loss=16.9070\n",
      "Epoch 1: Total Loss=26.9303\n",
      "Epoch 2: Total Loss=11.0154\n",
      "Epoch 3: Total Loss=14.6186\n",
      "Epoch 4: Total Loss=9.6988\n",
      "Epoch 5: Total Loss=12.7531\n",
      "Epoch 6: Total Loss=29.4179\n",
      "Epoch 7: Total Loss=24.2511\n",
      "Epoch 8: Total Loss=11.7209\n",
      "Epoch 9: Total Loss=27.7878\n",
      "Updated x: [6.348123550415039, -6.789802074432373], Function Value: 86.40008544921875, Gradient: [-0.08368578553199768, -0.1035468652844429]\n",
      "\n",
      "Step 39/200\n",
      "Epoch 0: Total Loss=13.7918\n",
      "Epoch 1: Total Loss=15.4996\n",
      "Epoch 2: Total Loss=15.0180\n",
      "Epoch 3: Total Loss=15.8260\n",
      "Epoch 4: Total Loss=15.5638\n",
      "Epoch 5: Total Loss=26.3721\n",
      "Epoch 6: Total Loss=15.8668\n",
      "Epoch 7: Total Loss=11.2711\n",
      "Epoch 8: Total Loss=14.4585\n",
      "Epoch 9: Total Loss=13.4842\n",
      "Updated x: [6.332108020782471, -6.721940517425537], Function Value: 85.28007507324219, Gradient: [-0.0713067278265953, -0.08939788490533829]\n",
      "\n",
      "Step 40/200\n",
      "Epoch 0: Total Loss=11.8847\n",
      "Epoch 1: Total Loss=19.6726\n",
      "Epoch 2: Total Loss=15.3613\n",
      "Epoch 3: Total Loss=13.7139\n",
      "Epoch 4: Total Loss=23.4463\n",
      "Epoch 5: Total Loss=12.7562\n",
      "Epoch 6: Total Loss=10.2911\n",
      "Epoch 7: Total Loss=11.9342\n",
      "Epoch 8: Total Loss=12.2848\n",
      "Epoch 9: Total Loss=13.4510\n",
      "Updated x: [6.246167182922363, -6.582615375518799], Function Value: 82.34542846679688, Gradient: [-0.0729198232293129, -0.08915552496910095]\n",
      "\n",
      "Step 41/200\n",
      "Epoch 0: Total Loss=18.1085\n",
      "Epoch 1: Total Loss=11.1807\n",
      "Epoch 2: Total Loss=10.5300\n",
      "Epoch 3: Total Loss=11.9578\n",
      "Epoch 4: Total Loss=9.8218\n",
      "Epoch 5: Total Loss=11.7257\n",
      "Epoch 6: Total Loss=11.1623\n",
      "Epoch 7: Total Loss=31.8218\n",
      "Epoch 8: Total Loss=11.5290\n",
      "Epoch 9: Total Loss=15.2938\n",
      "Updated x: [6.151784896850586, -6.446626663208008], Function Value: 79.40345001220703, Gradient: [-0.0906737893819809, -0.11218566447496414]\n",
      "\n",
      "Step 42/200\n",
      "Epoch 0: Total Loss=19127.2705\n",
      "Epoch 1: Total Loss=18440.5488\n",
      "Epoch 2: Total Loss=18597.2520\n",
      "Epoch 3: Total Loss=18713.5063\n",
      "Epoch 4: Total Loss=19052.8569\n",
      "Epoch 5: Total Loss=18374.0938\n",
      "Epoch 6: Total Loss=18535.6484\n",
      "Epoch 7: Total Loss=18655.8447\n",
      "Epoch 8: Total Loss=18997.4404\n",
      "Epoch 9: Total Loss=18321.9165\n",
      "Updated x: [6.040345668792725, -6.329957008361816], Function Value: 76.55413055419922, Gradient: [-0.06305373460054398, -0.13034838438034058]\n",
      "\n",
      "Step 43/200\n",
      "Epoch 0: Total Loss=20.5916\n",
      "Epoch 1: Total Loss=35.4474\n",
      "Epoch 2: Total Loss=22.6663\n",
      "Epoch 3: Total Loss=28.4182\n",
      "Epoch 4: Total Loss=29.9197\n",
      "Epoch 5: Total Loss=26.6921\n",
      "Epoch 6: Total Loss=31.3654\n",
      "Epoch 7: Total Loss=20.3610\n",
      "Epoch 8: Total Loss=35.2799\n",
      "Epoch 9: Total Loss=22.4230\n",
      "Updated x: [5.900176525115967, -6.173424243927002], Function Value: 72.92324829101562, Gradient: [-0.06744611263275146, -0.09661954641342163]\n",
      "\n",
      "Step 44/200\n",
      "Epoch 0: Total Loss=17.4144\n",
      "Epoch 1: Total Loss=20.3802\n",
      "Epoch 2: Total Loss=25.7121\n",
      "Epoch 3: Total Loss=16.2476\n",
      "Epoch 4: Total Loss=18.5060\n",
      "Epoch 5: Total Loss=21.8747\n",
      "Epoch 6: Total Loss=20.7131\n",
      "Epoch 7: Total Loss=17.0124\n",
      "Epoch 8: Total Loss=19.5416\n",
      "Epoch 9: Total Loss=27.1606\n",
      "Updated x: [6.085611343383789, -5.94216775894165], Function Value: 72.34402465820312, Gradient: [-0.10438624769449234, -0.13326124846935272]\n",
      "\n",
      "Step 45/200\n",
      "Epoch 0: Total Loss=18.6184\n",
      "Epoch 1: Total Loss=20.5774\n",
      "Epoch 2: Total Loss=11.6851\n",
      "Epoch 3: Total Loss=14.3981\n",
      "Epoch 4: Total Loss=13.3243\n",
      "Epoch 5: Total Loss=23.9124\n",
      "Epoch 6: Total Loss=15.1269\n",
      "Epoch 7: Total Loss=11.9440\n",
      "Epoch 8: Total Loss=12.3098\n",
      "Epoch 9: Total Loss=18.9215\n",
      "Updated x: [6.108933925628662, -5.848696231842041], Function Value: 71.52632141113281, Gradient: [-0.09997016936540604, -0.12427118420600891]\n",
      "\n",
      "Step 46/200\n",
      "Epoch 0: Total Loss=17.6906\n",
      "Epoch 1: Total Loss=12.0945\n",
      "Epoch 2: Total Loss=22.3950\n",
      "Epoch 3: Total Loss=17.2409\n",
      "Epoch 4: Total Loss=15.9392\n",
      "Epoch 5: Total Loss=13.7875\n",
      "Epoch 6: Total Loss=17.6036\n",
      "Epoch 7: Total Loss=11.9569\n",
      "Epoch 8: Total Loss=22.3831\n",
      "Epoch 9: Total Loss=17.3126\n",
      "Updated x: [5.87144660949707, -5.846887588500977], Function Value: 68.65998077392578, Gradient: [-0.0824873074889183, -0.10968059301376343]\n",
      "\n",
      "Step 47/200\n",
      "Epoch 0: Total Loss=9.5972\n",
      "Epoch 1: Total Loss=17.3515\n",
      "Epoch 2: Total Loss=19.8568\n",
      "Epoch 3: Total Loss=15.4373\n",
      "Epoch 4: Total Loss=18.1522\n",
      "Epoch 5: Total Loss=12.9484\n",
      "Epoch 6: Total Loss=21.1000\n",
      "Epoch 7: Total Loss=9.6258\n",
      "Epoch 8: Total Loss=17.2067\n",
      "Epoch 9: Total Loss=19.7431\n",
      "Updated x: [5.6938982009887695, -5.873366832733154], Function Value: 66.91691589355469, Gradient: [-0.0716426894068718, -0.09990545362234116]\n",
      "\n",
      "Step 48/200\n",
      "Epoch 0: Total Loss=10.5356\n",
      "Epoch 1: Total Loss=11.8247\n",
      "Epoch 2: Total Loss=17.1713\n",
      "Epoch 3: Total Loss=15.3284\n",
      "Epoch 4: Total Loss=13.9911\n",
      "Epoch 5: Total Loss=14.7167\n",
      "Epoch 6: Total Loss=17.6069\n",
      "Epoch 7: Total Loss=16.4552\n",
      "Epoch 8: Total Loss=10.0239\n",
      "Epoch 9: Total Loss=10.1333\n",
      "Updated x: [5.531400203704834, -5.936157703399658], Function Value: 65.83435821533203, Gradient: [-0.07997678965330124, -0.11277906596660614]\n",
      "\n",
      "Step 49/200\n",
      "Epoch 0: Total Loss=11.8217\n",
      "Epoch 1: Total Loss=12.0792\n",
      "Epoch 2: Total Loss=14.9820\n",
      "Epoch 3: Total Loss=18.5031\n",
      "Epoch 4: Total Loss=13.5707\n",
      "Epoch 5: Total Loss=18.4093\n",
      "Epoch 6: Total Loss=15.1761\n",
      "Epoch 7: Total Loss=11.1425\n",
      "Epoch 8: Total Loss=14.4134\n",
      "Epoch 9: Total Loss=11.9765\n",
      "Updated x: [5.519091606140137, -5.751903057098389], Function Value: 63.544761657714844, Gradient: [-0.07678372412919998, -0.10901492089033127]\n",
      "\n",
      "Step 50/200\n",
      "Epoch 0: Total Loss=16.2346\n",
      "Epoch 1: Total Loss=13.9456\n",
      "Epoch 2: Total Loss=10.7761\n",
      "Epoch 3: Total Loss=12.7409\n",
      "Epoch 4: Total Loss=13.8737\n",
      "Epoch 5: Total Loss=12.6164\n",
      "Epoch 6: Total Loss=11.0381\n",
      "Epoch 7: Total Loss=12.9798\n",
      "Epoch 8: Total Loss=14.2046\n",
      "Epoch 9: Total Loss=17.5157\n",
      "Updated x: [5.423543453216553, -5.813164234161377], Function Value: 63.20770263671875, Gradient: [-0.06985358148813248, -0.09956400841474533]\n",
      "\n",
      "Step 51/200\n",
      "Epoch 0: Total Loss=10.6629\n",
      "Epoch 1: Total Loss=14.1143\n",
      "Epoch 2: Total Loss=12.4942\n",
      "Epoch 3: Total Loss=15.8569\n",
      "Epoch 4: Total Loss=12.6699\n",
      "Epoch 5: Total Loss=13.4193\n",
      "Epoch 6: Total Loss=12.8108\n",
      "Epoch 7: Total Loss=14.9575\n",
      "Epoch 8: Total Loss=11.1930\n",
      "Epoch 9: Total Loss=11.1235\n",
      "Updated x: [5.228899955749512, -5.79986047744751], Function Value: 60.979774475097656, Gradient: [-0.0566430501639843, -0.08860237896442413]\n",
      "\n",
      "Step 52/200\n",
      "Epoch 0: Total Loss=11399.0688\n",
      "Epoch 1: Total Loss=11439.5466\n",
      "Epoch 2: Total Loss=11405.5503\n",
      "Epoch 3: Total Loss=11213.1777\n",
      "Epoch 4: Total Loss=11357.6951\n",
      "Epoch 5: Total Loss=11399.5789\n",
      "Epoch 6: Total Loss=11366.1589\n",
      "Epoch 7: Total Loss=11174.4475\n",
      "Epoch 8: Total Loss=11318.4387\n",
      "Epoch 9: Total Loss=11360.0222\n",
      "Updated x: [5.107293128967285, -5.86959171295166], Function Value: 60.53655242919922, Gradient: [-0.0515323132276535, -0.11450734734535217]\n",
      "\n",
      "Step 53/200\n",
      "Epoch 0: Total Loss=12.2720\n",
      "Epoch 1: Total Loss=16.4545\n",
      "Epoch 2: Total Loss=12.9329\n",
      "Epoch 3: Total Loss=15.1268\n",
      "Epoch 4: Total Loss=11.9145\n",
      "Epoch 5: Total Loss=15.2761\n",
      "Epoch 6: Total Loss=13.5582\n",
      "Epoch 7: Total Loss=12.1312\n",
      "Epoch 8: Total Loss=16.3353\n",
      "Epoch 9: Total Loss=12.8287\n",
      "Updated x: [4.948641300201416, -5.80372428894043], Function Value: 58.172264099121094, Gradient: [-0.04854559153318405, -0.0698760375380516]\n",
      "\n",
      "Step 54/200\n",
      "Epoch 0: Total Loss=12.9666\n",
      "Epoch 1: Total Loss=19.2794\n",
      "Epoch 2: Total Loss=11.2348\n",
      "Epoch 3: Total Loss=11.1104\n",
      "Epoch 4: Total Loss=12.0378\n",
      "Epoch 5: Total Loss=19.4526\n",
      "Epoch 6: Total Loss=11.3634\n",
      "Epoch 7: Total Loss=11.1310\n",
      "Epoch 8: Total Loss=20.4275\n",
      "Epoch 9: Total Loss=10.9540\n",
      "Updated x: [4.890890598297119, -5.641425132751465], Function Value: 55.746490478515625, Gradient: [-0.04978633671998978, -0.08281490206718445]\n",
      "\n",
      "Step 55/200\n",
      "Epoch 0: Total Loss=12.0992\n",
      "Epoch 1: Total Loss=12.2960\n",
      "Epoch 2: Total Loss=14.9280\n",
      "Epoch 3: Total Loss=15.1620\n",
      "Epoch 4: Total Loss=11.6087\n",
      "Epoch 5: Total Loss=13.5023\n",
      "Epoch 6: Total Loss=12.0416\n",
      "Epoch 7: Total Loss=16.7518\n",
      "Epoch 8: Total Loss=13.0199\n",
      "Epoch 9: Total Loss=11.9342\n",
      "Updated x: [4.824380874633789, -5.59794807434082], Function Value: 54.611671447753906, Gradient: [-0.05902785807847977, -0.09402935206890106]\n",
      "\n",
      "Step 56/200\n",
      "Epoch 0: Total Loss=12.0769\n",
      "Epoch 1: Total Loss=11.2040\n",
      "Epoch 2: Total Loss=18.4223\n",
      "Epoch 3: Total Loss=13.6635\n",
      "Epoch 4: Total Loss=11.9087\n",
      "Epoch 5: Total Loss=11.4528\n",
      "Epoch 6: Total Loss=12.0728\n",
      "Epoch 7: Total Loss=11.2239\n",
      "Epoch 8: Total Loss=18.4009\n",
      "Epoch 9: Total Loss=13.6524\n",
      "Updated x: [4.682368755340576, -5.429651260375977], Function Value: 51.40569305419922, Gradient: [-0.08215634524822235, -0.12444431334733963]\n",
      "\n",
      "Step 57/200\n",
      "Epoch 0: Total Loss=11.3184\n",
      "Epoch 1: Total Loss=15.2052\n",
      "Epoch 2: Total Loss=12.4297\n",
      "Epoch 3: Total Loss=12.5145\n",
      "Epoch 4: Total Loss=15.5298\n",
      "Epoch 5: Total Loss=11.6460\n",
      "Epoch 6: Total Loss=10.5062\n",
      "Epoch 7: Total Loss=11.3248\n",
      "Epoch 8: Total Loss=15.1825\n",
      "Epoch 9: Total Loss=12.4310\n",
      "Updated x: [4.635532379150391, -5.377109050750732], Function Value: 50.40146255493164, Gradient: [-0.09641928970813751, -0.1442413628101349]\n",
      "\n",
      "Step 58/200\n",
      "Epoch 0: Total Loss=13.5921\n",
      "Epoch 1: Total Loss=14.8667\n",
      "Epoch 2: Total Loss=11.6512\n",
      "Epoch 3: Total Loss=11.7975\n",
      "Epoch 4: Total Loss=11.0618\n",
      "Epoch 5: Total Loss=12.5170\n",
      "Epoch 6: Total Loss=11.8494\n",
      "Epoch 7: Total Loss=14.4434\n",
      "Epoch 8: Total Loss=13.5743\n",
      "Epoch 9: Total Loss=14.9285\n",
      "Updated x: [4.617142200469971, -5.222315311431885], Function Value: 48.590579986572266, Gradient: [-0.103748619556427, -0.15692740678787231]\n",
      "\n",
      "Step 59/200\n",
      "Epoch 0: Total Loss=11.1795\n",
      "Epoch 1: Total Loss=11.6776\n",
      "Epoch 2: Total Loss=10.6699\n",
      "Epoch 3: Total Loss=10.8464\n",
      "Epoch 4: Total Loss=11.8643\n",
      "Epoch 5: Total Loss=11.1340\n",
      "Epoch 6: Total Loss=11.7900\n",
      "Epoch 7: Total Loss=10.9512\n",
      "Epoch 8: Total Loss=11.5203\n",
      "Epoch 9: Total Loss=12.6706\n",
      "Updated x: [4.575185298919678, -5.1246256828308105], Function Value: 47.19410705566406, Gradient: [-0.11283961683511734, -0.17086975276470184]\n",
      "\n",
      "Step 60/200\n",
      "Epoch 0: Total Loss=11.8974\n",
      "Epoch 1: Total Loss=9.9043\n",
      "Epoch 2: Total Loss=11.2180\n",
      "Epoch 3: Total Loss=10.3021\n",
      "Epoch 4: Total Loss=10.6164\n",
      "Epoch 5: Total Loss=17.9567\n",
      "Epoch 6: Total Loss=10.9486\n",
      "Epoch 7: Total Loss=13.4491\n",
      "Epoch 8: Total Loss=11.4386\n",
      "Epoch 9: Total Loss=11.7252\n",
      "Updated x: [4.537263870239258, -4.885184288024902], Function Value: 44.45178985595703, Gradient: [-0.12141891568899155, -0.18467159569263458]\n",
      "\n",
      "Step 61/200\n",
      "Epoch 0: Total Loss=10.8973\n",
      "Epoch 1: Total Loss=17.8617\n",
      "Epoch 2: Total Loss=11.8695\n",
      "Epoch 3: Total Loss=13.9464\n",
      "Epoch 4: Total Loss=13.2859\n",
      "Epoch 5: Total Loss=10.8374\n",
      "Epoch 6: Total Loss=11.5585\n",
      "Epoch 7: Total Loss=10.7480\n",
      "Epoch 8: Total Loss=13.2225\n",
      "Epoch 9: Total Loss=19.3064\n",
      "Updated x: [4.337406158447266, -4.727054595947266], Function Value: 41.15813446044922, Gradient: [-0.1237255409359932, -0.1891695111989975]\n",
      "\n",
      "Step 62/200\n",
      "Epoch 0: Total Loss=7152.3458\n",
      "Epoch 1: Total Loss=7134.6359\n",
      "Epoch 2: Total Loss=7117.8629\n",
      "Epoch 3: Total Loss=7101.3054\n",
      "Epoch 4: Total Loss=7085.2666\n",
      "Epoch 5: Total Loss=7068.9534\n",
      "Epoch 6: Total Loss=7053.0314\n",
      "Epoch 7: Total Loss=7037.5825\n",
      "Epoch 8: Total Loss=7022.1897\n",
      "Epoch 9: Total Loss=7005.3447\n",
      "Updated x: [4.262593746185303, -4.784602642059326], Function Value: 41.06212615966797, Gradient: [-0.10190686583518982, -0.22822709381580353]\n",
      "\n",
      "Step 63/200\n",
      "Epoch 0: Total Loss=14.9131\n",
      "Epoch 1: Total Loss=15.4839\n",
      "Epoch 2: Total Loss=16.3664\n",
      "Epoch 3: Total Loss=13.1485\n",
      "Epoch 4: Total Loss=16.1664\n",
      "Epoch 5: Total Loss=13.7883\n",
      "Epoch 6: Total Loss=16.9291\n",
      "Epoch 7: Total Loss=13.8560\n",
      "Epoch 8: Total Loss=14.7384\n",
      "Epoch 9: Total Loss=16.2673\n",
      "Updated x: [4.253362655639648, -4.6677141189575195], Function Value: 39.87864685058594, Gradient: [-0.12414663285017014, -0.161138653755188]\n",
      "\n",
      "Step 64/200\n",
      "Epoch 0: Total Loss=16.4529\n",
      "Epoch 1: Total Loss=13.6889\n",
      "Epoch 2: Total Loss=14.9580\n",
      "Epoch 3: Total Loss=16.4501\n",
      "Epoch 4: Total Loss=15.5282\n",
      "Epoch 5: Total Loss=13.3186\n",
      "Epoch 6: Total Loss=16.9291\n",
      "Epoch 7: Total Loss=16.2993\n",
      "Epoch 8: Total Loss=12.4169\n",
      "Epoch 9: Total Loss=16.6315\n",
      "Updated x: [4.0514655113220215, -4.666544437408447], Function Value: 38.191009521484375, Gradient: [-0.12730009853839874, -0.19746573269367218]\n",
      "\n",
      "Step 65/200\n",
      "Epoch 0: Total Loss=17.3998\n",
      "Epoch 1: Total Loss=12.7174\n",
      "Epoch 2: Total Loss=13.7145\n",
      "Epoch 3: Total Loss=22.3041\n",
      "Epoch 4: Total Loss=15.8298\n",
      "Epoch 5: Total Loss=13.0783\n",
      "Epoch 6: Total Loss=20.1596\n",
      "Epoch 7: Total Loss=17.3849\n",
      "Epoch 8: Total Loss=13.0843\n",
      "Epoch 9: Total Loss=13.6918\n",
      "Updated x: [3.8309342861175537, -4.651577949523926], Function Value: 36.313232421875, Gradient: [-0.13835661113262177, -0.2149782031774521]\n",
      "\n",
      "Step 66/200\n",
      "Epoch 0: Total Loss=14.0016\n",
      "Epoch 1: Total Loss=15.1578\n",
      "Epoch 2: Total Loss=14.7473\n",
      "Epoch 3: Total Loss=12.9559\n",
      "Epoch 4: Total Loss=14.5552\n",
      "Epoch 5: Total Loss=14.3090\n",
      "Epoch 6: Total Loss=14.7318\n",
      "Epoch 7: Total Loss=13.9076\n",
      "Epoch 8: Total Loss=14.2805\n",
      "Epoch 9: Total Loss=13.0941\n",
      "Updated x: [3.7225656509399414, -4.64749813079834], Function Value: 35.45673370361328, Gradient: [-0.1205214411020279, -0.19694551825523376]\n",
      "\n",
      "Step 67/200\n",
      "Epoch 0: Total Loss=11.5972\n",
      "Epoch 1: Total Loss=11.6195\n",
      "Epoch 2: Total Loss=16.4300\n",
      "Epoch 3: Total Loss=13.6079\n",
      "Epoch 4: Total Loss=13.3280\n",
      "Epoch 5: Total Loss=12.0599\n",
      "Epoch 6: Total Loss=10.4583\n",
      "Epoch 7: Total Loss=16.0231\n",
      "Epoch 8: Total Loss=13.9836\n",
      "Epoch 9: Total Loss=14.4803\n",
      "Updated x: [3.686506509780884, -4.4357805252075195], Function Value: 33.2664794921875, Gradient: [-0.13958081603050232, -0.22590802609920502]\n",
      "\n",
      "Step 68/200\n",
      "Epoch 0: Total Loss=14.6283\n",
      "Epoch 1: Total Loss=13.4846\n",
      "Epoch 2: Total Loss=13.7403\n",
      "Epoch 3: Total Loss=17.5302\n",
      "Epoch 4: Total Loss=13.9156\n",
      "Epoch 5: Total Loss=14.0213\n",
      "Epoch 6: Total Loss=13.5971\n",
      "Epoch 7: Total Loss=14.3459\n",
      "Epoch 8: Total Loss=14.6239\n",
      "Epoch 9: Total Loss=17.4626\n",
      "Updated x: [3.5352509021759033, -4.298221111297607], Function Value: 30.97270393371582, Gradient: [-0.13929492235183716, -0.2472163885831833]\n",
      "\n",
      "Step 69/200\n",
      "Epoch 0: Total Loss=12.3304\n",
      "Epoch 1: Total Loss=13.4673\n",
      "Epoch 2: Total Loss=14.7700\n",
      "Epoch 3: Total Loss=14.8364\n",
      "Epoch 4: Total Loss=11.6162\n",
      "Epoch 5: Total Loss=14.5947\n",
      "Epoch 6: Total Loss=13.1436\n",
      "Epoch 7: Total Loss=12.1210\n",
      "Epoch 8: Total Loss=13.6536\n",
      "Epoch 9: Total Loss=14.5834\n",
      "Updated x: [3.328397512435913, -4.2904510498046875], Function Value: 29.4862003326416, Gradient: [-0.1369333267211914, -0.25072696805000305]\n",
      "\n",
      "Step 70/200\n",
      "Epoch 0: Total Loss=12.0385\n",
      "Epoch 1: Total Loss=14.6638\n",
      "Epoch 2: Total Loss=12.7480\n",
      "Epoch 3: Total Loss=15.0721\n",
      "Epoch 4: Total Loss=12.2286\n",
      "Epoch 5: Total Loss=15.2070\n",
      "Epoch 6: Total Loss=14.4610\n",
      "Epoch 7: Total Loss=12.3126\n",
      "Epoch 8: Total Loss=12.5417\n",
      "Epoch 9: Total Loss=14.7856\n",
      "Updated x: [3.4218106269836426, -3.9887900352478027], Function Value: 27.619234085083008, Gradient: [-0.166283518075943, -0.28617754578590393]\n",
      "\n",
      "Step 71/200\n",
      "Epoch 0: Total Loss=14.8584\n",
      "Epoch 1: Total Loss=12.4662\n",
      "Epoch 2: Total Loss=14.5427\n",
      "Epoch 3: Total Loss=15.1912\n",
      "Epoch 4: Total Loss=12.8536\n",
      "Epoch 5: Total Loss=12.0138\n",
      "Epoch 6: Total Loss=14.6716\n",
      "Epoch 7: Total Loss=10.9808\n",
      "Epoch 8: Total Loss=13.1346\n",
      "Epoch 9: Total Loss=14.4816\n",
      "Updated x: [3.4053759574890137, -3.887044906616211], Function Value: 26.705703735351562, Gradient: [-0.18079587817192078, -0.31154775619506836]\n",
      "\n",
      "Step 72/200\n",
      "Epoch 0: Total Loss=2985.2866\n",
      "Epoch 1: Total Loss=2972.5404\n",
      "Epoch 2: Total Loss=2960.0518\n",
      "Epoch 3: Total Loss=2947.8368\n",
      "Epoch 4: Total Loss=2935.0959\n",
      "Epoch 5: Total Loss=2923.1880\n",
      "Epoch 6: Total Loss=2910.8229\n",
      "Epoch 7: Total Loss=2898.8599\n",
      "Epoch 8: Total Loss=2887.1008\n",
      "Epoch 9: Total Loss=2875.3582\n",
      "Updated x: [3.2054500579833984, -3.8805644512176514], Function Value: 25.333690643310547, Gradient: [-0.1479378044605255, -0.3495248258113861]\n",
      "\n",
      "Step 73/200\n",
      "Epoch 0: Total Loss=15.2764\n",
      "Epoch 1: Total Loss=18.6210\n",
      "Epoch 2: Total Loss=18.3008\n",
      "Epoch 3: Total Loss=15.2151\n",
      "Epoch 4: Total Loss=21.1314\n",
      "Epoch 5: Total Loss=11.5892\n",
      "Epoch 6: Total Loss=20.8602\n",
      "Epoch 7: Total Loss=13.9180\n",
      "Epoch 8: Total Loss=17.8724\n",
      "Epoch 9: Total Loss=17.5331\n",
      "Updated x: [3.127455472946167, -3.811997175216675], Function Value: 24.312301635742188, Gradient: [-0.1781713217496872, -0.2717745006084442]\n",
      "\n",
      "Step 74/200\n",
      "Epoch 0: Total Loss=11.6624\n",
      "Epoch 1: Total Loss=13.7305\n",
      "Epoch 2: Total Loss=19.1164\n",
      "Epoch 3: Total Loss=11.8425\n",
      "Epoch 4: Total Loss=13.4846\n",
      "Epoch 5: Total Loss=20.1186\n",
      "Epoch 6: Total Loss=10.6457\n",
      "Epoch 7: Total Loss=16.9071\n",
      "Epoch 8: Total Loss=16.2463\n",
      "Epoch 9: Total Loss=11.1866\n",
      "Updated x: [3.018275260925293, -3.7355785369873047], Function Value: 23.064533233642578, Gradient: [-0.16433481872081757, -0.3199619948863983]\n",
      "\n",
      "Step 75/200\n",
      "Epoch 0: Total Loss=13.1252\n",
      "Epoch 1: Total Loss=9.6379\n",
      "Epoch 2: Total Loss=16.4361\n",
      "Epoch 3: Total Loss=11.6786\n",
      "Epoch 4: Total Loss=11.7240\n",
      "Epoch 5: Total Loss=12.9086\n",
      "Epoch 6: Total Loss=13.8687\n",
      "Epoch 7: Total Loss=13.2611\n",
      "Epoch 8: Total Loss=9.8271\n",
      "Epoch 9: Total Loss=16.6157\n",
      "Updated x: [2.9622671604156494, -3.6259379386901855], Function Value: 21.92245101928711, Gradient: [-0.17106662690639496, -0.3357161283493042]\n",
      "\n",
      "Step 76/200\n",
      "Epoch 0: Total Loss=10.1319\n",
      "Epoch 1: Total Loss=13.1288\n",
      "Epoch 2: Total Loss=12.2222\n",
      "Epoch 3: Total Loss=13.1635\n",
      "Epoch 4: Total Loss=12.9992\n",
      "Epoch 5: Total Loss=9.6299\n",
      "Epoch 6: Total Loss=15.1009\n",
      "Epoch 7: Total Loss=10.3379\n",
      "Epoch 8: Total Loss=15.4922\n",
      "Epoch 9: Total Loss=10.1790\n",
      "Updated x: [2.860193967819214, -3.5556530952453613], Function Value: 20.823379516601562, Gradient: [-0.15332473814487457, -0.3104119300842285]\n",
      "\n",
      "Step 77/200\n",
      "Epoch 0: Total Loss=15.1316\n",
      "Epoch 1: Total Loss=10.5798\n",
      "Epoch 2: Total Loss=11.2219\n",
      "Epoch 3: Total Loss=13.3713\n",
      "Epoch 4: Total Loss=9.5036\n",
      "Epoch 5: Total Loss=16.6960\n",
      "Epoch 6: Total Loss=10.1013\n",
      "Epoch 7: Total Loss=12.0586\n",
      "Epoch 8: Total Loss=12.8458\n",
      "Epoch 9: Total Loss=9.9300\n",
      "Updated x: [2.82828950881958, -3.4319729804992676], Function Value: 19.777660369873047, Gradient: [-0.1596337854862213, -0.32987597584724426]\n",
      "\n",
      "Step 78/200\n",
      "Epoch 0: Total Loss=12.6667\n",
      "Epoch 1: Total Loss=9.9911\n",
      "Epoch 2: Total Loss=10.8825\n",
      "Epoch 3: Total Loss=11.1655\n",
      "Epoch 4: Total Loss=12.7915\n",
      "Epoch 5: Total Loss=13.0189\n",
      "Epoch 6: Total Loss=12.7916\n",
      "Epoch 7: Total Loss=9.8345\n",
      "Epoch 8: Total Loss=10.8538\n",
      "Epoch 9: Total Loss=10.7599\n",
      "Updated x: [2.77868390083313, -3.2412514686584473], Function Value: 18.226795196533203, Gradient: [-0.1564093828201294, -0.32337692379951477]\n",
      "\n",
      "Step 79/200\n",
      "Epoch 0: Total Loss=12.4751\n",
      "Epoch 1: Total Loss=13.5787\n",
      "Epoch 2: Total Loss=10.8389\n",
      "Epoch 3: Total Loss=10.0691\n",
      "Epoch 4: Total Loss=12.1029\n",
      "Epoch 5: Total Loss=11.9900\n",
      "Epoch 6: Total Loss=9.4116\n",
      "Epoch 7: Total Loss=12.5004\n",
      "Epoch 8: Total Loss=13.7700\n",
      "Epoch 9: Total Loss=10.8751\n",
      "Updated x: [2.7807793617248535, -3.0512561798095703], Function Value: 17.042898178100586, Gradient: [-0.14538903534412384, -0.30629807710647583]\n",
      "\n",
      "Step 80/200\n",
      "Epoch 0: Total Loss=10.4834\n",
      "Epoch 1: Total Loss=10.3245\n",
      "Epoch 2: Total Loss=10.0902\n",
      "Epoch 3: Total Loss=14.0922\n",
      "Epoch 4: Total Loss=10.3540\n",
      "Epoch 5: Total Loss=13.0867\n",
      "Epoch 6: Total Loss=10.5241\n",
      "Epoch 7: Total Loss=14.8745\n",
      "Epoch 8: Total Loss=10.2812\n",
      "Epoch 9: Total Loss=10.1506\n",
      "Updated x: [2.6778337955474854, -2.88942813873291], Function Value: 15.519588470458984, Gradient: [-0.12258615344762802, -0.2465827614068985]\n",
      "\n",
      "Step 81/200\n",
      "Epoch 0: Total Loss=10.3626\n",
      "Epoch 1: Total Loss=9.7678\n",
      "Epoch 2: Total Loss=9.8575\n",
      "Epoch 3: Total Loss=9.7137\n",
      "Epoch 4: Total Loss=11.7075\n",
      "Epoch 5: Total Loss=10.4014\n",
      "Epoch 6: Total Loss=13.8885\n",
      "Epoch 7: Total Loss=12.5803\n",
      "Epoch 8: Total Loss=10.2410\n",
      "Epoch 9: Total Loss=10.4357\n",
      "Updated x: [2.605476140975952, -2.803513765335083], Function Value: 14.648195266723633, Gradient: [-0.09447488933801651, -0.1699737310409546]\n",
      "\n",
      "Step 82/200\n",
      "Epoch 0: Total Loss=897.3564\n",
      "Epoch 1: Total Loss=893.2430\n",
      "Epoch 2: Total Loss=889.3856\n",
      "Epoch 3: Total Loss=885.5994\n",
      "Epoch 4: Total Loss=881.9452\n",
      "Epoch 5: Total Loss=878.3775\n",
      "Epoch 6: Total Loss=874.5940\n",
      "Epoch 7: Total Loss=871.0112\n",
      "Epoch 8: Total Loss=867.2141\n",
      "Epoch 9: Total Loss=863.4621\n",
      "Updated x: [2.5130348205566406, -2.6427500247955322], Function Value: 13.299470901489258, Gradient: [-0.09527768939733505, -0.22790412604808807]\n",
      "\n",
      "Step 83/200\n",
      "Epoch 0: Total Loss=14.3831\n",
      "Epoch 1: Total Loss=15.2600\n",
      "Epoch 2: Total Loss=12.1485\n",
      "Epoch 3: Total Loss=15.0753\n",
      "Epoch 4: Total Loss=11.9258\n",
      "Epoch 5: Total Loss=15.1092\n",
      "Epoch 6: Total Loss=13.5185\n",
      "Epoch 7: Total Loss=13.6866\n",
      "Epoch 8: Total Loss=14.6072\n",
      "Epoch 9: Total Loss=11.7552\n",
      "Updated x: [2.4546518325805664, -2.434019088745117], Function Value: 11.949764251708984, Gradient: [-0.010191669687628746, 0.027673587203025818]\n",
      "\n",
      "Step 84/200\n",
      "Epoch 0: Total Loss=11.3532\n",
      "Epoch 1: Total Loss=12.1874\n",
      "Epoch 2: Total Loss=11.6682\n",
      "Epoch 3: Total Loss=9.4700\n",
      "Epoch 4: Total Loss=11.8852\n",
      "Epoch 5: Total Loss=11.4215\n",
      "Epoch 6: Total Loss=10.5508\n",
      "Epoch 7: Total Loss=11.1028\n",
      "Epoch 8: Total Loss=11.1554\n",
      "Epoch 9: Total Loss=10.5797\n",
      "Updated x: [2.3622214794158936, -2.381974935531616], Function Value: 11.253894805908203, Gradient: [-0.02363240346312523, -0.03359977900981903]\n",
      "\n",
      "Step 85/200\n",
      "Epoch 0: Total Loss=12.4727\n",
      "Epoch 1: Total Loss=10.1504\n",
      "Epoch 2: Total Loss=9.2031\n",
      "Epoch 3: Total Loss=12.3966\n",
      "Epoch 4: Total Loss=9.9357\n",
      "Epoch 5: Total Loss=9.2859\n",
      "Epoch 6: Total Loss=9.2107\n",
      "Epoch 7: Total Loss=12.3968\n",
      "Epoch 8: Total Loss=10.0735\n",
      "Epoch 9: Total Loss=9.2138\n",
      "Updated x: [2.2878711223602295, -2.316319227218628], Function Value: 10.599689483642578, Gradient: [-0.0594126395881176, -0.16507887840270996]\n",
      "\n",
      "Step 86/200\n",
      "Epoch 0: Total Loss=11.1727\n",
      "Epoch 1: Total Loss=9.1492\n",
      "Epoch 2: Total Loss=11.4490\n",
      "Epoch 3: Total Loss=9.2811\n",
      "Epoch 4: Total Loss=9.9680\n",
      "Epoch 5: Total Loss=10.7771\n",
      "Epoch 6: Total Loss=10.8326\n",
      "Epoch 7: Total Loss=9.3233\n",
      "Epoch 8: Total Loss=10.0659\n",
      "Epoch 9: Total Loss=11.1678\n",
      "Updated x: [2.133141279220581, -2.1556270122528076], Function Value: 9.197019577026367, Gradient: [-0.022870218381285667, -0.03545714542269707]\n",
      "\n",
      "Step 87/200\n",
      "Epoch 0: Total Loss=8.5689\n",
      "Epoch 1: Total Loss=9.3771\n",
      "Epoch 2: Total Loss=9.9776\n",
      "Epoch 3: Total Loss=12.1944\n",
      "Epoch 4: Total Loss=10.1963\n",
      "Epoch 5: Total Loss=8.5570\n",
      "Epoch 6: Total Loss=8.5538\n",
      "Epoch 7: Total Loss=10.6550\n",
      "Epoch 8: Total Loss=11.6493\n",
      "Epoch 9: Total Loss=10.7854\n",
      "Updated x: [1.9638739824295044, -2.122469663619995], Function Value: 8.361679077148438, Gradient: [-0.04915221408009529, -0.14008502662181854]\n",
      "\n",
      "Step 88/200\n",
      "Epoch 0: Total Loss=10.6962\n",
      "Epoch 1: Total Loss=8.6926\n",
      "Epoch 2: Total Loss=8.7554\n",
      "Epoch 3: Total Loss=10.5171\n",
      "Epoch 4: Total Loss=9.6333\n",
      "Epoch 5: Total Loss=9.2261\n",
      "Epoch 6: Total Loss=10.8377\n",
      "Epoch 7: Total Loss=8.6647\n",
      "Epoch 8: Total Loss=8.5273\n",
      "Epoch 9: Total Loss=10.6431\n",
      "Updated x: [1.8941339254379272, -2.0244035720825195], Function Value: 7.685953140258789, Gradient: [0.0021161313634365797, 0.049519363790750504]\n",
      "\n",
      "Step 89/200\n",
      "Epoch 0: Total Loss=9.5258\n",
      "Epoch 1: Total Loss=11.9687\n",
      "Epoch 2: Total Loss=9.5545\n",
      "Epoch 3: Total Loss=8.3175\n",
      "Epoch 4: Total Loss=8.4336\n",
      "Epoch 5: Total Loss=8.7693\n",
      "Epoch 6: Total Loss=8.8435\n",
      "Epoch 7: Total Loss=9.5607\n",
      "Epoch 8: Total Loss=12.0254\n",
      "Epoch 9: Total Loss=9.6839\n",
      "Updated x: [1.7739472389221191, -1.9493589401245117], Function Value: 6.9468889236450195, Gradient: [0.03537808358669281, 0.1650673747062683]\n",
      "\n",
      "Step 90/200\n",
      "Epoch 0: Total Loss=8.3491\n",
      "Epoch 1: Total Loss=8.3060\n",
      "Epoch 2: Total Loss=9.1146\n",
      "Epoch 3: Total Loss=8.8259\n",
      "Epoch 4: Total Loss=9.0152\n",
      "Epoch 5: Total Loss=8.7990\n",
      "Epoch 6: Total Loss=10.2946\n",
      "Epoch 7: Total Loss=10.6356\n",
      "Epoch 8: Total Loss=8.3131\n",
      "Epoch 9: Total Loss=8.2780\n",
      "Updated x: [1.5921895503997803, -1.8694179058074951], Function Value: 6.029790878295898, Gradient: [0.026989329606294632, 0.1399843841791153]\n",
      "\n",
      "Step 91/200\n",
      "Epoch 0: Total Loss=8.1562\n",
      "Epoch 1: Total Loss=8.3107\n",
      "Epoch 2: Total Loss=8.4824\n",
      "Epoch 3: Total Loss=8.6652\n",
      "Epoch 4: Total Loss=9.9657\n",
      "Epoch 5: Total Loss=8.2079\n",
      "Epoch 6: Total Loss=9.7316\n",
      "Epoch 7: Total Loss=8.3056\n",
      "Epoch 8: Total Loss=12.2577\n",
      "Epoch 9: Total Loss=8.4067\n",
      "Updated x: [1.3220982551574707, -1.7705777883529663], Function Value: 4.882889270782471, Gradient: [0.03973623737692833, 0.18409009277820587]\n",
      "\n",
      "Step 92/200\n",
      "Epoch 0: Total Loss=128.4009\n",
      "Epoch 1: Total Loss=126.4022\n",
      "Epoch 2: Total Loss=133.4423\n",
      "Epoch 3: Total Loss=119.8310\n",
      "Epoch 4: Total Loss=122.6048\n",
      "Epoch 5: Total Loss=120.4336\n",
      "Epoch 6: Total Loss=126.5990\n",
      "Epoch 7: Total Loss=112.1491\n",
      "Epoch 8: Total Loss=116.2531\n",
      "Epoch 9: Total Loss=114.5842\n",
      "Updated x: [1.3418151140213013, -1.52715003490448], Function Value: 4.132655143737793, Gradient: [-0.013109317049384117, -0.019620832055807114]\n",
      "\n",
      "Step 93/200\n",
      "Epoch 0: Total Loss=11.2162\n",
      "Epoch 1: Total Loss=9.8396\n",
      "Epoch 2: Total Loss=9.3062\n",
      "Epoch 3: Total Loss=11.4638\n",
      "Epoch 4: Total Loss=10.2972\n",
      "Epoch 5: Total Loss=9.9942\n",
      "Epoch 6: Total Loss=11.3420\n",
      "Epoch 7: Total Loss=9.2203\n",
      "Epoch 8: Total Loss=11.2265\n",
      "Epoch 9: Total Loss=9.8753\n",
      "Updated x: [1.2704588174819946, -1.483769178390503], Function Value: 3.81563663482666, Gradient: [-0.043091271072626114, -0.10705269128084183]\n",
      "\n",
      "Step 94/200\n",
      "Epoch 0: Total Loss=9.3826\n",
      "Epoch 1: Total Loss=9.4967\n",
      "Epoch 2: Total Loss=8.5455\n",
      "Epoch 3: Total Loss=9.6749\n",
      "Epoch 4: Total Loss=9.2492\n",
      "Epoch 5: Total Loss=8.5316\n",
      "Epoch 6: Total Loss=9.0085\n",
      "Epoch 7: Total Loss=9.4493\n",
      "Epoch 8: Total Loss=8.7376\n",
      "Epoch 9: Total Loss=10.4530\n",
      "Updated x: [1.2824963331222534, -1.322869896888733], Function Value: 3.3947815895080566, Gradient: [-0.03851257264614105, -0.08657761663198471]\n",
      "\n",
      "Step 95/200\n",
      "Epoch 0: Total Loss=9.1419\n",
      "Epoch 1: Total Loss=8.3861\n",
      "Epoch 2: Total Loss=9.1895\n",
      "Epoch 3: Total Loss=10.0557\n",
      "Epoch 4: Total Loss=8.1840\n",
      "Epoch 5: Total Loss=8.9243\n",
      "Epoch 6: Total Loss=9.1157\n",
      "Epoch 7: Total Loss=8.7520\n",
      "Epoch 8: Total Loss=10.8198\n",
      "Epoch 9: Total Loss=9.4997\n",
      "Updated x: [1.0812041759490967, -1.275104284286499], Function Value: 2.794893264770508, Gradient: [-0.049460504204034805, -0.12542717158794403]\n",
      "\n",
      "Step 96/200\n",
      "Epoch 0: Total Loss=8.3472\n",
      "Epoch 1: Total Loss=9.0337\n",
      "Epoch 2: Total Loss=8.4217\n",
      "Epoch 3: Total Loss=9.4352\n",
      "Epoch 4: Total Loss=9.3508\n",
      "Epoch 5: Total Loss=10.2094\n",
      "Epoch 6: Total Loss=9.0303\n",
      "Epoch 7: Total Loss=8.9186\n",
      "Epoch 8: Total Loss=9.8418\n",
      "Epoch 9: Total Loss=9.3730\n",
      "Updated x: [0.9079898595809937, -1.3265374898910522], Function Value: 2.5841474533081055, Gradient: [-0.06011880934238434, -0.1516028791666031]\n",
      "\n",
      "Step 97/200\n",
      "Epoch 0: Total Loss=9.0476\n",
      "Epoch 1: Total Loss=9.9248\n",
      "Epoch 2: Total Loss=9.1114\n",
      "Epoch 3: Total Loss=8.6159\n",
      "Epoch 4: Total Loss=10.6819\n",
      "Epoch 5: Total Loss=8.3835\n",
      "Epoch 6: Total Loss=9.6150\n",
      "Epoch 7: Total Loss=9.1828\n",
      "Epoch 8: Total Loss=9.6540\n",
      "Epoch 9: Total Loss=10.0281\n",
      "Updated x: [0.9077145457267761, -1.1079360246658325], Function Value: 2.0514678955078125, Gradient: [-0.05282210931181908, -0.14996400475502014]\n",
      "\n",
      "Step 98/200\n",
      "Epoch 0: Total Loss=9.7836\n",
      "Epoch 1: Total Loss=9.4770\n",
      "Epoch 2: Total Loss=9.6275\n",
      "Epoch 3: Total Loss=9.4064\n",
      "Epoch 4: Total Loss=9.2005\n",
      "Epoch 5: Total Loss=9.2964\n",
      "Epoch 6: Total Loss=10.1832\n",
      "Epoch 7: Total Loss=9.3563\n",
      "Epoch 8: Total Loss=8.2016\n",
      "Epoch 9: Total Loss=8.3781\n",
      "Updated x: [0.8077647686004639, -0.8857859373092651], Function Value: 1.4371006488800049, Gradient: [-0.03426485136151314, -0.08841856569051743]\n",
      "\n",
      "Step 99/200\n",
      "Epoch 0: Total Loss=9.0528\n",
      "Epoch 1: Total Loss=7.9509\n",
      "Epoch 2: Total Loss=9.6383\n",
      "Epoch 3: Total Loss=9.3507\n",
      "Epoch 4: Total Loss=9.4933\n",
      "Epoch 5: Total Loss=8.8943\n",
      "Epoch 6: Total Loss=8.6874\n",
      "Epoch 7: Total Loss=9.0043\n",
      "Epoch 8: Total Loss=10.2165\n",
      "Epoch 9: Total Loss=8.5651\n",
      "Updated x: [0.6188086271286011, -0.8448489904403687], Function Value: 1.0966938734054565, Gradient: [-0.03510500490665436, -0.09041337668895721]\n",
      "\n",
      "Step 100/200\n",
      "Epoch 0: Total Loss=7.7782\n",
      "Epoch 1: Total Loss=10.5130\n",
      "Epoch 2: Total Loss=8.7140\n",
      "Epoch 3: Total Loss=9.0709\n",
      "Epoch 4: Total Loss=9.2503\n",
      "Epoch 5: Total Loss=9.9117\n",
      "Epoch 6: Total Loss=8.3195\n",
      "Epoch 7: Total Loss=9.4174\n",
      "Epoch 8: Total Loss=8.5395\n",
      "Epoch 9: Total Loss=10.4124\n",
      "Updated x: [0.5837928652763367, -0.6518717408180237], Function Value: 0.7657508850097656, Gradient: [-0.019801929593086243, -0.024381954222917557]\n",
      "\n",
      "Step 101/200\n",
      "Epoch 0: Total Loss=9.7219\n",
      "Epoch 1: Total Loss=8.7152\n",
      "Epoch 2: Total Loss=8.7363\n",
      "Epoch 3: Total Loss=8.5667\n",
      "Epoch 4: Total Loss=8.8891\n",
      "Epoch 5: Total Loss=8.1636\n",
      "Epoch 6: Total Loss=8.6755\n",
      "Epoch 7: Total Loss=10.0179\n",
      "Epoch 8: Total Loss=8.7702\n",
      "Epoch 9: Total Loss=8.5894\n",
      "Updated x: [0.5136186480522156, -0.5799341201782227], Function Value: 0.6001276969909668, Gradient: [-0.014411132782697678, 0.003939071204513311]\n",
      "\n",
      "Step 102/200\n",
      "Epoch 0: Total Loss=9.8995\n",
      "Epoch 1: Total Loss=9.4197\n",
      "Epoch 2: Total Loss=9.5524\n",
      "Epoch 3: Total Loss=9.5146\n",
      "Epoch 4: Total Loss=9.6178\n",
      "Epoch 5: Total Loss=9.5623\n",
      "Epoch 6: Total Loss=9.2825\n",
      "Epoch 7: Total Loss=9.0950\n",
      "Epoch 8: Total Loss=9.5034\n",
      "Epoch 9: Total Loss=9.4919\n",
      "Updated x: [0.35354334115982056, -0.42168062925338745], Function Value: 0.30280745029449463, Gradient: [-0.04054301604628563, -0.17470811307430267]\n",
      "\n",
      "Step 103/200\n",
      "Epoch 0: Total Loss=8.2833\n",
      "Epoch 1: Total Loss=8.0653\n",
      "Epoch 2: Total Loss=7.8529\n",
      "Epoch 3: Total Loss=7.9276\n",
      "Epoch 4: Total Loss=8.2137\n",
      "Epoch 5: Total Loss=8.0793\n",
      "Epoch 6: Total Loss=8.2931\n",
      "Epoch 7: Total Loss=8.0697\n",
      "Epoch 8: Total Loss=8.1384\n",
      "Epoch 9: Total Loss=8.1989\n",
      "Updated x: [0.2781619429588318, -0.4058096706867218], Function Value: 0.24205556511878967, Gradient: [-0.014173763804137707, -0.044158559292554855]\n",
      "\n",
      "Step 104/200\n",
      "Epoch 0: Total Loss=7.6354\n",
      "Epoch 1: Total Loss=7.8996\n",
      "Epoch 2: Total Loss=7.7754\n",
      "Epoch 3: Total Loss=8.0148\n",
      "Epoch 4: Total Loss=8.1392\n",
      "Epoch 5: Total Loss=8.1890\n",
      "Epoch 6: Total Loss=8.0764\n",
      "Epoch 7: Total Loss=7.7321\n",
      "Epoch 8: Total Loss=7.9259\n",
      "Epoch 9: Total Loss=8.0756\n",
      "Updated x: [0.18354272842407227, -0.29459506273269653], Function Value: 0.1204741820693016, Gradient: [-0.010316078551113605, -0.03942234814167023]\n",
      "\n",
      "Step 105/200\n",
      "Epoch 0: Total Loss=7.7556\n",
      "Epoch 1: Total Loss=7.7440\n",
      "Epoch 2: Total Loss=8.0591\n",
      "Epoch 3: Total Loss=7.8678\n",
      "Epoch 4: Total Loss=8.0827\n",
      "Epoch 5: Total Loss=7.9108\n",
      "Epoch 6: Total Loss=7.9307\n",
      "Epoch 7: Total Loss=8.1609\n",
      "Epoch 8: Total Loss=8.0069\n",
      "Epoch 9: Total Loss=7.9336\n",
      "Updated x: [0.1563263088464737, -0.19890457391738892], Function Value: 0.06400094926357269, Gradient: [-0.006600712891668081, -0.014010436832904816]\n",
      "\n",
      "Step 106/200\n",
      "Epoch 0: Total Loss=7.6936\n",
      "Epoch 1: Total Loss=7.6977\n",
      "Epoch 2: Total Loss=7.7877\n",
      "Epoch 3: Total Loss=7.7468\n",
      "Epoch 4: Total Loss=8.4404\n",
      "Epoch 5: Total Loss=8.0821\n",
      "Epoch 6: Total Loss=7.9608\n",
      "Epoch 7: Total Loss=7.9914\n",
      "Epoch 8: Total Loss=8.1309\n",
      "Epoch 9: Total Loss=8.1771\n",
      "Updated x: [0.15353567898273468, -0.10157525539398193], Function Value: 0.0338907390832901, Gradient: [-0.006537201814353466, -0.005816402845084667]\n",
      "\n",
      "Step 107/200\n",
      "Epoch 0: Total Loss=7.6234\n",
      "Epoch 1: Total Loss=7.7573\n",
      "Epoch 2: Total Loss=7.6935\n",
      "Epoch 3: Total Loss=8.2530\n",
      "Epoch 4: Total Loss=7.8043\n",
      "Epoch 5: Total Loss=8.3467\n",
      "Epoch 6: Total Loss=7.5996\n",
      "Epoch 7: Total Loss=7.7302\n",
      "Epoch 8: Total Loss=8.2466\n",
      "Epoch 9: Total Loss=7.9197\n",
      "Updated x: [-0.010088354349136353, -0.04726366326212883], Function Value: 0.002335628727450967, Gradient: [-0.006056426092982292, 0.0017606269102543592]\n",
      "\n",
      "Step 108/200\n",
      "Epoch 0: Total Loss=7.8033\n",
      "Epoch 1: Total Loss=7.7449\n",
      "Epoch 2: Total Loss=7.8077\n",
      "Epoch 3: Total Loss=7.7824\n",
      "Epoch 4: Total Loss=7.7367\n",
      "Epoch 5: Total Loss=7.9305\n",
      "Epoch 6: Total Loss=7.5239\n",
      "Epoch 7: Total Loss=7.8982\n",
      "Epoch 8: Total Loss=7.8533\n",
      "Epoch 9: Total Loss=7.8051\n",
      "Updated x: [-0.04001813009381294, -0.022548139095306396], Function Value: 0.002109869383275509, Gradient: [-0.004611749202013016, 0.01054387353360653]\n",
      "\n",
      "Step 109/200\n",
      "Epoch 0: Total Loss=7.8003\n",
      "Epoch 1: Total Loss=7.6798\n",
      "Epoch 2: Total Loss=7.7913\n",
      "Epoch 3: Total Loss=7.7869\n",
      "Epoch 4: Total Loss=7.8711\n",
      "Epoch 5: Total Loss=7.7825\n",
      "Epoch 6: Total Loss=7.7295\n",
      "Epoch 7: Total Loss=7.7063\n",
      "Epoch 8: Total Loss=8.2054\n",
      "Epoch 9: Total Loss=7.9305\n",
      "Updated x: [-0.013698840513825417, -0.03192383423447609], Function Value: 0.0012067893985658884, Gradient: [-0.005863505881279707, 0.012178045697510242]\n",
      "\n",
      "Step 110/200\n",
      "Epoch 0: Total Loss=7.7734\n",
      "Epoch 1: Total Loss=7.4307\n",
      "Epoch 2: Total Loss=7.9379\n",
      "Epoch 3: Total Loss=7.7300\n",
      "Epoch 4: Total Loss=8.0942\n",
      "Epoch 5: Total Loss=7.8278\n",
      "Epoch 6: Total Loss=8.0203\n",
      "Epoch 7: Total Loss=7.9941\n",
      "Epoch 8: Total Loss=7.9883\n",
      "Epoch 9: Total Loss=7.9772\n",
      "Updated x: [-0.08195290714502335, 0.07494223117828369], Function Value: 0.012332616373896599, Gradient: [-0.005017267540097237, 0.018515756353735924]\n",
      "\n",
      "Step 111/200\n",
      "Epoch 0: Total Loss=7.7052\n",
      "Epoch 1: Total Loss=7.7321\n",
      "Epoch 2: Total Loss=7.6826\n",
      "Epoch 3: Total Loss=7.9004\n",
      "Epoch 4: Total Loss=7.9704\n",
      "Epoch 5: Total Loss=7.7336\n",
      "Epoch 6: Total Loss=7.5219\n",
      "Epoch 7: Total Loss=7.8726\n",
      "Epoch 8: Total Loss=7.7501\n",
      "Epoch 9: Total Loss=7.8660\n",
      "Updated x: [-0.007933586835861206, 0.06249787285923958], Function Value: 0.003968925680965185, Gradient: [-0.0053179035894572735, 0.021755076944828033]\n",
      "\n",
      "Step 112/200\n",
      "Epoch 0: Total Loss=7.4931\n",
      "Epoch 1: Total Loss=7.3622\n",
      "Epoch 2: Total Loss=7.3015\n",
      "Epoch 3: Total Loss=7.4638\n",
      "Epoch 4: Total Loss=7.2599\n",
      "Epoch 5: Total Loss=7.3623\n",
      "Epoch 6: Total Loss=7.4289\n",
      "Epoch 7: Total Loss=7.3178\n",
      "Epoch 8: Total Loss=7.4666\n",
      "Epoch 9: Total Loss=7.3431\n",
      "Updated x: [0.030211269855499268, 0.012497086077928543], Function Value: 0.0010688980109989643, Gradient: [-0.0034422629978507757, 0.022181574255228043]\n",
      "\n",
      "Step 113/200\n",
      "Epoch 0: Total Loss=7.3846\n",
      "Epoch 1: Total Loss=7.4113\n",
      "Epoch 2: Total Loss=7.3625\n",
      "Epoch 3: Total Loss=7.3522\n",
      "Epoch 4: Total Loss=7.3916\n",
      "Epoch 5: Total Loss=7.4071\n",
      "Epoch 6: Total Loss=7.4098\n",
      "Epoch 7: Total Loss=7.3704\n",
      "Epoch 8: Total Loss=7.3871\n",
      "Epoch 9: Total Loss=7.5091\n",
      "Updated x: [0.027346165850758553, -0.03581113740801811], Function Value: 0.002030250383540988, Gradient: [-0.0025101772043854, 0.01733776181936264]\n",
      "\n",
      "Step 114/200\n",
      "Epoch 0: Total Loss=7.4087\n",
      "Epoch 1: Total Loss=7.3856\n",
      "Epoch 2: Total Loss=7.3610\n",
      "Epoch 3: Total Loss=7.4084\n",
      "Epoch 4: Total Loss=7.3437\n",
      "Epoch 5: Total Loss=7.4555\n",
      "Epoch 6: Total Loss=7.3922\n",
      "Epoch 7: Total Loss=7.5503\n",
      "Epoch 8: Total Loss=7.3545\n",
      "Epoch 9: Total Loss=7.3243\n",
      "Updated x: [0.030360789969563484, -0.012688323855400085], Function Value: 0.0010827711084857583, Gradient: [-0.002194629982113838, 0.020660940557718277]\n",
      "\n",
      "Step 115/200\n",
      "Epoch 0: Total Loss=7.3506\n",
      "Epoch 1: Total Loss=7.2982\n",
      "Epoch 2: Total Loss=7.4551\n",
      "Epoch 3: Total Loss=7.2522\n",
      "Epoch 4: Total Loss=7.3878\n",
      "Epoch 5: Total Loss=7.3096\n",
      "Epoch 6: Total Loss=7.3768\n",
      "Epoch 7: Total Loss=7.4042\n",
      "Epoch 8: Total Loss=7.4346\n",
      "Epoch 9: Total Loss=7.3513\n",
      "Updated x: [-0.012022057548165321, 0.05698201060295105], Function Value: 0.0033914793748408556, Gradient: [-0.001527767046354711, 0.013267472386360168]\n",
      "\n",
      "Step 116/200\n",
      "Epoch 0: Total Loss=7.3624\n",
      "Epoch 1: Total Loss=7.3400\n",
      "Epoch 2: Total Loss=7.4162\n",
      "Epoch 3: Total Loss=7.4656\n",
      "Epoch 4: Total Loss=7.3516\n",
      "Epoch 5: Total Loss=7.2854\n",
      "Epoch 6: Total Loss=7.4724\n",
      "Epoch 7: Total Loss=7.4301\n",
      "Epoch 8: Total Loss=7.4411\n",
      "Epoch 9: Total Loss=7.4233\n",
      "Updated x: [-0.06484086811542511, 0.05784786492586136], Function Value: 0.0075507136061787605, Gradient: [-0.0015744739212095737, 0.011703088879585266]\n",
      "\n",
      "Step 117/200\n",
      "Epoch 0: Total Loss=7.4586\n",
      "Epoch 1: Total Loss=7.4038\n",
      "Epoch 2: Total Loss=7.2655\n",
      "Epoch 3: Total Loss=7.3127\n",
      "Epoch 4: Total Loss=7.3595\n",
      "Epoch 5: Total Loss=7.3571\n",
      "Epoch 6: Total Loss=7.4158\n",
      "Epoch 7: Total Loss=7.3447\n",
      "Epoch 8: Total Loss=7.4173\n",
      "Epoch 9: Total Loss=7.4096\n",
      "Updated x: [-0.042401887476444244, -0.004666194319725037], Function Value: 0.0018196934834122658, Gradient: [-0.0013357398565858603, 0.008144727908074856]\n",
      "\n",
      "Step 118/200\n",
      "Epoch 0: Total Loss=7.4045\n",
      "Epoch 1: Total Loss=7.3461\n",
      "Epoch 2: Total Loss=7.4898\n",
      "Epoch 3: Total Loss=7.3169\n",
      "Epoch 4: Total Loss=7.3840\n",
      "Epoch 5: Total Loss=7.3160\n",
      "Epoch 6: Total Loss=7.2161\n",
      "Epoch 7: Total Loss=7.3254\n",
      "Epoch 8: Total Loss=7.3168\n",
      "Epoch 9: Total Loss=7.5578\n",
      "Updated x: [0.024377457797527313, -0.01059960387647152], Function Value: 0.0007066120742820203, Gradient: [-0.0011654009576886892, 0.00698475819081068]\n",
      "\n",
      "Step 119/200\n",
      "Epoch 0: Total Loss=7.3664\n",
      "Epoch 1: Total Loss=7.4594\n",
      "Epoch 2: Total Loss=7.2253\n",
      "Epoch 3: Total Loss=7.3885\n",
      "Epoch 4: Total Loss=7.3632\n",
      "Epoch 5: Total Loss=7.3856\n",
      "Epoch 6: Total Loss=7.3818\n",
      "Epoch 7: Total Loss=7.3695\n",
      "Epoch 8: Total Loss=7.4926\n",
      "Epoch 9: Total Loss=7.2748\n",
      "Updated x: [0.013592863455414772, 0.03354688733816147], Function Value: 0.0013101595686748624, Gradient: [-0.0010860468028113246, 0.006191007327288389]\n",
      "\n",
      "Step 120/200\n",
      "Epoch 0: Total Loss=7.3843\n",
      "Epoch 1: Total Loss=7.3803\n",
      "Epoch 2: Total Loss=7.3442\n",
      "Epoch 3: Total Loss=7.3202\n",
      "Epoch 4: Total Loss=7.4481\n",
      "Epoch 5: Total Loss=7.3781\n",
      "Epoch 6: Total Loss=7.3708\n",
      "Epoch 7: Total Loss=7.3565\n",
      "Epoch 8: Total Loss=7.2875\n",
      "Epoch 9: Total Loss=7.3390\n",
      "Updated x: [0.04581198841333389, -0.0012534931302070618], Function Value: 0.002100309357047081, Gradient: [-0.0009917319985106587, 0.007602908182889223]\n",
      "\n",
      "Step 121/200\n",
      "Epoch 0: Total Loss=7.4188\n",
      "Epoch 1: Total Loss=7.4442\n",
      "Epoch 2: Total Loss=7.4233\n",
      "Epoch 3: Total Loss=7.2536\n",
      "Epoch 4: Total Loss=7.4501\n",
      "Epoch 5: Total Loss=7.4846\n",
      "Epoch 6: Total Loss=7.4185\n",
      "Epoch 7: Total Loss=7.3849\n",
      "Epoch 8: Total Loss=7.3643\n",
      "Epoch 9: Total Loss=7.3242\n",
      "Updated x: [-0.0017554797232151031, 0.02686992846429348], Function Value: 0.0007250747294165194, Gradient: [-0.0005442705587483943, 0.0068472810089588165]\n",
      "\n",
      "Step 122/200\n",
      "Epoch 0: Total Loss=6.9785\n",
      "Epoch 1: Total Loss=7.0086\n",
      "Epoch 2: Total Loss=7.0024\n",
      "Epoch 3: Total Loss=6.9599\n",
      "Epoch 4: Total Loss=6.9770\n",
      "Epoch 5: Total Loss=6.9859\n",
      "Epoch 6: Total Loss=7.0199\n",
      "Epoch 7: Total Loss=6.9596\n",
      "Epoch 8: Total Loss=6.9521\n",
      "Epoch 9: Total Loss=6.9980\n",
      "Updated x: [0.025619348511099815, -0.054952576756477356], Function Value: 0.0036761367227882147, Gradient: [-0.0012650599237531424, 0.020555788651108742]\n",
      "\n",
      "Step 123/200\n",
      "Epoch 0: Total Loss=6.9531\n",
      "Epoch 1: Total Loss=6.9558\n",
      "Epoch 2: Total Loss=6.9758\n",
      "Epoch 3: Total Loss=6.9815\n",
      "Epoch 4: Total Loss=6.9737\n",
      "Epoch 5: Total Loss=6.9917\n",
      "Epoch 6: Total Loss=6.9755\n",
      "Epoch 7: Total Loss=7.0053\n",
      "Epoch 8: Total Loss=6.9871\n",
      "Epoch 9: Total Loss=6.9513\n",
      "Updated x: [-0.07075999677181244, -0.013792451471090317], Function Value: 0.005197209306061268, Gradient: [-0.0011232332326471806, 0.018681712448596954]\n",
      "\n",
      "Step 124/200\n",
      "Epoch 0: Total Loss=6.9779\n",
      "Epoch 1: Total Loss=6.9859\n",
      "Epoch 2: Total Loss=6.9737\n",
      "Epoch 3: Total Loss=6.9428\n",
      "Epoch 4: Total Loss=6.9601\n",
      "Epoch 5: Total Loss=7.0293\n",
      "Epoch 6: Total Loss=6.9761\n",
      "Epoch 7: Total Loss=6.9926\n",
      "Epoch 8: Total Loss=6.9489\n",
      "Epoch 9: Total Loss=6.9642\n",
      "Updated x: [-0.01852252706885338, -0.03937859460711479], Function Value: 0.0018937577260658145, Gradient: [-0.0009709489531815052, 0.023326653987169266]\n",
      "\n",
      "Step 125/200\n",
      "Epoch 0: Total Loss=7.0189\n",
      "Epoch 1: Total Loss=6.9590\n",
      "Epoch 2: Total Loss=6.9717\n",
      "Epoch 3: Total Loss=6.9557\n",
      "Epoch 4: Total Loss=6.9425\n",
      "Epoch 5: Total Loss=6.9880\n",
      "Epoch 6: Total Loss=6.9911\n",
      "Epoch 7: Total Loss=6.9648\n",
      "Epoch 8: Total Loss=7.0068\n",
      "Epoch 9: Total Loss=6.9640\n",
      "Updated x: [-0.030594628304243088, 0.038682710379362106], Function Value: 0.0024323833640664816, Gradient: [-0.0017235828563570976, 0.004937272518873215]\n",
      "\n",
      "Step 126/200\n",
      "Epoch 0: Total Loss=6.9903\n",
      "Epoch 1: Total Loss=6.9595\n",
      "Epoch 2: Total Loss=6.9659\n",
      "Epoch 3: Total Loss=6.9900\n",
      "Epoch 4: Total Loss=6.9538\n",
      "Epoch 5: Total Loss=6.9723\n",
      "Epoch 6: Total Loss=6.9656\n",
      "Epoch 7: Total Loss=6.9478\n",
      "Epoch 8: Total Loss=6.9818\n",
      "Epoch 9: Total Loss=6.9992\n",
      "Updated x: [-0.02614203840494156, 0.03872740641236305], Function Value: 0.002183218253776431, Gradient: [-0.002045297296717763, 0.0146964555606246]\n",
      "\n",
      "Step 127/200\n",
      "Epoch 0: Total Loss=6.9499\n",
      "Epoch 1: Total Loss=6.9402\n",
      "Epoch 2: Total Loss=6.9667\n",
      "Epoch 3: Total Loss=6.9728\n",
      "Epoch 4: Total Loss=7.0006\n",
      "Epoch 5: Total Loss=6.9596\n",
      "Epoch 6: Total Loss=6.9631\n",
      "Epoch 7: Total Loss=6.9873\n",
      "Epoch 8: Total Loss=6.9725\n",
      "Epoch 9: Total Loss=6.9667\n",
      "Updated x: [0.03319719806313515, -0.023690305650234222], Function Value: 0.0016632844926789403, Gradient: [-0.0012404299341142178, 0.01727268286049366]\n",
      "\n",
      "Step 128/200\n",
      "Epoch 0: Total Loss=6.9917\n",
      "Epoch 1: Total Loss=6.9734\n",
      "Epoch 2: Total Loss=6.9675\n",
      "Epoch 3: Total Loss=6.9864\n",
      "Epoch 4: Total Loss=6.9768\n",
      "Epoch 5: Total Loss=6.9405\n",
      "Epoch 6: Total Loss=6.9933\n",
      "Epoch 7: Total Loss=6.9466\n",
      "Epoch 8: Total Loss=6.9946\n",
      "Epoch 9: Total Loss=6.9953\n",
      "Updated x: [0.001531209796667099, -0.07329030334949493], Function Value: 0.005373813211917877, Gradient: [-0.0003866019251290709, 0.01364726759493351]\n",
      "\n",
      "Step 129/200\n",
      "Epoch 0: Total Loss=7.0022\n",
      "Epoch 1: Total Loss=6.9812\n",
      "Epoch 2: Total Loss=6.9516\n",
      "Epoch 3: Total Loss=6.9763\n",
      "Epoch 4: Total Loss=7.0094\n",
      "Epoch 5: Total Loss=6.9528\n",
      "Epoch 6: Total Loss=7.0016\n",
      "Epoch 7: Total Loss=6.9576\n",
      "Epoch 8: Total Loss=6.9889\n",
      "Epoch 9: Total Loss=6.9657\n",
      "Updated x: [-0.05706543102860451, 0.03510541468858719], Function Value: 0.004488853737711906, Gradient: [-0.0005033388151787221, 0.004918227903544903]\n",
      "\n",
      "Step 130/200\n",
      "Epoch 0: Total Loss=6.9583\n",
      "Epoch 1: Total Loss=6.9740\n",
      "Epoch 2: Total Loss=7.0099\n",
      "Epoch 3: Total Loss=6.9870\n",
      "Epoch 4: Total Loss=6.9845\n",
      "Epoch 5: Total Loss=6.9982\n",
      "Epoch 6: Total Loss=6.9971\n",
      "Epoch 7: Total Loss=6.9735\n",
      "Epoch 8: Total Loss=6.9455\n",
      "Epoch 9: Total Loss=6.9470\n",
      "Updated x: [-0.06030048429965973, -0.06838636100292206], Function Value: 0.008312842808663845, Gradient: [0.0007053933222778141, 0.01566854678094387]\n",
      "\n",
      "Step 131/200\n",
      "Epoch 0: Total Loss=6.9647\n",
      "Epoch 1: Total Loss=6.9597\n",
      "Epoch 2: Total Loss=6.9706\n",
      "Epoch 3: Total Loss=6.9587\n",
      "Epoch 4: Total Loss=6.9454\n",
      "Epoch 5: Total Loss=6.9655\n",
      "Epoch 6: Total Loss=6.9975\n",
      "Epoch 7: Total Loss=6.9864\n",
      "Epoch 8: Total Loss=6.9739\n",
      "Epoch 9: Total Loss=6.9537\n",
      "Updated x: [0.005926631391048431, -0.02573462575674057], Function Value: 0.0006973959389142692, Gradient: [7.04688909536344e-06, 0.012114201672375202]\n",
      "\n",
      "Step 132/200\n",
      "Epoch 0: Total Loss=7.6618\n",
      "Epoch 1: Total Loss=7.7568\n",
      "Epoch 2: Total Loss=7.8993\n",
      "Epoch 3: Total Loss=8.2804\n",
      "Epoch 4: Total Loss=7.5854\n",
      "Epoch 5: Total Loss=7.9451\n",
      "Epoch 6: Total Loss=8.1731\n",
      "Epoch 7: Total Loss=7.2265\n",
      "Epoch 8: Total Loss=8.4013\n",
      "Epoch 9: Total Loss=8.1424\n",
      "Updated x: [-0.0618538036942482, 0.05834093689918518], Function Value: 0.007229558192193508, Gradient: [0.001907280646264553, 0.01891675777733326]\n",
      "\n",
      "Step 133/200\n",
      "Epoch 0: Total Loss=7.8615\n",
      "Epoch 1: Total Loss=7.4818\n",
      "Epoch 2: Total Loss=7.9230\n",
      "Epoch 3: Total Loss=7.6350\n",
      "Epoch 4: Total Loss=7.7895\n",
      "Epoch 5: Total Loss=8.0772\n",
      "Epoch 6: Total Loss=7.4594\n",
      "Epoch 7: Total Loss=7.8588\n",
      "Epoch 8: Total Loss=7.8636\n",
      "Epoch 9: Total Loss=7.6100\n",
      "Updated x: [0.010505802929401398, 0.06299929320812225], Function Value: 0.004079282749444246, Gradient: [-2.495981243555434e-05, 0.03311542794108391]\n",
      "\n",
      "Step 134/200\n",
      "Epoch 0: Total Loss=7.9957\n",
      "Epoch 1: Total Loss=7.5745\n",
      "Epoch 2: Total Loss=7.9019\n",
      "Epoch 3: Total Loss=8.4531\n",
      "Epoch 4: Total Loss=7.7407\n",
      "Epoch 5: Total Loss=8.0828\n",
      "Epoch 6: Total Loss=7.8156\n",
      "Epoch 7: Total Loss=8.5722\n",
      "Epoch 8: Total Loss=7.9988\n",
      "Epoch 9: Total Loss=7.5353\n",
      "Updated x: [-0.015366574749350548, 0.017077405005693436], Function Value: 0.0005277693853713572, Gradient: [0.0004419869801495224, 0.030864695087075233]\n",
      "\n",
      "Step 135/200\n",
      "Epoch 0: Total Loss=8.0491\n",
      "Epoch 1: Total Loss=7.8444\n",
      "Epoch 2: Total Loss=7.9125\n",
      "Epoch 3: Total Loss=8.1634\n",
      "Epoch 4: Total Loss=7.6718\n",
      "Epoch 5: Total Loss=7.6031\n",
      "Epoch 6: Total Loss=7.7970\n",
      "Epoch 7: Total Loss=8.1266\n",
      "Epoch 8: Total Loss=7.8555\n",
      "Epoch 9: Total Loss=8.1132\n",
      "Updated x: [0.016466500237584114, 0.011577184312045574], Function Value: 0.0004051768337376416, Gradient: [0.0002987847838085145, 0.01826733537018299]\n",
      "\n",
      "Step 136/200\n",
      "Epoch 0: Total Loss=7.7584\n",
      "Epoch 1: Total Loss=7.7505\n",
      "Epoch 2: Total Loss=8.7224\n",
      "Epoch 3: Total Loss=7.7497\n",
      "Epoch 4: Total Loss=7.8478\n",
      "Epoch 5: Total Loss=7.6549\n",
      "Epoch 6: Total Loss=8.1020\n",
      "Epoch 7: Total Loss=7.8459\n",
      "Epoch 8: Total Loss=7.8674\n",
      "Epoch 9: Total Loss=8.3040\n",
      "Updated x: [0.019518127664923668, 0.052465785294771194], Function Value: 0.00313361594453454, Gradient: [-0.0001202700223075226, 0.020042147487401962]\n",
      "\n",
      "Step 137/200\n",
      "Epoch 0: Total Loss=8.2969\n",
      "Epoch 1: Total Loss=7.7907\n",
      "Epoch 2: Total Loss=7.3980\n",
      "Epoch 3: Total Loss=7.5252\n",
      "Epoch 4: Total Loss=7.5273\n",
      "Epoch 5: Total Loss=7.4415\n",
      "Epoch 6: Total Loss=7.7602\n",
      "Epoch 7: Total Loss=7.6974\n",
      "Epoch 8: Total Loss=8.6711\n",
      "Epoch 9: Total Loss=7.9379\n",
      "Updated x: [0.02979932725429535, 0.00021662190556526184], Function Value: 0.0008880468085408211, Gradient: [-3.894654582836665e-05, 0.02367180585861206]\n",
      "\n",
      "Step 138/200\n",
      "Epoch 0: Total Loss=7.6253\n",
      "Epoch 1: Total Loss=8.3109\n",
      "Epoch 2: Total Loss=8.3679\n",
      "Epoch 3: Total Loss=7.8713\n",
      "Epoch 4: Total Loss=7.7807\n",
      "Epoch 5: Total Loss=7.5811\n",
      "Epoch 6: Total Loss=8.0214\n",
      "Epoch 7: Total Loss=7.8879\n",
      "Epoch 8: Total Loss=8.4253\n",
      "Epoch 9: Total Loss=7.9220\n",
      "Updated x: [0.047010939568281174, -0.0765104740858078], Function Value: 0.00806388072669506, Gradient: [0.0005368732381612062, 0.022309832274913788]\n",
      "\n",
      "Step 139/200\n",
      "Epoch 0: Total Loss=7.5808\n",
      "Epoch 1: Total Loss=7.4037\n",
      "Epoch 2: Total Loss=8.2966\n",
      "Epoch 3: Total Loss=7.7642\n",
      "Epoch 4: Total Loss=8.2907\n",
      "Epoch 5: Total Loss=8.1659\n",
      "Epoch 6: Total Loss=7.5884\n",
      "Epoch 7: Total Loss=7.7316\n",
      "Epoch 8: Total Loss=7.8677\n",
      "Epoch 9: Total Loss=8.4635\n",
      "Updated x: [0.03100116178393364, 0.01376701146364212], Function Value: 0.0011506027076393366, Gradient: [0.00027164019411429763, 0.014900430105626583]\n",
      "\n",
      "Step 140/200\n",
      "Epoch 0: Total Loss=7.7018\n",
      "Epoch 1: Total Loss=7.8763\n",
      "Epoch 2: Total Loss=8.2839\n",
      "Epoch 3: Total Loss=7.7236\n",
      "Epoch 4: Total Loss=7.9027\n",
      "Epoch 5: Total Loss=7.9797\n",
      "Epoch 6: Total Loss=7.8370\n",
      "Epoch 7: Total Loss=8.2555\n",
      "Epoch 8: Total Loss=8.6335\n",
      "Epoch 9: Total Loss=7.8271\n",
      "Updated x: [-0.012142665684223175, -0.02569076418876648], Function Value: 0.0008074596989899874, Gradient: [0.0013283621519804, 0.016042931005358696]\n",
      "\n",
      "Step 141/200\n",
      "Epoch 0: Total Loss=7.7634\n",
      "Epoch 1: Total Loss=8.0226\n",
      "Epoch 2: Total Loss=7.3516\n",
      "Epoch 3: Total Loss=7.6266\n",
      "Epoch 4: Total Loss=8.1433\n",
      "Epoch 5: Total Loss=8.0178\n",
      "Epoch 6: Total Loss=8.1817\n",
      "Epoch 7: Total Loss=7.5996\n",
      "Epoch 8: Total Loss=7.8140\n",
      "Epoch 9: Total Loss=8.1753\n",
      "Updated x: [-0.03658732771873474, 0.03694020211696625], Function Value: 0.002703211037442088, Gradient: [0.000881248852238059, 0.019901517778635025]\n",
      "\n",
      "Step 142/200\n",
      "Epoch 0: Total Loss=7.5140\n",
      "Epoch 1: Total Loss=7.4521\n",
      "Epoch 2: Total Loss=7.4698\n",
      "Epoch 3: Total Loss=7.4364\n",
      "Epoch 4: Total Loss=7.2854\n",
      "Epoch 5: Total Loss=7.5691\n",
      "Epoch 6: Total Loss=7.4903\n",
      "Epoch 7: Total Loss=7.3918\n",
      "Epoch 8: Total Loss=7.7250\n",
      "Epoch 9: Total Loss=7.5922\n",
      "Updated x: [-0.03508896753191948, 0.019322501495480537], Function Value: 0.0016045947559177876, Gradient: [0.00020380897331051528, 0.028162814676761627]\n",
      "\n",
      "Step 143/200\n",
      "Epoch 0: Total Loss=7.5863\n",
      "Epoch 1: Total Loss=7.4999\n",
      "Epoch 2: Total Loss=7.6086\n",
      "Epoch 3: Total Loss=7.3680\n",
      "Epoch 4: Total Loss=7.5881\n",
      "Epoch 5: Total Loss=7.4650\n",
      "Epoch 6: Total Loss=7.6031\n",
      "Epoch 7: Total Loss=7.4945\n",
      "Epoch 8: Total Loss=7.5141\n",
      "Epoch 9: Total Loss=7.5349\n",
      "Updated x: [-0.02759648486971855, -0.03235567361116409], Function Value: 0.0018084555631503463, Gradient: [0.0008502381388098001, 0.009998024441301823]\n",
      "\n",
      "Step 144/200\n",
      "Epoch 0: Total Loss=7.5390\n",
      "Epoch 1: Total Loss=7.5874\n",
      "Epoch 2: Total Loss=7.6697\n",
      "Epoch 3: Total Loss=7.3580\n",
      "Epoch 4: Total Loss=7.5201\n",
      "Epoch 5: Total Loss=7.6526\n",
      "Epoch 6: Total Loss=7.5703\n",
      "Epoch 7: Total Loss=7.4848\n",
      "Epoch 8: Total Loss=7.4967\n",
      "Epoch 9: Total Loss=7.3283\n",
      "Updated x: [-0.025116000324487686, 0.023268137127161026], Function Value: 0.0011722196359187365, Gradient: [0.0003923852345906198, 0.006379415281116962]\n",
      "\n",
      "Step 145/200\n",
      "Epoch 0: Total Loss=7.6214\n",
      "Epoch 1: Total Loss=7.5156\n",
      "Epoch 2: Total Loss=7.5706\n",
      "Epoch 3: Total Loss=7.5124\n",
      "Epoch 4: Total Loss=7.7334\n",
      "Epoch 5: Total Loss=7.3768\n",
      "Epoch 6: Total Loss=7.5948\n",
      "Epoch 7: Total Loss=7.4440\n",
      "Epoch 8: Total Loss=7.6021\n",
      "Epoch 9: Total Loss=7.5806\n",
      "Updated x: [0.00010082125663757324, 0.010463030077517033], Function Value: 0.00010948516137432307, Gradient: [8.65377951413393e-05, 0.01665559411048889]\n",
      "\n",
      "Step 146/200\n",
      "Epoch 0: Total Loss=7.6672\n",
      "Epoch 1: Total Loss=7.5245\n",
      "Epoch 2: Total Loss=7.4734\n",
      "Epoch 3: Total Loss=7.4208\n",
      "Epoch 4: Total Loss=7.7924\n",
      "Epoch 5: Total Loss=7.5614\n",
      "Epoch 6: Total Loss=7.5822\n",
      "Epoch 7: Total Loss=7.2563\n",
      "Epoch 8: Total Loss=7.6907\n",
      "Epoch 9: Total Loss=7.6599\n",
      "Updated x: [-0.0015238368650898337, 0.04316767677664757], Function Value: 0.001865770434960723, Gradient: [-6.6087901359424e-05, 0.016015024855732918]\n",
      "\n",
      "Step 147/200\n",
      "Epoch 0: Total Loss=7.5352\n",
      "Epoch 1: Total Loss=7.5275\n",
      "Epoch 2: Total Loss=7.4391\n",
      "Epoch 3: Total Loss=7.3714\n",
      "Epoch 4: Total Loss=7.6588\n",
      "Epoch 5: Total Loss=7.7141\n",
      "Epoch 6: Total Loss=7.3507\n",
      "Epoch 7: Total Loss=7.5575\n",
      "Epoch 8: Total Loss=7.7757\n",
      "Epoch 9: Total Loss=7.5211\n",
      "Updated x: [-0.0009209251147694886, -0.004973944276571274], Function Value: 2.5588225980754942e-05, Gradient: [0.0006292598554864526, 0.01583188585937023]\n",
      "\n",
      "Step 148/200\n",
      "Epoch 0: Total Loss=7.4956\n",
      "Epoch 1: Total Loss=7.4947\n",
      "Epoch 2: Total Loss=7.6356\n",
      "Epoch 3: Total Loss=7.4692\n",
      "Epoch 4: Total Loss=7.5590\n",
      "Epoch 5: Total Loss=7.4143\n",
      "Epoch 6: Total Loss=7.4667\n",
      "Epoch 7: Total Loss=7.6944\n",
      "Epoch 8: Total Loss=7.4235\n",
      "Epoch 9: Total Loss=7.4884\n",
      "Updated x: [0.009325575083494186, 0.04928510636091232], Function Value: 0.002515988191589713, Gradient: [-0.00046706764260306954, 0.009667192585766315]\n",
      "\n",
      "Step 149/200\n",
      "Epoch 0: Total Loss=7.5198\n",
      "Epoch 1: Total Loss=7.5282\n",
      "Epoch 2: Total Loss=7.7171\n",
      "Epoch 3: Total Loss=7.7454\n",
      "Epoch 4: Total Loss=7.5770\n",
      "Epoch 5: Total Loss=7.4901\n",
      "Epoch 6: Total Loss=7.7876\n",
      "Epoch 7: Total Loss=7.4156\n",
      "Epoch 8: Total Loss=7.3913\n",
      "Epoch 9: Total Loss=7.5986\n",
      "Updated x: [0.03138050436973572, -0.07340925931930542], Function Value: 0.006373655050992966, Gradient: [0.0010113747557625175, 0.014047625474631786]\n",
      "\n",
      "Step 150/200\n",
      "Epoch 0: Total Loss=7.3200\n",
      "Epoch 1: Total Loss=7.7375\n",
      "Epoch 2: Total Loss=7.3209\n",
      "Epoch 3: Total Loss=7.5736\n",
      "Epoch 4: Total Loss=7.7653\n",
      "Epoch 5: Total Loss=7.3820\n",
      "Epoch 6: Total Loss=7.5139\n",
      "Epoch 7: Total Loss=7.5003\n",
      "Epoch 8: Total Loss=7.5928\n",
      "Epoch 9: Total Loss=7.4533\n",
      "Updated x: [-0.050404079258441925, 0.05061846226453781], Function Value: 0.005102800205349922, Gradient: [7.060063126118621e-06, 0.013759799301624298]\n",
      "\n",
      "Step 151/200\n",
      "Epoch 0: Total Loss=7.4494\n",
      "Epoch 1: Total Loss=7.4685\n",
      "Epoch 2: Total Loss=7.5742\n",
      "Epoch 3: Total Loss=7.6464\n",
      "Epoch 4: Total Loss=7.7829\n",
      "Epoch 5: Total Loss=7.3980\n",
      "Epoch 6: Total Loss=7.5764\n",
      "Epoch 7: Total Loss=7.5147\n",
      "Epoch 8: Total Loss=7.5316\n",
      "Epoch 9: Total Loss=7.5894\n",
      "Updated x: [-0.023049447685480118, -0.09783618897199631], Function Value: 0.010103196837008, Gradient: [0.001698031323030591, 0.01654111035168171]\n",
      "\n",
      "Step 152/200\n",
      "Epoch 0: Total Loss=7.1498\n",
      "Epoch 1: Total Loss=7.1794\n",
      "Epoch 2: Total Loss=7.1896\n",
      "Epoch 3: Total Loss=7.0754\n",
      "Epoch 4: Total Loss=7.1167\n",
      "Epoch 5: Total Loss=7.1198\n",
      "Epoch 6: Total Loss=7.1027\n",
      "Epoch 7: Total Loss=7.1816\n",
      "Epoch 8: Total Loss=7.1757\n",
      "Epoch 9: Total Loss=7.2895\n",
      "Updated x: [-0.03266647830605507, -0.035292305052280426], Function Value: 0.0023126457817852497, Gradient: [-0.0005754873272962868, -0.017887204885482788]\n",
      "\n",
      "Step 153/200\n",
      "Epoch 0: Total Loss=7.1560\n",
      "Epoch 1: Total Loss=7.1366\n",
      "Epoch 2: Total Loss=7.2020\n",
      "Epoch 3: Total Loss=7.1524\n",
      "Epoch 4: Total Loss=7.2168\n",
      "Epoch 5: Total Loss=7.1803\n",
      "Epoch 6: Total Loss=7.1188\n",
      "Epoch 7: Total Loss=7.1605\n",
      "Epoch 8: Total Loss=7.2179\n",
      "Epoch 9: Total Loss=7.1795\n",
      "Updated x: [0.04085388407111168, -0.0028516463935375214], Function Value: 0.0016771716764196754, Gradient: [0.0003153646248392761, -0.007771821692585945]\n",
      "\n",
      "Step 154/200\n",
      "Epoch 0: Total Loss=7.1114\n",
      "Epoch 1: Total Loss=7.1097\n",
      "Epoch 2: Total Loss=7.2853\n",
      "Epoch 3: Total Loss=7.1281\n",
      "Epoch 4: Total Loss=7.2097\n",
      "Epoch 5: Total Loss=7.1913\n",
      "Epoch 6: Total Loss=7.1516\n",
      "Epoch 7: Total Loss=7.1138\n",
      "Epoch 8: Total Loss=7.1297\n",
      "Epoch 9: Total Loss=7.1537\n",
      "Updated x: [0.001474715769290924, 0.01443752832710743], Function Value: 0.00021061701409053057, Gradient: [0.0001951415470102802, 0.00334173534065485]\n",
      "\n",
      "Step 155/200\n",
      "Epoch 0: Total Loss=7.1649\n",
      "Epoch 1: Total Loss=7.1311\n",
      "Epoch 2: Total Loss=7.1999\n",
      "Epoch 3: Total Loss=7.1441\n",
      "Epoch 4: Total Loss=7.1015\n",
      "Epoch 5: Total Loss=7.1725\n",
      "Epoch 6: Total Loss=7.1863\n",
      "Epoch 7: Total Loss=7.2484\n",
      "Epoch 8: Total Loss=7.1582\n",
      "Epoch 9: Total Loss=7.1206\n",
      "Updated x: [0.020186958834528923, 0.014099767431616783], Function Value: 0.0006063167238608003, Gradient: [0.0006881075678393245, 0.005767188034951687]\n",
      "\n",
      "Step 156/200\n",
      "Epoch 0: Total Loss=7.1126\n",
      "Epoch 1: Total Loss=7.1747\n",
      "Epoch 2: Total Loss=7.1275\n",
      "Epoch 3: Total Loss=7.1290\n",
      "Epoch 4: Total Loss=7.1481\n",
      "Epoch 5: Total Loss=7.1684\n",
      "Epoch 6: Total Loss=7.2084\n",
      "Epoch 7: Total Loss=7.1255\n",
      "Epoch 8: Total Loss=7.3095\n",
      "Epoch 9: Total Loss=7.1333\n",
      "Updated x: [0.005160071887075901, -0.03166159987449646], Function Value: 0.0010290832724422216, Gradient: [0.0017834097379818559, 0.010247482918202877]\n",
      "\n",
      "Step 157/200\n",
      "Epoch 0: Total Loss=7.1727\n",
      "Epoch 1: Total Loss=7.0491\n",
      "Epoch 2: Total Loss=7.1808\n",
      "Epoch 3: Total Loss=7.1864\n",
      "Epoch 4: Total Loss=7.1702\n",
      "Epoch 5: Total Loss=7.1471\n",
      "Epoch 6: Total Loss=7.1350\n",
      "Epoch 7: Total Loss=7.2000\n",
      "Epoch 8: Total Loss=7.1281\n",
      "Epoch 9: Total Loss=7.0930\n",
      "Updated x: [-0.01237229723483324, -0.05366361886262894], Function Value: 0.003032857785001397, Gradient: [0.001884743571281433, 0.008790039457380772]\n",
      "\n",
      "Step 158/200\n",
      "Epoch 0: Total Loss=7.1463\n",
      "Epoch 1: Total Loss=7.0597\n",
      "Epoch 2: Total Loss=7.1268\n",
      "Epoch 3: Total Loss=7.1903\n",
      "Epoch 4: Total Loss=7.1717\n",
      "Epoch 5: Total Loss=7.1412\n",
      "Epoch 6: Total Loss=7.1484\n",
      "Epoch 7: Total Loss=7.2060\n",
      "Epoch 8: Total Loss=7.1473\n",
      "Epoch 9: Total Loss=7.1214\n",
      "Updated x: [-0.038886673748493195, 0.03667359799146652], Function Value: 0.002857126295566559, Gradient: [0.0009510763920843601, 0.00778835779055953]\n",
      "\n",
      "Step 159/200\n",
      "Epoch 0: Total Loss=7.1010\n",
      "Epoch 1: Total Loss=7.1781\n",
      "Epoch 2: Total Loss=7.2238\n",
      "Epoch 3: Total Loss=7.2062\n",
      "Epoch 4: Total Loss=7.1186\n",
      "Epoch 5: Total Loss=7.1380\n",
      "Epoch 6: Total Loss=7.1969\n",
      "Epoch 7: Total Loss=7.1674\n",
      "Epoch 8: Total Loss=7.2375\n",
      "Epoch 9: Total Loss=7.1763\n",
      "Updated x: [0.018065445125102997, 0.02439577877521515], Function Value: 0.0009215143509209156, Gradient: [0.0009566583903506398, 0.010577298700809479]\n",
      "\n",
      "Step 160/200\n",
      "Epoch 0: Total Loss=7.1825\n",
      "Epoch 1: Total Loss=7.1708\n",
      "Epoch 2: Total Loss=7.0728\n",
      "Epoch 3: Total Loss=7.1777\n",
      "Epoch 4: Total Loss=7.1082\n",
      "Epoch 5: Total Loss=7.1836\n",
      "Epoch 6: Total Loss=7.0732\n",
      "Epoch 7: Total Loss=7.2351\n",
      "Epoch 8: Total Loss=7.1622\n",
      "Epoch 9: Total Loss=7.1093\n",
      "Updated x: [0.015458323992788792, 0.016936037689447403], Function Value: 0.000525789160747081, Gradient: [0.001419678097590804, 0.0103132463991642]\n",
      "\n",
      "Step 161/200\n",
      "Epoch 0: Total Loss=7.1126\n",
      "Epoch 1: Total Loss=7.2243\n",
      "Epoch 2: Total Loss=7.1783\n",
      "Epoch 3: Total Loss=7.2117\n",
      "Epoch 4: Total Loss=7.1147\n",
      "Epoch 5: Total Loss=7.1389\n",
      "Epoch 6: Total Loss=7.1146\n",
      "Epoch 7: Total Loss=7.1662\n",
      "Epoch 8: Total Loss=7.1441\n",
      "Epoch 9: Total Loss=7.1786\n",
      "Updated x: [0.00024078227579593658, 0.028311453759670258], Function Value: 0.0008015963830985129, Gradient: [0.0013143166434019804, 0.010327371768653393]\n",
      "\n",
      "Step 162/200\n",
      "Epoch 0: Total Loss=6.8436\n",
      "Epoch 1: Total Loss=6.8375\n",
      "Epoch 2: Total Loss=6.8342\n",
      "Epoch 3: Total Loss=6.8437\n",
      "Epoch 4: Total Loss=6.8455\n",
      "Epoch 5: Total Loss=6.8333\n",
      "Epoch 6: Total Loss=6.8269\n",
      "Epoch 7: Total Loss=6.8393\n",
      "Epoch 8: Total Loss=6.8260\n",
      "Epoch 9: Total Loss=6.8359\n",
      "Updated x: [-0.06745679676532745, 0.006266601383686066], Function Value: 0.004589689429849386, Gradient: [0.0011033861665055156, 0.046893734484910965]\n",
      "\n",
      "Step 163/200\n",
      "Epoch 0: Total Loss=6.8295\n",
      "Epoch 1: Total Loss=6.8370\n",
      "Epoch 2: Total Loss=6.8427\n",
      "Epoch 3: Total Loss=6.8349\n",
      "Epoch 4: Total Loss=6.8308\n",
      "Epoch 5: Total Loss=6.8325\n",
      "Epoch 6: Total Loss=6.8380\n",
      "Epoch 7: Total Loss=6.8481\n",
      "Epoch 8: Total Loss=6.8371\n",
      "Epoch 9: Total Loss=6.8356\n",
      "Updated x: [-0.016904756426811218, 0.0024811867624521255], Function Value: 0.00029192707734182477, Gradient: [0.0005897816154174507, 0.02327938936650753]\n",
      "\n",
      "Step 164/200\n",
      "Epoch 0: Total Loss=6.8392\n",
      "Epoch 1: Total Loss=6.8317\n",
      "Epoch 2: Total Loss=6.8385\n",
      "Epoch 3: Total Loss=6.8396\n",
      "Epoch 4: Total Loss=6.8318\n",
      "Epoch 5: Total Loss=6.8280\n",
      "Epoch 6: Total Loss=6.8459\n",
      "Epoch 7: Total Loss=6.8341\n",
      "Epoch 8: Total Loss=6.8352\n",
      "Epoch 9: Total Loss=6.8266\n",
      "Updated x: [-0.007201209664344788, 0.029367871582508087], Function Value: 0.000914329313673079, Gradient: [-0.00012985443754587322, 0.022585688158869743]\n",
      "\n",
      "Step 165/200\n",
      "Epoch 0: Total Loss=6.8437\n",
      "Epoch 1: Total Loss=6.8373\n",
      "Epoch 2: Total Loss=6.8279\n",
      "Epoch 3: Total Loss=6.8407\n",
      "Epoch 4: Total Loss=6.8254\n",
      "Epoch 5: Total Loss=6.8330\n",
      "Epoch 6: Total Loss=6.8457\n",
      "Epoch 7: Total Loss=6.8350\n",
      "Epoch 8: Total Loss=6.8428\n",
      "Epoch 9: Total Loss=6.8370\n",
      "Updated x: [-0.004544452298432589, -0.043061718344688416], Function Value: 0.0018749636365100741, Gradient: [0.0012370251351967454, 0.026080792769789696]\n",
      "\n",
      "Step 166/200\n",
      "Epoch 0: Total Loss=6.8415\n",
      "Epoch 1: Total Loss=6.8347\n",
      "Epoch 2: Total Loss=6.8321\n",
      "Epoch 3: Total Loss=6.8409\n",
      "Epoch 4: Total Loss=6.8348\n",
      "Epoch 5: Total Loss=6.8380\n",
      "Epoch 6: Total Loss=6.8338\n",
      "Epoch 7: Total Loss=6.8351\n",
      "Epoch 8: Total Loss=6.8305\n",
      "Epoch 9: Total Loss=6.8336\n",
      "Updated x: [-0.010424302890896797, -0.0043687112629413605], Function Value: 0.0001277517294511199, Gradient: [0.0007731104269623756, 0.01912572607398033]\n",
      "\n",
      "Step 167/200\n",
      "Epoch 0: Total Loss=6.8427\n",
      "Epoch 1: Total Loss=6.8356\n",
      "Epoch 2: Total Loss=6.8344\n",
      "Epoch 3: Total Loss=6.8284\n",
      "Epoch 4: Total Loss=6.8306\n",
      "Epoch 5: Total Loss=6.8271\n",
      "Epoch 6: Total Loss=6.8308\n",
      "Epoch 7: Total Loss=6.8431\n",
      "Epoch 8: Total Loss=6.8350\n",
      "Epoch 9: Total Loss=6.8338\n",
      "Updated x: [0.013340279459953308, 0.011261481791734695], Function Value: 0.00030478404369205236, Gradient: [0.0002837457286659628, 0.020266300067305565]\n",
      "\n",
      "Step 168/200\n",
      "Epoch 0: Total Loss=6.8357\n",
      "Epoch 1: Total Loss=6.8380\n",
      "Epoch 2: Total Loss=6.8381\n",
      "Epoch 3: Total Loss=6.8478\n",
      "Epoch 4: Total Loss=6.8351\n",
      "Epoch 5: Total Loss=6.8357\n",
      "Epoch 6: Total Loss=6.8422\n",
      "Epoch 7: Total Loss=6.8285\n",
      "Epoch 8: Total Loss=6.8348\n",
      "Epoch 9: Total Loss=6.8291\n",
      "Updated x: [0.057278525084257126, 0.04628978669643402], Function Value: 0.005423573777079582, Gradient: [-0.0007635799702256918, 0.018991420045495033]\n",
      "\n",
      "Step 169/200\n",
      "Epoch 0: Total Loss=6.8382\n",
      "Epoch 1: Total Loss=6.8318\n",
      "Epoch 2: Total Loss=6.8286\n",
      "Epoch 3: Total Loss=6.8293\n",
      "Epoch 4: Total Loss=6.8403\n",
      "Epoch 5: Total Loss=6.8273\n",
      "Epoch 6: Total Loss=6.8384\n",
      "Epoch 7: Total Loss=6.8297\n",
      "Epoch 8: Total Loss=6.8419\n",
      "Epoch 9: Total Loss=6.8368\n",
      "Updated x: [0.05580344796180725, -0.02215711772441864], Function Value: 0.0036049627233296633, Gradient: [0.0008694407879374921, 0.019909538328647614]\n",
      "\n",
      "Step 170/200\n",
      "Epoch 0: Total Loss=6.8415\n",
      "Epoch 1: Total Loss=6.8325\n",
      "Epoch 2: Total Loss=6.8291\n",
      "Epoch 3: Total Loss=6.8345\n",
      "Epoch 4: Total Loss=6.8298\n",
      "Epoch 5: Total Loss=6.8375\n",
      "Epoch 6: Total Loss=6.8408\n",
      "Epoch 7: Total Loss=6.8397\n",
      "Epoch 8: Total Loss=6.8288\n",
      "Epoch 9: Total Loss=6.8327\n",
      "Updated x: [-0.04591054469347, 0.020231623202562332], Function Value: 0.002517096698284149, Gradient: [0.0005872458568774164, 0.018964728340506554]\n",
      "\n",
      "Step 171/200\n",
      "Epoch 0: Total Loss=6.8382\n",
      "Epoch 1: Total Loss=6.8303\n",
      "Epoch 2: Total Loss=6.8331\n",
      "Epoch 3: Total Loss=6.8308\n",
      "Epoch 4: Total Loss=6.8287\n",
      "Epoch 5: Total Loss=6.8261\n",
      "Epoch 6: Total Loss=6.8299\n",
      "Epoch 7: Total Loss=6.8291\n",
      "Epoch 8: Total Loss=6.8300\n",
      "Epoch 9: Total Loss=6.8278\n",
      "Updated x: [0.03328373283147812, 0.0500478520989418], Function Value: 0.003612594213336706, Gradient: [-0.00030699619674123824, 0.015765277668833733]\n",
      "\n",
      "Step 172/200\n",
      "Epoch 0: Total Loss=7.6210\n",
      "Epoch 1: Total Loss=7.5093\n",
      "Epoch 2: Total Loss=8.1735\n",
      "Epoch 3: Total Loss=7.8690\n",
      "Epoch 4: Total Loss=7.6836\n",
      "Epoch 5: Total Loss=7.7236\n",
      "Epoch 6: Total Loss=7.7365\n",
      "Epoch 7: Total Loss=8.0835\n",
      "Epoch 8: Total Loss=8.2130\n",
      "Epoch 9: Total Loss=7.4570\n",
      "Updated x: [0.08331188559532166, -0.05114603042602539], Function Value: 0.009556787088513374, Gradient: [0.0015694256871938705, 0.0300417710095644]\n",
      "\n",
      "Step 173/200\n",
      "Epoch 0: Total Loss=7.6604\n",
      "Epoch 1: Total Loss=7.8650\n",
      "Epoch 2: Total Loss=7.4696\n",
      "Epoch 3: Total Loss=7.3593\n",
      "Epoch 4: Total Loss=7.5196\n",
      "Epoch 5: Total Loss=7.4821\n",
      "Epoch 6: Total Loss=7.7344\n",
      "Epoch 7: Total Loss=7.9153\n",
      "Epoch 8: Total Loss=7.6399\n",
      "Epoch 9: Total Loss=7.8465\n",
      "Updated x: [0.08919500559568405, 0.013275988399982452], Function Value: 0.00813200045377016, Gradient: [5.9778471040772274e-05, 0.019627412781119347]\n",
      "\n",
      "Step 174/200\n",
      "Epoch 0: Total Loss=7.5268\n",
      "Epoch 1: Total Loss=7.7549\n",
      "Epoch 2: Total Loss=7.4891\n",
      "Epoch 3: Total Loss=8.1640\n",
      "Epoch 4: Total Loss=7.6636\n",
      "Epoch 5: Total Loss=7.5986\n",
      "Epoch 6: Total Loss=7.6914\n",
      "Epoch 7: Total Loss=7.3329\n",
      "Epoch 8: Total Loss=7.6545\n",
      "Epoch 9: Total Loss=8.0410\n",
      "Updated x: [0.015620425343513489, 0.06635995209217072], Function Value: 0.004647640977054834, Gradient: [-0.0004607830778695643, 0.021205663681030273]\n",
      "\n",
      "Step 175/200\n",
      "Epoch 0: Total Loss=7.4433\n",
      "Epoch 1: Total Loss=7.8053\n",
      "Epoch 2: Total Loss=7.5517\n",
      "Epoch 3: Total Loss=7.3767\n",
      "Epoch 4: Total Loss=7.8033\n",
      "Epoch 5: Total Loss=7.8239\n",
      "Epoch 6: Total Loss=7.4391\n",
      "Epoch 7: Total Loss=7.4050\n",
      "Epoch 8: Total Loss=7.9025\n",
      "Epoch 9: Total Loss=7.8982\n",
      "Updated x: [-0.03698326647281647, -0.018194355070590973], Function Value: 0.0016987965209409595, Gradient: [0.00038322529871948063, 0.01922757923603058]\n",
      "\n",
      "Step 176/200\n",
      "Epoch 0: Total Loss=7.5430\n",
      "Epoch 1: Total Loss=7.8776\n",
      "Epoch 2: Total Loss=7.8315\n",
      "Epoch 3: Total Loss=7.7003\n",
      "Epoch 4: Total Loss=7.4202\n",
      "Epoch 5: Total Loss=7.3510\n",
      "Epoch 6: Total Loss=7.8649\n",
      "Epoch 7: Total Loss=7.8868\n",
      "Epoch 8: Total Loss=7.6405\n",
      "Epoch 9: Total Loss=8.0595\n",
      "Updated x: [-0.009165599942207336, -0.027006514370441437], Function Value: 0.0008133600349538028, Gradient: [9.796590165933594e-05, 0.02511717937886715]\n",
      "\n",
      "Step 177/200\n",
      "Epoch 0: Total Loss=7.3434\n",
      "Epoch 1: Total Loss=7.5926\n",
      "Epoch 2: Total Loss=7.3906\n",
      "Epoch 3: Total Loss=7.4774\n",
      "Epoch 4: Total Loss=7.4418\n",
      "Epoch 5: Total Loss=7.7096\n",
      "Epoch 6: Total Loss=8.0967\n",
      "Epoch 7: Total Loss=7.5333\n",
      "Epoch 8: Total Loss=7.5621\n",
      "Epoch 9: Total Loss=7.6882\n",
      "Updated x: [0.05051109567284584, -0.0591193325817585], Function Value: 0.006046466529369354, Gradient: [0.0007729085045866668, 0.02084403485059738]\n",
      "\n",
      "Step 178/200\n",
      "Epoch 0: Total Loss=7.9701\n",
      "Epoch 1: Total Loss=7.3166\n",
      "Epoch 2: Total Loss=7.9167\n",
      "Epoch 3: Total Loss=7.5414\n",
      "Epoch 4: Total Loss=8.1361\n",
      "Epoch 5: Total Loss=7.4084\n",
      "Epoch 6: Total Loss=7.5254\n",
      "Epoch 7: Total Loss=7.7341\n",
      "Epoch 8: Total Loss=7.5009\n",
      "Epoch 9: Total Loss=7.7470\n",
      "Updated x: [0.09839243441820145, -0.006857037544250488], Function Value: 0.009728089906275272, Gradient: [-0.0004475560854189098, 0.017730357125401497]\n",
      "\n",
      "Step 179/200\n",
      "Epoch 0: Total Loss=7.2940\n",
      "Epoch 1: Total Loss=7.5949\n",
      "Epoch 2: Total Loss=7.5617\n",
      "Epoch 3: Total Loss=7.7032\n",
      "Epoch 4: Total Loss=7.7969\n",
      "Epoch 5: Total Loss=7.4559\n",
      "Epoch 6: Total Loss=7.5212\n",
      "Epoch 7: Total Loss=7.7611\n",
      "Epoch 8: Total Loss=7.7883\n",
      "Epoch 9: Total Loss=7.3723\n",
      "Updated x: [-0.040866293013095856, -0.05577957257628441], Function Value: 0.00478141475468874, Gradient: [0.0009156489977613091, 0.01804131269454956]\n",
      "\n",
      "Step 180/200\n",
      "Epoch 0: Total Loss=7.4058\n",
      "Epoch 1: Total Loss=7.6094\n",
      "Epoch 2: Total Loss=7.6513\n",
      "Epoch 3: Total Loss=7.9745\n",
      "Epoch 4: Total Loss=7.8633\n",
      "Epoch 5: Total Loss=7.6415\n",
      "Epoch 6: Total Loss=8.1439\n",
      "Epoch 7: Total Loss=7.6222\n",
      "Epoch 8: Total Loss=7.7119\n",
      "Epoch 9: Total Loss=7.5689\n",
      "Updated x: [-0.008692529052495956, 0.0207136832177639], Function Value: 0.0005046167643740773, Gradient: [-0.000986478989943862, 0.015817798674106598]\n",
      "\n",
      "Step 181/200\n",
      "Epoch 0: Total Loss=7.8206\n",
      "Epoch 1: Total Loss=7.5585\n",
      "Epoch 2: Total Loss=7.9450\n",
      "Epoch 3: Total Loss=7.4150\n",
      "Epoch 4: Total Loss=7.8422\n",
      "Epoch 5: Total Loss=7.6292\n",
      "Epoch 6: Total Loss=7.6638\n",
      "Epoch 7: Total Loss=7.7993\n",
      "Epoch 8: Total Loss=7.4070\n",
      "Epoch 9: Total Loss=7.7528\n",
      "Updated x: [0.05871598795056343, 0.03823380172252655], Function Value: 0.004909391049295664, Gradient: [-0.0019183031981810927, 0.007288566790521145]\n",
      "\n",
      "Step 182/200\n",
      "Epoch 0: Total Loss=7.2730\n",
      "Epoch 1: Total Loss=7.2854\n",
      "Epoch 2: Total Loss=7.3803\n",
      "Epoch 3: Total Loss=7.6376\n",
      "Epoch 4: Total Loss=7.2934\n",
      "Epoch 5: Total Loss=7.3110\n",
      "Epoch 6: Total Loss=7.2236\n",
      "Epoch 7: Total Loss=7.3041\n",
      "Epoch 8: Total Loss=7.3063\n",
      "Epoch 9: Total Loss=7.4435\n",
      "Updated x: [0.02373718097805977, 0.04391343519091606], Function Value: 0.002491843421012163, Gradient: [0.0002553215017542243, 0.0511479377746582]\n",
      "\n",
      "Step 183/200\n",
      "Epoch 0: Total Loss=7.3484\n",
      "Epoch 1: Total Loss=7.2274\n",
      "Epoch 2: Total Loss=7.1302\n",
      "Epoch 3: Total Loss=7.1880\n",
      "Epoch 4: Total Loss=7.2249\n",
      "Epoch 5: Total Loss=7.4038\n",
      "Epoch 6: Total Loss=7.1838\n",
      "Epoch 7: Total Loss=7.2852\n",
      "Epoch 8: Total Loss=7.2446\n",
      "Epoch 9: Total Loss=7.4385\n",
      "Updated x: [-0.03126983717083931, -0.021505575627088547], Function Value: 0.0014402924571186304, Gradient: [0.00294927298091352, 0.035681288689374924]\n",
      "\n",
      "Step 184/200\n",
      "Epoch 0: Total Loss=7.1737\n",
      "Epoch 1: Total Loss=7.3917\n",
      "Epoch 2: Total Loss=7.1587\n",
      "Epoch 3: Total Loss=7.2178\n",
      "Epoch 4: Total Loss=7.1945\n",
      "Epoch 5: Total Loss=7.3491\n",
      "Epoch 6: Total Loss=7.2692\n",
      "Epoch 7: Total Loss=7.3177\n",
      "Epoch 8: Total Loss=7.3086\n",
      "Epoch 9: Total Loss=7.2889\n",
      "Updated x: [0.005020301789045334, -0.007819855585694313], Function Value: 8.635356789454818e-05, Gradient: [0.0018895254470407963, 0.01212501060217619]\n",
      "\n",
      "Step 185/200\n",
      "Epoch 0: Total Loss=7.3228\n",
      "Epoch 1: Total Loss=7.2635\n",
      "Epoch 2: Total Loss=7.2917\n",
      "Epoch 3: Total Loss=7.2042\n",
      "Epoch 4: Total Loss=7.4740\n",
      "Epoch 5: Total Loss=7.3521\n",
      "Epoch 6: Total Loss=7.3063\n",
      "Epoch 7: Total Loss=7.2692\n",
      "Epoch 8: Total Loss=7.2421\n",
      "Epoch 9: Total Loss=7.1155\n",
      "Updated x: [-0.02403334528207779, -0.039364732801914215], Function Value: 0.002127183834090829, Gradient: [0.002748159458860755, 0.017770085483789444]\n",
      "\n",
      "Step 186/200\n",
      "Epoch 0: Total Loss=7.4623\n",
      "Epoch 1: Total Loss=7.3677\n",
      "Epoch 2: Total Loss=7.2661\n",
      "Epoch 3: Total Loss=7.3571\n",
      "Epoch 4: Total Loss=7.3594\n",
      "Epoch 5: Total Loss=7.2910\n",
      "Epoch 6: Total Loss=7.2847\n",
      "Epoch 7: Total Loss=7.2064\n",
      "Epoch 8: Total Loss=7.2074\n",
      "Epoch 9: Total Loss=7.2481\n",
      "Updated x: [-0.05733656510710716, 0.0067494772374629974], Function Value: 0.003333037020638585, Gradient: [0.0018913064850494266, 0.01426743809133768]\n",
      "\n",
      "Step 187/200\n",
      "Epoch 0: Total Loss=7.2412\n",
      "Epoch 1: Total Loss=7.3874\n",
      "Epoch 2: Total Loss=7.2340\n",
      "Epoch 3: Total Loss=7.2180\n",
      "Epoch 4: Total Loss=7.3538\n",
      "Epoch 5: Total Loss=7.2153\n",
      "Epoch 6: Total Loss=7.2976\n",
      "Epoch 7: Total Loss=7.2718\n",
      "Epoch 8: Total Loss=7.2954\n",
      "Epoch 9: Total Loss=7.3892\n",
      "Updated x: [-0.05837283656001091, 0.007603175472468138], Function Value: 0.0034651963505893946, Gradient: [0.0026908214204013348, 0.010726705193519592]\n",
      "\n",
      "Step 188/200\n",
      "Epoch 0: Total Loss=7.2491\n",
      "Epoch 1: Total Loss=7.2603\n",
      "Epoch 2: Total Loss=7.2947\n",
      "Epoch 3: Total Loss=7.1088\n",
      "Epoch 4: Total Loss=7.3012\n",
      "Epoch 5: Total Loss=7.2411\n",
      "Epoch 6: Total Loss=7.4110\n",
      "Epoch 7: Total Loss=7.3201\n",
      "Epoch 8: Total Loss=7.3181\n",
      "Epoch 9: Total Loss=7.1581\n",
      "Updated x: [0.04210324212908745, -0.0014677341096103191], Function Value: 0.0017748372629284859, Gradient: [0.0031849888619035482, 0.016758127138018608]\n",
      "\n",
      "Step 189/200\n",
      "Epoch 0: Total Loss=7.2826\n",
      "Epoch 1: Total Loss=7.3215\n",
      "Epoch 2: Total Loss=7.2541\n",
      "Epoch 3: Total Loss=7.2091\n",
      "Epoch 4: Total Loss=7.2768\n",
      "Epoch 5: Total Loss=7.3416\n",
      "Epoch 6: Total Loss=7.3425\n",
      "Epoch 7: Total Loss=7.3145\n",
      "Epoch 8: Total Loss=7.1971\n",
      "Epoch 9: Total Loss=7.2789\n",
      "Updated x: [-0.008491840213537216, 0.031641989946365356], Function Value: 0.0010733269155025482, Gradient: [0.002741514705121517, 0.01891593635082245]\n",
      "\n",
      "Step 190/200\n",
      "Epoch 0: Total Loss=7.2275\n",
      "Epoch 1: Total Loss=7.2850\n",
      "Epoch 2: Total Loss=7.4710\n",
      "Epoch 3: Total Loss=7.2451\n",
      "Epoch 4: Total Loss=7.3050\n",
      "Epoch 5: Total Loss=7.3438\n",
      "Epoch 6: Total Loss=7.2817\n",
      "Epoch 7: Total Loss=7.3485\n",
      "Epoch 8: Total Loss=7.3132\n",
      "Epoch 9: Total Loss=7.2544\n",
      "Updated x: [-0.012557489797472954, 0.061150990426540375], Function Value: 0.0038971342146396637, Gradient: [0.002260534791275859, 0.013960368931293488]\n",
      "\n",
      "Step 191/200\n",
      "Epoch 0: Total Loss=7.1719\n",
      "Epoch 1: Total Loss=7.2775\n",
      "Epoch 2: Total Loss=7.2903\n",
      "Epoch 3: Total Loss=7.3661\n",
      "Epoch 4: Total Loss=7.3825\n",
      "Epoch 5: Total Loss=7.2470\n",
      "Epoch 6: Total Loss=7.3171\n",
      "Epoch 7: Total Loss=7.3135\n",
      "Epoch 8: Total Loss=7.4338\n",
      "Epoch 9: Total Loss=7.3619\n",
      "Updated x: [-0.004302149638533592, -0.017998844385147095], Function Value: 0.00034246689756400883, Gradient: [0.0036421262193471193, 0.017277760431170464]\n",
      "\n",
      "Step 192/200\n",
      "Epoch 0: Total Loss=6.9856\n",
      "Epoch 1: Total Loss=6.9838\n",
      "Epoch 2: Total Loss=7.0806\n",
      "Epoch 3: Total Loss=7.0443\n",
      "Epoch 4: Total Loss=7.0541\n",
      "Epoch 5: Total Loss=7.0146\n",
      "Epoch 6: Total Loss=7.0417\n",
      "Epoch 7: Total Loss=6.9851\n",
      "Epoch 8: Total Loss=7.0150\n",
      "Epoch 9: Total Loss=6.9691\n",
      "Updated x: [-0.010590627789497375, -0.01036873459815979], Function Value: 0.00021967204520478845, Gradient: [0.0012122896732762456, 0.01862826943397522]\n",
      "\n",
      "Step 193/200\n",
      "Epoch 0: Total Loss=6.9700\n",
      "Epoch 1: Total Loss=7.0670\n",
      "Epoch 2: Total Loss=6.9793\n",
      "Epoch 3: Total Loss=7.0307\n",
      "Epoch 4: Total Loss=7.0207\n",
      "Epoch 5: Total Loss=7.0087\n",
      "Epoch 6: Total Loss=6.9788\n",
      "Epoch 7: Total Loss=7.0290\n",
      "Epoch 8: Total Loss=6.9889\n",
      "Epoch 9: Total Loss=7.0146\n",
      "Updated x: [-0.028029095381498337, 0.009110644459724426], Function Value: 0.0008686340297572315, Gradient: [0.0024161306209862232, 0.02528959885239601]\n",
      "\n",
      "Step 194/200\n",
      "Epoch 0: Total Loss=7.0401\n",
      "Epoch 1: Total Loss=7.0221\n",
      "Epoch 2: Total Loss=6.9490\n",
      "Epoch 3: Total Loss=7.0105\n",
      "Epoch 4: Total Loss=6.9945\n",
      "Epoch 5: Total Loss=7.0842\n",
      "Epoch 6: Total Loss=7.0361\n",
      "Epoch 7: Total Loss=6.9691\n",
      "Epoch 8: Total Loss=7.0125\n",
      "Epoch 9: Total Loss=7.0036\n",
      "Updated x: [0.047061268240213394, 0.033602043986320496], Function Value: 0.003343860385939479, Gradient: [-0.00020800322818104178, 0.02995852194726467]\n",
      "\n",
      "Step 195/200\n",
      "Epoch 0: Total Loss=7.0159\n",
      "Epoch 1: Total Loss=6.9980\n",
      "Epoch 2: Total Loss=7.0120\n",
      "Epoch 3: Total Loss=7.0213\n",
      "Epoch 4: Total Loss=6.9956\n",
      "Epoch 5: Total Loss=6.9531\n",
      "Epoch 6: Total Loss=6.9788\n",
      "Epoch 7: Total Loss=7.0535\n",
      "Epoch 8: Total Loss=7.0029\n",
      "Epoch 9: Total Loss=6.9880\n",
      "Updated x: [0.044953279197216034, 0.032187867909669876], Function Value: 0.003056856105104089, Gradient: [-0.0008720845216885209, 0.0254278015345335]\n",
      "\n",
      "Step 196/200\n",
      "Epoch 0: Total Loss=7.0057\n",
      "Epoch 1: Total Loss=7.0178\n",
      "Epoch 2: Total Loss=7.0860\n",
      "Epoch 3: Total Loss=7.0306\n",
      "Epoch 4: Total Loss=7.0177\n",
      "Epoch 5: Total Loss=7.0164\n",
      "Epoch 6: Total Loss=7.0291\n",
      "Epoch 7: Total Loss=7.0608\n",
      "Epoch 8: Total Loss=7.0694\n",
      "Epoch 9: Total Loss=6.9865\n",
      "Updated x: [0.028809623792767525, -0.011269114911556244], Function Value: 0.0009569873800501227, Gradient: [0.0009642730001360178, 0.02337842807173729]\n",
      "\n",
      "Step 197/200\n",
      "Epoch 0: Total Loss=6.9939\n",
      "Epoch 1: Total Loss=7.0245\n",
      "Epoch 2: Total Loss=6.9738\n",
      "Epoch 3: Total Loss=6.9997\n",
      "Epoch 4: Total Loss=6.9829\n",
      "Epoch 5: Total Loss=6.9730\n",
      "Epoch 6: Total Loss=6.9538\n",
      "Epoch 7: Total Loss=7.0292\n",
      "Epoch 8: Total Loss=7.0457\n",
      "Epoch 9: Total Loss=7.0076\n",
      "Updated x: [0.02577190287411213, 0.02390507236123085], Function Value: 0.0012356434017419815, Gradient: [-0.00037928749225102365, 0.01662764698266983]\n",
      "\n",
      "Step 198/200\n",
      "Epoch 0: Total Loss=6.9900\n",
      "Epoch 1: Total Loss=6.9905\n",
      "Epoch 2: Total Loss=7.0014\n",
      "Epoch 3: Total Loss=7.0290\n",
      "Epoch 4: Total Loss=6.9893\n",
      "Epoch 5: Total Loss=7.0591\n",
      "Epoch 6: Total Loss=7.0077\n",
      "Epoch 7: Total Loss=6.9757\n",
      "Epoch 8: Total Loss=7.0639\n",
      "Epoch 9: Total Loss=7.0366\n",
      "Updated x: [0.05893835425376892, 0.03760971501469612], Function Value: 0.004888220224529505, Gradient: [-0.0007355008856393397, 0.014608653262257576]\n",
      "\n",
      "Step 199/200\n",
      "Epoch 0: Total Loss=6.9845\n",
      "Epoch 1: Total Loss=7.0585\n",
      "Epoch 2: Total Loss=7.0145\n",
      "Epoch 3: Total Loss=7.0406\n",
      "Epoch 4: Total Loss=7.0202\n",
      "Epoch 5: Total Loss=7.0127\n",
      "Epoch 6: Total Loss=7.0407\n",
      "Epoch 7: Total Loss=6.9958\n",
      "Epoch 8: Total Loss=7.0308\n",
      "Epoch 9: Total Loss=7.0593\n",
      "Updated x: [0.024059806019067764, 0.050652045756578445], Function Value: 0.0031445040367543697, Gradient: [-0.0007258221739903092, 0.016857938840985298]\n",
      "\n",
      "Step 200/200\n",
      "Epoch 0: Total Loss=7.0269\n",
      "Epoch 1: Total Loss=7.0037\n",
      "Epoch 2: Total Loss=6.9842\n",
      "Epoch 3: Total Loss=6.9541\n",
      "Epoch 4: Total Loss=6.9480\n",
      "Epoch 5: Total Loss=7.0212\n",
      "Epoch 6: Total Loss=7.0147\n",
      "Epoch 7: Total Loss=7.0108\n",
      "Epoch 8: Total Loss=7.0212\n",
      "Epoch 9: Total Loss=6.9857\n",
      "Updated x: [0.003291809931397438, 0.061327118426561356], Function Value: 0.0037718513049185276, Gradient: [-3.3929052733583376e-05, 0.022152850404381752]\n",
      "\n",
      "Step 1/200\n",
      "Epoch 0: Total Loss=39.5094\n",
      "Epoch 1: Total Loss=13.6280\n",
      "Epoch 2: Total Loss=25.4194\n",
      "Epoch 3: Total Loss=26.2049\n",
      "Epoch 4: Total Loss=13.6741\n",
      "Epoch 5: Total Loss=39.4891\n",
      "Epoch 6: Total Loss=13.6199\n",
      "Epoch 7: Total Loss=25.4004\n",
      "Epoch 8: Total Loss=26.1933\n",
      "Epoch 9: Total Loss=13.6650\n",
      "Updated x: [9.911603927612305, -9.936601638793945], Function Value: 196.9759521484375, Gradient: [0.03687697649002075, 0.04021086543798447]\n",
      "\n",
      "Step 2/200\n",
      "Epoch 0: Total Loss=197.2032\n",
      "Epoch 1: Total Loss=217.8477\n",
      "Epoch 2: Total Loss=191.7254\n",
      "Epoch 3: Total Loss=245.2072\n",
      "Epoch 4: Total Loss=206.9311\n",
      "Epoch 5: Total Loss=217.3337\n",
      "Epoch 6: Total Loss=227.8447\n",
      "Epoch 7: Total Loss=243.7469\n",
      "Epoch 8: Total Loss=224.2366\n",
      "Epoch 9: Total Loss=207.1129\n",
      "Updated x: [9.907362937927246, -9.824329376220703], Function Value: 194.67327880859375, Gradient: [0.039438750594854355, 0.03418437018990517]\n",
      "\n",
      "Step 3/200\n",
      "Epoch 0: Total Loss=255.4687\n",
      "Epoch 1: Total Loss=208.8094\n",
      "Epoch 2: Total Loss=191.5419\n",
      "Epoch 3: Total Loss=208.0347\n",
      "Epoch 4: Total Loss=201.9563\n",
      "Epoch 5: Total Loss=256.6058\n",
      "Epoch 6: Total Loss=219.0061\n",
      "Epoch 7: Total Loss=190.6708\n",
      "Epoch 8: Total Loss=227.9598\n",
      "Epoch 9: Total Loss=223.5131\n",
      "Updated x: [9.655692100524902, -9.75372314453125], Function Value: 188.3675079345703, Gradient: [0.06016489490866661, 0.04787691310048103]\n",
      "\n",
      "Step 4/200\n",
      "Epoch 0: Total Loss=210.8091\n",
      "Epoch 1: Total Loss=204.9422\n",
      "Epoch 2: Total Loss=208.7363\n",
      "Epoch 3: Total Loss=215.3355\n",
      "Epoch 4: Total Loss=206.3870\n",
      "Epoch 5: Total Loss=198.7975\n",
      "Epoch 6: Total Loss=216.4310\n",
      "Epoch 7: Total Loss=208.7113\n",
      "Epoch 8: Total Loss=226.7212\n",
      "Epoch 9: Total Loss=197.0389\n",
      "Updated x: [9.543089866638184, -9.574037551879883], Function Value: 182.73275756835938, Gradient: [0.04728022590279579, 0.035153742879629135]\n",
      "\n",
      "Step 5/200\n",
      "Epoch 0: Total Loss=193.1778\n",
      "Epoch 1: Total Loss=202.2754\n",
      "Epoch 2: Total Loss=233.4153\n",
      "Epoch 3: Total Loss=193.2016\n",
      "Epoch 4: Total Loss=203.9709\n",
      "Epoch 5: Total Loss=199.7536\n",
      "Epoch 6: Total Loss=200.1974\n",
      "Epoch 7: Total Loss=199.9871\n",
      "Epoch 8: Total Loss=199.3994\n",
      "Epoch 9: Total Loss=217.5727\n",
      "Updated x: [9.566473007202148, -9.423857688903809], Function Value: 180.32650756835938, Gradient: [0.04741206392645836, 0.034054502844810486]\n",
      "\n",
      "Step 6/200\n",
      "Epoch 0: Total Loss=198.4950\n",
      "Epoch 1: Total Loss=185.8914\n",
      "Epoch 2: Total Loss=227.5195\n",
      "Epoch 3: Total Loss=205.4119\n",
      "Epoch 4: Total Loss=193.6087\n",
      "Epoch 5: Total Loss=222.5067\n",
      "Epoch 6: Total Loss=212.4394\n",
      "Epoch 7: Total Loss=218.0038\n",
      "Epoch 8: Total Loss=208.1940\n",
      "Epoch 9: Total Loss=209.1998\n",
      "Updated x: [9.527847290039062, -9.2304048538208], Function Value: 175.98025512695312, Gradient: [0.05031193420290947, 0.036090463399887085]\n",
      "\n",
      "Step 7/200\n",
      "Epoch 0: Total Loss=226.1962\n",
      "Epoch 1: Total Loss=175.6222\n",
      "Epoch 2: Total Loss=205.1270\n",
      "Epoch 3: Total Loss=206.6007\n",
      "Epoch 4: Total Loss=201.4680\n",
      "Epoch 5: Total Loss=189.4026\n",
      "Epoch 6: Total Loss=209.7949\n",
      "Epoch 7: Total Loss=188.8600\n",
      "Epoch 8: Total Loss=225.2693\n",
      "Epoch 9: Total Loss=210.2375\n",
      "Updated x: [9.437760353088379, -9.015097618103027], Function Value: 170.3433074951172, Gradient: [0.04479771852493286, 0.034471675753593445]\n",
      "\n",
      "Step 8/200\n",
      "Epoch 0: Total Loss=204.7077\n",
      "Epoch 1: Total Loss=186.2158\n",
      "Epoch 2: Total Loss=249.3209\n",
      "Epoch 3: Total Loss=217.9447\n",
      "Epoch 4: Total Loss=225.0337\n",
      "Epoch 5: Total Loss=210.0359\n",
      "Epoch 6: Total Loss=196.2246\n",
      "Epoch 7: Total Loss=182.9506\n",
      "Epoch 8: Total Loss=253.7924\n",
      "Epoch 9: Total Loss=223.2962\n",
      "Updated x: [9.211715698242188, -8.888124465942383], Function Value: 163.85446166992188, Gradient: [0.054776161909103394, 0.04262533783912659]\n",
      "\n",
      "Step 9/200\n",
      "Epoch 0: Total Loss=198.4809\n",
      "Epoch 1: Total Loss=205.5167\n",
      "Epoch 2: Total Loss=187.3369\n",
      "Epoch 3: Total Loss=196.3602\n",
      "Epoch 4: Total Loss=197.9641\n",
      "Epoch 5: Total Loss=203.9833\n",
      "Epoch 6: Total Loss=244.8864\n",
      "Epoch 7: Total Loss=196.5528\n",
      "Epoch 8: Total Loss=197.3068\n",
      "Epoch 9: Total Loss=197.1718\n",
      "Updated x: [9.123497009277344, -8.836087226867676], Function Value: 161.31463623046875, Gradient: [0.06085549294948578, 0.04856516793370247]\n",
      "\n",
      "Step 10/200\n",
      "Epoch 0: Total Loss=197.8745\n",
      "Epoch 1: Total Loss=218.8008\n",
      "Epoch 2: Total Loss=206.9416\n",
      "Epoch 3: Total Loss=207.6787\n",
      "Epoch 4: Total Loss=210.3078\n",
      "Epoch 5: Total Loss=220.8252\n",
      "Epoch 6: Total Loss=201.1112\n",
      "Epoch 7: Total Loss=211.9391\n",
      "Epoch 8: Total Loss=201.0601\n",
      "Epoch 9: Total Loss=198.5987\n",
      "Updated x: [8.972179412841797, -8.767295837402344], Function Value: 157.365478515625, Gradient: [0.060701657086610794, 0.045206159353256226]\n",
      "\n",
      "Step 11/200\n",
      "Epoch 0: Total Loss=201.2082\n",
      "Epoch 1: Total Loss=195.9228\n",
      "Epoch 2: Total Loss=226.6988\n",
      "Epoch 3: Total Loss=206.4468\n",
      "Epoch 4: Total Loss=196.3634\n",
      "Epoch 5: Total Loss=219.1233\n",
      "Epoch 6: Total Loss=218.1481\n",
      "Epoch 7: Total Loss=206.6550\n",
      "Epoch 8: Total Loss=186.6876\n",
      "Epoch 9: Total Loss=216.7406\n",
      "Updated x: [8.863582611083984, -8.662389755249023], Function Value: 153.60009765625, Gradient: [0.07454342395067215, 0.0517200343310833]\n",
      "\n",
      "Step 12/200\n",
      "Epoch 0: Total Loss=32.9006\n",
      "Epoch 1: Total Loss=49.3619\n",
      "Epoch 2: Total Loss=60.6063\n",
      "Epoch 3: Total Loss=48.5375\n",
      "Epoch 4: Total Loss=60.7939\n",
      "Epoch 5: Total Loss=32.8229\n",
      "Epoch 6: Total Loss=49.3076\n",
      "Epoch 7: Total Loss=60.5145\n",
      "Epoch 8: Total Loss=48.4935\n",
      "Epoch 9: Total Loss=60.7253\n",
      "Updated x: [8.749004364013672, -8.416287422180176], Function Value: 147.37896728515625, Gradient: [0.11903730779886246, 0.07802578806877136]\n",
      "\n",
      "Step 13/200\n",
      "Epoch 0: Total Loss=48.2360\n",
      "Epoch 1: Total Loss=18.2377\n",
      "Epoch 2: Total Loss=18.2202\n",
      "Epoch 3: Total Loss=15.1800\n",
      "Epoch 4: Total Loss=18.9622\n",
      "Epoch 5: Total Loss=48.2007\n",
      "Epoch 6: Total Loss=18.2185\n",
      "Epoch 7: Total Loss=18.1994\n",
      "Epoch 8: Total Loss=15.1602\n",
      "Epoch 9: Total Loss=18.9446\n",
      "Updated x: [8.637653350830078, -8.398313522338867], Function Value: 145.14071655273438, Gradient: [0.13184688985347748, 0.09097623080015182]\n",
      "\n",
      "Step 14/200\n",
      "Epoch 0: Total Loss=12.4547\n",
      "Epoch 1: Total Loss=14.7277\n",
      "Epoch 2: Total Loss=46.5209\n",
      "Epoch 3: Total Loss=8.4302\n",
      "Epoch 4: Total Loss=8.8654\n",
      "Epoch 5: Total Loss=8.7199\n",
      "Epoch 6: Total Loss=14.6265\n",
      "Epoch 7: Total Loss=13.9705\n",
      "Epoch 8: Total Loss=9.7351\n",
      "Epoch 9: Total Loss=48.0015\n",
      "Updated x: [8.587928771972656, -8.306869506835938], Function Value: 142.756591796875, Gradient: [0.13931038975715637, 0.10234443098306656]\n",
      "\n",
      "Step 15/200\n",
      "Epoch 0: Total Loss=7.7660\n",
      "Epoch 1: Total Loss=10.8987\n",
      "Epoch 2: Total Loss=10.8909\n",
      "Epoch 3: Total Loss=8.5081\n",
      "Epoch 4: Total Loss=14.2329\n",
      "Epoch 5: Total Loss=9.9810\n",
      "Epoch 6: Total Loss=15.7307\n",
      "Epoch 7: Total Loss=39.5245\n",
      "Epoch 8: Total Loss=14.2480\n",
      "Epoch 9: Total Loss=14.0562\n",
      "Updated x: [8.563128471374512, -8.227359771728516], Function Value: 141.01661682128906, Gradient: [0.13053558766841888, 0.10094733536243439]\n",
      "\n",
      "Step 16/200\n",
      "Epoch 0: Total Loss=13.2967\n",
      "Epoch 1: Total Loss=12.6844\n",
      "Epoch 2: Total Loss=7.8588\n",
      "Epoch 3: Total Loss=9.4686\n",
      "Epoch 4: Total Loss=13.8985\n",
      "Epoch 5: Total Loss=8.2883\n",
      "Epoch 6: Total Loss=10.6201\n",
      "Epoch 7: Total Loss=12.7490\n",
      "Epoch 8: Total Loss=10.0386\n",
      "Epoch 9: Total Loss=17.4722\n",
      "Updated x: [8.432007789611816, -8.126530647277832], Function Value: 137.13925170898438, Gradient: [0.12354709953069687, 0.0969892218708992]\n",
      "\n",
      "Step 17/200\n",
      "Epoch 0: Total Loss=11.1452\n",
      "Epoch 1: Total Loss=8.4510\n",
      "Epoch 2: Total Loss=12.4350\n",
      "Epoch 3: Total Loss=13.4082\n",
      "Epoch 4: Total Loss=8.9352\n",
      "Epoch 5: Total Loss=7.7537\n",
      "Epoch 6: Total Loss=17.2382\n",
      "Epoch 7: Total Loss=41.1599\n",
      "Epoch 8: Total Loss=11.3140\n",
      "Epoch 9: Total Loss=6.3969\n",
      "Updated x: [8.426148414611816, -8.025165557861328], Function Value: 135.40325927734375, Gradient: [0.14609088003635406, 0.11153548210859299]\n",
      "\n",
      "Step 18/200\n",
      "Epoch 0: Total Loss=10.0067\n",
      "Epoch 1: Total Loss=15.5629\n",
      "Epoch 2: Total Loss=12.6260\n",
      "Epoch 3: Total Loss=8.8045\n",
      "Epoch 4: Total Loss=41.0195\n",
      "Epoch 5: Total Loss=9.6427\n",
      "Epoch 6: Total Loss=13.7636\n",
      "Epoch 7: Total Loss=8.0624\n",
      "Epoch 8: Total Loss=10.4905\n",
      "Epoch 9: Total Loss=9.0013\n",
      "Updated x: [8.368298530578613, -7.900545120239258], Function Value: 132.44703674316406, Gradient: [0.127327561378479, 0.09979134798049927]\n",
      "\n",
      "Step 19/200\n",
      "Epoch 0: Total Loss=41.6758\n",
      "Epoch 1: Total Loss=14.5383\n",
      "Epoch 2: Total Loss=7.4575\n",
      "Epoch 3: Total Loss=8.0660\n",
      "Epoch 4: Total Loss=15.9692\n",
      "Epoch 5: Total Loss=8.2390\n",
      "Epoch 6: Total Loss=9.7162\n",
      "Epoch 7: Total Loss=14.8669\n",
      "Epoch 8: Total Loss=14.3936\n",
      "Epoch 9: Total Loss=9.0436\n",
      "Updated x: [8.208671569824219, -7.835016250610352], Function Value: 128.76976013183594, Gradient: [0.15355661511421204, 0.11794260889291763]\n",
      "\n",
      "Step 20/200\n",
      "Epoch 0: Total Loss=10.4994\n",
      "Epoch 1: Total Loss=20.4204\n",
      "Epoch 2: Total Loss=9.7893\n",
      "Epoch 3: Total Loss=7.3605\n",
      "Epoch 4: Total Loss=10.4506\n",
      "Epoch 5: Total Loss=6.9136\n",
      "Epoch 6: Total Loss=11.4954\n",
      "Epoch 7: Total Loss=7.1957\n",
      "Epoch 8: Total Loss=11.2533\n",
      "Epoch 9: Total Loss=7.5239\n",
      "Updated x: [8.153101921081543, -7.680660247802734], Function Value: 125.46560668945312, Gradient: [0.13868428766727448, 0.1081605777144432]\n",
      "\n",
      "Step 21/200\n",
      "Epoch 0: Total Loss=9.5248\n",
      "Epoch 1: Total Loss=9.3838\n",
      "Epoch 2: Total Loss=7.4817\n",
      "Epoch 3: Total Loss=6.9590\n",
      "Epoch 4: Total Loss=7.9283\n",
      "Epoch 5: Total Loss=9.5225\n",
      "Epoch 6: Total Loss=8.0947\n",
      "Epoch 7: Total Loss=9.1994\n",
      "Epoch 8: Total Loss=9.1404\n",
      "Epoch 9: Total Loss=8.6554\n",
      "Updated x: [8.087759971618652, -7.69705867767334], Function Value: 124.65657043457031, Gradient: [0.1418217569589615, 0.10695952922105789]\n",
      "\n",
      "Step 22/200\n",
      "Epoch 0: Total Loss=42.1718\n",
      "Epoch 1: Total Loss=40.1974\n",
      "Epoch 2: Total Loss=39.0258\n",
      "Epoch 3: Total Loss=34.6330\n",
      "Epoch 4: Total Loss=38.2400\n",
      "Epoch 5: Total Loss=42.0268\n",
      "Epoch 6: Total Loss=40.6194\n",
      "Epoch 7: Total Loss=39.1642\n",
      "Epoch 8: Total Loss=34.5437\n",
      "Epoch 9: Total Loss=38.5703\n",
      "Updated x: [8.061835289001465, -7.501539707183838], Function Value: 121.26628112792969, Gradient: [0.16538089513778687, 0.11216721683740616]\n",
      "\n",
      "Step 23/200\n",
      "Epoch 0: Total Loss=13.8486\n",
      "Epoch 1: Total Loss=13.5006\n",
      "Epoch 2: Total Loss=25.1455\n",
      "Epoch 3: Total Loss=13.0450\n",
      "Epoch 4: Total Loss=14.7646\n",
      "Epoch 5: Total Loss=20.3642\n",
      "Epoch 6: Total Loss=19.0733\n",
      "Epoch 7: Total Loss=13.6294\n",
      "Epoch 8: Total Loss=15.7948\n",
      "Epoch 9: Total Loss=24.6462\n",
      "Updated x: [7.968174934387207, -7.544473648071289], Function Value: 120.41089630126953, Gradient: [0.15664269030094147, 0.10101542621850967]\n",
      "\n",
      "Step 24/200\n",
      "Epoch 0: Total Loss=19.0576\n",
      "Epoch 1: Total Loss=11.7708\n",
      "Epoch 2: Total Loss=12.1012\n",
      "Epoch 3: Total Loss=16.1099\n",
      "Epoch 4: Total Loss=14.6956\n",
      "Epoch 5: Total Loss=19.1254\n",
      "Epoch 6: Total Loss=11.7842\n",
      "Epoch 7: Total Loss=12.3995\n",
      "Epoch 8: Total Loss=16.3073\n",
      "Epoch 9: Total Loss=14.6158\n",
      "Updated x: [7.8700337409973145, -7.408603668212891], Function Value: 116.82484436035156, Gradient: [0.17097997665405273, 0.10748013854026794]\n",
      "\n",
      "Step 25/200\n",
      "Epoch 0: Total Loss=9.1139\n",
      "Epoch 1: Total Loss=28.4599\n",
      "Epoch 2: Total Loss=14.4654\n",
      "Epoch 3: Total Loss=16.5470\n",
      "Epoch 4: Total Loss=16.3641\n",
      "Epoch 5: Total Loss=11.9048\n",
      "Epoch 6: Total Loss=13.2629\n",
      "Epoch 7: Total Loss=13.5517\n",
      "Epoch 8: Total Loss=25.0471\n",
      "Epoch 9: Total Loss=13.3173\n",
      "Updated x: [7.836794376373291, -7.141550540924072], Function Value: 112.41708374023438, Gradient: [0.1775210201740265, 0.10923567414283752]\n",
      "\n",
      "Step 26/200\n",
      "Epoch 0: Total Loss=18.8764\n",
      "Epoch 1: Total Loss=22.7379\n",
      "Epoch 2: Total Loss=18.7823\n",
      "Epoch 3: Total Loss=12.4007\n",
      "Epoch 4: Total Loss=10.1712\n",
      "Epoch 5: Total Loss=16.3072\n",
      "Epoch 6: Total Loss=9.7577\n",
      "Epoch 7: Total Loss=10.6962\n",
      "Epoch 8: Total Loss=16.1534\n",
      "Epoch 9: Total Loss=19.5383\n",
      "Updated x: [7.747873783111572, -7.103060722351074], Function Value: 110.48301696777344, Gradient: [0.17903855443000793, 0.10709792375564575]\n",
      "\n",
      "Step 27/200\n",
      "Epoch 0: Total Loss=9.9129\n",
      "Epoch 1: Total Loss=14.3883\n",
      "Epoch 2: Total Loss=11.9766\n",
      "Epoch 3: Total Loss=9.8946\n",
      "Epoch 4: Total Loss=8.1452\n",
      "Epoch 5: Total Loss=15.3864\n",
      "Epoch 6: Total Loss=10.6764\n",
      "Epoch 7: Total Loss=9.0388\n",
      "Epoch 8: Total Loss=12.9670\n",
      "Epoch 9: Total Loss=18.5826\n",
      "Updated x: [7.620847225189209, -7.039021968841553], Function Value: 107.62513732910156, Gradient: [0.1851327270269394, 0.10527912527322769]\n",
      "\n",
      "Step 28/200\n",
      "Epoch 0: Total Loss=12.1055\n",
      "Epoch 1: Total Loss=13.0060\n",
      "Epoch 2: Total Loss=10.8153\n",
      "Epoch 3: Total Loss=13.9866\n",
      "Epoch 4: Total Loss=10.6538\n",
      "Epoch 5: Total Loss=9.6421\n",
      "Epoch 6: Total Loss=16.0663\n",
      "Epoch 7: Total Loss=16.2564\n",
      "Epoch 8: Total Loss=15.6681\n",
      "Epoch 9: Total Loss=15.7745\n",
      "Updated x: [7.496158599853516, -6.8989081382751465], Function Value: 103.78732299804688, Gradient: [0.17871102690696716, 0.09747859090566635]\n",
      "\n",
      "Step 29/200\n",
      "Epoch 0: Total Loss=9.5220\n",
      "Epoch 1: Total Loss=15.1844\n",
      "Epoch 2: Total Loss=12.4493\n",
      "Epoch 3: Total Loss=8.6597\n",
      "Epoch 4: Total Loss=16.5451\n",
      "Epoch 5: Total Loss=10.0952\n",
      "Epoch 6: Total Loss=11.7331\n",
      "Epoch 7: Total Loss=12.2424\n",
      "Epoch 8: Total Loss=12.2091\n",
      "Epoch 9: Total Loss=9.3718\n",
      "Updated x: [7.471158504486084, -6.746842861175537], Function Value: 101.33810424804688, Gradient: [0.19049648940563202, 0.10646670311689377]\n",
      "\n",
      "Step 30/200\n",
      "Epoch 0: Total Loss=14.6857\n",
      "Epoch 1: Total Loss=10.3517\n",
      "Epoch 2: Total Loss=15.0228\n",
      "Epoch 3: Total Loss=10.7410\n",
      "Epoch 4: Total Loss=15.1321\n",
      "Epoch 5: Total Loss=10.7306\n",
      "Epoch 6: Total Loss=13.9985\n",
      "Epoch 7: Total Loss=8.5322\n",
      "Epoch 8: Total Loss=13.2501\n",
      "Epoch 9: Total Loss=14.0664\n",
      "Updated x: [7.313309192657471, -6.667707443237305], Function Value: 97.94281005859375, Gradient: [0.18226218223571777, 0.09027280658483505]\n",
      "\n",
      "Step 31/200\n",
      "Epoch 0: Total Loss=10.0799\n",
      "Epoch 1: Total Loss=15.8981\n",
      "Epoch 2: Total Loss=15.2800\n",
      "Epoch 3: Total Loss=11.0565\n",
      "Epoch 4: Total Loss=15.8205\n",
      "Epoch 5: Total Loss=8.9652\n",
      "Epoch 6: Total Loss=17.8079\n",
      "Epoch 7: Total Loss=7.5822\n",
      "Epoch 8: Total Loss=10.2720\n",
      "Epoch 9: Total Loss=14.0800\n",
      "Updated x: [7.197239875793457, -6.54261589050293], Function Value: 94.60608673095703, Gradient: [0.19812235236167908, 0.09930847585201263]\n",
      "\n",
      "Step 32/200\n",
      "Epoch 0: Total Loss=46.7628\n",
      "Epoch 1: Total Loss=34.1868\n",
      "Epoch 2: Total Loss=51.1045\n",
      "Epoch 3: Total Loss=39.9456\n",
      "Epoch 4: Total Loss=41.4774\n",
      "Epoch 5: Total Loss=46.6014\n",
      "Epoch 6: Total Loss=34.1057\n",
      "Epoch 7: Total Loss=51.0398\n",
      "Epoch 8: Total Loss=39.9315\n",
      "Epoch 9: Total Loss=41.4754\n",
      "Updated x: [6.968564987182617, -6.441157341003418], Function Value: 90.04940795898438, Gradient: [0.220648393034935, 0.08531835675239563]\n",
      "\n",
      "Step 33/200\n",
      "Epoch 0: Total Loss=30.2298\n",
      "Epoch 1: Total Loss=21.0633\n",
      "Epoch 2: Total Loss=22.6679\n",
      "Epoch 3: Total Loss=33.6359\n",
      "Epoch 4: Total Loss=20.6564\n",
      "Epoch 5: Total Loss=23.9509\n",
      "Epoch 6: Total Loss=25.7269\n",
      "Epoch 7: Total Loss=29.0331\n",
      "Epoch 8: Total Loss=25.0485\n",
      "Epoch 9: Total Loss=24.2463\n",
      "Updated x: [6.889665603637695, -6.276294231414795], Function Value: 86.85935974121094, Gradient: [0.27637359499931335, 0.12238472700119019]\n",
      "\n",
      "Step 34/200\n",
      "Epoch 0: Total Loss=16.7279\n",
      "Epoch 1: Total Loss=26.3165\n",
      "Epoch 2: Total Loss=16.8826\n",
      "Epoch 3: Total Loss=15.2236\n",
      "Epoch 4: Total Loss=12.2666\n",
      "Epoch 5: Total Loss=16.6826\n",
      "Epoch 6: Total Loss=26.3273\n",
      "Epoch 7: Total Loss=16.8715\n",
      "Epoch 8: Total Loss=15.3004\n",
      "Epoch 9: Total Loss=12.2914\n",
      "Updated x: [6.809066295623779, -6.211431980133057], Function Value: 84.94526672363281, Gradient: [0.30632105469703674, 0.14010871946811676]\n",
      "\n",
      "Step 35/200\n",
      "Epoch 0: Total Loss=12.8841\n",
      "Epoch 1: Total Loss=19.1264\n",
      "Epoch 2: Total Loss=19.8979\n",
      "Epoch 3: Total Loss=16.1803\n",
      "Epoch 4: Total Loss=16.7663\n",
      "Epoch 5: Total Loss=12.6137\n",
      "Epoch 6: Total Loss=13.9258\n",
      "Epoch 7: Total Loss=18.0347\n",
      "Epoch 8: Total Loss=23.2962\n",
      "Epoch 9: Total Loss=13.0206\n",
      "Updated x: [6.614320278167725, -6.253313064575195], Function Value: 82.85315704345703, Gradient: [0.27331605553627014, 0.1258312612771988]\n",
      "\n",
      "Step 36/200\n",
      "Epoch 0: Total Loss=12.5831\n",
      "Epoch 1: Total Loss=12.5143\n",
      "Epoch 2: Total Loss=18.2099\n",
      "Epoch 3: Total Loss=13.5469\n",
      "Epoch 4: Total Loss=10.6483\n",
      "Epoch 5: Total Loss=13.4880\n",
      "Epoch 6: Total Loss=15.3589\n",
      "Epoch 7: Total Loss=25.1426\n",
      "Epoch 8: Total Loss=11.0949\n",
      "Epoch 9: Total Loss=14.0494\n",
      "Updated x: [6.420568466186523, -6.300057888031006], Function Value: 80.9144287109375, Gradient: [0.2395794540643692, 0.09445556253194809]\n",
      "\n",
      "Step 37/200\n",
      "Epoch 0: Total Loss=16.6559\n",
      "Epoch 1: Total Loss=14.0024\n",
      "Epoch 2: Total Loss=12.4717\n",
      "Epoch 3: Total Loss=13.1703\n",
      "Epoch 4: Total Loss=19.9134\n",
      "Epoch 5: Total Loss=11.8735\n",
      "Epoch 6: Total Loss=10.3992\n",
      "Epoch 7: Total Loss=15.4884\n",
      "Epoch 8: Total Loss=11.5192\n",
      "Epoch 9: Total Loss=12.8158\n",
      "Updated x: [6.414767742156982, -6.158979892730713], Function Value: 79.082275390625, Gradient: [0.259581983089447, 0.10998868942260742]\n",
      "\n",
      "Step 38/200\n",
      "Epoch 0: Total Loss=24.4142\n",
      "Epoch 1: Total Loss=12.1010\n",
      "Epoch 2: Total Loss=9.1421\n",
      "Epoch 3: Total Loss=14.7237\n",
      "Epoch 4: Total Loss=11.9896\n",
      "Epoch 5: Total Loss=12.7359\n",
      "Epoch 6: Total Loss=10.4926\n",
      "Epoch 7: Total Loss=8.7325\n",
      "Epoch 8: Total Loss=14.2046\n",
      "Epoch 9: Total Loss=8.8120\n",
      "Updated x: [6.378901958465576, -5.999852180480957], Function Value: 76.68861389160156, Gradient: [0.24320685863494873, 0.10002981126308441]\n",
      "\n",
      "Step 39/200\n",
      "Epoch 0: Total Loss=11.6922\n",
      "Epoch 1: Total Loss=10.4504\n",
      "Epoch 2: Total Loss=14.0936\n",
      "Epoch 3: Total Loss=13.2955\n",
      "Epoch 4: Total Loss=18.4014\n",
      "Epoch 5: Total Loss=10.9905\n",
      "Epoch 6: Total Loss=11.4779\n",
      "Epoch 7: Total Loss=11.2356\n",
      "Epoch 8: Total Loss=12.3224\n",
      "Epoch 9: Total Loss=18.5064\n",
      "Updated x: [6.316396236419678, -5.902883529663086], Function Value: 74.74089050292969, Gradient: [0.23627567291259766, 0.09876410663127899]\n",
      "\n",
      "Step 40/200\n",
      "Epoch 0: Total Loss=9.9217\n",
      "Epoch 1: Total Loss=14.7924\n",
      "Epoch 2: Total Loss=8.6266\n",
      "Epoch 3: Total Loss=14.2504\n",
      "Epoch 4: Total Loss=9.1492\n",
      "Epoch 5: Total Loss=10.3931\n",
      "Epoch 6: Total Loss=11.7513\n",
      "Epoch 7: Total Loss=9.0534\n",
      "Epoch 8: Total Loss=11.1065\n",
      "Epoch 9: Total Loss=12.4812\n",
      "Updated x: [6.320927619934082, -5.735322952270508], Function Value: 72.84805297851562, Gradient: [0.22507132589817047, 0.08595643192529678]\n",
      "\n",
      "Step 41/200\n",
      "Epoch 0: Total Loss=11.8978\n",
      "Epoch 1: Total Loss=9.2691\n",
      "Epoch 2: Total Loss=10.5290\n",
      "Epoch 3: Total Loss=12.8041\n",
      "Epoch 4: Total Loss=8.6219\n",
      "Epoch 5: Total Loss=11.6498\n",
      "Epoch 6: Total Loss=11.6159\n",
      "Epoch 7: Total Loss=20.8061\n",
      "Epoch 8: Total Loss=13.6212\n",
      "Epoch 9: Total Loss=12.5291\n",
      "Updated x: [6.231210231781006, -5.741812705993652], Function Value: 71.79639434814453, Gradient: [0.19112040102481842, 0.07349741458892822]\n",
      "\n",
      "Step 42/200\n",
      "Epoch 0: Total Loss=30.4902\n",
      "Epoch 1: Total Loss=28.5638\n",
      "Epoch 2: Total Loss=32.0578\n",
      "Epoch 3: Total Loss=24.3630\n",
      "Epoch 4: Total Loss=31.1565\n",
      "Epoch 5: Total Loss=31.0224\n",
      "Epoch 6: Total Loss=28.8901\n",
      "Epoch 7: Total Loss=32.2550\n",
      "Epoch 8: Total Loss=24.6119\n",
      "Epoch 9: Total Loss=30.2609\n",
      "Updated x: [6.1419291496276855, -5.528090953826904], Function Value: 68.2830810546875, Gradient: [0.26282230019569397, 0.09232338517904282]\n",
      "\n",
      "Step 43/200\n",
      "Epoch 0: Total Loss=17.9157\n",
      "Epoch 1: Total Loss=17.8309\n",
      "Epoch 2: Total Loss=20.4072\n",
      "Epoch 3: Total Loss=13.7023\n",
      "Epoch 4: Total Loss=20.9015\n",
      "Epoch 5: Total Loss=17.6982\n",
      "Epoch 6: Total Loss=17.9726\n",
      "Epoch 7: Total Loss=20.0045\n",
      "Epoch 8: Total Loss=13.5191\n",
      "Epoch 9: Total Loss=20.4176\n",
      "Updated x: [6.146468162536621, -5.343078136444092], Function Value: 66.32756042480469, Gradient: [0.1320226639509201, -0.023609310388565063]\n",
      "\n",
      "Step 44/200\n",
      "Epoch 0: Total Loss=15.1968\n",
      "Epoch 1: Total Loss=16.4802\n",
      "Epoch 2: Total Loss=13.0408\n",
      "Epoch 3: Total Loss=17.4619\n",
      "Epoch 4: Total Loss=17.0269\n",
      "Epoch 5: Total Loss=12.6204\n",
      "Epoch 6: Total Loss=13.2424\n",
      "Epoch 7: Total Loss=18.6292\n",
      "Epoch 8: Total Loss=15.6010\n",
      "Epoch 9: Total Loss=12.5436\n",
      "Updated x: [6.0344438552856445, -5.218177318572998], Function Value: 63.64388656616211, Gradient: [0.22231115400791168, 0.05838398635387421]\n",
      "\n",
      "Step 45/200\n",
      "Epoch 0: Total Loss=13.3458\n",
      "Epoch 1: Total Loss=19.7260\n",
      "Epoch 2: Total Loss=25.8212\n",
      "Epoch 3: Total Loss=14.1502\n",
      "Epoch 4: Total Loss=13.3486\n",
      "Epoch 5: Total Loss=13.4824\n",
      "Epoch 6: Total Loss=19.3829\n",
      "Epoch 7: Total Loss=25.4250\n",
      "Epoch 8: Total Loss=14.5932\n",
      "Epoch 9: Total Loss=13.3385\n",
      "Updated x: [5.805156707763672, -5.029380798339844], Function Value: 58.99451446533203, Gradient: [0.24749542772769928, 0.0940270945429802]\n",
      "\n",
      "Step 46/200\n",
      "Epoch 0: Total Loss=16.5790\n",
      "Epoch 1: Total Loss=19.9092\n",
      "Epoch 2: Total Loss=15.6376\n",
      "Epoch 3: Total Loss=26.7289\n",
      "Epoch 4: Total Loss=14.3685\n",
      "Epoch 5: Total Loss=13.6010\n",
      "Epoch 6: Total Loss=13.6585\n",
      "Epoch 7: Total Loss=19.0573\n",
      "Epoch 8: Total Loss=18.5771\n",
      "Epoch 9: Total Loss=16.1263\n",
      "Updated x: [5.512321472167969, -5.0062713623046875], Function Value: 55.44844055175781, Gradient: [0.24362242221832275, 0.0841289684176445]\n",
      "\n",
      "Step 47/200\n",
      "Epoch 0: Total Loss=17.1758\n",
      "Epoch 1: Total Loss=13.0400\n",
      "Epoch 2: Total Loss=15.5281\n",
      "Epoch 3: Total Loss=18.0486\n",
      "Epoch 4: Total Loss=16.7115\n",
      "Epoch 5: Total Loss=18.7882\n",
      "Epoch 6: Total Loss=13.8780\n",
      "Epoch 7: Total Loss=17.0288\n",
      "Epoch 8: Total Loss=14.9629\n",
      "Epoch 9: Total Loss=14.3387\n",
      "Updated x: [5.408347129821777, -4.897282600402832], Function Value: 53.23359680175781, Gradient: [0.2521866261959076, 0.09177173674106598]\n",
      "\n",
      "Step 48/200\n",
      "Epoch 0: Total Loss=19.3946\n",
      "Epoch 1: Total Loss=14.9678\n",
      "Epoch 2: Total Loss=16.1520\n",
      "Epoch 3: Total Loss=18.8860\n",
      "Epoch 4: Total Loss=16.3757\n",
      "Epoch 5: Total Loss=16.1280\n",
      "Epoch 6: Total Loss=13.7514\n",
      "Epoch 7: Total Loss=14.4851\n",
      "Epoch 8: Total Loss=15.1694\n",
      "Epoch 9: Total Loss=18.7746\n",
      "Updated x: [5.312635898590088, -4.744179725646973], Function Value: 50.73134231567383, Gradient: [0.274551123380661, 0.09023673832416534]\n",
      "\n",
      "Step 49/200\n",
      "Epoch 0: Total Loss=14.9058\n",
      "Epoch 1: Total Loss=18.3556\n",
      "Epoch 2: Total Loss=15.6855\n",
      "Epoch 3: Total Loss=20.0197\n",
      "Epoch 4: Total Loss=14.3595\n",
      "Epoch 5: Total Loss=14.4025\n",
      "Epoch 6: Total Loss=16.7631\n",
      "Epoch 7: Total Loss=12.1764\n",
      "Epoch 8: Total Loss=13.9643\n",
      "Epoch 9: Total Loss=14.8326\n",
      "Updated x: [5.295288562774658, -4.430869102478027], Function Value: 47.67268371582031, Gradient: [0.3094453811645508, 0.1133032813668251]\n",
      "\n",
      "Step 50/200\n",
      "Epoch 0: Total Loss=16.4983\n",
      "Epoch 1: Total Loss=14.1586\n",
      "Epoch 2: Total Loss=14.6978\n",
      "Epoch 3: Total Loss=12.7168\n",
      "Epoch 4: Total Loss=17.7567\n",
      "Epoch 5: Total Loss=15.8936\n",
      "Epoch 6: Total Loss=14.9595\n",
      "Epoch 7: Total Loss=13.1759\n",
      "Epoch 8: Total Loss=14.4454\n",
      "Epoch 9: Total Loss=19.4089\n",
      "Updated x: [5.039618968963623, -4.307460784912109], Function Value: 43.95197677612305, Gradient: [0.25984781980514526, 0.0738145112991333]\n",
      "\n",
      "Step 51/200\n",
      "Epoch 0: Total Loss=18.3573\n",
      "Epoch 1: Total Loss=13.2030\n",
      "Epoch 2: Total Loss=15.9747\n",
      "Epoch 3: Total Loss=13.9106\n",
      "Epoch 4: Total Loss=16.2020\n",
      "Epoch 5: Total Loss=15.9337\n",
      "Epoch 6: Total Loss=15.0570\n",
      "Epoch 7: Total Loss=17.4778\n",
      "Epoch 8: Total Loss=13.4646\n",
      "Epoch 9: Total Loss=13.6551\n",
      "Updated x: [4.8294219970703125, -4.164877414703369], Function Value: 40.66952133178711, Gradient: [0.29798173904418945, 0.10665928572416306]\n",
      "\n",
      "Step 52/200\n",
      "Epoch 0: Total Loss=21.6706\n",
      "Epoch 1: Total Loss=24.0103\n",
      "Epoch 2: Total Loss=24.4563\n",
      "Epoch 3: Total Loss=25.7789\n",
      "Epoch 4: Total Loss=24.7104\n",
      "Epoch 5: Total Loss=21.4518\n",
      "Epoch 6: Total Loss=24.0175\n",
      "Epoch 7: Total Loss=24.3687\n",
      "Epoch 8: Total Loss=25.7141\n",
      "Epoch 9: Total Loss=24.5042\n",
      "Updated x: [4.719187259674072, -3.9836761951446533], Function Value: 38.140403747558594, Gradient: [0.20040364563465118, -0.028659747913479805]\n",
      "\n",
      "Step 53/200\n",
      "Epoch 0: Total Loss=19.5303\n",
      "Epoch 1: Total Loss=14.5228\n",
      "Epoch 2: Total Loss=17.0529\n",
      "Epoch 3: Total Loss=16.8776\n",
      "Epoch 4: Total Loss=14.9967\n",
      "Epoch 5: Total Loss=19.5614\n",
      "Epoch 6: Total Loss=14.3484\n",
      "Epoch 7: Total Loss=16.9424\n",
      "Epoch 8: Total Loss=17.0860\n",
      "Epoch 9: Total Loss=15.0291\n",
      "Updated x: [4.535757064819336, -4.00058650970459], Function Value: 36.577781677246094, Gradient: [0.18840111792087555, -0.04555948078632355]\n",
      "\n",
      "Step 54/200\n",
      "Epoch 0: Total Loss=12.8879\n",
      "Epoch 1: Total Loss=13.4494\n",
      "Epoch 2: Total Loss=12.5512\n",
      "Epoch 3: Total Loss=11.4032\n",
      "Epoch 4: Total Loss=12.7733\n",
      "Epoch 5: Total Loss=13.1509\n",
      "Epoch 6: Total Loss=12.1400\n",
      "Epoch 7: Total Loss=10.8839\n",
      "Epoch 8: Total Loss=14.4870\n",
      "Epoch 9: Total Loss=13.8369\n",
      "Updated x: [4.417923450469971, -3.893995761871338], Function Value: 34.681251525878906, Gradient: [0.1500025987625122, -0.05029364302754402]\n",
      "\n",
      "Step 55/200\n",
      "Epoch 0: Total Loss=9.3438\n",
      "Epoch 1: Total Loss=11.9142\n",
      "Epoch 2: Total Loss=11.4163\n",
      "Epoch 3: Total Loss=9.7779\n",
      "Epoch 4: Total Loss=12.6720\n",
      "Epoch 5: Total Loss=9.4150\n",
      "Epoch 6: Total Loss=11.9943\n",
      "Epoch 7: Total Loss=11.5500\n",
      "Epoch 8: Total Loss=9.8155\n",
      "Epoch 9: Total Loss=12.6674\n",
      "Updated x: [4.408125877380371, -3.7528200149536133], Function Value: 33.51523208618164, Gradient: [0.15184809267520905, -0.03528488799929619]\n",
      "\n",
      "Step 56/200\n",
      "Epoch 0: Total Loss=11.0275\n",
      "Epoch 1: Total Loss=10.1594\n",
      "Epoch 2: Total Loss=10.1963\n",
      "Epoch 3: Total Loss=10.6385\n",
      "Epoch 4: Total Loss=10.5670\n",
      "Epoch 5: Total Loss=11.8082\n",
      "Epoch 6: Total Loss=12.3560\n",
      "Epoch 7: Total Loss=9.8448\n",
      "Epoch 8: Total Loss=9.8937\n",
      "Epoch 9: Total Loss=10.4610\n",
      "Updated x: [4.234529495239258, -3.701157808303833], Function Value: 31.629810333251953, Gradient: [0.15709882974624634, -0.046470172703266144]\n",
      "\n",
      "Step 57/200\n",
      "Epoch 0: Total Loss=10.2978\n",
      "Epoch 1: Total Loss=11.4203\n",
      "Epoch 2: Total Loss=11.7104\n",
      "Epoch 3: Total Loss=9.8572\n",
      "Epoch 4: Total Loss=9.4090\n",
      "Epoch 5: Total Loss=10.3153\n",
      "Epoch 6: Total Loss=9.2386\n",
      "Epoch 7: Total Loss=10.2660\n",
      "Epoch 8: Total Loss=10.6035\n",
      "Epoch 9: Total Loss=13.5047\n",
      "Updated x: [4.138551712036133, -3.6762332916259766], Function Value: 30.642303466796875, Gradient: [0.14973580837249756, -0.04305282235145569]\n",
      "\n",
      "Step 58/200\n",
      "Epoch 0: Total Loss=10.7405\n",
      "Epoch 1: Total Loss=9.3157\n",
      "Epoch 2: Total Loss=11.0310\n",
      "Epoch 3: Total Loss=8.9944\n",
      "Epoch 4: Total Loss=9.7361\n",
      "Epoch 5: Total Loss=9.2184\n",
      "Epoch 6: Total Loss=11.2135\n",
      "Epoch 7: Total Loss=10.2726\n",
      "Epoch 8: Total Loss=11.1382\n",
      "Epoch 9: Total Loss=10.3220\n",
      "Updated x: [3.896543264389038, -3.7527449131011963], Function Value: 29.266143798828125, Gradient: [0.045208923518657684, -0.1161969006061554]\n",
      "\n",
      "Step 59/200\n",
      "Epoch 0: Total Loss=11.2075\n",
      "Epoch 1: Total Loss=9.3384\n",
      "Epoch 2: Total Loss=9.5187\n",
      "Epoch 3: Total Loss=10.1615\n",
      "Epoch 4: Total Loss=9.3485\n",
      "Epoch 5: Total Loss=9.2719\n",
      "Epoch 6: Total Loss=10.9526\n",
      "Epoch 7: Total Loss=11.9573\n",
      "Epoch 8: Total Loss=9.8525\n",
      "Epoch 9: Total Loss=10.1870\n",
      "Updated x: [3.757816791534424, -3.681122303009033], Function Value: 27.67184829711914, Gradient: [0.0005783769302070141, -0.15886986255645752]\n",
      "\n",
      "Step 60/200\n",
      "Epoch 0: Total Loss=10.1494\n",
      "Epoch 1: Total Loss=10.5098\n",
      "Epoch 2: Total Loss=10.1505\n",
      "Epoch 3: Total Loss=9.4032\n",
      "Epoch 4: Total Loss=10.1561\n",
      "Epoch 5: Total Loss=9.4542\n",
      "Epoch 6: Total Loss=10.6968\n",
      "Epoch 7: Total Loss=8.6251\n",
      "Epoch 8: Total Loss=9.6508\n",
      "Epoch 9: Total Loss=9.9279\n",
      "Updated x: [3.81886887550354, -3.433558940887451], Function Value: 26.373085021972656, Gradient: [0.058994948863983154, -0.11286486685276031]\n",
      "\n",
      "Step 61/200\n",
      "Epoch 0: Total Loss=10.5681\n",
      "Epoch 1: Total Loss=9.0261\n",
      "Epoch 2: Total Loss=11.1109\n",
      "Epoch 3: Total Loss=9.3676\n",
      "Epoch 4: Total Loss=11.4186\n",
      "Epoch 5: Total Loss=10.0846\n",
      "Epoch 6: Total Loss=10.5237\n",
      "Epoch 7: Total Loss=11.4518\n",
      "Epoch 8: Total Loss=9.6001\n",
      "Epoch 9: Total Loss=9.1952\n",
      "Updated x: [3.660407066345215, -3.3647825717926025], Function Value: 24.720340728759766, Gradient: [-0.02377849817276001, -0.18127471208572388]\n",
      "\n",
      "Step 62/200\n",
      "Epoch 0: Total Loss=17.3943\n",
      "Epoch 1: Total Loss=18.3894\n",
      "Epoch 2: Total Loss=16.6410\n",
      "Epoch 3: Total Loss=18.3605\n",
      "Epoch 4: Total Loss=19.1071\n",
      "Epoch 5: Total Loss=17.2035\n",
      "Epoch 6: Total Loss=18.1804\n",
      "Epoch 7: Total Loss=16.5337\n",
      "Epoch 8: Total Loss=18.1974\n",
      "Epoch 9: Total Loss=18.9030\n",
      "Updated x: [3.517970085144043, -3.129573106765747], Function Value: 22.17034149169922, Gradient: [-0.253056138753891, -0.4718480408191681]\n",
      "\n",
      "Step 63/200\n",
      "Epoch 0: Total Loss=10.3274\n",
      "Epoch 1: Total Loss=14.6925\n",
      "Epoch 2: Total Loss=11.9012\n",
      "Epoch 3: Total Loss=11.6352\n",
      "Epoch 4: Total Loss=13.7573\n",
      "Epoch 5: Total Loss=10.2512\n",
      "Epoch 6: Total Loss=14.6344\n",
      "Epoch 7: Total Loss=11.9047\n",
      "Epoch 8: Total Loss=11.5746\n",
      "Epoch 9: Total Loss=13.7650\n",
      "Updated x: [3.597470283508301, -2.832181692123413], Function Value: 20.96304702758789, Gradient: [0.04011489078402519, -0.21871386468410492]\n",
      "\n",
      "Step 64/200\n",
      "Epoch 0: Total Loss=11.4074\n",
      "Epoch 1: Total Loss=14.1999\n",
      "Epoch 2: Total Loss=10.9221\n",
      "Epoch 3: Total Loss=10.7654\n",
      "Epoch 4: Total Loss=11.4040\n",
      "Epoch 5: Total Loss=14.3783\n",
      "Epoch 6: Total Loss=12.0720\n",
      "Epoch 7: Total Loss=11.2311\n",
      "Epoch 8: Total Loss=10.3134\n",
      "Epoch 9: Total Loss=13.9153\n",
      "Updated x: [3.417295217514038, -2.6851720809936523], Function Value: 18.8880558013916, Gradient: [0.12184437364339828, -0.16109929978847504]\n",
      "\n",
      "Step 65/200\n",
      "Epoch 0: Total Loss=11.1291\n",
      "Epoch 1: Total Loss=11.0247\n",
      "Epoch 2: Total Loss=9.4566\n",
      "Epoch 3: Total Loss=13.6553\n",
      "Epoch 4: Total Loss=8.8044\n",
      "Epoch 5: Total Loss=11.1382\n",
      "Epoch 6: Total Loss=10.9990\n",
      "Epoch 7: Total Loss=9.4535\n",
      "Epoch 8: Total Loss=13.6274\n",
      "Epoch 9: Total Loss=8.7954\n",
      "Updated x: [3.3420684337615967, -2.523759603500366], Function Value: 17.53878402709961, Gradient: [0.19521667063236237, -0.10905323177576065]\n",
      "\n",
      "Step 66/200\n",
      "Epoch 0: Total Loss=9.6375\n",
      "Epoch 1: Total Loss=12.8040\n",
      "Epoch 2: Total Loss=9.4908\n",
      "Epoch 3: Total Loss=9.6414\n",
      "Epoch 4: Total Loss=10.6389\n",
      "Epoch 5: Total Loss=9.8151\n",
      "Epoch 6: Total Loss=9.5350\n",
      "Epoch 7: Total Loss=11.9037\n",
      "Epoch 8: Total Loss=9.7626\n",
      "Epoch 9: Total Loss=10.5715\n",
      "Updated x: [3.201448917388916, -2.5368812084198], Function Value: 16.685041427612305, Gradient: [0.21140390634536743, -0.11008160561323166]\n",
      "\n",
      "Step 67/200\n",
      "Epoch 0: Total Loss=8.8588\n",
      "Epoch 1: Total Loss=10.7423\n",
      "Epoch 2: Total Loss=8.4383\n",
      "Epoch 3: Total Loss=8.9138\n",
      "Epoch 4: Total Loss=9.2124\n",
      "Epoch 5: Total Loss=12.3492\n",
      "Epoch 6: Total Loss=8.5536\n",
      "Epoch 7: Total Loss=10.4629\n",
      "Epoch 8: Total Loss=9.1081\n",
      "Epoch 9: Total Loss=10.1535\n",
      "Updated x: [3.1386473178863525, -2.3733971118927], Function Value: 15.48412036895752, Gradient: [0.2569068968296051, -0.07612461596727371]\n",
      "\n",
      "Step 68/200\n",
      "Epoch 0: Total Loss=8.2186\n",
      "Epoch 1: Total Loss=9.7206\n",
      "Epoch 2: Total Loss=9.6494\n",
      "Epoch 3: Total Loss=8.4698\n",
      "Epoch 4: Total Loss=13.7023\n",
      "Epoch 5: Total Loss=7.5521\n",
      "Epoch 6: Total Loss=7.9512\n",
      "Epoch 7: Total Loss=8.8766\n",
      "Epoch 8: Total Loss=8.7243\n",
      "Epoch 9: Total Loss=9.7468\n",
      "Updated x: [3.0615110397338867, -2.294710159301758], Function Value: 14.638544082641602, Gradient: [0.22958864271640778, -0.05721311643719673]\n",
      "\n",
      "Step 69/200\n",
      "Epoch 0: Total Loss=7.7384\n",
      "Epoch 1: Total Loss=7.4522\n",
      "Epoch 2: Total Loss=8.7639\n",
      "Epoch 3: Total Loss=8.5527\n",
      "Epoch 4: Total Loss=8.4672\n",
      "Epoch 5: Total Loss=15.0448\n",
      "Epoch 6: Total Loss=8.9386\n",
      "Epoch 7: Total Loss=9.1127\n",
      "Epoch 8: Total Loss=8.4016\n",
      "Epoch 9: Total Loss=7.6740\n",
      "Updated x: [2.9033169746398926, -2.2116894721984863], Function Value: 13.320819854736328, Gradient: [0.15428581833839417, -0.0678481012582779]\n",
      "\n",
      "Step 70/200\n",
      "Epoch 0: Total Loss=11.4145\n",
      "Epoch 1: Total Loss=8.2785\n",
      "Epoch 2: Total Loss=8.2641\n",
      "Epoch 3: Total Loss=7.8552\n",
      "Epoch 4: Total Loss=8.6634\n",
      "Epoch 5: Total Loss=11.2789\n",
      "Epoch 6: Total Loss=8.3829\n",
      "Epoch 7: Total Loss=8.6133\n",
      "Epoch 8: Total Loss=9.4516\n",
      "Epoch 9: Total Loss=9.0901\n",
      "Updated x: [2.753592014312744, -2.1356265544891357], Function Value: 12.143169403076172, Gradient: [0.1938999742269516, 0.0003755760262720287]\n",
      "\n",
      "Step 71/200\n",
      "Epoch 0: Total Loss=7.5702\n",
      "Epoch 1: Total Loss=8.4423\n",
      "Epoch 2: Total Loss=7.8514\n",
      "Epoch 3: Total Loss=8.9262\n",
      "Epoch 4: Total Loss=8.6414\n",
      "Epoch 5: Total Loss=8.1758\n",
      "Epoch 6: Total Loss=8.0158\n",
      "Epoch 7: Total Loss=12.9503\n",
      "Epoch 8: Total Loss=10.4040\n",
      "Epoch 9: Total Loss=7.9798\n",
      "Updated x: [2.6712753772735596, -2.1684718132019043], Function Value: 11.837982177734375, Gradient: [0.18340550363063812, 0.021109826862812042]\n",
      "\n",
      "Step 72/200\n",
      "Epoch 0: Total Loss=15.3993\n",
      "Epoch 1: Total Loss=15.3185\n",
      "Epoch 2: Total Loss=15.0534\n",
      "Epoch 3: Total Loss=15.0011\n",
      "Epoch 4: Total Loss=14.9864\n",
      "Epoch 5: Total Loss=14.8914\n",
      "Epoch 6: Total Loss=15.0096\n",
      "Epoch 7: Total Loss=14.9684\n",
      "Epoch 8: Total Loss=14.9811\n",
      "Epoch 9: Total Loss=15.1698\n",
      "Updated x: [2.5480034351348877, -1.9385361671447754], Function Value: 10.250244140625, Gradient: [0.08486291021108627, -0.318625807762146]\n",
      "\n",
      "Step 73/200\n",
      "Epoch 0: Total Loss=9.8109\n",
      "Epoch 1: Total Loss=11.0842\n",
      "Epoch 2: Total Loss=9.9738\n",
      "Epoch 3: Total Loss=11.0001\n",
      "Epoch 4: Total Loss=9.8176\n",
      "Epoch 5: Total Loss=11.0095\n",
      "Epoch 6: Total Loss=9.9706\n",
      "Epoch 7: Total Loss=11.3392\n",
      "Epoch 8: Total Loss=9.9253\n",
      "Epoch 9: Total Loss=10.9148\n",
      "Updated x: [2.450169563293457, -1.870955228805542], Function Value: 9.503804206848145, Gradient: [0.1583348512649536, -0.34579870104789734]\n",
      "\n",
      "Step 74/200\n",
      "Epoch 0: Total Loss=10.9233\n",
      "Epoch 1: Total Loss=8.2670\n",
      "Epoch 2: Total Loss=10.3583\n",
      "Epoch 3: Total Loss=11.3565\n",
      "Epoch 4: Total Loss=8.4423\n",
      "Epoch 5: Total Loss=10.2595\n",
      "Epoch 6: Total Loss=10.4859\n",
      "Epoch 7: Total Loss=8.4835\n",
      "Epoch 8: Total Loss=10.1816\n",
      "Epoch 9: Total Loss=10.6997\n",
      "Updated x: [2.3009016513824463, -1.8385860919952393], Function Value: 8.67454719543457, Gradient: [0.07243010401725769, -0.4950191378593445]\n",
      "\n",
      "Step 75/200\n",
      "Epoch 0: Total Loss=8.4498\n",
      "Epoch 1: Total Loss=10.4755\n",
      "Epoch 2: Total Loss=8.1319\n",
      "Epoch 3: Total Loss=9.6599\n",
      "Epoch 4: Total Loss=8.5587\n",
      "Epoch 5: Total Loss=10.1937\n",
      "Epoch 6: Total Loss=8.0236\n",
      "Epoch 7: Total Loss=9.9916\n",
      "Epoch 8: Total Loss=8.4060\n",
      "Epoch 9: Total Loss=10.3309\n",
      "Updated x: [2.331796407699585, -1.66239595413208], Function Value: 8.200834274291992, Gradient: [0.18795794248580933, -0.29678165912628174]\n",
      "\n",
      "Step 76/200\n",
      "Epoch 0: Total Loss=9.5226\n",
      "Epoch 1: Total Loss=9.3893\n",
      "Epoch 2: Total Loss=9.8243\n",
      "Epoch 3: Total Loss=7.8671\n",
      "Epoch 4: Total Loss=8.3069\n",
      "Epoch 5: Total Loss=9.7846\n",
      "Epoch 6: Total Loss=9.6668\n",
      "Epoch 7: Total Loss=9.9747\n",
      "Epoch 8: Total Loss=7.8885\n",
      "Epoch 9: Total Loss=8.5228\n",
      "Updated x: [2.2089617252349854, -1.5573269128799438], Function Value: 7.304779052734375, Gradient: [0.1777433604001999, -0.03650445491075516]\n",
      "\n",
      "Step 77/200\n",
      "Epoch 0: Total Loss=7.9726\n",
      "Epoch 1: Total Loss=8.8724\n",
      "Epoch 2: Total Loss=8.7851\n",
      "Epoch 3: Total Loss=10.3241\n",
      "Epoch 4: Total Loss=9.9757\n",
      "Epoch 5: Total Loss=8.2045\n",
      "Epoch 6: Total Loss=7.9405\n",
      "Epoch 7: Total Loss=8.5795\n",
      "Epoch 8: Total Loss=8.5195\n",
      "Epoch 9: Total Loss=10.2393\n",
      "Updated x: [2.0769762992858887, -1.655468463897705], Function Value: 7.05440616607666, Gradient: [0.09627828747034073, -0.15219151973724365]\n",
      "\n",
      "Step 78/200\n",
      "Epoch 0: Total Loss=7.6846\n",
      "Epoch 1: Total Loss=9.3207\n",
      "Epoch 2: Total Loss=9.6368\n",
      "Epoch 3: Total Loss=8.5959\n",
      "Epoch 4: Total Loss=8.2728\n",
      "Epoch 5: Total Loss=8.9730\n",
      "Epoch 6: Total Loss=8.9659\n",
      "Epoch 7: Total Loss=7.6064\n",
      "Epoch 8: Total Loss=9.4556\n",
      "Epoch 9: Total Loss=9.6701\n",
      "Updated x: [1.8477556705474854, -1.5760231018066406], Function Value: 5.898049831390381, Gradient: [-0.05974706634879112, -0.14146511256694794]\n",
      "\n",
      "Step 79/200\n",
      "Epoch 0: Total Loss=8.3862\n",
      "Epoch 1: Total Loss=7.5207\n",
      "Epoch 2: Total Loss=8.8565\n",
      "Epoch 3: Total Loss=7.9147\n",
      "Epoch 4: Total Loss=8.6596\n",
      "Epoch 5: Total Loss=8.8271\n",
      "Epoch 6: Total Loss=10.2458\n",
      "Epoch 7: Total Loss=9.4168\n",
      "Epoch 8: Total Loss=8.3562\n",
      "Epoch 9: Total Loss=7.7360\n",
      "Updated x: [1.693384051322937, -1.522022008895874], Function Value: 5.18410062789917, Gradient: [-0.11011067032814026, -0.05069994926452637]\n",
      "\n",
      "Step 80/200\n",
      "Epoch 0: Total Loss=8.1466\n",
      "Epoch 1: Total Loss=9.8817\n",
      "Epoch 2: Total Loss=7.9088\n",
      "Epoch 3: Total Loss=9.1382\n",
      "Epoch 4: Total Loss=8.7326\n",
      "Epoch 5: Total Loss=8.5255\n",
      "Epoch 6: Total Loss=8.5702\n",
      "Epoch 7: Total Loss=8.5972\n",
      "Epoch 8: Total Loss=8.3792\n",
      "Epoch 9: Total Loss=7.9392\n",
      "Updated x: [1.529343843460083, -1.4506114721298218], Function Value: 4.443166255950928, Gradient: [-0.20061418414115906, -0.10119669884443283]\n",
      "\n",
      "Step 81/200\n",
      "Epoch 0: Total Loss=8.9228\n",
      "Epoch 1: Total Loss=8.4347\n",
      "Epoch 2: Total Loss=8.7467\n",
      "Epoch 3: Total Loss=9.4480\n",
      "Epoch 4: Total Loss=8.2489\n",
      "Epoch 5: Total Loss=7.7849\n",
      "Epoch 6: Total Loss=7.6111\n",
      "Epoch 7: Total Loss=8.2717\n",
      "Epoch 8: Total Loss=7.9717\n",
      "Epoch 9: Total Loss=8.5705\n",
      "Updated x: [1.3726710081100464, -1.4673689603805542], Function Value: 4.037397384643555, Gradient: [-0.31568774580955505, -0.1982204020023346]\n",
      "\n",
      "Step 82/200\n",
      "Epoch 0: Total Loss=7.8395\n",
      "Epoch 1: Total Loss=7.8936\n",
      "Epoch 2: Total Loss=7.8108\n",
      "Epoch 3: Total Loss=7.7313\n",
      "Epoch 4: Total Loss=7.7554\n",
      "Epoch 5: Total Loss=7.7564\n",
      "Epoch 6: Total Loss=7.6612\n",
      "Epoch 7: Total Loss=7.7036\n",
      "Epoch 8: Total Loss=7.7053\n",
      "Epoch 9: Total Loss=7.6775\n",
      "Updated x: [1.143694281578064, -1.3739542961120605], Function Value: 3.195786952972412, Gradient: [-0.14177069067955017, -0.3621835708618164]\n",
      "\n",
      "Step 83/200\n",
      "Epoch 0: Total Loss=7.5336\n",
      "Epoch 1: Total Loss=7.4258\n",
      "Epoch 2: Total Loss=7.5819\n",
      "Epoch 3: Total Loss=7.4300\n",
      "Epoch 4: Total Loss=7.5095\n",
      "Epoch 5: Total Loss=7.4051\n",
      "Epoch 6: Total Loss=7.5509\n",
      "Epoch 7: Total Loss=7.3540\n",
      "Epoch 8: Total Loss=7.5246\n",
      "Epoch 9: Total Loss=7.3996\n",
      "Updated x: [0.9871500730514526, -1.3117996454238892], Function Value: 2.6952834129333496, Gradient: [-0.08307161182165146, -0.40761634707450867]\n",
      "\n",
      "Step 84/200\n",
      "Epoch 0: Total Loss=7.1871\n",
      "Epoch 1: Total Loss=7.0334\n",
      "Epoch 2: Total Loss=7.2339\n",
      "Epoch 3: Total Loss=7.1938\n",
      "Epoch 4: Total Loss=6.9820\n",
      "Epoch 5: Total Loss=7.2598\n",
      "Epoch 6: Total Loss=7.1674\n",
      "Epoch 7: Total Loss=6.9696\n",
      "Epoch 8: Total Loss=7.2554\n",
      "Epoch 9: Total Loss=7.2363\n",
      "Updated x: [0.9030942320823669, -1.150708556175232], Function Value: 2.13970947265625, Gradient: [-0.11116420477628708, -0.2309660166501999]\n",
      "\n",
      "Step 85/200\n",
      "Epoch 0: Total Loss=7.0325\n",
      "Epoch 1: Total Loss=6.9628\n",
      "Epoch 2: Total Loss=7.2063\n",
      "Epoch 3: Total Loss=7.2639\n",
      "Epoch 4: Total Loss=7.0527\n",
      "Epoch 5: Total Loss=6.8747\n",
      "Epoch 6: Total Loss=7.0445\n",
      "Epoch 7: Total Loss=7.2875\n",
      "Epoch 8: Total Loss=7.1496\n",
      "Epoch 9: Total Loss=6.8548\n",
      "Updated x: [0.6961162686347961, -1.1304795742034912], Function Value: 1.7625619173049927, Gradient: [-0.1711461842060089, -0.1925271451473236]\n",
      "\n",
      "Step 86/200\n",
      "Epoch 0: Total Loss=7.0014\n",
      "Epoch 1: Total Loss=6.9560\n",
      "Epoch 2: Total Loss=6.9432\n",
      "Epoch 3: Total Loss=6.9799\n",
      "Epoch 4: Total Loss=6.9970\n",
      "Epoch 5: Total Loss=6.9403\n",
      "Epoch 6: Total Loss=6.9885\n",
      "Epoch 7: Total Loss=6.9202\n",
      "Epoch 8: Total Loss=6.9374\n",
      "Epoch 9: Total Loss=6.9587\n",
      "Updated x: [0.5760565996170044, -1.023482322692871], Function Value: 1.3793573379516602, Gradient: [-0.19223026931285858, -0.13154880702495575]\n",
      "\n",
      "Step 87/200\n",
      "Epoch 0: Total Loss=6.8386\n",
      "Epoch 1: Total Loss=6.8654\n",
      "Epoch 2: Total Loss=6.9806\n",
      "Epoch 3: Total Loss=6.8345\n",
      "Epoch 4: Total Loss=7.0052\n",
      "Epoch 5: Total Loss=6.9237\n",
      "Epoch 6: Total Loss=6.8469\n",
      "Epoch 7: Total Loss=6.8704\n",
      "Epoch 8: Total Loss=7.0226\n",
      "Epoch 9: Total Loss=6.8592\n",
      "Updated x: [0.49367305636405945, -0.8801068663597107], Function Value: 1.018301248550415, Gradient: [-0.1915479153394699, -0.050846390426158905]\n",
      "\n",
      "Step 88/200\n",
      "Epoch 0: Total Loss=6.9031\n",
      "Epoch 1: Total Loss=6.8207\n",
      "Epoch 2: Total Loss=7.0303\n",
      "Epoch 3: Total Loss=6.7245\n",
      "Epoch 4: Total Loss=6.8640\n",
      "Epoch 5: Total Loss=6.8358\n",
      "Epoch 6: Total Loss=6.9202\n",
      "Epoch 7: Total Loss=6.8837\n",
      "Epoch 8: Total Loss=6.8917\n",
      "Epoch 9: Total Loss=6.9953\n",
      "Updated x: [0.6673494577407837, -0.5793042182922363], Function Value: 0.7809486389160156, Gradient: [-0.22672809660434723, 0.01923479698598385]\n",
      "\n",
      "Step 89/200\n",
      "Epoch 0: Total Loss=6.8690\n",
      "Epoch 1: Total Loss=6.8199\n",
      "Epoch 2: Total Loss=6.7352\n",
      "Epoch 3: Total Loss=6.9600\n",
      "Epoch 4: Total Loss=6.9083\n",
      "Epoch 5: Total Loss=6.9466\n",
      "Epoch 6: Total Loss=6.8961\n",
      "Epoch 7: Total Loss=6.8287\n",
      "Epoch 8: Total Loss=6.9818\n",
      "Epoch 9: Total Loss=6.7848\n",
      "Updated x: [0.5643795728683472, -0.5649808049201965], Function Value: 0.6377276182174683, Gradient: [-0.197236567735672, 0.021967779844999313]\n",
      "\n",
      "Step 90/200\n",
      "Epoch 0: Total Loss=6.7983\n",
      "Epoch 1: Total Loss=6.9483\n",
      "Epoch 2: Total Loss=6.9090\n",
      "Epoch 3: Total Loss=6.7781\n",
      "Epoch 4: Total Loss=6.8681\n",
      "Epoch 5: Total Loss=6.8033\n",
      "Epoch 6: Total Loss=6.8509\n",
      "Epoch 7: Total Loss=6.8382\n",
      "Epoch 8: Total Loss=6.9164\n",
      "Epoch 9: Total Loss=6.8078\n",
      "Updated x: [0.4247605502605438, -0.5334146618843079], Function Value: 0.4649527370929718, Gradient: [-0.14288529753684998, 0.05275372043251991]\n",
      "\n",
      "Step 91/200\n",
      "Epoch 0: Total Loss=6.8141\n",
      "Epoch 1: Total Loss=6.8466\n",
      "Epoch 2: Total Loss=6.8844\n",
      "Epoch 3: Total Loss=6.8709\n",
      "Epoch 4: Total Loss=6.7806\n",
      "Epoch 5: Total Loss=6.7345\n",
      "Epoch 6: Total Loss=6.8199\n",
      "Epoch 7: Total Loss=6.8053\n",
      "Epoch 8: Total Loss=6.8239\n",
      "Epoch 9: Total Loss=6.7724\n",
      "Updated x: [0.4162386953830719, -0.3803589344024658], Function Value: 0.3179275691509247, Gradient: [-0.12698476016521454, 0.013928653672337532]\n",
      "\n",
      "Step 92/200\n",
      "Epoch 0: Total Loss=7.6077\n",
      "Epoch 1: Total Loss=7.6380\n",
      "Epoch 2: Total Loss=7.5145\n",
      "Epoch 3: Total Loss=8.2692\n",
      "Epoch 4: Total Loss=7.1270\n",
      "Epoch 5: Total Loss=7.1683\n",
      "Epoch 6: Total Loss=7.6959\n",
      "Epoch 7: Total Loss=7.1331\n",
      "Epoch 8: Total Loss=7.5032\n",
      "Epoch 9: Total Loss=7.6684\n",
      "Updated x: [0.15729287266731262, -0.23641490936279297], Function Value: 0.08063305914402008, Gradient: [0.0921408161520958, -0.16743801534175873]\n",
      "\n",
      "Step 93/200\n",
      "Epoch 0: Total Loss=7.1780\n",
      "Epoch 1: Total Loss=7.2996\n",
      "Epoch 2: Total Loss=8.0264\n",
      "Epoch 3: Total Loss=7.4063\n",
      "Epoch 4: Total Loss=8.1918\n",
      "Epoch 5: Total Loss=7.1720\n",
      "Epoch 6: Total Loss=7.3404\n",
      "Epoch 7: Total Loss=7.2636\n",
      "Epoch 8: Total Loss=7.0968\n",
      "Epoch 9: Total Loss=7.5472\n",
      "Updated x: [0.043567389249801636, -0.09559847414493561], Function Value: 0.011037185788154602, Gradient: [0.04785149544477463, -0.10596077889204025]\n",
      "\n",
      "Step 94/200\n",
      "Epoch 0: Total Loss=7.6447\n",
      "Epoch 1: Total Loss=7.7410\n",
      "Epoch 2: Total Loss=7.2974\n",
      "Epoch 3: Total Loss=7.5279\n",
      "Epoch 4: Total Loss=7.5520\n",
      "Epoch 5: Total Loss=7.2831\n",
      "Epoch 6: Total Loss=6.8068\n",
      "Epoch 7: Total Loss=7.1389\n",
      "Epoch 8: Total Loss=7.5091\n",
      "Epoch 9: Total Loss=7.1350\n",
      "Updated x: [0.08963468670845032, 0.037089020013809204], Function Value: 0.009409972466528416, Gradient: [0.026355911046266556, -0.09908188134431839]\n",
      "\n",
      "Step 95/200\n",
      "Epoch 0: Total Loss=7.0137\n",
      "Epoch 1: Total Loss=7.8687\n",
      "Epoch 2: Total Loss=7.8282\n",
      "Epoch 3: Total Loss=7.0620\n",
      "Epoch 4: Total Loss=7.0272\n",
      "Epoch 5: Total Loss=7.1131\n",
      "Epoch 6: Total Loss=7.4166\n",
      "Epoch 7: Total Loss=7.6818\n",
      "Epoch 8: Total Loss=7.2459\n",
      "Epoch 9: Total Loss=7.1761\n",
      "Updated x: [-0.011859320104122162, -0.014012277126312256], Function Value: 0.0003369873738847673, Gradient: [0.007534853182733059, -0.07088904827833176]\n",
      "\n",
      "Step 96/200\n",
      "Epoch 0: Total Loss=7.3804\n",
      "Epoch 1: Total Loss=7.4259\n",
      "Epoch 2: Total Loss=7.2672\n",
      "Epoch 3: Total Loss=7.6414\n",
      "Epoch 4: Total Loss=7.4862\n",
      "Epoch 5: Total Loss=6.7918\n",
      "Epoch 6: Total Loss=7.0308\n",
      "Epoch 7: Total Loss=7.5258\n",
      "Epoch 8: Total Loss=7.7281\n",
      "Epoch 9: Total Loss=7.4684\n",
      "Updated x: [-0.021746965125203133, 0.008383302018046379], Function Value: 0.0005432102479971945, Gradient: [0.0059106615372002125, -0.0639336109161377]\n",
      "\n",
      "Step 97/200\n",
      "Epoch 0: Total Loss=8.1511\n",
      "Epoch 1: Total Loss=7.3745\n",
      "Epoch 2: Total Loss=7.2128\n",
      "Epoch 3: Total Loss=7.1133\n",
      "Epoch 4: Total Loss=7.0161\n",
      "Epoch 5: Total Loss=7.1732\n",
      "Epoch 6: Total Loss=7.3704\n",
      "Epoch 7: Total Loss=7.8922\n",
      "Epoch 8: Total Loss=7.0329\n",
      "Epoch 9: Total Loss=7.3854\n",
      "Updated x: [0.010577240958809853, 0.02309042029082775], Function Value: 0.0006450455402955413, Gradient: [-0.0028708036988973618, -0.05708831921219826]\n",
      "\n",
      "Step 98/200\n",
      "Epoch 0: Total Loss=7.2384\n",
      "Epoch 1: Total Loss=7.2417\n",
      "Epoch 2: Total Loss=7.2275\n",
      "Epoch 3: Total Loss=6.9314\n",
      "Epoch 4: Total Loss=7.5871\n",
      "Epoch 5: Total Loss=7.4216\n",
      "Epoch 6: Total Loss=7.0491\n",
      "Epoch 7: Total Loss=7.5768\n",
      "Epoch 8: Total Loss=7.6406\n",
      "Epoch 9: Total Loss=7.1843\n",
      "Updated x: [-0.04427307844161987, 0.028953537344932556], Function Value: 0.0027984129264950752, Gradient: [0.002515246393159032, -0.05776071548461914]\n",
      "\n",
      "Step 99/200\n",
      "Epoch 0: Total Loss=7.2185\n",
      "Epoch 1: Total Loss=7.0874\n",
      "Epoch 2: Total Loss=7.3318\n",
      "Epoch 3: Total Loss=7.4019\n",
      "Epoch 4: Total Loss=7.0972\n",
      "Epoch 5: Total Loss=7.4115\n",
      "Epoch 6: Total Loss=7.5653\n",
      "Epoch 7: Total Loss=7.5236\n",
      "Epoch 8: Total Loss=7.3678\n",
      "Epoch 9: Total Loss=7.4278\n",
      "Updated x: [-0.003315553069114685, 0.005527041852474213], Function Value: 4.154108319198713e-05, Gradient: [-0.014292681589722633, -0.051844529807567596]\n",
      "\n",
      "Step 100/200\n",
      "Epoch 0: Total Loss=7.1016\n",
      "Epoch 1: Total Loss=8.3366\n",
      "Epoch 2: Total Loss=6.8980\n",
      "Epoch 3: Total Loss=7.5990\n",
      "Epoch 4: Total Loss=7.5316\n",
      "Epoch 5: Total Loss=7.6335\n",
      "Epoch 6: Total Loss=7.5019\n",
      "Epoch 7: Total Loss=7.4528\n",
      "Epoch 8: Total Loss=7.2249\n",
      "Epoch 9: Total Loss=6.9934\n",
      "Updated x: [-0.01965421997010708, 0.035358332097530365], Function Value: 0.0016365000046789646, Gradient: [-0.007803099229931831, -0.047791481018066406]\n",
      "\n",
      "Step 101/200\n",
      "Epoch 0: Total Loss=6.6839\n",
      "Epoch 1: Total Loss=7.5264\n",
      "Epoch 2: Total Loss=7.1130\n",
      "Epoch 3: Total Loss=7.0832\n",
      "Epoch 4: Total Loss=7.1327\n",
      "Epoch 5: Total Loss=7.2727\n",
      "Epoch 6: Total Loss=7.7293\n",
      "Epoch 7: Total Loss=7.3011\n",
      "Epoch 8: Total Loss=7.6035\n",
      "Epoch 9: Total Loss=7.5970\n",
      "Updated x: [0.049138978123664856, -0.03835228830575943], Function Value: 0.003885537153109908, Gradient: [-0.005166585091501474, -0.05761246010661125]\n",
      "\n",
      "Step 102/200\n",
      "Epoch 0: Total Loss=6.7870\n",
      "Epoch 1: Total Loss=6.8782\n",
      "Epoch 2: Total Loss=6.7142\n",
      "Epoch 3: Total Loss=6.8525\n",
      "Epoch 4: Total Loss=6.7728\n",
      "Epoch 5: Total Loss=6.7300\n",
      "Epoch 6: Total Loss=6.7822\n",
      "Epoch 7: Total Loss=6.7733\n",
      "Epoch 8: Total Loss=6.6680\n",
      "Epoch 9: Total Loss=6.8603\n",
      "Updated x: [0.04790815711021423, -0.028856225311756134], Function Value: 0.003127873409539461, Gradient: [-0.014121015556156635, -0.04865974187850952]\n",
      "\n",
      "Step 103/200\n",
      "Epoch 0: Total Loss=6.7813\n",
      "Epoch 1: Total Loss=6.6970\n",
      "Epoch 2: Total Loss=6.7760\n",
      "Epoch 3: Total Loss=6.6517\n",
      "Epoch 4: Total Loss=6.8399\n",
      "Epoch 5: Total Loss=6.6366\n",
      "Epoch 6: Total Loss=6.6573\n",
      "Epoch 7: Total Loss=6.7842\n",
      "Epoch 8: Total Loss=6.8842\n",
      "Epoch 9: Total Loss=6.8130\n",
      "Updated x: [-0.030021890997886658, 0.03705165535211563], Function Value: 0.0022741390857845545, Gradient: [-0.009989726357161999, -0.03731691464781761]\n",
      "\n",
      "Step 104/200\n",
      "Epoch 0: Total Loss=6.8393\n",
      "Epoch 1: Total Loss=6.7694\n",
      "Epoch 2: Total Loss=6.7145\n",
      "Epoch 3: Total Loss=6.8237\n",
      "Epoch 4: Total Loss=6.7514\n",
      "Epoch 5: Total Loss=6.9910\n",
      "Epoch 6: Total Loss=6.7554\n",
      "Epoch 7: Total Loss=6.7226\n",
      "Epoch 8: Total Loss=6.8164\n",
      "Epoch 9: Total Loss=6.7683\n",
      "Updated x: [-0.02484329417347908, 0.03356665372848511], Function Value: 0.0017439094372093678, Gradient: [-0.009091315791010857, -0.031653109937906265]\n",
      "\n",
      "Step 105/200\n",
      "Epoch 0: Total Loss=6.8432\n",
      "Epoch 1: Total Loss=6.8314\n",
      "Epoch 2: Total Loss=6.7946\n",
      "Epoch 3: Total Loss=6.8014\n",
      "Epoch 4: Total Loss=6.8013\n",
      "Epoch 5: Total Loss=6.6968\n",
      "Epoch 6: Total Loss=6.6888\n",
      "Epoch 7: Total Loss=6.6968\n",
      "Epoch 8: Total Loss=6.6972\n",
      "Epoch 9: Total Loss=6.7859\n",
      "Updated x: [0.039239976555109024, 0.01408405601978302], Function Value: 0.00173813640139997, Gradient: [-0.012324766255915165, -0.03125166520476341]\n",
      "\n",
      "Step 106/200\n",
      "Epoch 0: Total Loss=6.8545\n",
      "Epoch 1: Total Loss=6.8145\n",
      "Epoch 2: Total Loss=6.8842\n",
      "Epoch 3: Total Loss=6.7034\n",
      "Epoch 4: Total Loss=6.8119\n",
      "Epoch 5: Total Loss=6.7478\n",
      "Epoch 6: Total Loss=6.7638\n",
      "Epoch 7: Total Loss=6.7838\n",
      "Epoch 8: Total Loss=6.8569\n",
      "Epoch 9: Total Loss=6.7923\n",
      "Updated x: [0.00485895574092865, 0.005080436356365681], Function Value: 4.942028317600489e-05, Gradient: [-0.004456732422113419, -0.030994419008493423]\n",
      "\n",
      "Step 107/200\n",
      "Epoch 0: Total Loss=6.7141\n",
      "Epoch 1: Total Loss=6.7977\n",
      "Epoch 2: Total Loss=6.7644\n",
      "Epoch 3: Total Loss=6.7417\n",
      "Epoch 4: Total Loss=6.8206\n",
      "Epoch 5: Total Loss=6.7387\n",
      "Epoch 6: Total Loss=6.7023\n",
      "Epoch 7: Total Loss=6.8243\n",
      "Epoch 8: Total Loss=6.8492\n",
      "Epoch 9: Total Loss=6.7744\n",
      "Updated x: [-0.03653571009635925, 0.008261637762188911], Function Value: 0.0014031127793714404, Gradient: [-0.0011472958140075207, -0.03062088042497635]\n",
      "\n",
      "Step 108/200\n",
      "Epoch 0: Total Loss=6.7652\n",
      "Epoch 1: Total Loss=6.6001\n",
      "Epoch 2: Total Loss=6.6062\n",
      "Epoch 3: Total Loss=6.9049\n",
      "Epoch 4: Total Loss=6.7614\n",
      "Epoch 5: Total Loss=6.7228\n",
      "Epoch 6: Total Loss=6.7899\n",
      "Epoch 7: Total Loss=6.8874\n",
      "Epoch 8: Total Loss=6.7271\n",
      "Epoch 9: Total Loss=6.7831\n",
      "Updated x: [0.011196400970220566, -0.019465385004878044], Function Value: 0.0005042606499046087, Gradient: [-0.0029982218984514475, -0.027833517640829086]\n",
      "\n",
      "Step 109/200\n",
      "Epoch 0: Total Loss=6.8088\n",
      "Epoch 1: Total Loss=6.7368\n",
      "Epoch 2: Total Loss=6.6710\n",
      "Epoch 3: Total Loss=6.8115\n",
      "Epoch 4: Total Loss=6.7254\n",
      "Epoch 5: Total Loss=6.7885\n",
      "Epoch 6: Total Loss=6.6938\n",
      "Epoch 7: Total Loss=6.8356\n",
      "Epoch 8: Total Loss=6.7168\n",
      "Epoch 9: Total Loss=6.7942\n",
      "Updated x: [-0.05410575494170189, 0.031687282025814056], Function Value: 0.003931516781449318, Gradient: [0.003815647680312395, -0.027479171752929688]\n",
      "\n",
      "Step 110/200\n",
      "Epoch 0: Total Loss=6.8197\n",
      "Epoch 1: Total Loss=6.8295\n",
      "Epoch 2: Total Loss=6.7467\n",
      "Epoch 3: Total Loss=6.7707\n",
      "Epoch 4: Total Loss=6.9131\n",
      "Epoch 5: Total Loss=6.7366\n",
      "Epoch 6: Total Loss=6.8445\n",
      "Epoch 7: Total Loss=6.6757\n",
      "Epoch 8: Total Loss=6.7796\n",
      "Epoch 9: Total Loss=6.7942\n",
      "Updated x: [-0.013145104050636292, 0.027742156758904457], Function Value: 0.0009424210293218493, Gradient: [0.0017457364592701197, -0.028466297313570976]\n",
      "\n",
      "Step 111/200\n",
      "Epoch 0: Total Loss=6.6830\n",
      "Epoch 1: Total Loss=6.7318\n",
      "Epoch 2: Total Loss=6.8494\n",
      "Epoch 3: Total Loss=6.8175\n",
      "Epoch 4: Total Loss=6.8955\n",
      "Epoch 5: Total Loss=6.8312\n",
      "Epoch 6: Total Loss=6.8125\n",
      "Epoch 7: Total Loss=6.8040\n",
      "Epoch 8: Total Loss=6.6676\n",
      "Epoch 9: Total Loss=6.8196\n",
      "Updated x: [-0.043599933385849, -0.015281414613127708], Function Value: 0.0021344758570194244, Gradient: [0.002924425294622779, -0.026605945080518723]\n",
      "\n",
      "Step 112/200\n",
      "Epoch 0: Total Loss=6.3254\n",
      "Epoch 1: Total Loss=6.3299\n",
      "Epoch 2: Total Loss=6.3200\n",
      "Epoch 3: Total Loss=6.3397\n",
      "Epoch 4: Total Loss=6.3274\n",
      "Epoch 5: Total Loss=6.3397\n",
      "Epoch 6: Total Loss=6.3181\n",
      "Epoch 7: Total Loss=6.3069\n",
      "Epoch 8: Total Loss=6.3333\n",
      "Epoch 9: Total Loss=6.3166\n",
      "Updated x: [0.06198173016309738, 0.00884944200515747], Function Value: 0.003920047543942928, Gradient: [-0.0265017282217741, -0.03432788327336311]\n",
      "\n",
      "Step 113/200\n",
      "Epoch 0: Total Loss=6.3219\n",
      "Epoch 1: Total Loss=6.3202\n",
      "Epoch 2: Total Loss=6.3089\n",
      "Epoch 3: Total Loss=6.3348\n",
      "Epoch 4: Total Loss=6.3215\n",
      "Epoch 5: Total Loss=6.3208\n",
      "Epoch 6: Total Loss=6.3550\n",
      "Epoch 7: Total Loss=6.3199\n",
      "Epoch 8: Total Loss=6.3447\n",
      "Epoch 9: Total Loss=6.3202\n",
      "Updated x: [0.022251345217227936, 0.016276979818940163], Function Value: 0.00076006242306903, Gradient: [-0.01154417172074318, -0.03386131301522255]\n",
      "\n",
      "Step 114/200\n",
      "Epoch 0: Total Loss=6.3284\n",
      "Epoch 1: Total Loss=6.3176\n",
      "Epoch 2: Total Loss=6.3345\n",
      "Epoch 3: Total Loss=6.3408\n",
      "Epoch 4: Total Loss=6.3137\n",
      "Epoch 5: Total Loss=6.3196\n",
      "Epoch 6: Total Loss=6.3222\n",
      "Epoch 7: Total Loss=6.3177\n",
      "Epoch 8: Total Loss=6.3259\n",
      "Epoch 9: Total Loss=6.3303\n",
      "Updated x: [0.0008730422705411911, -0.03062182106077671], Function Value: 0.0009384581353515387, Gradient: [-0.0031964932568371296, -0.032717540860176086]\n",
      "\n",
      "Step 115/200\n",
      "Epoch 0: Total Loss=6.3269\n",
      "Epoch 1: Total Loss=6.3402\n",
      "Epoch 2: Total Loss=6.3045\n",
      "Epoch 3: Total Loss=6.3377\n",
      "Epoch 4: Total Loss=6.3285\n",
      "Epoch 5: Total Loss=6.3201\n",
      "Epoch 6: Total Loss=6.3254\n",
      "Epoch 7: Total Loss=6.3284\n",
      "Epoch 8: Total Loss=6.3412\n",
      "Epoch 9: Total Loss=6.3332\n",
      "Updated x: [0.0025813078973442316, 0.013917991891503334], Function Value: 0.0002003736444748938, Gradient: [0.00020395891624502838, -0.027589377015829086]\n",
      "\n",
      "Step 116/200\n",
      "Epoch 0: Total Loss=6.3001\n",
      "Epoch 1: Total Loss=6.3197\n",
      "Epoch 2: Total Loss=6.3439\n",
      "Epoch 3: Total Loss=6.3183\n",
      "Epoch 4: Total Loss=6.3093\n",
      "Epoch 5: Total Loss=6.3158\n",
      "Epoch 6: Total Loss=6.3119\n",
      "Epoch 7: Total Loss=6.3320\n",
      "Epoch 8: Total Loss=6.3104\n",
      "Epoch 9: Total Loss=6.3064\n",
      "Updated x: [0.04197763651609421, -0.010885937139391899], Function Value: 0.0018806254956871271, Gradient: [-0.003199805971235037, -0.02659255638718605]\n",
      "\n",
      "Step 117/200\n",
      "Epoch 0: Total Loss=6.3488\n",
      "Epoch 1: Total Loss=6.3225\n",
      "Epoch 2: Total Loss=6.3218\n",
      "Epoch 3: Total Loss=6.3121\n",
      "Epoch 4: Total Loss=6.3202\n",
      "Epoch 5: Total Loss=6.3280\n",
      "Epoch 6: Total Loss=6.3160\n",
      "Epoch 7: Total Loss=6.3180\n",
      "Epoch 8: Total Loss=6.3005\n",
      "Epoch 9: Total Loss=6.3350\n",
      "Updated x: [-0.01758219674229622, -0.05484066158533096], Function Value: 0.0033166317734867334, Gradient: [0.002354054246097803, -0.026319945231080055]\n",
      "\n",
      "Step 118/200\n",
      "Epoch 0: Total Loss=6.3141\n",
      "Epoch 1: Total Loss=6.3132\n",
      "Epoch 2: Total Loss=6.3375\n",
      "Epoch 3: Total Loss=6.3124\n",
      "Epoch 4: Total Loss=6.3130\n",
      "Epoch 5: Total Loss=6.3032\n",
      "Epoch 6: Total Loss=6.3050\n",
      "Epoch 7: Total Loss=6.3157\n",
      "Epoch 8: Total Loss=6.2987\n",
      "Epoch 9: Total Loss=6.3237\n",
      "Updated x: [0.007910670712590218, 0.0575360506772995], Function Value: 0.0033729758579283953, Gradient: [0.0014878842048346996, -0.02582504414021969]\n",
      "\n",
      "Step 119/200\n",
      "Epoch 0: Total Loss=6.3340\n",
      "Epoch 1: Total Loss=6.3086\n",
      "Epoch 2: Total Loss=6.2917\n",
      "Epoch 3: Total Loss=6.3492\n",
      "Epoch 4: Total Loss=6.3346\n",
      "Epoch 5: Total Loss=6.3293\n",
      "Epoch 6: Total Loss=6.2874\n",
      "Epoch 7: Total Loss=6.3278\n",
      "Epoch 8: Total Loss=6.3183\n",
      "Epoch 9: Total Loss=6.3272\n",
      "Updated x: [0.059147968888282776, -0.00851479172706604], Function Value: 0.003570983884856105, Gradient: [-0.001674309023655951, -0.024570828303694725]\n",
      "\n",
      "Step 120/200\n",
      "Epoch 0: Total Loss=6.3111\n",
      "Epoch 1: Total Loss=6.3393\n",
      "Epoch 2: Total Loss=6.3056\n",
      "Epoch 3: Total Loss=6.3243\n",
      "Epoch 4: Total Loss=6.3222\n",
      "Epoch 5: Total Loss=6.3161\n",
      "Epoch 6: Total Loss=6.3221\n",
      "Epoch 7: Total Loss=6.3178\n",
      "Epoch 8: Total Loss=6.3051\n",
      "Epoch 9: Total Loss=6.3177\n",
      "Updated x: [0.05199607089161873, 0.032449010759592056], Function Value: 0.003756529651582241, Gradient: [-0.0008566970354877412, -0.027243666350841522]\n",
      "\n",
      "Step 121/200\n",
      "Epoch 0: Total Loss=6.3165\n",
      "Epoch 1: Total Loss=6.3279\n",
      "Epoch 2: Total Loss=6.3109\n",
      "Epoch 3: Total Loss=6.3283\n",
      "Epoch 4: Total Loss=6.3040\n",
      "Epoch 5: Total Loss=6.3338\n",
      "Epoch 6: Total Loss=6.3196\n",
      "Epoch 7: Total Loss=6.3300\n",
      "Epoch 8: Total Loss=6.3402\n",
      "Epoch 9: Total Loss=6.3248\n",
      "Updated x: [-0.03818682208657265, -0.0016624704003334045], Function Value: 0.0014609971549361944, Gradient: [0.008992132730782032, -0.023931965231895447]\n",
      "\n",
      "Step 122/200\n",
      "Epoch 0: Total Loss=6.8555\n",
      "Epoch 1: Total Loss=7.3118\n",
      "Epoch 2: Total Loss=7.1179\n",
      "Epoch 3: Total Loss=6.9342\n",
      "Epoch 4: Total Loss=6.7720\n",
      "Epoch 5: Total Loss=6.9658\n",
      "Epoch 6: Total Loss=6.9118\n",
      "Epoch 7: Total Loss=6.6042\n",
      "Epoch 8: Total Loss=7.0036\n",
      "Epoch 9: Total Loss=6.9453\n",
      "Updated x: [0.007863655686378479, -0.020801562815904617], Function Value: 0.0004945420660078526, Gradient: [-0.012976070865988731, -0.028712676838040352]\n",
      "\n",
      "Step 123/200\n",
      "Epoch 0: Total Loss=7.2818\n",
      "Epoch 1: Total Loss=6.8449\n",
      "Epoch 2: Total Loss=7.0657\n",
      "Epoch 3: Total Loss=7.0096\n",
      "Epoch 4: Total Loss=7.0540\n",
      "Epoch 5: Total Loss=7.1875\n",
      "Epoch 6: Total Loss=7.0815\n",
      "Epoch 7: Total Loss=6.9856\n",
      "Epoch 8: Total Loss=6.9603\n",
      "Epoch 9: Total Loss=6.9657\n",
      "Updated x: [-0.023636963218450546, -0.009469306096434593], Function Value: 0.0006483737961389124, Gradient: [-0.001890456536784768, -0.026667458936572075]\n",
      "\n",
      "Step 124/200\n",
      "Epoch 0: Total Loss=7.0136\n",
      "Epoch 1: Total Loss=6.8406\n",
      "Epoch 2: Total Loss=6.8530\n",
      "Epoch 3: Total Loss=6.7855\n",
      "Epoch 4: Total Loss=6.9980\n",
      "Epoch 5: Total Loss=6.9254\n",
      "Epoch 6: Total Loss=6.8703\n",
      "Epoch 7: Total Loss=6.8073\n",
      "Epoch 8: Total Loss=6.8345\n",
      "Epoch 9: Total Loss=7.0531\n",
      "Updated x: [0.009442150592803955, -0.041816018521785736], Function Value: 0.001837733667343855, Gradient: [-0.00047479887143708766, -0.0248028002679348]\n",
      "\n",
      "Step 125/200\n",
      "Epoch 0: Total Loss=6.9029\n",
      "Epoch 1: Total Loss=6.7033\n",
      "Epoch 2: Total Loss=6.7695\n",
      "Epoch 3: Total Loss=6.7971\n",
      "Epoch 4: Total Loss=6.9515\n",
      "Epoch 5: Total Loss=6.7801\n",
      "Epoch 6: Total Loss=7.0129\n",
      "Epoch 7: Total Loss=6.9431\n",
      "Epoch 8: Total Loss=6.9666\n",
      "Epoch 9: Total Loss=7.1000\n",
      "Updated x: [0.014966362155973911, 0.035651616752147675], Function Value: 0.0014950297772884369, Gradient: [0.002141266595572233, -0.028120186179876328]\n",
      "\n",
      "Step 126/200\n",
      "Epoch 0: Total Loss=6.8196\n",
      "Epoch 1: Total Loss=6.7693\n",
      "Epoch 2: Total Loss=7.0826\n",
      "Epoch 3: Total Loss=6.8274\n",
      "Epoch 4: Total Loss=7.0236\n",
      "Epoch 5: Total Loss=7.0218\n",
      "Epoch 6: Total Loss=6.7270\n",
      "Epoch 7: Total Loss=6.8925\n",
      "Epoch 8: Total Loss=6.9557\n",
      "Epoch 9: Total Loss=6.8662\n",
      "Updated x: [-0.057381391525268555, 0.0018888413906097412], Function Value: 0.003296191804111004, Gradient: [0.010113487020134926, -0.02384967729449272]\n",
      "\n",
      "Step 127/200\n",
      "Epoch 0: Total Loss=6.6969\n",
      "Epoch 1: Total Loss=6.7340\n",
      "Epoch 2: Total Loss=7.0066\n",
      "Epoch 3: Total Loss=6.8396\n",
      "Epoch 4: Total Loss=6.6982\n",
      "Epoch 5: Total Loss=6.8953\n",
      "Epoch 6: Total Loss=6.9946\n",
      "Epoch 7: Total Loss=6.8135\n",
      "Epoch 8: Total Loss=7.0358\n",
      "Epoch 9: Total Loss=6.8862\n",
      "Updated x: [0.052075207233428955, 0.06054937466979027], Function Value: 0.006378053687512875, Gradient: [0.0001278593554161489, -0.021807605400681496]\n",
      "\n",
      "Step 128/200\n",
      "Epoch 0: Total Loss=7.0592\n",
      "Epoch 1: Total Loss=6.7900\n",
      "Epoch 2: Total Loss=7.0175\n",
      "Epoch 3: Total Loss=7.1546\n",
      "Epoch 4: Total Loss=6.6289\n",
      "Epoch 5: Total Loss=6.8571\n",
      "Epoch 6: Total Loss=7.0207\n",
      "Epoch 7: Total Loss=6.8605\n",
      "Epoch 8: Total Loss=6.9197\n",
      "Epoch 9: Total Loss=7.1350\n",
      "Updated x: [-0.009271558374166489, -0.0271533764898777], Function Value: 0.000823267619125545, Gradient: [0.009456036612391472, -0.01913566328585148]\n",
      "\n",
      "Step 129/200\n",
      "Epoch 0: Total Loss=6.9466\n",
      "Epoch 1: Total Loss=6.7113\n",
      "Epoch 2: Total Loss=6.7713\n",
      "Epoch 3: Total Loss=7.0731\n",
      "Epoch 4: Total Loss=6.9996\n",
      "Epoch 5: Total Loss=6.9420\n",
      "Epoch 6: Total Loss=7.0623\n",
      "Epoch 7: Total Loss=6.9054\n",
      "Epoch 8: Total Loss=6.7231\n",
      "Epoch 9: Total Loss=6.9826\n",
      "Updated x: [-0.030884094536304474, -0.020825115963816643], Function Value: 0.0013875127770006657, Gradient: [0.010677309706807137, -0.021314483135938644]\n",
      "\n",
      "Step 130/200\n",
      "Epoch 0: Total Loss=6.9325\n",
      "Epoch 1: Total Loss=6.8638\n",
      "Epoch 2: Total Loss=6.9299\n",
      "Epoch 3: Total Loss=7.0649\n",
      "Epoch 4: Total Loss=6.8020\n",
      "Epoch 5: Total Loss=6.8090\n",
      "Epoch 6: Total Loss=7.2460\n",
      "Epoch 7: Total Loss=6.9926\n",
      "Epoch 8: Total Loss=7.0052\n",
      "Epoch 9: Total Loss=6.9890\n",
      "Updated x: [0.04259414225816727, -0.027523433789610863], Function Value: 0.002571800258010626, Gradient: [0.004549146164208651, -0.020755058154463768]\n",
      "\n",
      "Step 131/200\n",
      "Epoch 0: Total Loss=6.8844\n",
      "Epoch 1: Total Loss=7.1095\n",
      "Epoch 2: Total Loss=6.7094\n",
      "Epoch 3: Total Loss=6.7308\n",
      "Epoch 4: Total Loss=7.0467\n",
      "Epoch 5: Total Loss=6.8200\n",
      "Epoch 6: Total Loss=7.1133\n",
      "Epoch 7: Total Loss=6.7882\n",
      "Epoch 8: Total Loss=6.9121\n",
      "Epoch 9: Total Loss=6.8378\n",
      "Updated x: [0.03214988484978676, 0.01489768736064434], Function Value: 0.0012555561261251569, Gradient: [0.006618115119636059, -0.0213774461299181]\n",
      "\n",
      "Step 132/200\n",
      "Epoch 0: Total Loss=6.4624\n",
      "Epoch 1: Total Loss=6.5128\n",
      "Epoch 2: Total Loss=6.5697\n",
      "Epoch 3: Total Loss=6.5506\n",
      "Epoch 4: Total Loss=6.4915\n",
      "Epoch 5: Total Loss=6.5628\n",
      "Epoch 6: Total Loss=6.4928\n",
      "Epoch 7: Total Loss=6.4708\n",
      "Epoch 8: Total Loss=6.5236\n",
      "Epoch 9: Total Loss=6.4852\n",
      "Updated x: [0.03097078762948513, -0.056152306497097015], Function Value: 0.004112271126359701, Gradient: [0.011679680086672306, -0.01650715060532093]\n",
      "\n",
      "Step 133/200\n",
      "Epoch 0: Total Loss=6.4796\n",
      "Epoch 1: Total Loss=6.5580\n",
      "Epoch 2: Total Loss=6.4356\n",
      "Epoch 3: Total Loss=6.4310\n",
      "Epoch 4: Total Loss=6.5356\n",
      "Epoch 5: Total Loss=6.5879\n",
      "Epoch 6: Total Loss=6.5308\n",
      "Epoch 7: Total Loss=6.5286\n",
      "Epoch 8: Total Loss=6.5152\n",
      "Epoch 9: Total Loss=6.5149\n",
      "Updated x: [0.033193185925483704, 0.007707923650741577], Function Value: 0.001161199645139277, Gradient: [0.01186408381909132, -0.021412288770079613]\n",
      "\n",
      "Step 134/200\n",
      "Epoch 0: Total Loss=6.5222\n",
      "Epoch 1: Total Loss=6.5388\n",
      "Epoch 2: Total Loss=6.4897\n",
      "Epoch 3: Total Loss=6.5503\n",
      "Epoch 4: Total Loss=6.5126\n",
      "Epoch 5: Total Loss=6.4804\n",
      "Epoch 6: Total Loss=6.5243\n",
      "Epoch 7: Total Loss=6.5104\n",
      "Epoch 8: Total Loss=6.5265\n",
      "Epoch 9: Total Loss=6.4867\n",
      "Updated x: [-0.008864544332027435, -0.041626423597335815], Function Value: 0.0018113392870873213, Gradient: [0.012369154021143913, -0.019935067743062973]\n",
      "\n",
      "Step 135/200\n",
      "Epoch 0: Total Loss=6.4663\n",
      "Epoch 1: Total Loss=6.4971\n",
      "Epoch 2: Total Loss=6.4789\n",
      "Epoch 3: Total Loss=6.4698\n",
      "Epoch 4: Total Loss=6.4836\n",
      "Epoch 5: Total Loss=6.5096\n",
      "Epoch 6: Total Loss=6.5129\n",
      "Epoch 7: Total Loss=6.5098\n",
      "Epoch 8: Total Loss=6.4923\n",
      "Epoch 9: Total Loss=6.4630\n",
      "Updated x: [-0.015300826169550419, -0.023382166400551796], Function Value: 0.0007808409864082932, Gradient: [0.012144605629146099, -0.023168854415416718]\n",
      "\n",
      "Step 136/200\n",
      "Epoch 0: Total Loss=6.5426\n",
      "Epoch 1: Total Loss=6.4245\n",
      "Epoch 2: Total Loss=6.5218\n",
      "Epoch 3: Total Loss=6.6059\n",
      "Epoch 4: Total Loss=6.4953\n",
      "Epoch 5: Total Loss=6.5147\n",
      "Epoch 6: Total Loss=6.5880\n",
      "Epoch 7: Total Loss=6.6038\n",
      "Epoch 8: Total Loss=6.4446\n",
      "Epoch 9: Total Loss=6.4805\n",
      "Updated x: [0.023586340248584747, -0.00684850849211216], Function Value: 0.0006032175151631236, Gradient: [0.009694436565041542, -0.02195904590189457]\n",
      "\n",
      "Step 137/200\n",
      "Epoch 0: Total Loss=6.5589\n",
      "Epoch 1: Total Loss=6.4746\n",
      "Epoch 2: Total Loss=6.5731\n",
      "Epoch 3: Total Loss=6.4958\n",
      "Epoch 4: Total Loss=6.5681\n",
      "Epoch 5: Total Loss=6.4631\n",
      "Epoch 6: Total Loss=6.5689\n",
      "Epoch 7: Total Loss=6.5227\n",
      "Epoch 8: Total Loss=6.5123\n",
      "Epoch 9: Total Loss=6.5616\n",
      "Updated x: [-0.03054293990135193, 0.01156756840646267], Function Value: 0.001066679833456874, Gradient: [0.013825059868395329, -0.020659541711211205]\n",
      "\n",
      "Step 138/200\n",
      "Epoch 0: Total Loss=6.4706\n",
      "Epoch 1: Total Loss=6.4611\n",
      "Epoch 2: Total Loss=6.4983\n",
      "Epoch 3: Total Loss=6.4905\n",
      "Epoch 4: Total Loss=6.4593\n",
      "Epoch 5: Total Loss=6.5142\n",
      "Epoch 6: Total Loss=6.4976\n",
      "Epoch 7: Total Loss=6.4925\n",
      "Epoch 8: Total Loss=6.4511\n",
      "Epoch 9: Total Loss=6.5689\n",
      "Updated x: [-0.03235683962702751, -0.0003973469138145447], Function Value: 0.0010471228742972016, Gradient: [0.01538932602852583, -0.02067824825644493]\n",
      "\n",
      "Step 139/200\n",
      "Epoch 0: Total Loss=6.4562\n",
      "Epoch 1: Total Loss=6.5184\n",
      "Epoch 2: Total Loss=6.4996\n",
      "Epoch 3: Total Loss=6.4747\n",
      "Epoch 4: Total Loss=6.5318\n",
      "Epoch 5: Total Loss=6.5538\n",
      "Epoch 6: Total Loss=6.5620\n",
      "Epoch 7: Total Loss=6.4803\n",
      "Epoch 8: Total Loss=6.5379\n",
      "Epoch 9: Total Loss=6.6122\n",
      "Updated x: [-0.014840956777334213, -0.0038970117457211018], Function Value: 0.00023544068972114474, Gradient: [0.01442074216902256, -0.021278897300362587]\n",
      "\n",
      "Step 140/200\n",
      "Epoch 0: Total Loss=6.4646\n",
      "Epoch 1: Total Loss=6.4881\n",
      "Epoch 2: Total Loss=6.4381\n",
      "Epoch 3: Total Loss=6.4904\n",
      "Epoch 4: Total Loss=6.5355\n",
      "Epoch 5: Total Loss=6.5358\n",
      "Epoch 6: Total Loss=6.5273\n",
      "Epoch 7: Total Loss=6.5075\n",
      "Epoch 8: Total Loss=6.5002\n",
      "Epoch 9: Total Loss=6.5531\n",
      "Updated x: [-0.008493139408528805, -0.024200573563575745], Function Value: 0.0006578012253157794, Gradient: [0.012627454474568367, -0.020166868343949318]\n",
      "\n",
      "Step 141/200\n",
      "Epoch 0: Total Loss=6.5456\n",
      "Epoch 1: Total Loss=6.4603\n",
      "Epoch 2: Total Loss=6.5624\n",
      "Epoch 3: Total Loss=6.5365\n",
      "Epoch 4: Total Loss=6.5206\n",
      "Epoch 5: Total Loss=6.5221\n",
      "Epoch 6: Total Loss=6.5030\n",
      "Epoch 7: Total Loss=6.4728\n",
      "Epoch 8: Total Loss=6.4612\n",
      "Epoch 9: Total Loss=6.4677\n",
      "Updated x: [-0.03307321295142174, 0.03984560817480087], Function Value: 0.002681510057300329, Gradient: [0.01459142379462719, -0.02319668047130108]\n",
      "\n",
      "Step 142/200\n",
      "Epoch 0: Total Loss=8.1351\n",
      "Epoch 1: Total Loss=6.7114\n",
      "Epoch 2: Total Loss=6.8230\n",
      "Epoch 3: Total Loss=6.8559\n",
      "Epoch 4: Total Loss=6.8318\n",
      "Epoch 5: Total Loss=7.2339\n",
      "Epoch 6: Total Loss=7.1799\n",
      "Epoch 7: Total Loss=6.7806\n",
      "Epoch 8: Total Loss=7.0803\n",
      "Epoch 9: Total Loss=6.3432\n",
      "Updated x: [-0.0015885084867477417, 0.01716187410056591], Function Value: 0.00029705328051932156, Gradient: [0.013465155847370625, -0.014863473363220692]\n",
      "\n",
      "Step 143/200\n",
      "Epoch 0: Total Loss=6.9771\n",
      "Epoch 1: Total Loss=6.8452\n",
      "Epoch 2: Total Loss=6.7663\n",
      "Epoch 3: Total Loss=6.9326\n",
      "Epoch 4: Total Loss=7.1929\n",
      "Epoch 5: Total Loss=7.6013\n",
      "Epoch 6: Total Loss=7.2198\n",
      "Epoch 7: Total Loss=7.7932\n",
      "Epoch 8: Total Loss=7.9256\n",
      "Epoch 9: Total Loss=6.7706\n",
      "Updated x: [0.010609026066958904, -0.04127974063158035], Function Value: 0.0018165683140978217, Gradient: [0.021892784163355827, -0.01434094924479723]\n",
      "\n",
      "Step 144/200\n",
      "Epoch 0: Total Loss=7.0188\n",
      "Epoch 1: Total Loss=7.0832\n",
      "Epoch 2: Total Loss=6.7427\n",
      "Epoch 3: Total Loss=7.1150\n",
      "Epoch 4: Total Loss=6.7772\n",
      "Epoch 5: Total Loss=6.8889\n",
      "Epoch 6: Total Loss=7.2113\n",
      "Epoch 7: Total Loss=7.4841\n",
      "Epoch 8: Total Loss=6.6700\n",
      "Epoch 9: Total Loss=7.6376\n",
      "Updated x: [-0.0037846388295292854, -0.07353875041007996], Function Value: 0.005422270856797695, Gradient: [0.02568761631846428, -0.01246056891977787]\n",
      "\n",
      "Step 145/200\n",
      "Epoch 0: Total Loss=7.3749\n",
      "Epoch 1: Total Loss=6.7123\n",
      "Epoch 2: Total Loss=7.3579\n",
      "Epoch 3: Total Loss=6.6445\n",
      "Epoch 4: Total Loss=7.0759\n",
      "Epoch 5: Total Loss=6.7871\n",
      "Epoch 6: Total Loss=7.0429\n",
      "Epoch 7: Total Loss=6.6125\n",
      "Epoch 8: Total Loss=6.6849\n",
      "Epoch 9: Total Loss=6.6584\n",
      "Updated x: [-0.05425429344177246, -0.008843161165714264], Function Value: 0.003021729877218604, Gradient: [0.02061617560684681, -0.008855951018631458]\n",
      "\n",
      "Step 146/200\n",
      "Epoch 0: Total Loss=7.5829\n",
      "Epoch 1: Total Loss=6.8738\n",
      "Epoch 2: Total Loss=7.2335\n",
      "Epoch 3: Total Loss=6.9263\n",
      "Epoch 4: Total Loss=6.5691\n",
      "Epoch 5: Total Loss=6.9662\n",
      "Epoch 6: Total Loss=6.9267\n",
      "Epoch 7: Total Loss=7.1601\n",
      "Epoch 8: Total Loss=6.6449\n",
      "Epoch 9: Total Loss=6.9613\n",
      "Updated x: [0.008198942989110947, 0.03194098547101021], Function Value: 0.0010874491417780519, Gradient: [0.019296731799840927, -0.021258734166622162]\n",
      "\n",
      "Step 147/200\n",
      "Epoch 0: Total Loss=6.4920\n",
      "Epoch 1: Total Loss=6.7275\n",
      "Epoch 2: Total Loss=6.7892\n",
      "Epoch 3: Total Loss=6.5023\n",
      "Epoch 4: Total Loss=7.1782\n",
      "Epoch 5: Total Loss=8.0475\n",
      "Epoch 6: Total Loss=6.5414\n",
      "Epoch 7: Total Loss=6.8493\n",
      "Epoch 8: Total Loss=7.3249\n",
      "Epoch 9: Total Loss=7.0230\n",
      "Updated x: [0.013695361092686653, 0.032725878059864044], Function Value: 0.001258546020835638, Gradient: [0.01630486361682415, -0.01793459616601467]\n",
      "\n",
      "Step 148/200\n",
      "Epoch 0: Total Loss=6.6794\n",
      "Epoch 1: Total Loss=7.3189\n",
      "Epoch 2: Total Loss=6.9410\n",
      "Epoch 3: Total Loss=6.9419\n",
      "Epoch 4: Total Loss=7.0623\n",
      "Epoch 5: Total Loss=7.3261\n",
      "Epoch 6: Total Loss=6.6072\n",
      "Epoch 7: Total Loss=7.0549\n",
      "Epoch 8: Total Loss=6.3909\n",
      "Epoch 9: Total Loss=6.7537\n",
      "Updated x: [0.0015197591856122017, 0.017937732860445976], Function Value: 0.0003240719379391521, Gradient: [0.02049132250249386, -0.020683348178863525]\n",
      "\n",
      "Step 149/200\n",
      "Epoch 0: Total Loss=6.9753\n",
      "Epoch 1: Total Loss=7.0961\n",
      "Epoch 2: Total Loss=7.0753\n",
      "Epoch 3: Total Loss=6.5822\n",
      "Epoch 4: Total Loss=6.7655\n",
      "Epoch 5: Total Loss=6.7281\n",
      "Epoch 6: Total Loss=6.6722\n",
      "Epoch 7: Total Loss=6.9909\n",
      "Epoch 8: Total Loss=6.9758\n",
      "Epoch 9: Total Loss=7.4200\n",
      "Updated x: [-0.018409237265586853, -0.05100899934768677], Function Value: 0.002940818201750517, Gradient: [0.013202833011746407, -0.017721332609653473]\n",
      "\n",
      "Step 150/200\n",
      "Epoch 0: Total Loss=7.1334\n",
      "Epoch 1: Total Loss=6.8228\n",
      "Epoch 2: Total Loss=7.3807\n",
      "Epoch 3: Total Loss=6.8740\n",
      "Epoch 4: Total Loss=6.8318\n",
      "Epoch 5: Total Loss=6.6602\n",
      "Epoch 6: Total Loss=7.0547\n",
      "Epoch 7: Total Loss=6.6846\n",
      "Epoch 8: Total Loss=6.9460\n",
      "Epoch 9: Total Loss=7.0077\n",
      "Updated x: [0.011807793751358986, -0.05536898225545883], Function Value: 0.0032051480375230312, Gradient: [0.012955539859831333, -0.017486803233623505]\n",
      "\n",
      "Step 151/200\n",
      "Epoch 0: Total Loss=7.1275\n",
      "Epoch 1: Total Loss=7.4242\n",
      "Epoch 2: Total Loss=6.7290\n",
      "Epoch 3: Total Loss=6.5569\n",
      "Epoch 4: Total Loss=6.5394\n",
      "Epoch 5: Total Loss=6.7095\n",
      "Epoch 6: Total Loss=6.6436\n",
      "Epoch 7: Total Loss=6.8531\n",
      "Epoch 8: Total Loss=6.8142\n",
      "Epoch 9: Total Loss=7.3117\n",
      "Updated x: [0.0516086146235466, -0.016577325761318207], Function Value: 0.0029382568318396807, Gradient: [0.01274696085602045, -0.018217414617538452]\n",
      "\n",
      "Step 152/200\n",
      "Epoch 0: Total Loss=6.6491\n",
      "Epoch 1: Total Loss=6.6208\n",
      "Epoch 2: Total Loss=6.6960\n",
      "Epoch 3: Total Loss=6.7175\n",
      "Epoch 4: Total Loss=6.7226\n",
      "Epoch 5: Total Loss=6.6510\n",
      "Epoch 6: Total Loss=6.6367\n",
      "Epoch 7: Total Loss=6.5428\n",
      "Epoch 8: Total Loss=6.6452\n",
      "Epoch 9: Total Loss=6.9612\n",
      "Updated x: [0.02332913689315319, 0.038628336042165756], Function Value: 0.0020363968797028065, Gradient: [0.01369668822735548, -0.018087072297930717]\n",
      "\n",
      "Step 153/200\n",
      "Epoch 0: Total Loss=6.7232\n",
      "Epoch 1: Total Loss=6.6551\n",
      "Epoch 2: Total Loss=6.6941\n",
      "Epoch 3: Total Loss=6.7283\n",
      "Epoch 4: Total Loss=6.6662\n",
      "Epoch 5: Total Loss=6.8995\n",
      "Epoch 6: Total Loss=6.8647\n",
      "Epoch 7: Total Loss=6.6093\n",
      "Epoch 8: Total Loss=6.6267\n",
      "Epoch 9: Total Loss=6.6620\n",
      "Updated x: [0.006493302062153816, 0.00177672877907753], Function Value: 4.531973536359146e-05, Gradient: [0.017238421365618706, -0.016624372452497482]\n",
      "\n",
      "Step 154/200\n",
      "Epoch 0: Total Loss=6.5719\n",
      "Epoch 1: Total Loss=6.6274\n",
      "Epoch 2: Total Loss=6.7595\n",
      "Epoch 3: Total Loss=6.5985\n",
      "Epoch 4: Total Loss=6.6291\n",
      "Epoch 5: Total Loss=6.6745\n",
      "Epoch 6: Total Loss=6.6130\n",
      "Epoch 7: Total Loss=6.7537\n",
      "Epoch 8: Total Loss=6.6633\n",
      "Epoch 9: Total Loss=6.7991\n",
      "Updated x: [-0.04118330776691437, -0.004849165678024292], Function Value: 0.0017195792170241475, Gradient: [0.019014816731214523, -0.02091296575963497]\n",
      "\n",
      "Step 155/200\n",
      "Epoch 0: Total Loss=6.5574\n",
      "Epoch 1: Total Loss=6.7198\n",
      "Epoch 2: Total Loss=6.6494\n",
      "Epoch 3: Total Loss=6.6276\n",
      "Epoch 4: Total Loss=6.6016\n",
      "Epoch 5: Total Loss=6.8007\n",
      "Epoch 6: Total Loss=6.6518\n",
      "Epoch 7: Total Loss=6.7195\n",
      "Epoch 8: Total Loss=6.8736\n",
      "Epoch 9: Total Loss=6.6052\n",
      "Updated x: [0.006460696458816528, -0.038734305649995804], Function Value: 0.0015420870622619987, Gradient: [0.014633932150900364, -0.01983492635190487]\n",
      "\n",
      "Step 156/200\n",
      "Epoch 0: Total Loss=6.6173\n",
      "Epoch 1: Total Loss=6.7948\n",
      "Epoch 2: Total Loss=6.7030\n",
      "Epoch 3: Total Loss=6.5457\n",
      "Epoch 4: Total Loss=6.7510\n",
      "Epoch 5: Total Loss=6.7364\n",
      "Epoch 6: Total Loss=6.5303\n",
      "Epoch 7: Total Loss=6.6162\n",
      "Epoch 8: Total Loss=6.6943\n",
      "Epoch 9: Total Loss=6.8271\n",
      "Updated x: [0.007388911210000515, -0.03817776218056679], Function Value: 0.0015121374744921923, Gradient: [0.014771468937397003, -0.017572252079844475]\n",
      "\n",
      "Step 157/200\n",
      "Epoch 0: Total Loss=6.6856\n",
      "Epoch 1: Total Loss=6.5793\n",
      "Epoch 2: Total Loss=6.7062\n",
      "Epoch 3: Total Loss=6.4912\n",
      "Epoch 4: Total Loss=6.5986\n",
      "Epoch 5: Total Loss=6.8343\n",
      "Epoch 6: Total Loss=6.6977\n",
      "Epoch 7: Total Loss=6.7493\n",
      "Epoch 8: Total Loss=6.6133\n",
      "Epoch 9: Total Loss=6.5688\n",
      "Updated x: [0.04260748252272606, 0.03559168055653572], Function Value: 0.0030821652617305517, Gradient: [0.01291082613170147, -0.021118104457855225]\n",
      "\n",
      "Step 158/200\n",
      "Epoch 0: Total Loss=6.7089\n",
      "Epoch 1: Total Loss=6.8219\n",
      "Epoch 2: Total Loss=6.7590\n",
      "Epoch 3: Total Loss=6.6404\n",
      "Epoch 4: Total Loss=6.6866\n",
      "Epoch 5: Total Loss=6.7694\n",
      "Epoch 6: Total Loss=6.7385\n",
      "Epoch 7: Total Loss=6.6828\n",
      "Epoch 8: Total Loss=6.6668\n",
      "Epoch 9: Total Loss=6.6315\n",
      "Updated x: [0.034757502377033234, 0.021259963512420654], Function Value: 0.0016600699163973331, Gradient: [0.014993836171925068, -0.017893021926283836]\n",
      "\n",
      "Step 159/200\n",
      "Epoch 0: Total Loss=6.7299\n",
      "Epoch 1: Total Loss=6.6790\n",
      "Epoch 2: Total Loss=6.7418\n",
      "Epoch 3: Total Loss=6.8872\n",
      "Epoch 4: Total Loss=6.6472\n",
      "Epoch 5: Total Loss=6.7731\n",
      "Epoch 6: Total Loss=6.5281\n",
      "Epoch 7: Total Loss=6.6953\n",
      "Epoch 8: Total Loss=6.6853\n",
      "Epoch 9: Total Loss=6.7668\n",
      "Updated x: [0.03870274871587753, -0.013311844319105148], Function Value: 0.0016751079820096493, Gradient: [0.013826888985931873, -0.0156454686075449]\n",
      "\n",
      "Step 160/200\n",
      "Epoch 0: Total Loss=6.7924\n",
      "Epoch 1: Total Loss=6.7089\n",
      "Epoch 2: Total Loss=6.7114\n",
      "Epoch 3: Total Loss=6.6720\n",
      "Epoch 4: Total Loss=6.6534\n",
      "Epoch 5: Total Loss=6.6444\n",
      "Epoch 6: Total Loss=6.7210\n",
      "Epoch 7: Total Loss=6.7034\n",
      "Epoch 8: Total Loss=6.6089\n",
      "Epoch 9: Total Loss=6.5297\n",
      "Updated x: [0.0916920006275177, -0.07467438280582428], Function Value: 0.01398368738591671, Gradient: [0.008756755851209164, -0.01152168121188879]\n",
      "\n",
      "Step 161/200\n",
      "Epoch 0: Total Loss=6.6700\n",
      "Epoch 1: Total Loss=6.6792\n",
      "Epoch 2: Total Loss=6.6443\n",
      "Epoch 3: Total Loss=6.7529\n",
      "Epoch 4: Total Loss=6.7140\n",
      "Epoch 5: Total Loss=6.6466\n",
      "Epoch 6: Total Loss=6.6026\n",
      "Epoch 7: Total Loss=6.7220\n",
      "Epoch 8: Total Loss=6.6652\n",
      "Epoch 9: Total Loss=6.7080\n",
      "Updated x: [0.04226255789399147, -0.11224444210529327], Function Value: 0.014384938403964043, Gradient: [0.011732206679880619, -0.0110629266127944]\n",
      "\n",
      "Step 162/200\n",
      "Epoch 0: Total Loss=6.3362\n",
      "Epoch 1: Total Loss=6.3344\n",
      "Epoch 2: Total Loss=6.3249\n",
      "Epoch 3: Total Loss=6.3194\n",
      "Epoch 4: Total Loss=6.3253\n",
      "Epoch 5: Total Loss=6.3253\n",
      "Epoch 6: Total Loss=6.3416\n",
      "Epoch 7: Total Loss=6.3312\n",
      "Epoch 8: Total Loss=6.3476\n",
      "Epoch 9: Total Loss=6.3513\n",
      "Updated x: [0.006857659667730331, -0.025752872228622437], Function Value: 0.0007102378876879811, Gradient: [0.03181355074048042, -0.026590775698423386]\n",
      "\n",
      "Step 163/200\n",
      "Epoch 0: Total Loss=6.3693\n",
      "Epoch 1: Total Loss=6.3393\n",
      "Epoch 2: Total Loss=6.3189\n",
      "Epoch 3: Total Loss=6.3087\n",
      "Epoch 4: Total Loss=6.3201\n",
      "Epoch 5: Total Loss=6.3412\n",
      "Epoch 6: Total Loss=6.3394\n",
      "Epoch 7: Total Loss=6.3255\n",
      "Epoch 8: Total Loss=6.3349\n",
      "Epoch 9: Total Loss=6.3430\n",
      "Updated x: [0.03282994031906128, -0.007857212796807289], Function Value: 0.0011395406909286976, Gradient: [0.01813340000808239, -0.03017495572566986]\n",
      "\n",
      "Step 164/200\n",
      "Epoch 0: Total Loss=6.3590\n",
      "Epoch 1: Total Loss=6.3277\n",
      "Epoch 2: Total Loss=6.3177\n",
      "Epoch 3: Total Loss=6.3543\n",
      "Epoch 4: Total Loss=6.3404\n",
      "Epoch 5: Total Loss=6.3765\n",
      "Epoch 6: Total Loss=6.3191\n",
      "Epoch 7: Total Loss=6.3299\n",
      "Epoch 8: Total Loss=6.3554\n",
      "Epoch 9: Total Loss=6.3135\n",
      "Updated x: [0.019655734300613403, 0.06676896661520004], Function Value: 0.004844442941248417, Gradient: [0.020401639863848686, -0.026886286213994026]\n",
      "\n",
      "Step 165/200\n",
      "Epoch 0: Total Loss=6.3224\n",
      "Epoch 1: Total Loss=6.3162\n",
      "Epoch 2: Total Loss=6.3332\n",
      "Epoch 3: Total Loss=6.3438\n",
      "Epoch 4: Total Loss=6.3353\n",
      "Epoch 5: Total Loss=6.3198\n",
      "Epoch 6: Total Loss=6.3421\n",
      "Epoch 7: Total Loss=6.3284\n",
      "Epoch 8: Total Loss=6.3239\n",
      "Epoch 9: Total Loss=6.3136\n",
      "Updated x: [0.022220203652977943, -0.002872869372367859], Function Value: 0.0005019908421672881, Gradient: [0.01968533731997013, -0.01972397044301033]\n",
      "\n",
      "Step 166/200\n",
      "Epoch 0: Total Loss=6.3243\n",
      "Epoch 1: Total Loss=6.3242\n",
      "Epoch 2: Total Loss=6.3398\n",
      "Epoch 3: Total Loss=6.3238\n",
      "Epoch 4: Total Loss=6.3294\n",
      "Epoch 5: Total Loss=6.3378\n",
      "Epoch 6: Total Loss=6.3430\n",
      "Epoch 7: Total Loss=6.3276\n",
      "Epoch 8: Total Loss=6.3423\n",
      "Epoch 9: Total Loss=6.3440\n",
      "Updated x: [0.019369056448340416, -0.030287811532616615], Function Value: 0.0012925118207931519, Gradient: [0.017181970179080963, -0.022137977182865143]\n",
      "\n",
      "Step 167/200\n",
      "Epoch 0: Total Loss=6.3265\n",
      "Epoch 1: Total Loss=6.3124\n",
      "Epoch 2: Total Loss=6.3189\n",
      "Epoch 3: Total Loss=6.3162\n",
      "Epoch 4: Total Loss=6.3276\n",
      "Epoch 5: Total Loss=6.3141\n",
      "Epoch 6: Total Loss=6.3311\n",
      "Epoch 7: Total Loss=6.3119\n",
      "Epoch 8: Total Loss=6.3274\n",
      "Epoch 9: Total Loss=6.3147\n",
      "Updated x: [-0.0432150661945343, 0.08895499259233475], Function Value: 0.00978053268045187, Gradient: [0.022537466138601303, -0.023971257731318474]\n",
      "\n",
      "Step 168/200\n",
      "Epoch 0: Total Loss=6.3249\n",
      "Epoch 1: Total Loss=6.3228\n",
      "Epoch 2: Total Loss=6.3404\n",
      "Epoch 3: Total Loss=6.3373\n",
      "Epoch 4: Total Loss=6.3391\n",
      "Epoch 5: Total Loss=6.3143\n",
      "Epoch 6: Total Loss=6.3117\n",
      "Epoch 7: Total Loss=6.3340\n",
      "Epoch 8: Total Loss=6.3253\n",
      "Epoch 9: Total Loss=6.3430\n",
      "Updated x: [-0.03532176837325096, 0.04921332001686096], Function Value: 0.003669578116387129, Gradient: [0.021236153319478035, -0.020268891006708145]\n",
      "\n",
      "Step 169/200\n",
      "Epoch 0: Total Loss=6.3340\n",
      "Epoch 1: Total Loss=6.3033\n",
      "Epoch 2: Total Loss=6.3091\n",
      "Epoch 3: Total Loss=6.3312\n",
      "Epoch 4: Total Loss=6.3114\n",
      "Epoch 5: Total Loss=6.3294\n",
      "Epoch 6: Total Loss=6.3445\n",
      "Epoch 7: Total Loss=6.3442\n",
      "Epoch 8: Total Loss=6.3126\n",
      "Epoch 9: Total Loss=6.3280\n",
      "Updated x: [-0.02689265087246895, -0.04229673743247986], Function Value: 0.002512228675186634, Gradient: [0.016300566494464874, -0.019303053617477417]\n",
      "\n",
      "Step 170/200\n",
      "Epoch 0: Total Loss=6.3304\n",
      "Epoch 1: Total Loss=6.3420\n",
      "Epoch 2: Total Loss=6.3426\n",
      "Epoch 3: Total Loss=6.3362\n",
      "Epoch 4: Total Loss=6.3406\n",
      "Epoch 5: Total Loss=6.3370\n",
      "Epoch 6: Total Loss=6.3129\n",
      "Epoch 7: Total Loss=6.3369\n",
      "Epoch 8: Total Loss=6.3459\n",
      "Epoch 9: Total Loss=6.3524\n",
      "Updated x: [-0.011920575983822346, 0.0733799859881401], Function Value: 0.0055267224088311195, Gradient: [0.017489826306700706, -0.019261544570326805]\n",
      "\n",
      "Step 171/200\n",
      "Epoch 0: Total Loss=6.3509\n",
      "Epoch 1: Total Loss=6.3296\n",
      "Epoch 2: Total Loss=6.2884\n",
      "Epoch 3: Total Loss=6.3340\n",
      "Epoch 4: Total Loss=6.3392\n",
      "Epoch 5: Total Loss=6.3357\n",
      "Epoch 6: Total Loss=6.3260\n",
      "Epoch 7: Total Loss=6.3409\n",
      "Epoch 8: Total Loss=6.3384\n",
      "Epoch 9: Total Loss=6.3255\n",
      "Updated x: [0.003538193181157112, -0.020503006875514984], Function Value: 0.00043289209133945405, Gradient: [0.016398010775446892, -0.020425086840987206]\n",
      "\n",
      "Step 172/200\n",
      "Epoch 0: Total Loss=6.5069\n",
      "Epoch 1: Total Loss=6.8540\n",
      "Epoch 2: Total Loss=6.8596\n",
      "Epoch 3: Total Loss=6.9793\n",
      "Epoch 4: Total Loss=6.7079\n",
      "Epoch 5: Total Loss=6.7901\n",
      "Epoch 6: Total Loss=6.8956\n",
      "Epoch 7: Total Loss=6.6993\n",
      "Epoch 8: Total Loss=7.0160\n",
      "Epoch 9: Total Loss=7.1132\n",
      "Updated x: [0.0066125583834946156, -0.07379791140556335], Function Value: 0.005489857867360115, Gradient: [0.05452626198530197, 0.011180792935192585]\n",
      "\n",
      "Step 173/200\n",
      "Epoch 0: Total Loss=6.6620\n",
      "Epoch 1: Total Loss=6.8810\n",
      "Epoch 2: Total Loss=6.6687\n",
      "Epoch 3: Total Loss=6.8304\n",
      "Epoch 4: Total Loss=7.0498\n",
      "Epoch 5: Total Loss=6.9705\n",
      "Epoch 6: Total Loss=6.9857\n",
      "Epoch 7: Total Loss=6.6313\n",
      "Epoch 8: Total Loss=7.0633\n",
      "Epoch 9: Total Loss=6.9078\n",
      "Updated x: [0.030555546283721924, 0.007340088486671448], Function Value: 0.0009875183459371328, Gradient: [0.03215895593166351, -0.01031227596104145]\n",
      "\n",
      "Step 174/200\n",
      "Epoch 0: Total Loss=7.0212\n",
      "Epoch 1: Total Loss=6.6946\n",
      "Epoch 2: Total Loss=6.9280\n",
      "Epoch 3: Total Loss=6.6807\n",
      "Epoch 4: Total Loss=6.8964\n",
      "Epoch 5: Total Loss=6.8618\n",
      "Epoch 6: Total Loss=6.7501\n",
      "Epoch 7: Total Loss=7.0517\n",
      "Epoch 8: Total Loss=6.8323\n",
      "Epoch 9: Total Loss=6.6059\n",
      "Updated x: [-0.021597929298877716, 0.01734105497598648], Function Value: 0.0007671827333979309, Gradient: [0.026982050389051437, -0.015187669545412064]\n",
      "\n",
      "Step 175/200\n",
      "Epoch 0: Total Loss=6.7107\n",
      "Epoch 1: Total Loss=6.9512\n",
      "Epoch 2: Total Loss=6.5708\n",
      "Epoch 3: Total Loss=6.7028\n",
      "Epoch 4: Total Loss=7.0466\n",
      "Epoch 5: Total Loss=6.7944\n",
      "Epoch 6: Total Loss=6.8549\n",
      "Epoch 7: Total Loss=6.7672\n",
      "Epoch 8: Total Loss=7.0671\n",
      "Epoch 9: Total Loss=6.8289\n",
      "Updated x: [0.04990815371274948, 0.026986388489603996], Function Value: 0.0032190890051424503, Gradient: [0.01949544996023178, -0.018780484795570374]\n",
      "\n",
      "Step 176/200\n",
      "Epoch 0: Total Loss=6.9562\n",
      "Epoch 1: Total Loss=6.6499\n",
      "Epoch 2: Total Loss=6.7463\n",
      "Epoch 3: Total Loss=6.9222\n",
      "Epoch 4: Total Loss=6.6625\n",
      "Epoch 5: Total Loss=6.5777\n",
      "Epoch 6: Total Loss=6.7757\n",
      "Epoch 7: Total Loss=6.7073\n",
      "Epoch 8: Total Loss=7.0664\n",
      "Epoch 9: Total Loss=7.0113\n",
      "Updated x: [-0.0028437115252017975, 0.03325574845075607], Function Value: 0.001114031532779336, Gradient: [0.02202928066253662, -0.017603904008865356]\n",
      "\n",
      "Step 177/200\n",
      "Epoch 0: Total Loss=6.6868\n",
      "Epoch 1: Total Loss=6.8490\n",
      "Epoch 2: Total Loss=6.8283\n",
      "Epoch 3: Total Loss=6.7025\n",
      "Epoch 4: Total Loss=6.8018\n",
      "Epoch 5: Total Loss=6.9542\n",
      "Epoch 6: Total Loss=6.7038\n",
      "Epoch 7: Total Loss=6.7261\n",
      "Epoch 8: Total Loss=7.0381\n",
      "Epoch 9: Total Loss=6.9449\n",
      "Updated x: [-0.06065163388848305, 0.017193341627717018], Function Value: 0.003974231891334057, Gradient: [0.023176761344075203, -0.02171463333070278]\n",
      "\n",
      "Step 178/200\n",
      "Epoch 0: Total Loss=7.0650\n",
      "Epoch 1: Total Loss=6.8999\n",
      "Epoch 2: Total Loss=6.8432\n",
      "Epoch 3: Total Loss=6.7511\n",
      "Epoch 4: Total Loss=6.7698\n",
      "Epoch 5: Total Loss=6.7555\n",
      "Epoch 6: Total Loss=6.7620\n",
      "Epoch 7: Total Loss=6.8448\n",
      "Epoch 8: Total Loss=6.5417\n",
      "Epoch 9: Total Loss=6.7676\n",
      "Updated x: [-0.013558793812990189, 0.05310804396867752], Function Value: 0.003004305297508836, Gradient: [0.021675143390893936, -0.015039786696434021]\n",
      "\n",
      "Step 179/200\n",
      "Epoch 0: Total Loss=6.6159\n",
      "Epoch 1: Total Loss=6.7927\n",
      "Epoch 2: Total Loss=6.6963\n",
      "Epoch 3: Total Loss=6.7419\n",
      "Epoch 4: Total Loss=6.6365\n",
      "Epoch 5: Total Loss=6.6254\n",
      "Epoch 6: Total Loss=6.9467\n",
      "Epoch 7: Total Loss=6.8650\n",
      "Epoch 8: Total Loss=6.7190\n",
      "Epoch 9: Total Loss=6.7048\n",
      "Updated x: [0.0072470493614673615, 0.030474480241537094], Function Value: 0.0009812137577682734, Gradient: [0.019610371440649033, -0.015372476540505886]\n",
      "\n",
      "Step 180/200\n",
      "Epoch 0: Total Loss=6.7251\n",
      "Epoch 1: Total Loss=6.6960\n",
      "Epoch 2: Total Loss=6.6328\n",
      "Epoch 3: Total Loss=6.7998\n",
      "Epoch 4: Total Loss=6.8886\n",
      "Epoch 5: Total Loss=6.8134\n",
      "Epoch 6: Total Loss=6.9390\n",
      "Epoch 7: Total Loss=6.9138\n",
      "Epoch 8: Total Loss=6.8109\n",
      "Epoch 9: Total Loss=6.7335\n",
      "Updated x: [-0.04044776409864426, 0.0351790115237236], Function Value: 0.0028735846281051636, Gradient: [0.02071283757686615, -0.020014123991131783]\n",
      "\n",
      "Step 181/200\n",
      "Epoch 0: Total Loss=6.6035\n",
      "Epoch 1: Total Loss=6.6690\n",
      "Epoch 2: Total Loss=7.1279\n",
      "Epoch 3: Total Loss=6.4676\n",
      "Epoch 4: Total Loss=6.9668\n",
      "Epoch 5: Total Loss=6.7685\n",
      "Epoch 6: Total Loss=6.7004\n",
      "Epoch 7: Total Loss=6.6607\n",
      "Epoch 8: Total Loss=6.6201\n",
      "Epoch 9: Total Loss=6.7464\n",
      "Updated x: [-0.022114474326372147, 0.007487209513783455], Function Value: 0.0005451082834042609, Gradient: [0.01911906525492668, -0.019740642979741096]\n",
      "\n",
      "Step 182/200\n",
      "Epoch 0: Total Loss=6.4852\n",
      "Epoch 1: Total Loss=6.5168\n",
      "Epoch 2: Total Loss=6.5720\n",
      "Epoch 3: Total Loss=6.4985\n",
      "Epoch 4: Total Loss=6.4686\n",
      "Epoch 5: Total Loss=6.5120\n",
      "Epoch 6: Total Loss=6.5364\n",
      "Epoch 7: Total Loss=6.5432\n",
      "Epoch 8: Total Loss=6.5268\n",
      "Epoch 9: Total Loss=6.4160\n",
      "Updated x: [-0.016509948298335075, -0.017515601590275764], Function Value: 0.0005793747259303927, Gradient: [0.010250386781990528, -0.020262306556105614]\n",
      "\n",
      "Step 183/200\n",
      "Epoch 0: Total Loss=6.5160\n",
      "Epoch 1: Total Loss=6.4888\n",
      "Epoch 2: Total Loss=6.4512\n",
      "Epoch 3: Total Loss=6.5505\n",
      "Epoch 4: Total Loss=6.4904\n",
      "Epoch 5: Total Loss=6.4677\n",
      "Epoch 6: Total Loss=6.5168\n",
      "Epoch 7: Total Loss=6.4448\n",
      "Epoch 8: Total Loss=6.4579\n",
      "Epoch 9: Total Loss=6.5429\n",
      "Updated x: [0.0012649744749069214, 0.0014737248420715332], Function Value: 3.7720253658335423e-06, Gradient: [0.006691465154290199, -0.026332182809710503]\n",
      "\n",
      "Step 184/200\n",
      "Epoch 0: Total Loss=6.5195\n",
      "Epoch 1: Total Loss=6.3858\n",
      "Epoch 2: Total Loss=6.5193\n",
      "Epoch 3: Total Loss=6.4822\n",
      "Epoch 4: Total Loss=6.5504\n",
      "Epoch 5: Total Loss=6.5272\n",
      "Epoch 6: Total Loss=6.4983\n",
      "Epoch 7: Total Loss=6.4237\n",
      "Epoch 8: Total Loss=6.3986\n",
      "Epoch 9: Total Loss=6.4491\n",
      "Updated x: [0.01056059543043375, -0.02777615748345852], Function Value: 0.0008830410661175847, Gradient: [0.00897262617945671, -0.02526182495057583]\n",
      "\n",
      "Step 185/200\n",
      "Epoch 0: Total Loss=6.4719\n",
      "Epoch 1: Total Loss=6.4989\n",
      "Epoch 2: Total Loss=6.4075\n",
      "Epoch 3: Total Loss=6.5221\n",
      "Epoch 4: Total Loss=6.5535\n",
      "Epoch 5: Total Loss=6.4498\n",
      "Epoch 6: Total Loss=6.4317\n",
      "Epoch 7: Total Loss=6.4944\n",
      "Epoch 8: Total Loss=6.4717\n",
      "Epoch 9: Total Loss=6.4755\n",
      "Updated x: [-0.036503568291664124, 0.014015382155776024], Function Value: 0.0015289414441213012, Gradient: [0.017375465482473373, -0.020188063383102417]\n",
      "\n",
      "Step 186/200\n",
      "Epoch 0: Total Loss=6.4780\n",
      "Epoch 1: Total Loss=6.4880\n",
      "Epoch 2: Total Loss=6.4031\n",
      "Epoch 3: Total Loss=6.4103\n",
      "Epoch 4: Total Loss=6.5076\n",
      "Epoch 5: Total Loss=6.4458\n",
      "Epoch 6: Total Loss=6.5101\n",
      "Epoch 7: Total Loss=6.4271\n",
      "Epoch 8: Total Loss=6.3899\n",
      "Epoch 9: Total Loss=6.5546\n",
      "Updated x: [-0.008670153096318245, 0.001124715432524681], Function Value: 7.643653952982277e-05, Gradient: [0.014798146672546864, -0.01978924497961998]\n",
      "\n",
      "Step 187/200\n",
      "Epoch 0: Total Loss=6.5197\n",
      "Epoch 1: Total Loss=6.4474\n",
      "Epoch 2: Total Loss=6.5137\n",
      "Epoch 3: Total Loss=6.4942\n",
      "Epoch 4: Total Loss=6.4263\n",
      "Epoch 5: Total Loss=6.4923\n",
      "Epoch 6: Total Loss=6.5001\n",
      "Epoch 7: Total Loss=6.4474\n",
      "Epoch 8: Total Loss=6.4191\n",
      "Epoch 9: Total Loss=6.4236\n",
      "Updated x: [0.012030944228172302, 0.06172388046979904], Function Value: 0.00395458098500967, Gradient: [0.014685362577438354, -0.019142020493745804]\n",
      "\n",
      "Step 188/200\n",
      "Epoch 0: Total Loss=6.4588\n",
      "Epoch 1: Total Loss=6.4979\n",
      "Epoch 2: Total Loss=6.5036\n",
      "Epoch 3: Total Loss=6.5386\n",
      "Epoch 4: Total Loss=6.4491\n",
      "Epoch 5: Total Loss=6.4786\n",
      "Epoch 6: Total Loss=6.4431\n",
      "Epoch 7: Total Loss=6.4398\n",
      "Epoch 8: Total Loss=6.5352\n",
      "Epoch 9: Total Loss=6.4818\n",
      "Updated x: [0.005203929264098406, -0.059406787157058716], Function Value: 0.003556247102096677, Gradient: [0.016763728111982346, -0.015373185276985168]\n",
      "\n",
      "Step 189/200\n",
      "Epoch 0: Total Loss=6.4415\n",
      "Epoch 1: Total Loss=6.5285\n",
      "Epoch 2: Total Loss=6.4757\n",
      "Epoch 3: Total Loss=6.5114\n",
      "Epoch 4: Total Loss=6.4621\n",
      "Epoch 5: Total Loss=6.4943\n",
      "Epoch 6: Total Loss=6.5146\n",
      "Epoch 7: Total Loss=6.4917\n",
      "Epoch 8: Total Loss=6.5384\n",
      "Epoch 9: Total Loss=6.4483\n",
      "Updated x: [0.03059464879333973, 0.0020573213696479797], Function Value: 0.0009402650757692754, Gradient: [0.015821652486920357, -0.021842489019036293]\n",
      "\n",
      "Step 190/200\n",
      "Epoch 0: Total Loss=6.4070\n",
      "Epoch 1: Total Loss=6.5197\n",
      "Epoch 2: Total Loss=6.4348\n",
      "Epoch 3: Total Loss=6.5430\n",
      "Epoch 4: Total Loss=6.5242\n",
      "Epoch 5: Total Loss=6.4976\n",
      "Epoch 6: Total Loss=6.4835\n",
      "Epoch 7: Total Loss=6.5431\n",
      "Epoch 8: Total Loss=6.4138\n",
      "Epoch 9: Total Loss=6.5340\n",
      "Updated x: [0.006885139271616936, 0.0021812026388943195], Function Value: 5.21627880516462e-05, Gradient: [0.018503332510590553, -0.020680474117398262]\n",
      "\n",
      "Step 191/200\n",
      "Epoch 0: Total Loss=6.4655\n",
      "Epoch 1: Total Loss=6.5216\n",
      "Epoch 2: Total Loss=6.4343\n",
      "Epoch 3: Total Loss=6.4912\n",
      "Epoch 4: Total Loss=6.4341\n",
      "Epoch 5: Total Loss=6.4429\n",
      "Epoch 6: Total Loss=6.4535\n",
      "Epoch 7: Total Loss=6.4670\n",
      "Epoch 8: Total Loss=6.4854\n",
      "Epoch 9: Total Loss=6.3918\n",
      "Updated x: [-0.008014354854822159, -0.02016512118279934], Function Value: 0.0004708619962912053, Gradient: [0.01745069958269596, -0.0201185941696167]\n",
      "\n",
      "Step 192/200\n",
      "Epoch 0: Total Loss=6.5483\n",
      "Epoch 1: Total Loss=7.1164\n",
      "Epoch 2: Total Loss=7.5470\n",
      "Epoch 3: Total Loss=6.7614\n",
      "Epoch 4: Total Loss=6.3872\n",
      "Epoch 5: Total Loss=7.1417\n",
      "Epoch 6: Total Loss=6.6078\n",
      "Epoch 7: Total Loss=6.4568\n",
      "Epoch 8: Total Loss=6.2327\n",
      "Epoch 9: Total Loss=6.5364\n",
      "Updated x: [0.02806057035923004, 0.039398446679115295], Function Value: 0.0023396331816911697, Gradient: [0.0059417905285954475, -0.03974075987935066]\n",
      "\n",
      "Step 193/200\n",
      "Epoch 0: Total Loss=6.3688\n",
      "Epoch 1: Total Loss=6.6099\n",
      "Epoch 2: Total Loss=6.3680\n",
      "Epoch 3: Total Loss=7.1463\n",
      "Epoch 4: Total Loss=7.6908\n",
      "Epoch 5: Total Loss=6.7031\n",
      "Epoch 6: Total Loss=7.9312\n",
      "Epoch 7: Total Loss=6.7952\n",
      "Epoch 8: Total Loss=7.0372\n",
      "Epoch 9: Total Loss=6.8007\n",
      "Updated x: [-0.010499279946088791, 0.03887973725795746], Function Value: 0.0016218688106164336, Gradient: [0.011666085571050644, -0.03372132405638695]\n",
      "\n",
      "Step 194/200\n",
      "Epoch 0: Total Loss=6.5735\n",
      "Epoch 1: Total Loss=7.4010\n",
      "Epoch 2: Total Loss=8.1615\n",
      "Epoch 3: Total Loss=10.0590\n",
      "Epoch 4: Total Loss=7.3484\n",
      "Epoch 5: Total Loss=6.3062\n",
      "Epoch 6: Total Loss=6.6523\n",
      "Epoch 7: Total Loss=7.8716\n",
      "Epoch 8: Total Loss=6.8909\n",
      "Epoch 9: Total Loss=6.4711\n",
      "Updated x: [-0.014897461980581284, -0.033915095031261444], Function Value: 0.0013721680734306574, Gradient: [0.01674453355371952, -0.01421613059937954]\n",
      "\n",
      "Step 195/200\n",
      "Epoch 0: Total Loss=6.4782\n",
      "Epoch 1: Total Loss=7.7053\n",
      "Epoch 2: Total Loss=6.8120\n",
      "Epoch 3: Total Loss=7.0905\n",
      "Epoch 4: Total Loss=6.7628\n",
      "Epoch 5: Total Loss=6.8750\n",
      "Epoch 6: Total Loss=7.0952\n",
      "Epoch 7: Total Loss=6.9205\n",
      "Epoch 8: Total Loss=8.0097\n",
      "Epoch 9: Total Loss=7.5865\n",
      "Updated x: [0.04405798763036728, -0.009907515719532967], Function Value: 0.0020392651204019785, Gradient: [0.004544674884527922, -0.016909312456846237]\n",
      "\n",
      "Step 196/200\n",
      "Epoch 0: Total Loss=6.2574\n",
      "Epoch 1: Total Loss=7.3244\n",
      "Epoch 2: Total Loss=6.2430\n",
      "Epoch 3: Total Loss=6.4089\n",
      "Epoch 4: Total Loss=7.5245\n",
      "Epoch 5: Total Loss=6.4448\n",
      "Epoch 6: Total Loss=8.1291\n",
      "Epoch 7: Total Loss=8.2991\n",
      "Epoch 8: Total Loss=6.7758\n",
      "Epoch 9: Total Loss=8.1516\n",
      "Updated x: [0.03766803815960884, 0.0744047611951828], Function Value: 0.00695494981482625, Gradient: [0.014021290466189384, -0.02791866473853588]\n",
      "\n",
      "Step 197/200\n",
      "Epoch 0: Total Loss=6.2355\n",
      "Epoch 1: Total Loss=6.2284\n",
      "Epoch 2: Total Loss=6.7652\n",
      "Epoch 3: Total Loss=6.3940\n",
      "Epoch 4: Total Loss=6.5578\n",
      "Epoch 5: Total Loss=7.2128\n",
      "Epoch 6: Total Loss=7.5234\n",
      "Epoch 7: Total Loss=7.3210\n",
      "Epoch 8: Total Loss=7.1904\n",
      "Epoch 9: Total Loss=6.2238\n",
      "Updated x: [-0.011246316134929657, -0.02230984717607498], Function Value: 0.0006242089439183474, Gradient: [0.01280977949500084, -0.01971127651631832]\n",
      "\n",
      "Step 198/200\n",
      "Epoch 0: Total Loss=6.3064\n",
      "Epoch 1: Total Loss=6.2401\n",
      "Epoch 2: Total Loss=6.7968\n",
      "Epoch 3: Total Loss=8.2132\n",
      "Epoch 4: Total Loss=6.3438\n",
      "Epoch 5: Total Loss=6.5358\n",
      "Epoch 6: Total Loss=6.8146\n",
      "Epoch 7: Total Loss=7.1223\n",
      "Epoch 8: Total Loss=8.3702\n",
      "Epoch 9: Total Loss=6.3603\n",
      "Updated x: [-0.009470326825976372, -0.029626965522766113], Function Value: 0.0009674441535025835, Gradient: [0.01706015318632126, -0.014462701044976711]\n",
      "\n",
      "Step 199/200\n",
      "Epoch 0: Total Loss=6.8458\n",
      "Epoch 1: Total Loss=6.9800\n",
      "Epoch 2: Total Loss=6.6074\n",
      "Epoch 3: Total Loss=6.3531\n",
      "Epoch 4: Total Loss=7.5574\n",
      "Epoch 5: Total Loss=7.0358\n",
      "Epoch 6: Total Loss=7.8834\n",
      "Epoch 7: Total Loss=6.6844\n",
      "Epoch 8: Total Loss=6.5579\n",
      "Epoch 9: Total Loss=6.7019\n",
      "Updated x: [-0.046781495213508606, -0.010027913376688957], Function Value: 0.0022890674881637096, Gradient: [0.0156420785933733, -0.020596640184521675]\n",
      "\n",
      "Step 200/200\n",
      "Epoch 0: Total Loss=7.5302\n",
      "Epoch 1: Total Loss=7.3811\n",
      "Epoch 2: Total Loss=6.5579\n",
      "Epoch 3: Total Loss=6.7810\n",
      "Epoch 4: Total Loss=8.3252\n",
      "Epoch 5: Total Loss=7.4116\n",
      "Epoch 6: Total Loss=7.6577\n",
      "Epoch 7: Total Loss=6.4734\n",
      "Epoch 8: Total Loss=6.4179\n",
      "Epoch 9: Total Loss=7.2227\n",
      "Updated x: [-0.022891635075211525, -0.023264368996024132], Function Value: 0.0010652578203007579, Gradient: [0.008352969773113728, -0.02534213662147522]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define the number of optimization steps\n",
    "optim_steps = 200\n",
    "\n",
    "# Define the range of N_s values\n",
    "N_s_values = np.arange(1, 11,3)  # N_s from 1 to 10\n",
    "\n",
    "# Define dataset\n",
    "dataset = data  # Using only the standard dataset\n",
    "\n",
    "# Dictionary to store results\n",
    "results = {}\n",
    "\n",
    "# Loop over N_s values\n",
    "for N_s in N_s_values:\n",
    "    old_dataset = OldDataSet(dataset, k=10)\n",
    "    new_dataset = NewDataSet(k=10)\n",
    "    model = MLP(2, [5, 5, 5], 1)  # Standard network size\n",
    "\n",
    "    # Set an out-of-distribution starting point\n",
    "    x_start = torch.tensor([10, -10], dtype=torch.float32, requires_grad=True)\n",
    "\n",
    "    # Run optimization\n",
    "    _, y_path = optimize_surrogate_model(\n",
    "        model, old_dataset, new_dataset, assSim, \n",
    "        optim_steps=optim_steps, N_s=N_s, lr=0.001, merge_interval=10, x_init=x_start\n",
    "    )\n",
    "\n",
    "    # Store results\n",
    "    results[N_s] = y_path\n",
    "\n",
    "# Plot the results\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "for N_s in N_s_values:\n",
    "    plt.plot(range(optim_steps), results[N_s], label=f\"N_s = {N_s}\")\n",
    "\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.ylabel(\"Objective y\")\n",
    "plt.title(\"Effect of N_s on Optimization with Out-of-Distribution Start (10,10)\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
