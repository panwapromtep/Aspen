{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c7deb0aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added to sys.path: /Users/panwapromtep/Library/CloudStorage/OneDrive-JohnsHopkins/Process Design/Aspen\n",
      "/Users/panwapromtep/Library/CloudStorage/OneDrive-JohnsHopkins/Process Design/Aspen\n",
      "['/Users/panwapromtep/miniforge3/envs/torch/lib/python312.zip', '/Users/panwapromtep/miniforge3/envs/torch/lib/python3.12', '/Users/panwapromtep/miniforge3/envs/torch/lib/python3.12/lib-dynload', '', '/Users/panwapromtep/miniforge3/envs/torch/lib/python3.12/site-packages', '/Users/panwapromtep/Library/CloudStorage/OneDrive-JohnsHopkins/Process Design/Aspen', '/Users/panwapromtep/Library/CloudStorage/OneDrive-JohnsHopkins/Process Design/Aspen', '/Users/panwapromtep/Library/CloudStorage/OneDrive-JohnsHopkins/Process Design/Aspen']\n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "\n",
    "# Get the absolute path of the notebook's directory\n",
    "notebook_dir = os.getcwd()\n",
    "\n",
    "# Navigate to the parent directory\n",
    "parent_dir = os.path.abspath(os.path.join(notebook_dir, \"../..\"))\n",
    "\n",
    "# Add the parent directory to sys.path so we can import modules\n",
    "sys.path.append(parent_dir)\n",
    "\n",
    "# Verify the path\n",
    "print(f\"Added to sys.path: {parent_dir}\")\n",
    "\n",
    "# Add it to sys.path\n",
    "sys.path.append(parent_dir)\n",
    "\n",
    "print(parent_dir)\n",
    "from localityaware.module import *\n",
    "from NSGA_nn.nsga import *\n",
    "from FlashOperation.Refrig2DrumHeatExConstrDummy import Refrig2DrumConstraintHeatExConstDummy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "88a7feed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c912a96c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating new data...\n",
      "⚠️  Dummy Mode: Rosenbrock function in place of AspenSim.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "import time\n",
    "\n",
    "# Define the file path for saving/loading the data\n",
    "data_file = \"flash_simulation_data_sim_new.pkl\"\n",
    "\n",
    "# Define parameter ranges\n",
    "flash_1_range_sim = np.linspace(-15, 15, 10)\n",
    "flash_2_range_sim = np.linspace(-15, 15, 10)\n",
    "\n",
    "print(\"Generating new data...\")\n",
    "assSim = Refrig2DrumConstraintHeatExConstDummy(AspenFile=\"../FlashOperation/FlashOperation_HeatExchanger.bkp\",\n",
    "                                        wdpath=\"../FlashOperation\",\n",
    "                                        visibility=False,\n",
    "                                        Penalty=1e3)\n",
    "\n",
    "start_time = time.time()  # Start timing\n",
    "data_sim = []\n",
    "for flash_1 in flash_1_range_sim:\n",
    "    for flash_2 in flash_2_range_sim:\n",
    "        x_unflat = assSim.unflatten_params([float(flash_1), float(flash_2)])\n",
    "        data_sim.append([flash_1, flash_2, assSim.run_obj(x_unflat)])\n",
    "\n",
    "data_sim = np.array(data_sim)\n",
    "data_gen_time = time.time() - start_time  # Total time to generate data\n",
    "total_original_assSim_calls = len(data_sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "868f2e5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min max y: 123.90123456790182 5760256.0\n"
     ]
    }
   ],
   "source": [
    "miny = np.min(data_sim[:, 2])\n",
    "maxy = np.max(data_sim[:, 2])\n",
    "print(\"min max y:\", miny, maxy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fdeb824e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "scaler = TorchMinMaxScaler((-1, 1), \n",
    "                           max_vals=[15.0, 15.0],\n",
    "                           min_vals=[-15.0, -15.0],\n",
    "                           min_y=0,\n",
    "                           max_y=1e7 ,\n",
    "                           scale_y=True)\n",
    "#scale data_sim \n",
    "data_sim_xscaled, data_sim_yscaled = scaler.transform(data_sim[:, :2], data_sim[:, 2])\n",
    "\n",
    "#recombine the data\n",
    "data_sim_scaled = np.column_stack([data_sim_xscaled, data_sim_yscaled])\n",
    "\n",
    "# **Initialize Model & Datasets**\n",
    "dataset = DynamicDataset(data_sim_scaled)\n",
    "model = MLP(2, [20,20, 20, 20], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "da9f664c",
   "metadata": {},
   "outputs": [],
   "source": [
    "problem = FlashOpProblemNN(model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d1b755c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0: Training surrogate model...\n",
      "=================================================\n",
      "n_gen  |  n_eval  |     f_avg     |     f_min    \n",
      "=================================================\n",
      "     1 |     1000 | -7.928882E-01 | -1.039387E+00\n",
      "     2 |     2000 | -1.008169E+00 | -1.039387E+00\n",
      "     3 |     3000 | -1.023396E+00 | -1.039387E+00\n",
      "     4 |     4000 | -1.030457E+00 | -1.039387E+00\n",
      "     5 |     5000 | -1.034810E+00 | -1.039535E+00\n",
      "     6 |     6000 | -1.037462E+00 | -1.039539E+00\n",
      "     7 |     7000 | -1.038626E+00 | -1.039539E+00\n",
      "     8 |     8000 | -1.039069E+00 | -1.039540E+00\n",
      "     9 |     9000 | -1.039267E+00 | -1.039541E+00\n",
      "    10 |    10000 | -1.039383E+00 | -1.039541E+00\n",
      "    11 |    11000 | -1.039448E+00 | -1.039541E+00\n",
      "    12 |    12000 | -1.039485E+00 | -1.039541E+00\n",
      "    13 |    13000 | -1.039506E+00 | -1.039541E+00\n",
      "    14 |    14000 | -1.039520E+00 | -1.039541E+00\n",
      "    15 |    15000 | -1.039528E+00 | -1.039541E+00\n",
      "    16 |    16000 | -1.039532E+00 | -1.039541E+00\n",
      "    17 |    17000 | -1.039535E+00 | -1.039541E+00\n",
      "    18 |    18000 | -1.039537E+00 | -1.039541E+00\n",
      "    19 |    19000 | -1.039539E+00 | -1.039541E+00\n",
      "    20 |    20000 | -1.039540E+00 | -1.039541E+00\n",
      "Iteration 0: Optimal input [ -0.4873314 -12.181346 ], output 15424.965443768133, dataset size (121, 3)\n",
      "Iteration 1: Training surrogate model...\n",
      "Using previous population of size 1000\n",
      "=================================================\n",
      "n_gen  |  n_eval  |     f_avg     |     f_min    \n",
      "=================================================\n",
      "     1 |     1000 | -7.944352E-01 | -1.015369E+00\n",
      "     2 |     2000 | -9.940454E-01 | -1.015388E+00\n",
      "     3 |     3000 | -1.003710E+00 | -1.015388E+00\n",
      "     4 |     4000 | -1.009835E+00 | -1.015447E+00\n",
      "     5 |     5000 | -1.013022E+00 | -1.015447E+00\n",
      "     6 |     6000 | -1.014318E+00 | -1.015447E+00\n",
      "     7 |     7000 | -1.014893E+00 | -1.015447E+00\n",
      "     8 |     8000 | -1.015145E+00 | -1.015447E+00\n",
      "     9 |     9000 | -1.015278E+00 | -1.015447E+00\n",
      "    10 |    10000 | -1.015349E+00 | -1.015447E+00\n",
      "    11 |    11000 | -1.015390E+00 | -1.015447E+00\n",
      "    12 |    12000 | -1.015413E+00 | -1.015447E+00\n",
      "    13 |    13000 | -1.015426E+00 | -1.015447E+00\n",
      "    14 |    14000 | -1.015434E+00 | -1.015447E+00\n",
      "    15 |    15000 | -1.015439E+00 | -1.015447E+00\n",
      "    16 |    16000 | -1.015441E+00 | -1.015447E+00\n",
      "    17 |    17000 | -1.015443E+00 | -1.015447E+00\n",
      "    18 |    18000 | -1.015445E+00 | -1.015447E+00\n",
      "    19 |    19000 | -1.015445E+00 | -1.015447E+00\n",
      "    20 |    20000 | -1.015446E+00 | -1.015447E+00\n",
      "Iteration 1: Optimal input [ 3.635624 10.482367], output 755.1849913733574, dataset size (142, 3)\n",
      "Iteration 2: Training surrogate model...\n",
      "Using previous population of size 1000\n",
      "=================================================\n",
      "n_gen  |  n_eval  |     f_avg     |     f_min    \n",
      "=================================================\n",
      "     1 |     1000 | -7.956204E-01 | -1.003185E+00\n",
      "     2 |     2000 | -9.934850E-01 | -1.003185E+00\n",
      "     3 |     3000 | -1.000346E+00 | -1.003201E+00\n",
      "     4 |     4000 | -1.002084E+00 | -1.003216E+00\n",
      "     5 |     5000 | -1.002559E+00 | -1.003216E+00\n",
      "     6 |     6000 | -1.002778E+00 | -1.003216E+00\n",
      "     7 |     7000 | -1.002965E+00 | -1.003216E+00\n",
      "     8 |     8000 | -1.003079E+00 | -1.003216E+00\n",
      "     9 |     9000 | -1.003141E+00 | -1.003216E+00\n",
      "    10 |    10000 | -1.003175E+00 | -1.003216E+00\n",
      "    11 |    11000 | -1.003192E+00 | -1.003217E+00\n",
      "    12 |    12000 | -1.003202E+00 | -1.003217E+00\n",
      "    13 |    13000 | -1.003208E+00 | -1.003217E+00\n",
      "    14 |    14000 | -1.003211E+00 | -1.003217E+00\n",
      "    15 |    15000 | -1.003213E+00 | -1.003217E+00\n",
      "    16 |    16000 | -1.003215E+00 | -1.003217E+00\n",
      "    17 |    17000 | -1.003215E+00 | -1.003217E+00\n",
      "    18 |    18000 | -1.003216E+00 | -1.003217E+00\n",
      "    19 |    19000 | -1.003216E+00 | -1.003217E+00\n",
      "    20 |    20000 | -1.003216E+00 | -1.003217E+00\n",
      "Iteration 2: Optimal input [2.4806423 5.7988777], output 14.774120582083004, dataset size (163, 3)\n",
      "Iteration 3: Training surrogate model...\n",
      "Using previous population of size 1000\n",
      "=================================================\n",
      "n_gen  |  n_eval  |     f_avg     |     f_min    \n",
      "=================================================\n",
      "     1 |     1000 | -7.945868E-01 | -1.002391E+00\n",
      "     2 |     2000 | -9.942582E-01 | -1.002393E+00\n",
      "     3 |     3000 | -1.000129E+00 | -1.002400E+00\n",
      "     4 |     4000 | -1.001524E+00 | -1.002401E+00\n",
      "     5 |     5000 | -1.002027E+00 | -1.002413E+00\n",
      "     6 |     6000 | -1.002229E+00 | -1.002413E+00\n",
      "     7 |     7000 | -1.002318E+00 | -1.002413E+00\n",
      "     8 |     8000 | -1.002362E+00 | -1.002414E+00\n",
      "     9 |     9000 | -1.002385E+00 | -1.002414E+00\n",
      "    10 |    10000 | -1.002397E+00 | -1.002414E+00\n",
      "    11 |    11000 | -1.002404E+00 | -1.002414E+00\n",
      "    12 |    12000 | -1.002408E+00 | -1.002414E+00\n",
      "    13 |    13000 | -1.002410E+00 | -1.002414E+00\n",
      "    14 |    14000 | -1.002411E+00 | -1.002414E+00\n",
      "    15 |    15000 | -1.002412E+00 | -1.002414E+00\n",
      "    16 |    16000 | -1.002413E+00 | -1.002414E+00\n",
      "    17 |    17000 | -1.002413E+00 | -1.002414E+00\n",
      "    18 |    18000 | -1.002413E+00 | -1.002414E+00\n",
      "    19 |    19000 | -1.002413E+00 | -1.002414E+00\n",
      "    20 |    20000 | -1.002413E+00 | -1.002414E+00\n",
      "Iteration 3: Optimal input [ 1.162756  -3.0327759], output 1922.6537004275015, dataset size (184, 3)\n",
      "Iteration 4: Training surrogate model...\n",
      "Using previous population of size 1000\n",
      "=================================================\n",
      "n_gen  |  n_eval  |     f_avg     |     f_min    \n",
      "=================================================\n",
      "     1 |     1000 | -7.958263E-01 | -1.001215E+00\n",
      "     2 |     2000 | -9.931580E-01 | -1.001233E+00\n",
      "     3 |     3000 | -9.990222E-01 | -1.001396E+00\n",
      "     4 |     4000 | -1.000322E+00 | -1.001396E+00\n",
      "     5 |     5000 | -1.000815E+00 | -1.001433E+00\n",
      "     6 |     6000 | -1.001041E+00 | -1.001445E+00\n",
      "     7 |     7000 | -1.001161E+00 | -1.001523E+00\n",
      "     8 |     8000 | -1.001219E+00 | -1.001523E+00\n",
      "     9 |     9000 | -1.001254E+00 | -1.001524E+00\n",
      "    10 |    10000 | -1.001274E+00 | -1.001526E+00\n",
      "    11 |    11000 | -1.001290E+00 | -1.001539E+00\n",
      "    12 |    12000 | -1.001310E+00 | -1.001539E+00\n",
      "    13 |    13000 | -1.001334E+00 | -1.001539E+00\n",
      "    14 |    14000 | -1.001373E+00 | -1.001539E+00\n",
      "    15 |    15000 | -1.001437E+00 | -1.001539E+00\n",
      "    16 |    16000 | -1.001488E+00 | -1.001541E+00\n",
      "    17 |    17000 | -1.001512E+00 | -1.001541E+00\n",
      "    18 |    18000 | -1.001525E+00 | -1.001541E+00\n",
      "    19 |    19000 | -1.001531E+00 | -1.001541E+00\n",
      "    20 |    20000 | -1.001535E+00 | -1.001541E+00\n",
      "Iteration 4: Optimal input [ 3.6781921 14.999992 ], output 223.52591194293234, dataset size (205, 3)\n",
      "Iteration 5: Training surrogate model...\n",
      "Using previous population of size 1000\n",
      "=================================================\n",
      "n_gen  |  n_eval  |     f_avg     |     f_min    \n",
      "=================================================\n",
      "     1 |     1000 | -7.946690E-01 | -1.001203E+00\n",
      "     2 |     2000 | -9.942618E-01 | -1.001292E+00\n",
      "     3 |     3000 | -9.991748E-01 | -1.001293E+00\n",
      "     4 |     4000 | -1.000385E+00 | -1.001318E+00\n",
      "     5 |     5000 | -1.000887E+00 | -1.001320E+00\n",
      "     6 |     6000 | -1.001131E+00 | -1.001320E+00\n",
      "     7 |     7000 | -1.001226E+00 | -1.001320E+00\n",
      "     8 |     8000 | -1.001268E+00 | -1.001320E+00\n",
      "     9 |     9000 | -1.001289E+00 | -1.001320E+00\n",
      "    10 |    10000 | -1.001301E+00 | -1.001320E+00\n",
      "    11 |    11000 | -1.001309E+00 | -1.001320E+00\n",
      "    12 |    12000 | -1.001314E+00 | -1.001320E+00\n",
      "    13 |    13000 | -1.001316E+00 | -1.001320E+00\n",
      "    14 |    14000 | -1.001317E+00 | -1.001320E+00\n",
      "    15 |    15000 | -1.001318E+00 | -1.001320E+00\n",
      "    16 |    16000 | -1.001319E+00 | -1.001320E+00\n",
      "    17 |    17000 | -1.001319E+00 | -1.001320E+00\n",
      "    18 |    18000 | -1.001319E+00 | -1.001320E+00\n",
      "    19 |    19000 | -1.001320E+00 | -1.001320E+00\n",
      "    20 |    20000 | -1.001320E+00 | -1.001320E+00\n",
      "Iteration 5: Optimal input [1.4154835 3.7973938], output 321.9445894791287, dataset size (226, 3)\n"
     ]
    }
   ],
   "source": [
    "out = optimize_surr_ga(model=model,\n",
    "                   dataset=dataset,\n",
    "                   assSim=assSim,\n",
    "                   problem=problem,\n",
    "                   lrs={'first':1e-4, 'others':1e-4},\n",
    "                   epochs={'first':3000, 'others':600},\n",
    "                   min_vals=scaler.min_x,\n",
    "                   max_vals=scaler.max_x,\n",
    "                   scaler=scaler,\n",
    "                   device='cpu',\n",
    "                   iter=6,\n",
    "                   print_loss=False,\n",
    "                   print_it_data=True,\n",
    "                   pop_size=1000,\n",
    "                   n_gen = 20,\n",
    "                   new_data_size=20,\n",
    "                   batch_size=128\n",
    "                   )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
